---
editor: 
  markdown: 
    wrap: 72
number-depth: 3
code-annotations: hover
---

# Geospatial investigation {#sec-geospatial-cleaning}

An important part of observational data is the location, specifying
where each observation of an organism or species took place. These
locations can range from locality descriptions (e.g. “Near Tellera Hill
station”) to exact longitude and latitude coordinates tracked by a GPS
system. The accuracy of these geospatial data will determine the types
of ecological analyses you can perform. It is important to know the
precision of these observations, along with the range of uncertainty
around an observation’s location, to contextualize any findings or
conclusions made using the data.

In this chapter, we will discuss some different ways to assess the
precision and uncertainty of coordinates associated with occurrence
records, and highlight how to identify spatial characteristics or errors
when visualizing occurrences on maps.

### Prerequisites

In this chapter we'll use data of *Banksia serrata* occurrence records
since 2022 and quokka occurrence records from the ALA.

```{r prereq-internal}
#| echo: false
#| warning: false
#| message: false
# packages
library(galah)
library(ggplot2)
library(dplyr)
library(sf)
library(ozmaps)
library(tidyr)
library(stringr)
galah_config(email = Sys.getenv("ALA_EMAIL"),
             verbose = FALSE)

# get DOIs for chapter
doi_table <- here::here("data", "galah-dois", "doi_table") |>
  arrow::open_dataset() |>
  filter(chapter == "Geospatial investigation") |>
  collect()

# extract dois
doi_banksia <- doi_table |> filter(name == "banksia") |> pull(doi)
doi_quokkas <- doi_table |> filter(name == "quokkas") |> pull(doi)

# download
banksia <- galah_call() |>
  filter(doi == doi_banksia) |>
  atlas_occurrences()

quokkas <- galah_call() |>
  filter(doi == doi_quokkas) |>
  atlas_occurrences()
```

```{r prereq-external}
#| echo: false
test <- glue::glue(
"
# packages
library(galah)
library(dplyr)
galah_config(email = \"your-email-here\") # ALA-registered email

banksia <- galah_call() |>
  filter(doi == \"{doi_banksia}\") |>
  atlas_occurrences()

quokkas <- galah_call() |>
  filter(doi == \"{doi_quokkas}\") |>
  atlas_occurrences()
"
)
```

```{r prereq-printed}
#| eval: false
#| code: !expr test
#| echo: true
```

::::: aside
<img src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/f/6/1/1/401b8f4d-d896-493c-9c93-e0aecca9116f/original" class="rounded"/></img>

::: figure-caption
[*Banksia serrata*.<br>Photo by kate_and_sam CC-BY-NC 4.0
(Int)](https://biocache.ala.org.au/occurrences/7a57075b-57fa-4b56-9565-29e8aea08223)
:::

<img src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/9/b/a/d/d994e948-cdb1-4e33-a925-dfce99bbdab9/original" class="rounded"/></img>

::: figure-caption
[*Setonix brachyurus* munching on leaves.<br>Photo by Stephen Cox
CC-BY-NC 4.0
(Int)](https://biocache.ala.org.au/occurrences/077bb0ae-3ecc-451a-a216-2bf0ebed7954)
:::
:::::

<!-- Queries -->

::: {.callout-note collapse="true" appearance="minimal"}
#### Original download queries

**Note:** You don't need to run this code block to read this chapter. It
can, however, be useful to see the original download query. This code
will download the latest data from the ALA, which you are welcome to use
instead, though the data might not exactly reproduce results in this
chapter.

```{r prereq-orig-query}
#| eval: false
library(galah)
galah_config(email = "your-email-here")

banksia <- galah_call() |>
  identify("banksia serrata") |>
  filter(year > 2022) |>
  select(group = "basic",
         coordinatePrecision, 
         coordinateUncertaintyInMeters) |>
  atlas_occurrences() # <1>

quokkas <- galah_call() |>
  identify("Setonix brachyurus") |>
  galah_select(group = "basic", 
               dataGeneralizations) |>
  atlas_occurrences() # <1>
```

1.  We created a custom DOI for our download by using
    `atlas_occurrences(mint_doi = TRUE)`.
:::

::: {.callout-important collapse="true"}
## Using "Assertions"

To check data quality, data infrastructures like the Atlas of Living
Australia have *assertions*---data quality tests that data
infrastructures use to flag when a record has an issue. The results of
these assertions are saved in assertions columns that can be accessed by
users if they would like them.

If we use galah to download records, we can add assertions columns to
our query to help identify and clean suspicious records.

If you would like to view assertions, use `show_all()`.

```{r}
assertions <- show_all(assertions)
assertions |>
  print(n = 7)
```

You can use the stringr package to search for text matches.

```{r}
assertions |>
  filter(str_detect(id, "COORDINATE")) |>
  print(n = 5)
```

In this chapter, we will detail when an assertion column can help
identify occurrence records with geospatial issues.
:::

## Quick visualisation

Mentioned in the [Inspect chapter](../1_exploring/inspect.qmd), one of
the most straightforward ways to check for spatial errors is to plot
your data onto a map. More obvious spatial errors are much easier to
spot visually.

In most spatial datasets, the most important columns are
`decimalLatitude` and `decimalLongitude` (or similarly named columns).
These contain the latitude and longitude of each observation in decimal
form (rather than degrees).

```{r}
# Retrieve map of Australia
aus <- st_transform(ozmap_country, 4326)

# A quick plot of banksia occurrences
ggplot() + 
  geom_sf(data = aus, colour = "black") + 
  geom_point(data = banksia, 
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             colour = "#e34e23")
```

In a quick glance, we can check whether there are any records in places
that they shouldn't be. Are there records in the ocean? Are there
records in states/territories where our species definitely doesn't live?
Is the data too sparse to use for our expected analysis plan?

Lucky for us, the `banksia` data we just plotted doesn't seem to have
any glaring issues, though you might notice some stray points in Tasmania 
and inland Australia that deserve some additional interrogating!

## Precision

Not all observations have the same degree of precision. Coordinate
precision can vary between data sources and recording equipment. For
example, coordinates recorded with a GPS unit or a phone generally have
higher precision than coordinates recorded manually from a locality
description.

The degree of precision you require will depend on the granularity of
your research question and analysis. A fine-scale question will require
data measured at a fine-scale to answer it. National or global scale
questions require less precise data.

When downloading data from the ALA with the galah package, it's possible
to include the
[`coordinatePrecision`](https://dwc.tdwg.org/terms/#dwc:coordinatePrecision)
field with your data; this provides a decimal representation of the
precision of coordinates for each observation.

```{r}
banksia |>
  select(scientificName, 
         coordinatePrecision
         ) |>
  filter(!is.na(coordinatePrecision)) # <1>
```

1.  Not all records have this information recorded, so we also filter to
    only records with a `coordinatePrecision` value.

Only a few records have `coordinatePrecision` recorded, but that subset
of records are very precise.

```{r}
banksia |> 
  group_by(coordinatePrecision) |>
  count()
```

Filter your records to only those under a specific measure of precision.

```{r}
#| eval: false
# Filter by number of decimal places
banksia <- banksia |>
  filter(coordinatePrecision <= 0.001)
```

## Uncertainty

<!-- I got a little confused here initially, and I wonder if it would be less (potentially) confusing to refer to precision and accuracy instead, and explain that accuracy is referred to as uncertainty in the ALA? I'm still not even sure I have correctly understood this, so feel free to ignore if I've gotten it wrong - SB -->

Similarly, not all observations have the same degree of accuracy. An
organism's *exact* location will likely have an area of uncertainty
around it. This uncertainty can vary due to the opportunistic condition
of an observation (a species was observed at some distance before moving
elsewhere), or from inaccurate measurement or documentation. However, a
main distinction between record uncertainty and record precision is that
data infrastructures like the ALA can *add uncertainty* to a record,
usually [for sensitivity
purposes](geospatial-investigation.qmd#obfusctaed-locations) (described in
more detail in the next section). Although adding uncertainty to data is
important for protecting individual species, uncertainty inevitably
affects [how robust the results from species distribution models
are](https://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2664.2007.01408.x),
so it is important to be aware of location uncertainty.

When downloading data from the ALA with the galah package, it's possible
to include the
[`coordinateUncertaintyInMeters`](https://dwc.tdwg.org/terms/#dwc:coordinateUncertaintyInMeters)
field with your data. This refers to the margin of error, represented as
a circular area, around the true location of the recorded observation.
We added this column in our [original galah
query](geospatial-investigation.qmd#prerequisites).

```{r}
banksia |>
  select(scientificName,
         coordinateUncertaintyInMeters
         )
```

There is a range of coordinate uncertainty in our data, with many
falling within 10m of uncertainty.

```{r}
banksia |> 
  count(coordinateUncertaintyInMeters) 
```

If your analysis requires greater certainty, you can then filter your
records to a smaller area of uncertainty.

```{r}
#| eval: false
# Filter by number of decimal places
banksia <- banksia |>
  filter(coordinateUncertaintyInMeters <= 5)
```

## Obfuscated locations

Some species observations are classified as *sensitive*, meaning that 
information about these species and where they are located is restricted for some reason (e.g., endangered, subject
to poaching or misuse, privacy concerns). Occurrence records of
sensitive species may be deliberately *obfuscated*---have their their locations made less accurate---to protect the true
locations of these species. Although removing accuracy makes these data more
difficult to work with, obfuscation helps to avoid risks like poaching
or capture while still allowing these species' data to be included in
broader summaries.

There are a couple of ways to obfuscate locations, either by *randomisation* or 
*generalisation*. Generalisation, the method used by the ALA, involves the 
removal of decimal points from decimal coordinates, rounded to distances of 1km, 10km or 50km (in accordance with state/territory legislation)[^randomisation]. This effectively 'snaps' any point within a grid cell to the corner of that cell.

[^randomisation]: Alternatively, *randomisation* involves placing an observation in a new location randomly within certain distance from its true location. For example iNaturalist randomises their data at a 30 km resolution prior to sharing data with the Atlas of Living Australia.

:::{.callout-note collapse="true"}
##### How does generalisation work?

When points are generalised, all points within the same grid cell will snap to the same corner regardless of where they sit within the grid cell. In Australia, this is the north west corner, in Brazil it’s the north east corner, in China it’s the south west corner and in Europe it’s the south east corner. The animation below demonstrates how this affects data points rounded from 4 decimals (frame 1), to 2 decimals (frame 2), to 1 decimal (frame 3)[^decimals]. Note that longitude values (`x`) are always rounded down and latitude values (`y`) are always rounded up to ensure all points in the grid generalise to the same corner.

[^decimals]: For example, `-33.9847, 149.0578` → `-33.98, 149.05` → `-33.9, 149.0`. 

```{r}
#| eval: false
#| code-fold: true
library(ggplot2)
library(dplyr)
library(glue)
library(ggtext)
library(gganimate)

# generate sample data
set.seed(2021)

data1 <- tibble::tibble(
  id = 1:15,
  x = round(runif(15, min = 149.0000, max = 149.9999), digits = 4),
  y = round(runif(15, min = -33.9999, max = -33.0000), digits = 4),
  phase = 1
)

data2 <- data1 |>
  mutate(
    x = floor(x * 100) / 100,
    y = ceiling(y * 100) / 100,
    phase = 2
  )

data3 <- data2 |>
  mutate(
    x = floor(x * 10) / 10,
    y = ceiling(y * 10) / 10,
    phase = 3
  )

data <- bind_rows(data1, data2, data3)

anim <- ggplot(data) +
  geom_point(
    aes(x = x, y = y),
    size = 2,
    alpha = .5,
    colour = "#e34e23"
  ) +
  labs(title = "Frame {closest_state}/3") +
  pilot::theme_pilot() +
  scale_x_continuous(
    breaks = c(149, 149.1, 149.2, 149.3, 149.4, 149.5,149.6, 149.7, 149.8, 149.9, 150)
  ) +
  scale_y_continuous(
    breaks = c(-34, -33.9, -33.8, -33.7, -33.6, -33.5, -33.4, -33.3, -33.2, -33.1, -33)
  ) +
  theme(
    legend.position = "none",
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    axis.text.x = element_markdown(),
    plot.title = element_text()
  ) +
  transition_states(phase, transition_length = 0.05, state_length = .2) +
  ease_aes('linear')

anim
```

![Example of generalisation, where coordinates are rounded to 4 decimals, 2 decimals, and 1 decimal.](../images/generalise-example.gif)

For more info on the methods of generalisation (and obfuscation more broadly), see [this online book on current best practices by Arthur Chapman](https://docs.gbif.org/sensitive-species-best-practices/master/en/#s-generalization).

:::

In the ALA, the field `dataGeneralizations` indicates whether a record
has been generalised and provides information on the size of the
area to which the point has been generalised. The numeric distance of 
generalisation is also held in the column `generalisationInMetres`.

Including these fields in your data download is essential if you think there 
might be sensitive species included. Obfuscation can also impact the results of your 
download query, including [which species are returned when searching within a specified area or polygon](https://labs.ala.org.au/posts/2025-08-26_adding-buffers-in-python/#:~:text=about%20buffer%20size.-,Obfuscation%20and%20why%20it%E2%80%99s%20important%20for%20sensitive%20species,-When%20we%20talk).

::: {.callout-note collapse="true"}
#### Note on `dataGeneralizations`

The `dataGeneralizations` and `generalisationInMetres` fields will only be available to use or
download when there are records in your query that have been
generalised.
:::

```{r}
search_all(fields, "dataGeneralization")
```

```{r}
#| echo: false

total_tortoise_count <- galah_call() |>
  identify("Pseudemydura umbrina") |>
  atlas_counts()

generalised_tortoise_count <- galah_call() |>
  identify("Pseudemydura umbrina") |>
  group_by(dataGeneralizations) |>
  atlas_counts()
  
```

For example, the Western Swamp Tortoise is [a critically endangered
species in Western
Australia](https://www.dcceew.gov.au/environment/biodiversity/threatened/action-plan/priority-reptiles/western-swamp-tortoise).
There are `r total_tortoise_count` records of this species in the ALA.

```{r}
galah_call() |>
  identify("Pseudemydura umbrina") |>
  atlas_counts()
```

Grouping record counts by the `dataGeneralizations` column shows that
`r generalised_tortoise_count$count` of the `r total_tortoise_count`
records have been obscured by 10 km.

```{r}
#| column: body-outset-right
galah_call() |>
  identify("Pseudemydura umbrina") |>
  group_by(dataGeneralizations) |>
  atlas_counts()
```

#### What do generalised data look like?

Quokka data offer a nice example of what to look for when data points
have been obfuscated. When plotted, obfuscated occurrence data appear as if
points were placed onto a grid [^geospatial-investigation-1].

[^geospatial-investigation-1]: This *is* what actually
    happened---locations have been "snapped" onto a grid determined by
    the generalised distance.

```{r}
# remove records with missing coordinates
quokkas <- quokkas |>
  tidyr::drop_na(decimalLatitude, decimalLongitude)

# aus map
aus <- ozmap_country |> st_transform(4326)

# map quokka occurrences
ggplot() + 
  geom_sf(data = aus, colour = "black", fill = NA) + 
  geom_point(data = quokkas, 
             aes(x = decimalLongitude,
                 y = decimalLatitude,
                 colour = dataGeneralizations |>
                   str_wrap(18))) +
  scale_colour_manual(values = c("sienna3", "snow4"),
                      guide = guide_legend(position = "bottom")) +
  guides(colour = guide_legend(title = "Data\ngeneralizations")) +
  xlim(114,120) + 
  ylim(-36,-31)
```

Keep in mind that survey data can also appear gridded if survey
locations were evenly spaced, so be sure to double check before assuming
data have been obfuscated!

For more information, check out the ALA's [support article about working
with threatened, migratory and sensitive
species](https://support.ala.org.au/support/solutions/articles/6000261705-working-with-conservation-and-sensitive-species-information).

## Summary

In this chapter, we showed some ways to investigate the geospatial
coordinates of our data and determine the degree of precision or
uncertainty around each data point.

In the next chapter, we'll see examples of issues with coordinates that
require correcting or removing.