---
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, setup, include=FALSE}

knitr::opts_chunk$set(
  comment = "",
  fig.width = 6,
  fig.height = 6,
  eval = FALSE,
  echo = FALSE,
  warning = FALSE
)

options(tidyverse.quiet = TRUE)

library(galah)
library(dplyr)
library(arrow)
library(skimr)
library(janitor)
```

## Initial inspection

Before diving into cleaning, it is always a good idea to start by familiarising
yourself with the data. A great way to get an initial overview of your data is
to use the R package `skimr`, which provides tables of descriptive statistics,
such as amount of missing data, for each variable. The output is also grouped by
data type (numeric, character, date) so you can also check for any
inconsistencies. 

As you are looking through the output, ask yourself whether the data is in line
with your expectations.If you requested data for a group of species, are they
all represented? Are the values for a variable reasonable? Looking at the
quartiles can help you get the sense of the distribution of data. These
considerations will help you detect potential issues in the data. Make sure you
take note of any issues you find, to investigate further and later address. 

```{r, echo = TRUE}
library(skimr)

skim(african_ele)
```

Here is the `skimr` report for our African elephant dataset we [downloaded
earlier](download-data.qmd). #todo more info needed 

```{r, eval = TRUE}
african_ele <- read_parquet("data/gbif/elephant")

skim(african_ele)
```

## Structural inconsistencies

### String inconsistencies and typographical errors

String inconsistencies include misspellings, capitalisation errors, misplaced
punctuation or trailing white spaces. We will use the `janitor` R package to
explore whether our data has any of these issues. The function `tabyl` will
compute a counts and percent of total rows for each unique value.

We recommend `tabyl-ing` any character strings that are relevant to your
project. For example, here is the
[`stateProvince`](https://dwc.tdwg.org/terms/#dwc:stateProvince) in alphabetical
order.

```{r, echo = TRUE}
library(janitor)

african_ele %>%
  pull(stateProvince) %>%
  tabyl() %>%
  tibble() %>%
  print(n = 20)
```

```{r, eval = TRUE}
african_ele %>%
  pull(stateProvince) %>%
  tabyl() %>%
  tibble() %>%
  print(n = 20)
```

From the `tabyl` output, we can see there are few different variations of
`Province`, `Prov.`, `Prov`. As an example, we will correct these with the
`tidyverse` packages `stringr`, `dplyr`, `tidyr` as well as `glue`. If you are
not very familiar with regular expressions, we highly recommend this
[cheatsheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf)

```{r, eval = TRUE, echo = TRUE}
library(tidyverse)
library(glue)

# Create a regular expression to match Prov. and Prov
# The pattern below means Prov that is NOT followed by any lowercase letters
pattern <- regex("Prov(?![:lower:])")

# Use `str_subset` to pull out the cases that match our pattern
# Confirm that these are the problematic ones
# Assign these into an object
str_subset(african_ele$stateProvince, pattern = pattern)
typos_provinces <- str_subset(african_ele$stateProvince, pattern = pattern)

# Create a new variable `stateProvince_clean` using `mutate`, `if_else`, `str_detect` and `glue`
# `str_detect` will evaluate values of `stateProvince` that matches our pattern we defined earlier.
# Matches will return TRUE, non-matches will return FALSE.
# The `if_else` will then evaluate these logicals (TRUE/FALSE/NA)
# for TRUE values, the `glue` function will take the first part of the province name enclosed in and join it with word Province.
# for FALSE values , it will just take the corresponding value in stateProvince
# Note that we are assigning these changes to a new object (`african_ele_2`)
african_ele_2 <- african_ele %>%
  mutate(stateProvince_clean = if_else(str_detect(stateProvince, pattern = pattern),
    true = glue('{word(stateProvince, sep = " P")} Province'),
    false = stateProvince
  ))

# Once we've made the correction we want to check we've done it correctly.
# ALWAYS CHECK YOUR CORRECTIONS
# Use the `select` function to isolate columns that `starts_with` "stateProvince"
# Use the `filter` function to subset our the problematic provinces
african_ele_2 %>%
  select(starts_with("stateProvince")) %>%
  filter(stateProvince %in% typos_provinces)

# Its good practice to check the other values were not affected by your corrections
# Here we are removing the NA with `drop_na` and subsetting unique rows with `distinct`
african_ele_2 %>%
  select(starts_with("stateProvince")) %>%
  drop_na() %>%
  distinct()

# Final check
# Check with the original code that detected the issue
african_ele_2 %>%
  pull(stateProvince_clean) %>%
  tabyl() %>%
  tibble() %>%
  print(n = 20)
```

There are some other issues that can be corrected in a similar approach:

-   `North West`, `North West District` and `North-Western`
-   `Ã€frica Central`, `Central Province` and `Central`
-   `Atacora` and `Atakora`
-   `Coastal Province` and `Coastal`

We recommend consulting reputable sources that can help delineate or consolidate
similar values. Googling and looking at Wikipedia's sources are good places to
find resources that you can verify accepted state and province names.

