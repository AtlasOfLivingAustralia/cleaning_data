---
editor: 
  markdown: 
    wrap: 72
number-depth: 3
code-annotations: hover
---

# Geospatial data {#sec-spatial}

In this chapter, we will discuss some different ways to check for
spatial outliers as well as the removal of records in certain geographic
areas known to be problematic.

### Prerequisites

In this chapter we'll use data of ...

```{r}
#| warning: false
#| message: false
library(galah)
library(ggplot2)
library(dplyr)
library(sf)
library(ozmaps)

galah_config(atlas = "Australia",
             email = Sys.getenv("ALA_EMAIL"),
             verbose = FALSE)

banksia <- galah_call() |>
  identify("banksia serrata") |>
  filter(year > 2022) |>
  select(group = "basic",
         coordinatePrecision, coordinateUncertaintyInMeters) |>
  atlas_occurrences()

frogs <- galah_call() |>
  identify("Litoria chloris") |>
  filter(year == 2013) |>
  select(group = "basic",
         countryCode, locality,
         family, genus, species, 
         cl22, eventDate) |>
  atlas_occurrences()
```

::: aside

<img src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/3/1/a/b/987382fa-8168-4249-870b-4e043824ba13/original" class="rounded"/></img>

::: figure-caption
[*Litoria chloris* standing on leaves.<br>Photo by Reiner Richter
CC-BY](https://biocache.ala.org.au/occurrences/e0d5d604-e148-408e-8dbf-984f42701b4c)
:::
:::

## Quick visualisation

Mentioned in the [Inspect chapter](LINK%20to%20chapter), one of the most
straightforward ways to check for spatial errors is to plot your data
onto a map. More obvious spatial errors are much easier to spot
visually.

```{r}
# Retrieve map of Australia
aus <- st_transform(ozmap_country, 4326)

# Remove missing coordinates in Banksia data
# Then transform into 'sf' object
banksia_sf <- banksia |> 
  tidyr::drop_na(starts_with("decimal")) |> 
  st_as_sf(coords = c("decimalLongitude", "decimalLatitude"), 
           crs = 4326)

# A quick plot
ggplot() + 
  geom_sf(data = aus, colour = "black", fill = NA) + 
  geom_sf(data = banksia_sf)
```

## Missing coordinate data

<!-- This is mentioned in missing-values chapter. Does it need to be repeated here or not? -->

Mentioned in the [Missing Values chapter](LINK%20to%20chapter), many
spatial analytical tools are not compatible with missing coordinate
data. We recommend identifying the rows that have missing data before
deciding to exclude them.

```{r}
# Identify missing data in coordinates
banksia |> 
  filter(is.na(decimalLatitude) | is.na (decimalLongitude))
```

You can use `drop_na()` to remove missing values from your dataset.

```{r}
# Excluding them
banksia <- banksia |> 
  tidyr::drop_na(decimalLatitude, decimalLongitude)
```

## Coordinate precision & uncertainty

Not all observations have the same degree of precision. Coordinate
precision can vary between data sources and recording equipment. For
example, coordinates recorded with a GPS unit or a phone generally have
higher precision than coordinates determined manually from a locality
description.
<!-- For example, an observation in the field area using a clipboard and pencil to describe a locality is less precise than an observation recorded using satellite location services on a phone. --><!-- Which is better? -->

Similarly, the interaction of methods and species observed can determine
the degree of coordinate uncertainty. If a person uses a precise GPS and
high-definition camera to make observations of snails, their observed
location will be of higher certainty. In contrast, if a person
uses a phone camera to observe a species of bird in the distance, their
observed location will be of lower certainty.

The degree of precision and certainty you require will depend on the
granularity of your research question and analyses. A fine-scale
question will require data measured at a fine-scale to answer it,
whereas national or global scale questions can use less precise data.

When downloading data from the ALA with the galah package, it's possible
to include columns
[`coordinatePrecision`](https://dwc.tdwg.org/terms/#dwc:coordinatePrecision)
(a decimal representation of how precise the coordinates of an
observation are) and
[`coordinateUncertaintyInMeters`](https://dwc.tdwg.org/terms/#dwc:coordinateUncertaintyInMeters)
(a measure of the circular area that captures the true location).

```{r}
banksia |>
  select(scientificName, 
         coordinatePrecision, 
         coordinateUncertaintyInMeters
         ) |>
  filter(!is.na(coordinatePrecision)) # <1>
```

1.  Not all records have this information recorded, so we also filter to
    only records with a `coordinatePrecision` value.

Only a few records have `coordinatePrecision` recorded, but that subset of records are very precise.

```{r}
banksia |> 
  group_by(coordinatePrecision) |>
  count()
```

There is a range of coordinate uncertainty in our data, but all records
are assumed within a 10-metre area of their observation.

```{r}
banksia |> 
  group_by(coordinateUncertaintyInMeters) |>
  count()
```

If your analysis requires greater certainty, you can then filter your
records to a smaller area of uncertainty.

```{r, eval=FALSE}
# Filter by number of decimal places
banksia <- banksia |>
  filter(coordinatePrecision <= 5)
```

<!-- This paper describes some stuff about how uncertainty reduces model performance. Could probably cite it above -->

https://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2664.2007.01408.x

## Coordinate correction

Spatial outliers aren't always due to a misidentified species.
Sometimes, they can be true observations with mistakes in their
coordinates. It's good practice to use several sources of spatial
information to decide whether an unexpected data point is due to a small
but fixable error in coordinates.

Many coordinates issues can be solved with data manipulation instead of
discarding. Here are several coordinate issues that can be identified
and solved by correcting the data.

#### Flipped coordinates

**Flipped coordinates:** Flipped coordinates typically appear as a
clustering of points, whereby swapping the latitude and longitude will
place the coordinates where they are expected. [@jin2020]

```{r}
#| eval: false
galah_call() |>
  filter(decimalLongitude > 10 & decimalLongitude < 45) |>
  group_by(species) |>
  atlas_counts()
```

```{r}
#| eval: false
records <- galah_call() |>
  filter(decimalLongitude > -155 & decimalLongitude < -111 & 
           decimalLatitude < 45 & decimalLatitude > 9) |>
  select(scientificName, decimalLongitude, decimalLatitude,
         eventDate, country, countryCode, locality,
         group = "assertions") |>
  atlas_occurrences()

records |>
  colnames()

records |>
  filter(PRESUMED_NEGATED_LONGITUDE == TRUE)

records |>
  filter(PRESUMED_SWAPPED_COORDINATE == TRUE)
```

```{r}
native_mice <- galah_call() |>
  identify("Dasyuroides byrnei") |>
  select(scientificName, decimalLongitude, decimalLatitude,
         eventDate,
         country, countryCode, locality, 
         group = "assertions") |>
  atlas_occurrences()
  

native_mice |>
  filter(COUNTRY_COORDINATE_MISMATCH == TRUE) |>
  select(decimalLongitude, decimalLatitude, eventDate, country, countryCode, locality)

ggplot() + 
  geom_sf(data = aus) +
  geom_point(data = native_mice,
             aes(x = decimalLongitude,
                 y = decimalLatitude))


```

If I were to guess, I'd say the Latitude values were entered in the Longitude column, and then the Longitude values (which are probably in the Latitude column) have been translated incorrectly, and then the Latitude column might be missing a `1` in the front (e.g., `156` not `56`) but who knows.



#### Incorrect numeric sign

**Numerical sign confusion:** As with flipped coordinates, if there is a
clustering of points mirrored to another hemisphere, consider swapping
the sign and correct rather than discarding the points.

---

This is a simpler example with both coordinates with the wrong sign

```{r}
desert_plant <- galah_call() |>
  identify("Eremophila macdonnellii") |>
  select(group = "basic", 
         PRESUMED_SWAPPED_COORDINATE) |>
  atlas_occurrences() |>
  drop_na(decimalLongitude, decimalLatitude) # remove NA coordinates

ggplot() + 
  geom_sf(data = aus) +
  geom_point(data = desert_plant,
             aes(x = decimalLongitude, y = decimalLatitude))
```


```{r}
desert_plant |>
  filter(PRESUMED_SWAPPED_COORDINATE == TRUE)
```

Fix it

```{r}
#| warning: false
#| message: false
library(stringr)
desert_plant_filtered <- desert_plant |>
  mutate(
    decimalLongitude = case_when(
      PRESUMED_SWAPPED_COORDINATE == TRUE ~ str_remove(decimalLongitude, "-") |>
        as.numeric(),
      .default = decimalLongitude
    ),
    decimalLatitude = case_when(
      PRESUMED_SWAPPED_COORDINATE == TRUE ~ glue::glue("-{decimalLatitude}") |> 
        as.numeric(),
      .default = decimalLatitude
    ))

ggplot() + 
  geom_sf(data = aus) +
  geom_point(data = desert_plant_filtered,
             aes(x = decimalLongitude, y = decimalLatitude))

```

---

<!-- This example doesn't feel fixable. Include it? -->

#### Country doesn't match coordinates

**Country field doesn't match coordinates:** The coordinates could be
wrong or just the country listed.

```{r}
# need an example? Could substitute for below example

```

If I were to guess, I'd say the Longitude column and Latitude column values are reversed, and then the Latitude column might be missing a `1` in the front (e.g., `156` not `56`)

---

#### Location description doesn't match coordinates

<!-- This example is cool but also more complicated. Should we include it? -->

When we plot the coordinates of our red-eyed tree
frog occurrences, there is an unexpected observation near Japan. This is
quite surprising - red-eyed tree frogs are not native to Japan!

```{r}
# Get a map of aus, transform projection
aus <- ozmaps::ozmap_country |>
  st_transform(crs = st_crs(4326))

# Map
ggplot() +
  geom_sf(data = aus,
          fill = NA,
          colour = "grey60") +
  geom_point(data = frogs,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             colour = "#557755") +
  theme_void()

```

Let's check the `countryCode` column to see whether this might be an
Australian record with a mistake in the coordinates.

Using `distinct()`, we can see that there are 2 country codes...

```{r}
frogs |>
  distinct(countryCode)
```

...and filtering to Japan (`"JP"`) identifies our stray data point.

```{r}
frogs |>
  filter(countryCode == "JP")
```

So far this observation does seem to be in Japan. To be extra certain,
we can also use the column `locality`, which provides additional
information from the data collector about the record's location.

```{r}
frogs |>
  filter(countryCode == "JP") |>
  select(countryCode, locality, scientificName, decimalLatitude, decimalLongitude)
```

The `locality` column reveals the observation was made in "mt bucca".
This is surprising to see because Mt Bucca is a mountain in Queensland!

When we look at our Japan data point's `decimalLongitude` and
`decimalLatitude` alongside other values in our data, it becomes clear
that the Japan data point seems to sit within the same numerical range
as other points, but is positive rather than negative.

```{r}
frogs |>
  arrange(desc(countryCode)) |>
  select(countryCode, decimalLongitude, decimalLatitude) |>
  print(n = 5)
```

All of this evidence suggests that our Japan "outlier" might instead be
an occurrence point with a mis-entered latitude coordinate.

Let's fix this by adding a negative symbol (`-`) to the record's
latitude coordinate number. We'll use `case_when()` from dplyr, which
works the same as an `ifelse` statement (but can handle many of them) to
specify that if the `countryCode == "JP"`, then we'll "stick" a negative
in front of `decimalLatitude` (using `glue()` from [the glue
package](https://glue.tidyverse.org/)).

```{r}
library(glue)

frogs_fixed <- frogs |>
  mutate(
    decimalLatitude = case_when(
      countryCode == "JP" ~ glue("-{decimalLatitude}"),
      .default = as.character(decimalLatitude) # <1>
    ) |> 
      as.integer() # <2>
  )

frogs_fixed |>
  filter(countryCode == "JP") |> 
  select(decimalLatitude, decimalLongitude, countryCode)
```

1.  This is like a catch-all `else` statement. To make it work, we have
    to convert our `decimalLatitude` to a `character` because the result
    of using `glue` or `paste` in R is a `character` class (we are
    pasting `characters` together to make something new, so to be safe R
    assumes the class isn't `numeric` anymore).
2.  The result of our `case_when()` is a column of class `character`.
    So, we have to convert it back to a number so we can use it as a
    coordinate again, rather than as text.

Mapping our data again shows our outlier is an outlier no longer!

```{r}
#| code-fold: true
ggplot() +
  geom_sf(data = aus,
          fill = NA,
          colour = "grey60") +
  geom_point(data = frogs_fixed,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             colour = "#557755") +
  theme_void()

```

## Cleaning coordinates

### Equal longitude/latitude

Some records might have an accidental duplicated coordinate, resulting
in longitude and latitude coordinates that are the same. You can
identify and filter these records by checking for equal lat/lon
coordinates.

```{r}
# Need to find some data that has this
banksia |>
  filter(decimalLatitude == decimalLongitude)
```

### Zero coordinates
Some records are mistakenly recorded with zero as their latitude and/or longitude coordinates. These records will not accurately represent their valid
location and must be removed.

```{r}
# zero coordinates

galah_call() |>
  identify("acacia") |>
  filter(decimalLongitude == 0,
         decimalLatitude == 0) |>
  group_by(species) |>
  atlas_counts()

galah_call() |>
  identify("Acacia aneura") |>
  atlas_counts()
```

```{r}
acacias <- galah_call() |>
  identify("acacia aneura") |>
  select(group = "basic",
         ZERO_COORDINATE,
         countryCode, locality) |>
  atlas_occurrences()

ggplot() + 
  geom_sf(data = aus) +
  geom_point(data = acacias,
             aes(x = decimalLongitude, 
                 y = decimalLatitude))
```

Fix it

```{r}
acacias_filtered <- acacias |>
  filter(decimalLongitude != 0,
         decimalLatitude != 0)

ggplot() + 
  geom_sf(data = aus) +
  geom_point(data = acacias_filtered,
             aes(x = decimalLongitude, 
                 y = decimalLatitude))
```


### Using expert distributions

<!-- This section can have an example expert distribution, then plot points on the top, then find which points are outside of the distribution to investigate -->

One way to identify suspicious observations is to use an expert
distribution to determine whether an occurrence record is within the
possible range of a species. At the most basic, expert distributions can
be found in the literature (like [this one](an%20example)), then
compared visually to your points.

It's also possible to download expert distributions as shapefiles, and
these can be plotted on a map to directly compare with your occurrence
record locations.

<!-- Example: -->

```{r}

```

### Obfiscated coordinates

### Centroid coordinates

Centroids, or the coordinates that mark the exact centre point of an
area, are sometimes assigned to an occurrence record when the original
observation location was provided as a description from georeferencing
based on vague locality descriptions or from incorrect georeferencing.

Sometimes, records are erroneously entered with the physical location of
the specimen or because they represent individuals from captivity or
grown in horticulture, which were not clearly labelled as such.

```{r}
# example Heteronympha merope
```


### Public facilities and institutions

#### Zoos, aquariums & botanic gardens

Some observations are recorded in places or areas where animals and
plants live but do not naturally occur. A common example is observations
recorded at public facilities like zoos, aquariums and botanic gardens.
In some cases, like with records of the Eastern Grey Kangaroo, these
locations can appear obvious. The Perth Zoo happens to be located
exactly where the single point in Western Australia.

```{r}
#Eastern grey kangaroo example
```

Google the coordinates of zoos, aquariums and botanic gardens if you
think it's possible that your data might overlap. You can then filter
records that match these coordinates.

```{r}
# get sydney zoo location

# filter to records that match those coordinates.
```




---

<!-- This is a risk of all specimen records. Is it worth including? -->

#### Capital cities, urban areas, buildings

A risk of using data of many types is that sometimes, if observations and specimen data are mixed, some coordinates will specify the location of the specimen, not the observation. These records must be excluded if you are interested in analysing occurrence locations.


```{r}
# example of many samples in cities (USA & Europe)
# Placynthiella uliginosa
```

---

### CoordinateCleaner

This package probably worth specifying and giving an example.

```{r}

```


## Summary

Each of the cleaning steps in this chapter do not have to be run in order, or even at all. Whether they are used is context dependent and taxon dependent. As an example, what is one species that has many wrong coordinates based on many of the steps listed above? 

The Great White Shark.

[Shark photo, map of shark records]

Yet this species has a massive range and is observed in many locations across the globe. Be sure to consider the taxonomic and spatial range of your species before jumping into data cleaning! 
