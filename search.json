[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cleaning Biodiversity Data in R",
    "section": "",
    "text": "Welcome\nThis book is a practical guide for cleaning geo-referenced biodiversity data using R. It focuses specifically on the processes and challenges you’ll face with biodiversity data. As such, this book isn’t a general guide to data cleaning but a targeted resource for those working with or interested in ecology, evolution, and geo-referenced biodiversity data.\nThis book was last rendered on 30 July, 2024.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgement-of-country",
    "href": "index.html#acknowledgement-of-country",
    "title": "Cleaning Biodiversity Data in R",
    "section": "Acknowledgement of Country",
    "text": "Acknowledgement of Country\nThe Atlas of Living Australia acknowledges that we live and work on Aboriginal and Torres Strait Islander lands, rivers, and seas. Indigenous Australian peoples held and continue to hold incomparably intricate environmental knowledge as first peoples of this country. We are working with communities to acknowledge and archive these different types of knowledge in a culturally sensitive way.\nThe authors of this book currently reside on the lands of the Ngunnawal and Ngambri (Canberra), Wurundjeri Woi Wurrung and Bunurong (Naarm/Melbourne), Turrbal and Yuggera (Meanjin/Brisbane), Kaurna (Tarntanya/Adelaide), and Gadigal (Gadigal/Sydney) peoples. We pay our respects to Elders past and present.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Cleaning Biodiversity Data in R",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA).",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "People working with ecological or biological data want to know how to clean data effectively, but data cleaning can be a daunting task because of the complexity inherent in these types of data. At the Atlas of Living Australia, questions about data cleaning come up so frequently that it made us wonder…is there a general ecological data cleaning workflow that is considered best-practice?\nTo find out, we undertook an informal literature review on ecological data cleaning processes using peer-reviewed and grey literature. The key themes we searched for were:\n\nData cleaning for species distribution models\nData cleaning open biodiversity data\nAustralian and global naming authorities\nR packages for biodiversity data cleaning\n\nWe created a collection of papers that matched these themes, choosing recently published papers that used up-to-date workflows with recent packages and tools in R. We also added several frequently referenced papers for comprehensiveness, and we reviewed data cleaning workflows from our project partners (Marsh et al. 2021; Godfree et al. 2021) to understand their processes, issues, and needs.\nFrom our informal search, we ended up with a list of 18 papers and resources (listed here) with relevant ecological data cleaning workflows. To determine any common, best-practice steps—and common sequences for ordering these steps—we read through their methods sections and collated their data cleaning protocols into a spreadsheet. Our hope was that collating these methods would reveal several clear data cleaning workflows that scientists and researchers use regularly to clean their data.\nBut, to our surprise, that’s not what we found. Instead, the steps to cleaning ecological data were even messier than we first thought. The diagrams below visualise the findings of our spreadsheet, showing the complexity of processes used to clean data, many of which are iterative.\n\n\n\nA flow diagram of possible ecological data cleaning workflows\n\n\n\n\n\nA simplified flow diagram of possible ecological data cleaning workflows, which still looks not very simple\n\n\nIn the end, our search showed us that there is no single, unified, step-by-step workflow to clean all types of ecological data. Instead, data are cleaned in a huge variety of ways, and the process can look completely different depending on the type of investigation. No wonder people frequently ask how to do it!\nThis book is our response to questions about how to clean ecological data, and to our discovery that (because workflows vary immensely) there don’t seem to be many resources that consolidate methods to clean ecological data in R. We are by no means experts in cleaning all types of data for all types of ecological analyses. We do, however, work with ecological data on a daily basis and encounter many data cleaning issues in our own work. We aspired for this book to be an up-to-date resource for a diverse range of data cleaning tasks in R. We hope that (at the very least) it is a resource that documents many common ecological data cleaning steps in one place!\nDax Kellie27 May, 2024\n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville, Libby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts of the 2019-20 Wildfires of Southern and Eastern Australia on Invertebrate Species Final Report.”",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Who is this book for?\nIf you are new to working with geo-referenced biodiversity data in R, or are looking for a quick reference to data cleaning processes or concepts in R, then this book is for you! By learning how to download and apply common data cleaning steps, you will also develop a better understanding of biodiversity data, and common issues to be aware of.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#what-this-book-covers",
    "href": "introduction.html#what-this-book-covers",
    "title": "Introduction",
    "section": "What this book covers",
    "text": "What this book covers\nIn this book, we provide an overview of a typical data cleaning workflow for open-access geo-referenced biodiversity data—from acquisition, to error identification, to correction. These processes are broken down into three main sections. The chapters within each section include practical guidelines, example R code, and additional resources that may aid with each data cleaning step.\n\n\n\n\n\n\n    \n\n\nThe first section is about exploring data. This section introduces ways to inspect and summarise taxonomic, spatial, and temporal elements in your data to identify areas that need cleaning.\n\n\n\n\n\n\n\n\n\n\n    \n\n\nThe second section is about general data cleaning processes. This section provides a checklist of data science tools and functions to clean different aspects of your data like strings, dates, and missing values.\n\n\n\n\n\n\n\n\n\n\n    \n\n\nThe third section is about data cleaning processes that require expertise in your study species. This section discusses ways to spot errors that require ecological consideration about how best to handle each issue for your specific research question.\n\n\n\nThis book attempts to fill a niche between works that discuss data cleaning principles without using code (e.g., (Chapman, 2005)) and articles that describe technical solutions to computational problems (e.g., the bdc toolkit; (Ribeiro et al., 2024)).\nAlthough the principles we cover to clean data apply to many types of data (not just biodiversity data), our perspective is strongly focused on cleaning “unstructured” occurrence data with one row per observation (as provided by the Global Biodiversity Information Facility (GBIF) and it’s partner nodes).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#what-we-dont-cover",
    "href": "introduction.html#what-we-dont-cover",
    "title": "Introduction",
    "section": "What we don’t cover",
    "text": "What we don’t cover\nThe areas of research and uses of biodiversity data are many and varied. Here we have focused on just one facet—downloading and cleaning geo-referenced occurrence/biodiversity data. As such, this book will not cover:\n\nHypothesis testing or experimental design\nHow to clean environmental data that is not occurrence / biodiversity data (e.g. trait data)\nHow to perform analyses (e.g. species distribution modelling)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#requirements",
    "href": "introduction.html#requirements",
    "title": "Introduction",
    "section": "Requirements",
    "text": "Requirements\n\nUser accounts\nWe will be working with point-based species occurrence data retrieved from online infrastructures such as the Global Biodiversity Information Facility (GBIF) and the Atlas of Living Australia (ALA). To retrieve data from these services, you will need to create a user account, if you do not already have one:\n\nRegister an account with Atlas of Living Australia\nRegister an account with Global Biodiversity Information Facility\n\n\n\nR\nTo get the most out of this book, a basic knowledge of using R and RStudio is recommended. We use R because it is commonly used across ecological projects and has a rich ecosystem of packages for data cleaning and visualisation. If you are new to R or need a refresher, there are many amazing and freely available resources available online. Data Analysis and Visualisation in R for Ecologists and R for Data Science are both excellent starting points.\nDownload R from CRAN, selecting the version that matches your operating system, and install it on your device.\n\n\nRStudio\nRStudio is an integrated development environment (IDE) for R programming. RStudio provides a range of tools to make working with R easier, and you can download and install RStudio for your operating system here.\nOther excellent IDEs like Visual Studio Code can be good alternative options depending on your preferences.\n\n\nPackages\nWe use a range of R packages throughout the book, primarily for data cleaning and visualisation. These packages will be typically noted at the beginning of a chapter, and occasionally a code block. To access biodiversity data we will be primarily working with the galah package. If you have collected your own occurrence data, you should still find this book useful.\nA list of the most common packages in this book can be found on the Packages page.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#conventions",
    "href": "introduction.html#conventions",
    "title": "Introduction",
    "section": "Conventions",
    "text": "Conventions\n\nCode blocks\nExamples throughout this book are accompanied by code blocks. These blocks show how a particular task was executed in R:\n\n# This is a code block with a comment\nlibrary(package-name)\nlibrary(palmerpenguins)\n\npenguins |&gt;\n   dplyr::group_by(species)\n\n\n\n\n\n\n\nYou can copy code by clicking the  button in the top right corner of a code block.\n\n\n\n\n\nCode line comments\nSome code blocks have circled numbers near the right edge of the code block. You can hover over these numbers to read additional context about that specific line of code.\n\npenguins |&gt;\n1  dplyr::group_by(species) |&gt;\n2  dplyr::summarise(mean_bill_length = mean(bill_length_mm))\n\n\n1\n\nThis line of code groups penguins data by each distinct value in the variable species\n\n2\n\nThis line of code summarises each species’ mean bill length, saving the output in a new column mean_bill_length\n\n\n\n\nThroughout this book, we use “pipes” in our code (|&gt;, or %&gt;% from the magrittr package). Pipes allow you to chain multiple functions sequentially to an object or a dataset. Pipes can be read as saying “and then”. For example, the code block above can be read as “Get data penguins, and then group by species, and then summarise (setting mean_bill_length to contain the mean of bill_length_mm).”",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#how-to-contribute",
    "href": "introduction.html#how-to-contribute",
    "title": "Introduction",
    "section": "How to contribute",
    "text": "How to contribute\nSuggestions, contributions, questions or other feedback to improve this book are welcome. We recommend opening an issue in our GitHub repository first to discuss improvements or potential changes. More helpful information about licensing and contributing guidelines can be found here.\n\n\n\n\nChapman, A. D. (2005). Principles and methods of data cleaning. GBIF.\n\n\nRibeiro, B., Velazco, S., Guidoni-Martins, K., Tessarolo, G., & Jardim, L. (2024). Bdc: Biodiversity Data Cleaning. https://brunobrr.github.io/bdc/ (website) https://github.com/brunobrr/bdc",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "data-in-this-book.html",
    "href": "data-in-this-book.html",
    "title": "Data in this book",
    "section": "",
    "text": "Prerequisites\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(readr)\nlibrary(here)",
    "crumbs": [
      "Data in this book"
    ]
  },
  {
    "objectID": "data-in-this-book.html#data",
    "href": "data-in-this-book.html#data",
    "title": "Data in this book",
    "section": "Data",
    "text": "Data\n\nbees\nThis is a subset of a larger dataset—Curated Plant and Invertebrate Dataset for Bushfire Modelling.\n\n\n\n\nBraunsapis species hovering in front of a ghost gum tree flower.Photo by Zig Madycki CC-BY-NC-ND 4.0 (Int)\n\nClick on the download button below to download as a parquet file. Save the parquet in your working directory and load it using the code below.\n Download bees data \n\nbees &lt;- read_parquet(here(\"path\", \"to\", \"bees.parquet\"))\n\n\n\ninverts\nThis is a subset of a larger dataset—Curated Plant and Invertebrate Dataset for Bushfire Modelling.\n\n\n\n\nParalaoma mucoides on a rock.Photo by Nick Porch CC-BY-NC 4.0 (Int)\n\nClick on the download button below to download as a parquet file. Save the parquet in your working directory and load it using the code below.\n Download inverts data \n\ninverts &lt;- read_parquet(here(\"path\", \"to\", \"inverts.parquet\"))\n\n\n\ngbif_species_list\nA species list of Eucalyptus downloaded from GBIF.\nClick on the download button below to download as a parquet file. Save the parquet in your working directory and load it using the code below.\n Download gbif_species_list data \n\ngbif_species_list &lt;- read_parquet(here(\"path\", \"to\", \"gbif_species_list.parquet\"))\n\n\n\nmarine_sp\nA subset of World Register of Marine Species (WoRMS) data.\nClick on the download button to download as a .csv file. Save the csv in your working directory and load it using the code below.\n Download marine_sp data \n\nmarine_sp &lt;- read_csv(here(\"path\",\"to\", \"worms.csv\"))",
    "crumbs": [
      "Data in this book"
    ]
  },
  {
    "objectID": "1_exploring/inspect.html",
    "href": "1_exploring/inspect.html",
    "title": "1  Inspect",
    "section": "",
    "text": "1.0.1 Prerequisites\nIn this chapter we will use Kingfisher (Alcedinidae) occurrence records in 2023 from the ALA.\n# packages\nlibrary(galah)\nlibrary(ggplot2)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\nbirds &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.702e73e4-ba9d-471a-a0a4-872ecb5d0f32\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inspect</span>"
    ]
  },
  {
    "objectID": "1_exploring/inspect.html#getting-to-know-your-data",
    "href": "1_exploring/inspect.html#getting-to-know-your-data",
    "title": "1  Inspect",
    "section": "1.1 Getting to know your data",
    "text": "1.1 Getting to know your data\nMetadata is a description of data, where information about different aspects of the data is documented. Some examples include definitions of the variables being measured, how and why the data were collected, and any data standards used. Reviewing the metadata associated with a dataset can be very helpful for understanding the types of data you are working with and any considerations that may need to be accounted for in your analyses.\nMany datasets include descriptions of the data’s taxonomic, spatial, and temporal parameters. An example of well formatted metadata is of FrogID from the Australian Museum.\n\n\n\nMetadata of the FrogID dataset on the ALA\n\n\nFrom reading FrogID’s metadata (Rowley and Callaghan 2020), we understand that:\n\nThe dataset comprises acoustic data1\nThis is citizen science data2\nAudio is recorded via a smartphone app3\nThese data record presences, but not absences\nThe data are under a Creative Commons license which is relevant for reuse and republishing\n\n\n\n\n\n\n\nData standards\n\n\n\n\n\nMany data infrastructures like the Atlas of Living Australia also follow and encourage a data standard to help consolidate data from many different data providers4.\nThe data standard used by the Atlas of Living Australia is called Darwin Core. Darwin Core works by defining a) a set of standard terms5 to use across datasets as column names, and b) values eligible to be recorded underneath these terms. Darwin Core standards require that additional files detailing metadata and data structure are supplied along with the dataset. This helps make sure the data is ingested correctly into the data infrastructure.\nKnowing whether your dataset follows a standard can allow you to look up term definitions to help you familiarise yourself with the data.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inspect</span>"
    ]
  },
  {
    "objectID": "1_exploring/inspect.html#a-first-glimpse",
    "href": "1_exploring/inspect.html#a-first-glimpse",
    "title": "1  Inspect",
    "section": "1.2 A first glimpse",
    "text": "1.2 A first glimpse\nWhen starting with a new dataset, we want to get an initial idea:\n\nHow many rows and columns are there?\nWhat are the column names?\nWhat types of data are in each column?\nWhat are their possible values or ranges?\n\nThese answers are useful to know before jumping into wrangling and cleaning data.\nThere are several ways to return an overview of your data, ranging in how comprehensively you wish to summarise your data’s structure.\n\nglimpse()skim()str()\n\n\nReturn a condensed summary of your data’s structure using glimpse() from dplyr.\n\nlibrary(dplyr)\n\nglimpse(birds)\n\nRows: 140,835\nColumns: 13\n$ recordID         &lt;chr&gt; \"00000eb7-95a6-40ad-acc5-9b58ed2ab95b\", \"0000c741-b70…\n$ scientificName   &lt;chr&gt; \"Dacelo (Dacelo) novaeguineae\", \"Dacelo (Dacelo) nova…\n$ taxonConceptID   &lt;chr&gt; \"https://biodiversity.org.au/afd/taxa/1fc76c4d-4830-4…\n$ decimalLatitude  &lt;dbl&gt; -37.77953, -37.70718, -42.96048, -36.89798, -32.90858…\n$ decimalLongitude &lt;dbl&gt; 145.0460, 143.5939, 147.2209, 147.0573, 151.6859, 150…\n$ eventDate        &lt;dttm&gt; 2022-04-19 11:30:00, 2022-12-25 07:37:00, 2022-10-27…\n$ occurrenceStatus &lt;chr&gt; \"PRESENT\", \"PRESENT\", \"PRESENT\", \"PRESENT\", \"PRESENT\"…\n$ dataResourceName &lt;chr&gt; \"eBird Australia\", \"eBird Australia\", \"eBird Australi…\n$ family           &lt;chr&gt; \"Alcedinidae\", \"Alcedinidae\", \"Alcedinidae\", \"Alcedin…\n$ genus            &lt;chr&gt; \"Dacelo\", \"Dacelo\", \"Dacelo\", \"Dacelo\", \"Dacelo\", \"To…\n$ species          &lt;chr&gt; \"Dacelo novaeguineae\", \"Dacelo novaeguineae\", \"Dacelo…\n$ cl22             &lt;chr&gt; \"Victoria\", \"Victoria\", \"Tasmania\", \"Victoria\", \"New …\n$ year             &lt;dbl&gt; 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022, 2022,…\n\n\n\n\nReturn tables of descriptive statistics for each variable, grouped by data type (e.g., numeric, character, date) using skim() from skimr.\n\nlibrary(skimr)\n\nskim(birds)\n\n\nData summary\n\n\nName\nbirds\n\n\nNumber of rows\n140835\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n9\n\n\nnumeric\n3\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrecordID\n0\n1.00\n36\n36\n0\n140835\n0\n\n\nscientificName\n0\n1.00\n6\n42\n0\n22\n0\n\n\ntaxonConceptID\n0\n1.00\n73\n73\n0\n22\n0\n\n\noccurrenceStatus\n0\n1.00\n7\n7\n0\n1\n0\n\n\ndataResourceName\n0\n1.00\n8\n58\n0\n17\n0\n\n\nfamily\n0\n1.00\n11\n11\n0\n1\n0\n\n\ngenus\n116\n1.00\n4\n11\n0\n5\n0\n\n\nspecies\n2859\n0.98\n12\n24\n0\n10\n0\n\n\ncl22\n1718\n0.99\n8\n28\n0\n8\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndecimalLatitude\n0\n1\n-28.84\n7.91\n-43.58\n-34.97\n-30.54\n-26.32\n35.6\n▇▆▁▁▁\n\n\ndecimalLongitude\n0\n1\n146.09\n8.80\n96.87\n145.11\n148.95\n152.38\n174.8\n▁▁▂▇▁\n\n\nyear\n0\n1\n2022.00\n0.00\n2022.00\n2022.00\n2022.00\n2022.00\n2022.0\n▁▁▇▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n4\n1\n2021-12-31 18:07:00\n2022-12-31 22:50:00\n2022-07-31 08:00:00\n77135\n\n\n\n\n\n\n\nReturn a quick summary of your data’s structure using base R str()\n\nstr(birds)\n\nspc_tbl_ [140,835 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ recordID        : chr [1:140835] \"00000eb7-95a6-40ad-acc5-9b58ed2ab95b\" \"0000c741-b706-49dc-864e-bf9be82982a8\" \"0001057f-c7e9-4ae2-b7db-f0f03b4e52a0\" \"000121a3-a27e-4656-ad55-e817ebf05341\" ...\n $ scientificName  : chr [1:140835] \"Dacelo (Dacelo) novaeguineae\" \"Dacelo (Dacelo) novaeguineae\" \"Dacelo (Dacelo) novaeguineae\" \"Dacelo (Dacelo) novaeguineae\" ...\n $ taxonConceptID  : chr [1:140835] \"https://biodiversity.org.au/afd/taxa/1fc76c4d-4830-4129-9b86-1c7e944c3c50\" \"https://biodiversity.org.au/afd/taxa/1fc76c4d-4830-4129-9b86-1c7e944c3c50\" \"https://biodiversity.org.au/afd/taxa/1fc76c4d-4830-4129-9b86-1c7e944c3c50\" \"https://biodiversity.org.au/afd/taxa/1fc76c4d-4830-4129-9b86-1c7e944c3c50\" ...\n $ decimalLatitude : num [1:140835] -37.8 -37.7 -43 -36.9 -32.9 ...\n $ decimalLongitude: num [1:140835] 145 144 147 147 152 ...\n $ eventDate       : POSIXct[1:140835], format: \"2022-04-19 11:30:00\" \"2022-12-25 07:37:00\" ...\n $ occurrenceStatus: chr [1:140835] \"PRESENT\" \"PRESENT\" \"PRESENT\" \"PRESENT\" ...\n $ dataResourceName: chr [1:140835] \"eBird Australia\" \"eBird Australia\" \"eBird Australia\" \"eBird Australia\" ...\n $ family          : chr [1:140835] \"Alcedinidae\" \"Alcedinidae\" \"Alcedinidae\" \"Alcedinidae\" ...\n $ genus           : chr [1:140835] \"Dacelo\" \"Dacelo\" \"Dacelo\" \"Dacelo\" ...\n $ species         : chr [1:140835] \"Dacelo novaeguineae\" \"Dacelo novaeguineae\" \"Dacelo novaeguineae\" \"Dacelo novaeguineae\" ...\n $ cl22            : chr [1:140835] \"Victoria\" \"Victoria\" \"Tasmania\" \"Victoria\" ...\n $ year            : num [1:140835] 2022 2022 2022 2022 2022 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   recordID = col_character(),\n  ..   scientificName = col_character(),\n  ..   taxonConceptID = col_character(),\n  ..   decimalLatitude = col_double(),\n  ..   decimalLongitude = col_double(),\n  ..   eventDate = col_datetime(format = \"\"),\n  ..   occurrenceStatus = col_character(),\n  ..   dataResourceName = col_character(),\n  ..   family = col_character(),\n  ..   genus = col_character(),\n  ..   species = col_character(),\n  ..   cl22 = col_character(),\n  ..   year = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n - attr(*, \"doi\")= chr \"https://doi.org /10.26197/ala.702e73e4-ba9d-471a-a0a4-872ecb5d0f32\"\n\n\n\n\n\n\n\n\n\nDacelo (Dacelo) novaeguineae perched with a fresh worm in its beak. Photo by Rob Shepherd CC-BY-NC 4.0 (Int)\n\nAt this early stage, it’s helpful to assess whether your dataset meets your expectations. Consider if the data appear as anticipated. Are the values in each column reasonable? Are there any noticeable gaps or errors that might need to be corrected, or that could potentially render the data unusable?",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inspect</span>"
    ]
  },
  {
    "objectID": "1_exploring/inspect.html#next-steps",
    "href": "1_exploring/inspect.html#next-steps",
    "title": "1  Inspect",
    "section": "1.3 Next steps",
    "text": "1.3 Next steps\nWe have just learned some ways to initially inspect our dataset. Keep in mind, we don’t expect everything to be perfect. Some issues are expected and may indicate problems with our query or the data itself. This initial inspection is a good opportunity to identify where these issues might be and assess their severity.\nWhen you are confident that the dataset is largely as expected, you are ready to start summarising your data.\n\n\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset: Expert-Validated Occurrence Records of Australia’s Frogs Collected by Citizen Scientists.” ZooKeys 912: 139.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inspect</span>"
    ]
  },
  {
    "objectID": "1_exploring/inspect.html#footnotes",
    "href": "1_exploring/inspect.html#footnotes",
    "title": "1  Inspect",
    "section": "",
    "text": "Meaning the majority of individuals recorded are male.↩︎\nSuggesting these data could be biased towards populated areas.↩︎\nAs a result, the authors recommend filtering data to geographic uncertainty of &lt;3000m if you require high coordinate precision.↩︎\nMaking datasets easier to consolidate is also referred to as interoperability, one of the principles of FAIR data.↩︎\nWe suggest using Ctrl/CMD + F and searching your variable name on the webpage. Don’t hesitate to Google variable names if you are unsure what they represent.↩︎",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Inspect</span>"
    ]
  },
  {
    "objectID": "1_exploring/summarise.html",
    "href": "1_exploring/summarise.html",
    "title": "2  Summarise",
    "section": "",
    "text": "2.0.1 Prerequisites\nIn this chapter, we will use occurrence records for Alcedinidae (Kingfishers) in 2023 from the ALA.\n# packages\nlibrary(galah)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(janitor)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\nbirds &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.75b1f2a4-eed2-4eaa-8381-b32de8994c85\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summarise</span>"
    ]
  },
  {
    "objectID": "1_exploring/summarise.html#taxonomic",
    "href": "1_exploring/summarise.html#taxonomic",
    "title": "2  Summarise",
    "section": "2.1 Taxonomic",
    "text": "2.1 Taxonomic\n\n2.1.1 Counts\nPrior to downloading data, it can be useful to see a taxonomic breakdown of the occurrence records that exist for our query. For example, with the Alcedinidae dataset, we can count the total number of occurrence records…\n\ngalah_call() |&gt;\n  identify(\"alcedinidae\") |&gt;\n  filter(year == 2022) |&gt;\n  atlas_counts()\n\n# A tibble: 1 × 1\n   count\n   &lt;int&gt;\n1 142050\n\n\n…or group by a taxonomic rank like genus…\n\ngalah_call() |&gt;\n  identify(\"alcedinidae\") |&gt;\n  filter(year == 2022) |&gt;\n  group_by(genus) |&gt;\n  atlas_counts()\n\n# A tibble: 5 × 2\n  genus       count\n  &lt;chr&gt;       &lt;int&gt;\n1 Dacelo      93239\n2 Todiramphus 41425\n3 Ceyx         6013\n4 Tanysiptera   903\n5 Syma          349\n\n\n…or species.\n\ngalah_call() |&gt;\n  identify(\"alcedinidae\") |&gt;\n  filter(year == 2022) |&gt;\n  group_by(species) |&gt;\n  atlas_counts()\n\n# A tibble: 10 × 2\n   species                  count\n   &lt;chr&gt;                    &lt;int&gt;\n 1 Dacelo novaeguineae      85782\n 2 Todiramphus sanctus      26228\n 3 Todiramphus macleayii    10037\n 4 Dacelo leachii            7451\n 5 Ceyx azureus              5342\n 6 Todiramphus pyrrhopygius  2365\n 7 Tanysiptera sylvia         903\n 8 Ceyx pusillus              671\n 9 Syma torotoro              349\n10 Todiramphus chloris         29\n\n\nOur results show that the large majority of records are of Dacelo novaeguineae (aka the Laughing Kookaburra).\nYou can get the same summaries after downloading the data locally using dplyr or janitor.\n\ndplyrjanitor\n\n\n\n# Using our pre-downloaded dataset\nbirds |&gt;\n  group_by(genus) |&gt;\n  count() |&gt;\n  arrange(desc(-n))\n\n# A tibble: 6 × 2\n# Groups:   genus [6]\n  genus           n\n  &lt;chr&gt;       &lt;int&gt;\n1 &lt;NA&gt;          116\n2 Syma          340\n3 Tanysiptera   886\n4 Ceyx         5906\n5 Todiramphus 40892\n6 Dacelo      92695\n\nbirds |&gt;\n  group_by(species) |&gt;\n  count() |&gt;\n  arrange(desc(-n))\n\n# A tibble: 11 × 2\n# Groups:   species [11]\n   species                      n\n   &lt;chr&gt;                    &lt;int&gt;\n 1 Todiramphus chloris         29\n 2 Syma torotoro              340\n 3 Ceyx pusillus              658\n 4 Tanysiptera sylvia         886\n 5 Todiramphus pyrrhopygius  2322\n 6 &lt;NA&gt;                      2859\n 7 Ceyx azureus              5248\n 8 Dacelo leachii            7264\n 9 Todiramphus macleayii     9866\n10 Todiramphus sanctus      25938\n11 Dacelo novaeguineae      85425\n\n\n\n\n\n# Using our pre-downloaded dataset\nbirds |&gt;\n  tabyl(genus) |&gt;\n  adorn_pct_formatting()\n\n       genus     n percent valid_percent\n        Ceyx  5906    4.2%          4.2%\n      Dacelo 92695   65.8%         65.9%\n        Syma   340    0.2%          0.2%\n Tanysiptera   886    0.6%          0.6%\n Todiramphus 40892   29.0%         29.1%\n        &lt;NA&gt;   116    0.1%             -\n\nbirds |&gt;\n  tabyl(species) |&gt;\n  adorn_pct_formatting()\n\n                  species     n percent valid_percent\n             Ceyx azureus  5248    3.7%          3.8%\n            Ceyx pusillus   658    0.5%          0.5%\n           Dacelo leachii  7264    5.2%          5.3%\n      Dacelo novaeguineae 85425   60.7%         61.9%\n            Syma torotoro   340    0.2%          0.2%\n       Tanysiptera sylvia   886    0.6%          0.6%\n      Todiramphus chloris    29    0.0%          0.0%\n    Todiramphus macleayii  9866    7.0%          7.2%\n Todiramphus pyrrhopygius  2322    1.6%          1.7%\n      Todiramphus sanctus 25938   18.4%         18.8%\n                     &lt;NA&gt;  2859    2.0%             -\n\n\n\n\n\n\n\n\n\nSyma torotoro perched on a branch. Photo by Matt Goodwin CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summarise</span>"
    ]
  },
  {
    "objectID": "1_exploring/summarise.html#spatial",
    "href": "1_exploring/summarise.html#spatial",
    "title": "2  Summarise",
    "section": "2.2 Spatial",
    "text": "2.2 Spatial\n\n2.2.1 Counts by region\nIt can be useful to summarise occurrence numbers by a specific region. With galah, you can do this summarising prior to downloading occurrence records.\nFor example, you might wish to summarise your data by state/territory. We can search for the correct field to use in galah, determining that field ID cl22 contains “Australian States and Territories” and seems to suit our needs best.\n\nsearch_all(fields, \"states\")\n\n# A tibble: 6 × 3\n  id       description                            type  \n  &lt;chr&gt;    &lt;chr&gt;                                  &lt;chr&gt; \n1 cl2013   ASGS Australian States and Territories fields\n2 cl22     Australian States and Territories      fields\n3 cl927    States including coastal waters        fields\n4 cl10925  PSMA States (2016)                     fields\n5 cl11174  States and Territories 2021            fields\n6 cl110925 PSMA States - Abbreviated (2016)       fields\n\n\nNow we can use the field ID cl22 to group our counts.\n\ngalah_call() |&gt;\n  identify(\"alcedinidae\") |&gt;\n  filter(year == 2022) |&gt;\n  group_by(cl22) |&gt;\n  atlas_counts()\n\n# A tibble: 8 × 2\n  cl22                         count\n  &lt;chr&gt;                        &lt;int&gt;\n1 Queensland                   51028\n2 New South Wales              39075\n3 Victoria                     23941\n4 Northern Territory            9870\n5 Western Australia             7860\n6 Australian Capital Territory  3518\n7 South Australia               2504\n8 Tasmania                      2500\n\n\nWe can also group our counts by state/territory and a taxonomic rank like genus.\n\ngalah_call() |&gt;\n  identify(\"alcedinidae\") |&gt;\n  filter(year == 2022) |&gt;\n  group_by(cl22, genus) |&gt;\n  atlas_counts()\n\n# A tibble: 26 × 3\n   cl22            genus       count\n   &lt;chr&gt;           &lt;chr&gt;       &lt;int&gt;\n 1 Queensland      Dacelo      27383\n 2 Queensland      Todiramphus 19692\n 3 Queensland      Ceyx         2632\n 4 Queensland      Tanysiptera   902\n 5 Queensland      Syma          347\n 6 New South Wales Dacelo      29944\n 7 New South Wales Todiramphus  7636\n 8 New South Wales Ceyx         1484\n 9 Victoria        Dacelo      19655\n10 Victoria        Todiramphus  3763\n# ℹ 16 more rows\n\n\nOur results show that we have the most records in Queensland and New South Wales.\nYou can get the same summaries after downloading the data locally with dplyr and janitor.\n\ndplyrjanitor\n\n\n\n# Using our pre-downloaded dataset\nbirds |&gt;\n  group_by(cl22) |&gt;\n  count() |&gt;\n  arrange(desc(n))\n\n# A tibble: 9 × 2\n# Groups:   cl22 [9]\n  cl22                             n\n  &lt;chr&gt;                        &lt;int&gt;\n1 Queensland                   50295\n2 New South Wales              38868\n3 Victoria                     24075\n4 Northern Territory            9789\n5 Western Australia             7654\n6 Australian Capital Territory  3519\n7 South Australia               2474\n8 Tasmania                      2443\n9 &lt;NA&gt;                          1718\n\nbirds |&gt;\n  group_by(cl22, species) |&gt;\n  count() |&gt;\n  arrange(desc(n))\n\n# A tibble: 59 × 3\n# Groups:   cl22, species [59]\n   cl22               species                   n\n   &lt;chr&gt;              &lt;chr&gt;                 &lt;int&gt;\n 1 New South Wales    Dacelo novaeguineae   29826\n 2 Queensland         Dacelo novaeguineae   23920\n 3 Victoria           Dacelo novaeguineae   19786\n 4 Queensland         Todiramphus sanctus   10254\n 5 New South Wales    Todiramphus sanctus    6766\n 6 Queensland         Todiramphus macleayii  6360\n 7 Western Australia  Dacelo novaeguineae    3964\n 8 Victoria           Todiramphus sanctus    3762\n 9 Northern Territory Todiramphus macleayii  3138\n10 Queensland         Dacelo leachii         3124\n# ℹ 49 more rows\n\n\n\n\n\n# Using our pre-downloaded dataset\nbirds |&gt;\n  tabyl(cl22) |&gt;\n  adorn_pct_formatting()\n\n                         cl22     n percent valid_percent\n Australian Capital Territory  3519    2.5%          2.5%\n              New South Wales 38868   27.6%         27.9%\n           Northern Territory  9789    7.0%          7.0%\n                   Queensland 50295   35.7%         36.2%\n              South Australia  2474    1.8%          1.8%\n                     Tasmania  2443    1.7%          1.8%\n                     Victoria 24075   17.1%         17.3%\n            Western Australia  7654    5.4%          5.5%\n                         &lt;NA&gt;  1718    1.2%             -\n\nbirds |&gt;\n  tabyl(cl22, species) |&gt;\n  adorn_pct_formatting()\n\n                         cl22 Ceyx azureus Ceyx pusillus Dacelo leachii\n Australian Capital Territory      4700.0%          0.0%           0.0%\n              New South Wales    146700.0%          0.0%           0.0%\n           Northern Territory     93000.0%      11300.0%      304200.0%\n                   Queensland    202600.0%      53700.0%      312400.0%\n              South Australia       200.0%          0.0%           0.0%\n                     Tasmania      2100.0%          0.0%           0.0%\n                     Victoria     51700.0%          0.0%           0.0%\n            Western Australia     16300.0%          0.0%      106000.0%\n                         &lt;NA&gt;      7500.0%        800.0%        3800.0%\n Dacelo novaeguineae Syma torotoro Tanysiptera sylvia Todiramphus chloris\n           283600.0%          0.0%               0.0%                0.0%\n          2982600.0%          0.0%               0.0%              800.0%\n                0.0%          0.0%               0.0%                0.0%\n          2392000.0%      33800.0%           88500.0%              100.0%\n           184900.0%          0.0%               0.0%                0.0%\n           240200.0%          0.0%               0.0%                0.0%\n          1978600.0%          0.0%               0.0%                0.0%\n           396400.0%          0.0%               0.0%             1300.0%\n            84200.0%        200.0%             100.0%              700.0%\n Todiramphus macleayii Todiramphus pyrrhopygius Todiramphus sanctus       NA_\n                  0.0%                     0.0%            63600.0%      0.0%\n              33300.0%                 24700.0%           676600.0%  22100.0%\n             313800.0%                 74600.0%           145300.0%  36700.0%\n             636000.0%                 74400.0%          1025400.0% 210600.0%\n                  0.0%                 26800.0%            35200.0%    300.0%\n                  0.0%                     0.0%             2000.0%      0.0%\n                  0.0%                   800.0%           376200.0%    200.0%\n                  0.0%                 30800.0%           211800.0%   2800.0%\n               3500.0%                   100.0%            57700.0%  13200.0%\n\n\n\n\n\n\n\n\n\nDacelo (Dacelo) novaeguineae perched on a backyard fence. Photo by laura_free19 CC-BY-NC 4.0 (Int)\n\n\n\n2.2.2 Maps\nWe can use maps to visualise summaries of our data. To illustrate, we will use the sf package to handle spatial data, and the ozmaps package to get maps of Australia (as vector data).\n\nlibrary(sf)\nlibrary(ozmaps)\n\nThere are a few occurrence records in our birds dataset that are outside of Australia. For simplicity, we will filter our data to records within Australia’s land mass.\n\n# filter records to within Australia\nbirds_filtered &lt;- birds |&gt;\n  filter(decimalLongitude &gt; 110,\n         decimalLongitude &lt; 155, \n         decimalLatitude &gt; -45,\n         decimalLatitude &lt; -10)\n\nOur first step is to get a map of Australia from the ozmaps package. We will transform its Coordinate Reference System (CRS)1 projection to EPSG:4326 to match the CRS projection of ALA data2.\n\n# Get map of australia, and transform projection\naus &lt;- ozmaps::ozmap_states |&gt;\n  st_transform(crs = st_crs(4326))\n\nThen we can plot our occurrence points onto our map.\n\nPoint mapPoint density mapFacetted maps\n\n\nPoint maps are quick and effective ways to visually inspect the locations of your occurrence records. Here we have also adjusted the size and alpha values to make the points larger and more transparent.\n\n# Plot the observations on our map of Australia\nggplot() +\n  geom_sf(data = aus, \n          colour = \"grey60\", \n          fill = \"white\") +\n  geom_point(data = birds_filtered,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude),\n             colour = \"#428afe\",\n             size = 1.8, \n             alpha = 0.6) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\nWe can use the ggpointdensity package to visualise locations with many overlapping occurrences. With over 40,000 points plotted on our map, geom_pointdensity() allows us to see areas with higher densities of observations.\n\nlibrary(ggpointdensity)\nlibrary(viridis) # colour palette\n\nggplot() +\n  geom_sf(data = aus, \n          colour = \"grey60\", \n          fill = \"white\") +\n  geom_pointdensity(data = birds_filtered,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude),\n             size = 1.8, \n             alpha = 0.6) +\n  scale_colour_viridis_c(option = \"F\",     # palette\n                         end = .8,         # final light colour value\n                         direction = -1) + # reverse light-to-dark\n  guides(\n    colour = guide_colourbar(\n      title = \"Number of\\noverlapping\\nobservations\")\n    ) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\nIt can also be useful to create a collection of maps grouped by a specific variable (i.e., facetted). Here is one taxonomic example, grouping by species with facet_wrap(). Visualising by groups can reveal spatial trends, and also help you determine whether there is enough data for each species or taxonomic group for your later analyses.\n\nggplot() +\n  geom_sf(data = aus, \n          colour = \"grey60\", \n          fill = \"white\") +\n  geom_point(data = birds_filtered |&gt; \n               drop_na(species), # remove NA values \n             aes(x = decimalLongitude, \n                 y = decimalLatitude,\n                 colour = species),\n             size = 1.8, \n             alpha = 0.6) +\n  pilot::scale_color_pilot() +\n  theme_void() + \n  facet_wrap( ~ species) + \n  theme(legend.position = \"none\")",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summarise</span>"
    ]
  },
  {
    "objectID": "1_exploring/summarise.html#temporal",
    "href": "1_exploring/summarise.html#temporal",
    "title": "2  Summarise",
    "section": "2.3 Temporal",
    "text": "2.3 Temporal\n\n2.3.1 Counts by time scales\nUnderstanding the distribution of when observations are recorded can reveal seasonal trends among species. Checking this distribution can also help you determine whether you have enough data to infer patterns over different time spans—such as a week, month, year, decade, or even century—or whether your inferences about temporal trends are limited by the available data.\n\nYear\nFor example, an easy first summary is to know the number of records in each year. You can do this in galah prior to downloading data. We can search for the correct field to use in galah, determining that field ID year seems to suit our needs best.\n\nsearch_all(fields, \"year\")\n\n# A tibble: 8 × 3\n  id                  description            type  \n  &lt;chr&gt;               &lt;chr&gt;                  &lt;chr&gt; \n1 year                Year                   fields\n2 raw_year            Year (unprocessed)     fields\n3 endDayOfYear        End Day Of Year        fields\n4 startDayOfYear      Start Day Of Year      fields\n5 occurrenceYear      Date (by year)         fields\n6 raw_endDayOfYear    &lt;NA&gt;                   fields\n7 raw_startDayOfYear  &lt;NA&gt;                   fields\n8 namePublishedInYear Name Published In Year fields\n\n\nNow we can use the field ID year to group our counts, returning years 2016 and onwards.\n\ngalah_call() |&gt;\n  identify(\"alcedinidae\") |&gt;\n  filter(year &gt; 2016) |&gt;\n  group_by(year) |&gt;\n  atlas_counts()\n\n# A tibble: 8 × 2\n  year   count\n  &lt;chr&gt;  &lt;int&gt;\n1 2023  172918\n2 2022  142050\n3 2021  129197\n4 2020  109432\n5 2018   96343\n6 2019   94693\n7 2017   79232\n8 2024   61509\n\n\nAlternatively, you can use the lubridate package to summarise after downloading counts.\nWe’ll convert our column eventDate to a date class in R. Then we can extract relevant date data…\n\n# Using our pre-downloaded dataset\nlibrary(lubridate)\n\nbirds_date &lt;- birds |&gt;\n  mutate(eventDate = date(eventDate), # convert to date\n         year = year(eventDate),      # extract year\n         month = month(eventDate,     # extract month\n                       label = TRUE))\n\nbirds_date |&gt;\n  select(scientificName, eventDate, year, month)\n\n# A tibble: 140,835 × 4\n   scientificName                    eventDate   year month\n   &lt;chr&gt;                             &lt;date&gt;     &lt;dbl&gt; &lt;ord&gt;\n 1 Dacelo (Dacelo) novaeguineae      2022-04-19  2022 Apr  \n 2 Dacelo (Dacelo) novaeguineae      2022-12-25  2022 Dec  \n 3 Dacelo (Dacelo) novaeguineae      2022-10-27  2022 Oct  \n 4 Dacelo (Dacelo) novaeguineae      2022-01-23  2022 Jan  \n 5 Dacelo (Dacelo) novaeguineae      2022-11-09  2022 Nov  \n 6 Todiramphus (Todiramphus) sanctus 2022-02-05  2022 Feb  \n 7 Todiramphus (Todiramphus) sanctus 2022-11-24  2022 Nov  \n 8 Dacelo (Dacelo) novaeguineae      2022-10-01  2022 Oct  \n 9 Dacelo (Dacelo) novaeguineae      2022-03-21  2022 Mar  \n10 Dacelo (Dacelo) novaeguineae      2022-08-14  2022 Aug  \n# ℹ 140,825 more rows\n\n\n…and summarise using dplyr or janitor.\n\ndplyrjanitor\n\n\n\n# by year\nbirds_date |&gt;   \n  group_by(year) |&gt;\n  count()\n\n# A tibble: 3 × 2\n# Groups:   year [3]\n   year      n\n  &lt;dbl&gt;  &lt;int&gt;\n1  2021      4\n2  2022 140827\n3    NA      4\n\n\n\n# by month\nbirds_date |&gt;\n  group_by(month) |&gt;\n  count() |&gt;\n  arrange(-desc(month))\n\n# A tibble: 13 × 2\n# Groups:   month [13]\n   month     n\n   &lt;ord&gt; &lt;int&gt;\n 1 Jan   14772\n 2 Feb    9300\n 3 Mar    8845\n 4 Apr    9492\n 5 May    8598\n 6 Jun    9073\n 7 Jul   10703\n 8 Aug   11954\n 9 Sep   13421\n10 Oct   16127\n11 Nov   14451\n12 Dec   14095\n13 &lt;NA&gt;      4\n\n\n\n\n\n# by year\nbirds_date |&gt;\n  tabyl(year) |&gt;\n  adorn_pct_formatting()\n\n year      n percent valid_percent\n 2021      4    0.0%          0.0%\n 2022 140827  100.0%        100.0%\n   NA      4    0.0%             -\n\n\n\n# by month\nbirds_date |&gt;\n  tabyl(month) |&gt;\n  arrange(desc(month))\n\n month     n      percent valid_percent\n   Dec 14095 1.000817e-01    0.10008450\n   Nov 14451 1.026094e-01    0.10261235\n   Oct 16127 1.145099e-01    0.11451314\n   Sep 13421 9.529591e-02    0.09529862\n   Aug 11954 8.487947e-02    0.08488188\n   Jul 10703 7.599673e-02    0.07599889\n   Jun  9073 6.442291e-02    0.06442474\n   May  8598 6.105017e-02    0.06105190\n   Apr  9492 6.739802e-02    0.06739993\n   Mar  8845 6.280399e-02    0.06280577\n   Feb  9300 6.603472e-02    0.06603660\n   Jan 14772 1.048887e-01    0.10489168\n  &lt;NA&gt;     4 2.840203e-05            NA\n\n\n\n\n\n\n\n\n\nTanysiptera (Uralcyon) sylvia perched on a branch. Photo by Kris Bernard CC-BY-NC 4.0 (Int)\n\n\n\nLine plots\nAnother way to summarise temporal data is using line plots to visualise trends at different time scales over one or more years.\nThere are a few records that seem to be from 2021 despite downloading data for 20223. For simplicity, we’ll filter them out.\n\n# filter dataset to 2022 only\nbirds_day &lt;- birds_date |&gt;\n  filter(year(eventDate) == 2022) |&gt;\n  mutate(day = yday(eventDate))\n\nNow we can group our records by each day of the year, and summarise the record count for each day…\n\nbirds_day &lt;- birds_day |&gt;\n  group_by(day) |&gt;\n  summarise(count = n()) \nbirds_day\n\n# A tibble: 365 × 2\n     day count\n   &lt;dbl&gt; &lt;int&gt;\n 1     1   892\n 2     2   746\n 3     3   692\n 4     4   595\n 5     5   461\n 6     6   441\n 7     7   398\n 8     8   572\n 9     9   683\n10    10   434\n# ℹ 355 more rows\n\n\n…which we can visualise as a line plot. There are huge fluctuations in our daily count data (from near zero to nearly 1000 observations), so to make the plot easier to read, we can use a log10 scale.\n\nggplot(birds_day, aes(x = day, y = count)) +\n  geom_line() +  # Add lines\n  geom_point() + # Add points\n  labs(x = \"Day\", y = \"Count (log10)\") +\n  scale_x_continuous(breaks = seq(1, 365, by = 30)) +\n  scale_y_log10() +  # Set logarithmic scale for y-axis\n  theme_minimal()  # Set a minimal theme\n\n\n\n\nNumber of observations per day (2022)\n\n\n\n\nThe same method above can be used to group record counts by week4.\n\n\nCode\nbirds_week &lt;- birds_date |&gt;\n  filter(year(eventDate) == 2022) |&gt;\n  mutate(\n    week = week(eventDate)) |&gt;\n  group_by(week) |&gt;\n  summarise(count = n()) \n\nggplot(birds_week, aes(x = week, y = count)) +\n  geom_line() +  # Add lines\n  geom_point() + # Add points\n  labs(x = \"Week\", y = \"Count\") +\n  scale_x_continuous(breaks = seq(1, 52, by = 4)) + \n  theme_minimal()  # Set a minimal theme\n\n\n\n\n\nNumber of observations per week (2022)\n\n\n\n\nOur temporal plots show that occurrences generally drop in the earlier months, then inflate in the later months of the year.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summarise</span>"
    ]
  },
  {
    "objectID": "1_exploring/summarise.html#summary",
    "href": "1_exploring/summarise.html#summary",
    "title": "2  Summarise",
    "section": "2.4 Summary",
    "text": "2.4 Summary\nIn this chapter we have provided a few ways to summarise your data taxonomically, spatially, and temporally. We hope that these code chunks will help you in summarising your own data. Summarising and visualising data are some of the most useful ways to spot errors for data cleaning. As such, we suggest using these tools often though the course of your analysis.\nIn the next part of this book, we will tackle these issues to clean your dataset.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summarise</span>"
    ]
  },
  {
    "objectID": "1_exploring/summarise.html#footnotes",
    "href": "1_exploring/summarise.html#footnotes",
    "title": "2  Summarise",
    "section": "",
    "text": "The Coordinate Reference System (CRS) determines how to display our shape of Australia, which exists on a spherical globe (the Earth), onto a flat surface (our map).↩︎\nData from the ALA use EPSG:4326 (also known as “WGS84”) as the Coordinate Reference System. Transforming our map to the same projection of our data ensures the points are plotted in their actual locations on the map.↩︎\nThis is due to timezone conversion when the ALA standardises its data. There are several timezones across Australia, so although these points might have been in 2022, once converted they fell outside of 2022!↩︎\nNotice, though, that we’ve ommitted the log scale because grouping by week has less variation in counts than by day (above).↩︎",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summarise</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/column-names-and-classes.html",
    "href": "2_general-cleaning/column-names-and-classes.html",
    "title": "3  Column classes & names",
    "section": "",
    "text": "3.0.1 Prerequisites\nIn this chapter, we will use Litoria frog occurrence data since 2020 in Tasmania from the ALA.\n# packages\nlibrary(galah)\nlibrary(dplyr)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\nfrogs &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.dde3e89f-28bf-4515-9128-ab18bce19a08\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Column classes & names</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/column-names-and-classes.html#column-classes",
    "href": "2_general-cleaning/column-names-and-classes.html#column-classes",
    "title": "3  Column classes & names",
    "section": "3.1 Column classes",
    "text": "3.1 Column classes\nColumns define what type of data they contain by having a class, and it’s important to know what these classes are because R handles each class differently.\nViewing your data using functions we introduced in the Inspect chapter allows you to get a quick overview of each column’s class.\n\nglimpse()str()skim()sapply()map()\n\n\nUsing glimpse() displays the class beside each column name (e.g. &lt;chr&gt;)\n\nlibrary(dplyr)\n\nglimpse(frogs)\n\nRows: 2,763\nColumns: 10\n$ recordID         &lt;chr&gt; \"00052544-d943-42e9-bd85-83693c6dd824\", \"00168ca6-84d…\n$ scientificName   &lt;chr&gt; \"Litoria ewingii\", \"Litoria raniformis\", \"Litoria ewi…\n$ taxonConceptID   &lt;chr&gt; \"https://biodiversity.org.au/afd/taxa/1c89eedb-42b6-4…\n$ decimalLatitude  &lt;dbl&gt; -42.87917, -41.19207, -42.98559, -41.15305, -42.85886…\n$ decimalLongitude &lt;dbl&gt; 147.4754, 146.4331, 147.0589, 146.5241, 147.6137, 147…\n$ eventDate        &lt;dttm&gt; 2022-09-19 00:00:00, 2023-12-20 23:20:19, 2021-08-07…\n$ occurrenceStatus &lt;chr&gt; \"PRESENT\", \"PRESENT\", \"PRESENT\", \"PRESENT\", \"PRESENT\"…\n$ dataResourceName &lt;chr&gt; \"FrogID\", \"iNaturalist Australia\", \"FrogID\", \"iNatura…\n$ genus            &lt;chr&gt; \"Litoria\", \"Litoria\", \"Litoria\", \"Litoria\", \"Litoria\"…\n$ species          &lt;chr&gt; \"Litoria ewingii\", \"Litoria raniformis\", \"Litoria ewi…\n\n\n\n\nUsing str() displays the class after the column name and before the number of rows (e.g. chr)\n\nstr(frogs)\n\nspc_tbl_ [2,763 × 10] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ recordID        : chr [1:2763] \"00052544-d943-42e9-bd85-83693c6dd824\" \"00168ca6-84d0-4af1-8fa8-875fd69d25da\" \"001a43fe-8586-4064-9e76-7373a837a759\" \"00250163-ec50-4eda-a5d5-58ae98bc5834\" ...\n $ scientificName  : chr [1:2763] \"Litoria ewingii\" \"Litoria raniformis\" \"Litoria ewingii\" \"Litoria raniformis\" ...\n $ taxonConceptID  : chr [1:2763] \"https://biodiversity.org.au/afd/taxa/1c89eedb-42b6-4675-b688-2e0b59ea689e\" \"https://biodiversity.org.au/afd/taxa/89a7a289-bf04-40e0-aaef-7ec6bc968a9c\" \"https://biodiversity.org.au/afd/taxa/1c89eedb-42b6-4675-b688-2e0b59ea689e\" \"https://biodiversity.org.au/afd/taxa/89a7a289-bf04-40e0-aaef-7ec6bc968a9c\" ...\n $ decimalLatitude : num [1:2763] -42.9 -41.2 -43 -41.2 -42.9 ...\n $ decimalLongitude: num [1:2763] 147 146 147 147 148 ...\n $ eventDate       : POSIXct[1:2763], format: \"2022-09-19 00:00:00\" \"2023-12-20 23:20:19\" ...\n $ occurrenceStatus: chr [1:2763] \"PRESENT\" \"PRESENT\" \"PRESENT\" \"PRESENT\" ...\n $ dataResourceName: chr [1:2763] \"FrogID\" \"iNaturalist Australia\" \"FrogID\" \"iNaturalist Australia\" ...\n $ genus           : chr [1:2763] \"Litoria\" \"Litoria\" \"Litoria\" \"Litoria\" ...\n $ species         : chr [1:2763] \"Litoria ewingii\" \"Litoria raniformis\" \"Litoria ewingii\" \"Litoria raniformis\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   recordID = col_character(),\n  ..   scientificName = col_character(),\n  ..   taxonConceptID = col_character(),\n  ..   decimalLatitude = col_double(),\n  ..   decimalLongitude = col_double(),\n  ..   eventDate = col_datetime(format = \"\"),\n  ..   occurrenceStatus = col_character(),\n  ..   dataResourceName = col_character(),\n  ..   genus = col_character(),\n  ..   species = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n - attr(*, \"doi\")= chr \"https://doi.org /10.26197/ala.dde3e89f-28bf-4515-9128-ab18bce19a08\"\n\n\n\n\nThe skim() function groups columns by their type/class.\n\nlibrary(skimr)\n\nskim(frogs)\n\n\nData summary\n\n\nName\nfrogs\n\n\nNumber of rows\n2763\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n7\n\n\nnumeric\n2\n\n\nPOSIXct\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nrecordID\n0\n1\n36\n36\n0\n2763\n0\n\n\nscientificName\n0\n1\n7\n18\n0\n5\n0\n\n\ntaxonConceptID\n0\n1\n73\n73\n0\n5\n0\n\n\noccurrenceStatus\n0\n1\n7\n7\n0\n1\n0\n\n\ndataResourceName\n0\n1\n6\n27\n0\n3\n0\n\n\ngenus\n0\n1\n7\n7\n0\n1\n0\n\n\nspecies\n1\n1\n15\n18\n0\n4\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndecimalLatitude\n0\n1\n-42.17\n0.85\n-43.49\n-42.95\n-42.50\n-41.34\n-39.64\n▇▁▆▂▁\n\n\ndecimalLongitude\n0\n1\n147.01\n0.70\n143.84\n146.92\n147.15\n147.34\n148.30\n▁▁▁▇▂\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n0\n1\n2020-01-02\n2024-06-05 12:06:00\n2021-11-16\n1181\n\n\n\n\n\n\n\nYou can return the class of every column using sapply() from base R.\n\nsapply(frogs, class)\n\n$recordID\n[1] \"character\"\n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$decimalLatitude\n[1] \"numeric\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$occurrenceStatus\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"\n\n$genus\n[1] \"character\"\n\n$species\n[1] \"character\"\n\n\n\n\nYou can return the class of every column using map() from the purrr package.\n\nlibrary(purrr)\n\nfrogs |&gt;\n  purrr::map(class)\n\n$recordID\n[1] \"character\"\n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$decimalLatitude\n[1] \"numeric\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$occurrenceStatus\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"\n\n$genus\n[1] \"character\"\n\n$species\n[1] \"character\"\n\n\n\n\n\nIf you are using a tibble, the class is also displayed below each column name when you view your table. Depending on whether your output is in the console or inline, your tibble may be formatted as a paged table in R Studio.\n\nConsoleInline\n\n\n\nfrogs\n\n# A tibble: 2,763 × 10\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 00052544-d943… Litoria ewing… https://biodi…           -42.9             147.\n 2 00168ca6-84d0… Litoria ranif… https://biodi…           -41.2             146.\n 3 001a43fe-8586… Litoria ewing… https://biodi…           -43.0             147.\n 4 00250163-ec50… Litoria ranif… https://biodi…           -41.2             147.\n 5 003e0f63-9f95… Litoria ewing… https://biodi…           -42.9             148.\n 6 0070521f-bb45… Litoria ewing… https://biodi…           -43.1             147.\n 7 00898021-7ad3… Litoria ewing… https://biodi…           -42.8             147.\n 8 00a64bc4-f727… Litoria ewing… https://biodi…           -43.1             148.\n 9 00ab3454-6e77… Litoria ewing… https://biodi…           -41.6             147.\n10 00d33f5b-9cd7… Litoria ewing… https://biodi…           -43.0             147.\n# ℹ 2,753 more rows\n# ℹ 5 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;\n\n\n\n\n\nfrogs |&gt; rmarkdown::paged_table()\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\nOur data classes:\n\n\n\n\n\nFrom these quick overviews of the data, we’ve learned:\n\nColumn scientificName is strings of text (type character)\nColumns decimalLatitude and decimalLongitude are numbers with decimal points (type double)\nThe eventDate column contains a date + time (type POSIXct/dttm)\nColumns like recordID and taxonConceptID contain both text and numbers, but are of type character because this type prevents any loss of data1.\n\n\n\n\nHere, the column classes are what we’d expect given the types of data in each column. However, this is not always the case.\nFor instance, changing just one of the values in decimalLatitude from its assigned numeric value to a “degrees minutes seconds” format causes the entire column class to be changed to character to prevent loss of data.\n\n# duplicate data\nfrogs_class &lt;- frogs\n\n# check class\nclass(frogs_class$decimalLatitude)\n\n[1] \"numeric\"\n\n# change one of the values to a degrees minutes seconds format\nfrogs_class$decimalLatitude[5] &lt;- \"40° 51' 59 N\"\n\n# check class\nclass(frogs_class$decimalLatitude)\n\n[1] \"character\"\n\n\n\n\n\n\n\n\nLook out for typos\n\n\n\n\n\nA simple typo in the dataset you import into R could be all it takes to change the class of an entire column, so be sure to keep your eyes out for unexpected column classes!",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Column classes & names</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/column-names-and-classes.html#column-names",
    "href": "2_general-cleaning/column-names-and-classes.html#column-names",
    "title": "3  Column classes & names",
    "section": "3.2 Column names",
    "text": "3.2 Column names\nThere are many reasons why you might need to change the name of one or more columns in a table. We’ve outlined a few of the more common use cases here.\n\n3.2.1 Make column names consistent\nColumn names should use consistent naming conventions. R is case sensitive, so two names with the same letters but different capitalisations are considered different names (e.g. event vs. Event). Using a naming convention which is both human- and machine-readable (e.g. camel case, snake case), and being consistent in your usage of it, makes it less likely that you will make these sorts of errors.\nCamel case begins in lowercase and uses uppercase for the first letter of every subsequent word (e.g. scientificName, dataResourceName, eventDate).\nSnake case uses lowercase letters only, with words separated by an underscore _ (e.g. scientific_name, data_resource_name, event_date).\nSnake case is more popular in R, and is the naming convention we recommend. Data downloaded from the ALA is in camel case2.\n\ncolnames(frogs)\n\n [1] \"recordID\"         \"scientificName\"   \"taxonConceptID\"   \"decimalLatitude\" \n [5] \"decimalLongitude\" \"eventDate\"        \"occurrenceStatus\" \"dataResourceName\"\n [9] \"genus\"            \"species\"         \n\n\nOne of the most useful column name cleaning functions is clean_names() from the janitor package. This function will make all of your column names consistent, based on your preferred naming convention (defaults to snake case).\n\nlibrary(janitor)\n\nfrogs_clean &lt;- frogs |&gt;\n  clean_names() |&gt;\n  colnames()\nfrogs_clean\n\n [1] \"record_id\"          \"scientific_name\"    \"taxon_concept_id\"  \n [4] \"decimal_latitude\"   \"decimal_longitude\"  \"event_date\"        \n [7] \"occurrence_status\"  \"data_resource_name\" \"genus\"             \n[10] \"species\"           \n\n\nNow our names are in a consistent snake_case format.\n\n\nCode\nfrogs |&gt;\n  clean_names() |&gt;\n  rmarkdown::paged_table() # nice format\n\n\n\n  \n\n\n\n\n\n\n\nLitoria ewingii nestled in the mud. Photo by george_vaughan CC-BY-NC 4.0 (Int)\n\n\n\n3.2.2 Rename columns\nRenaming columns is a common data cleaning task. It may be necessary to rename columns to clarify the data they contain or to ensure consistency with another dataset before merging them.\nThere are several ways to rename columns in R.\n\n\nrename()names() + &lt;-\n\n\ndplyr::rename() provides an easy way to rename one or more columns.\n\nfrogs |&gt;\n  select(decimalLatitude, decimalLongitude) |&gt;\n  rename(latitude = decimalLatitude,\n         longitude = decimalLongitude) \n\n# A tibble: 2,763 × 2\n   latitude longitude\n      &lt;dbl&gt;     &lt;dbl&gt;\n 1    -42.9      147.\n 2    -41.2      146.\n 3    -43.0      147.\n 4    -41.2      147.\n 5    -42.9      148.\n 6    -43.1      147.\n 7    -42.8      147.\n 8    -43.1      148.\n 9    -41.6      147.\n10    -43.0      147.\n# ℹ 2,753 more rows\n\n\nrename_with() is a more powerful version of rename(). It allows more advanced renaming by using functions to rename matching columns. Here we convert column names starting with “decimal” to uppercase.\n\nfrogs |&gt;\n  select(decimalLatitude, decimalLongitude) |&gt;\n  rename_with(toupper, starts_with(\"decimal\"))\n\n# A tibble: 2,763 × 2\n   DECIMALLATITUDE DECIMALLONGITUDE\n             &lt;dbl&gt;            &lt;dbl&gt;\n 1           -42.9             147.\n 2           -41.2             146.\n 3           -43.0             147.\n 4           -41.2             147.\n 5           -42.9             148.\n 6           -43.1             147.\n 7           -42.8             147.\n 8           -43.1             148.\n 9           -41.6             147.\n10           -43.0             147.\n# ℹ 2,753 more rows\n\n\nAnd here we append the prefix “new_” to columns with names containing “decimal”, and convert them to lowercase.\n\nfrogs |&gt;\n  select(decimalLatitude, decimalLongitude) |&gt;\n1  rename_with( ~ tolower(gsub(\"decimal\", \"new_\", .x, fixed = TRUE)))\n\n\n1\n\n.x is shorthand for the variable this function will be applied to. In this case, .x refers to our frogs data frame.\n\n\n\n\n# A tibble: 2,763 × 2\n   new_latitude new_longitude\n          &lt;dbl&gt;         &lt;dbl&gt;\n 1        -42.9          147.\n 2        -41.2          146.\n 3        -43.0          147.\n 4        -41.2          147.\n 5        -42.9          148.\n 6        -43.1          147.\n 7        -42.8          147.\n 8        -43.1          148.\n 9        -41.6          147.\n10        -43.0          147.\n# ℹ 2,753 more rows\n\n\n\n\nIndex a specific column name in base R with the help of names(). Assign a new column name to replace an old column name using the assignment operator &lt;-.\n\nnames(frogs)[names(frogs) == \"decimalLatitude\"] &lt;- \"latitude\"\nnames(frogs)[names(frogs) == \"decimalLongitude\"] &lt;- \"longitude\"\n\nfrogs[,c(\"latitude\", \"longitude\")]\n\n# A tibble: 2,763 × 2\n   latitude longitude\n      &lt;dbl&gt;     &lt;dbl&gt;\n 1    -42.9      147.\n 2    -41.2      146.\n 3    -43.0      147.\n 4    -41.2      147.\n 5    -42.9      148.\n 6    -43.1      147.\n 7    -42.8      147.\n 8    -43.1      148.\n 9    -41.6      147.\n10    -43.0      147.\n# ℹ 2,753 more rows\n\n\n\n\n\n\n\n3.2.3 Separate columns\nSometimes it is useful to split information from one column into several columns. One good example is if genus and species names are contained in one column like scientificName. We can separate these names into two columns using separate() from the tidyr package.\n\nlibrary(tidyr)\n\nfrogs_separate &lt;- frogs |&gt;\n  separate(scientificName, \n           c(\"genus\", \"species\"), # new column names\n           fill = \"right\",        # fill missing values in right column\n           remove = FALSE         # keep input column\n           ) |&gt; \n  select(scientificName, genus, species)\n\nfrogs_separate |&gt; rmarkdown::paged_table() # nice format\n\n\n  \n\n\n\n\n\n3.2.4 Join columns\nConversely, we might want to combine information from multiple columns into a single column. We can rejoin the genus and species columns we created in the previous section using unite() from the tidyr package.\n\nfrogs_united &lt;- frogs_separate |&gt;\n  unite(\"single_name\", \n        genus:species, # select columns to join\n        sep = \" \",     # separate with a space\n        na.rm = TRUE,  # remove NA values\n        remove = FALSE # keep input column\n        ) |&gt;\n  select(genus, species, single_name)\n\nfrogs_united |&gt; rmarkdown::paged_table() # nice format\n\n\n  \n\n\n\n\n\n\n\nLitoria raniformis close-up Photo by sonyaf CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Column classes & names</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/column-names-and-classes.html#summary",
    "href": "2_general-cleaning/column-names-and-classes.html#summary",
    "title": "3  Column classes & names",
    "section": "3.3 Summary",
    "text": "3.3 Summary\nIn this chapter, we explored different ways to check the class of each column in your table to make sure R is interpreting your data correctly. We also demonstrated how to rename columns for easier handling and how to split or combine columns to access data more conveniently.\nIn this chapter, we examined various methods to verify the class of each column in your table, ensuring that R correctly interprets your data. We also demonstrated how to rename columns for easier handling and how to split or combine columns for more convenient data access.\nIn the next chapter, we will learn how to efficiently clean duplicate data. Duplicates can arise from errors in data collection or entry, or from merging data from multiple sources.",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Column classes & names</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/column-names-and-classes.html#footnotes",
    "href": "2_general-cleaning/column-names-and-classes.html#footnotes",
    "title": "3  Column classes & names",
    "section": "",
    "text": "To avoid conflicts, R has an internal coercion hierarchy rule to avoid data loss. The rule of thumb is that if a data type can’t exist in a child data type, then the parent data type is used instead. The R coercion hierarchy is: logical -&gt; integer -&gt; numeric -&gt; complex -&gt; characterYou don’t need to memorise this, but it’s worth being aware of this hierarchy, as R might make decisions to prevent a class error and you might not know why! Learn more in this article.↩︎\nQueries to the ALA use other coding languages, namely solr and JSON, and column names in these languages are typically in camel case. To maintain consistency with what’s in the ALA and to avoid hidden name cleaning, galah also returns names in camel case.↩︎",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Column classes & names</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/duplicates.html",
    "href": "2_general-cleaning/duplicates.html",
    "title": "4  Duplicates",
    "section": "",
    "text": "4.0.1 Prerequisites\nIn this chapter, we will use kingfisher (Alcedinidae) occurrence data in 2023 from the ALA.\n# packages\nlibrary(galah)\nlibrary(dplyr)\nlibrary(janitor)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\nbirds &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.37497b54-2bcb-4d47-bf43-823ee137d816\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Duplicates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/duplicates.html#find-duplicates",
    "href": "2_general-cleaning/duplicates.html#find-duplicates",
    "title": "4  Duplicates",
    "section": "4.1 Find duplicates",
    "text": "4.1 Find duplicates\nAs an first example, let’s remove all spatially-duplicated records, based on latitude and longitude coordinate values.\nThe first thing to do is find the duplicate records.\n\ndplyrjanitor\n\n\nReturn a summary of the number of duplicates for each set of coordinates.\n\nbirds |&gt; \n  group_by(decimalLongitude, decimalLatitude) |&gt;\n  filter(n() &gt; 1) |&gt;\n  summarise(n = n(), .groups = \"drop\")\n\n# A tibble: 5,263 × 3\n   decimalLongitude decimalLatitude     n\n              &lt;dbl&gt;           &lt;dbl&gt; &lt;int&gt;\n 1             115.           -34.1     2\n 2             115.           -33.8     2\n 3             115.           -33.7     2\n 4             115.           -33.6     2\n 5             115.           -34.0     2\n 6             115.           -33.9    12\n 7             115.           -33.9     2\n 8             115.           -33.6     2\n 9             115.           -33.6     2\n10             115.           -33.6     2\n# ℹ 5,253 more rows\n\n\nReturn a summary of duplicate decimal longitude and latitude rows in the entire dataset.\n\nbirds |&gt;\n  filter(duplicated(decimalLongitude) & duplicated(decimalLatitude))\n\n# A tibble: 27,297 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0036fdd3-947e… Todiramphus (… https://biodi…           -35.3             149.\n 2 006cea57-9ec8… Dacelo (Dacel… https://biodi…           -33.9             151.\n 3 007a75a3-aba2… Dacelo (Dacel… https://biodi…           -27.5             153.\n 4 007b39cf-2660… Todiramphus (… https://biodi…           -27.4             153.\n 5 0090348a-41bb… Todiramphus (… https://biodi…           -27.4             153.\n 6 009dd9a8-e12b… Todiramphus (… https://biodi…           -27.4             153.\n 7 00bde3fa-6095… Dacelo (Dacel… https://biodi…           -19.4             147.\n 8 00e8c718-f305… Dacelo (Dacel… https://biodi…           -31.7             116.\n 9 00fe93fc-86b9… Dacelo (Dacel… https://biodi…           -27.4             153.\n10 01006006-78b2… Todiramphus (… https://biodi…           -19.2             147.\n# ℹ 27,287 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n\n\n\nReturn duplicated rows and the number of duplicates of decimalLatitude OR decimalLongitude (note that this differs from the dplyr example because janitor uses commas as an OR statement).\n\nbirds |&gt; \n  get_dupes(decimalLatitude, decimalLongitude)\n\n# A tibble: 32,533 × 14\n   decimalLatitude decimalLongitude dupe_count recordID           scientificName\n             &lt;dbl&gt;            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;              &lt;chr&gt;         \n 1           -27.4             153.        686 00018120-2238-412… Dacelo (Dacel…\n 2           -27.4             153.        686 007b39cf-2660-415… Todiramphus (…\n 3           -27.4             153.        686 0090348a-41bb-4f3… Todiramphus (…\n 4           -27.4             153.        686 009dd9a8-e12b-45d… Todiramphus (…\n 5           -27.4             153.        686 00fe93fc-86b9-4cd… Dacelo (Dacel…\n 6           -27.4             153.        686 017e052c-dd85-43d… Todiramphus (…\n 7           -27.4             153.        686 01bda731-b532-43c… Dacelo (Dacel…\n 8           -27.4             153.        686 023f2c30-93a9-4d6… Dacelo (Dacel…\n 9           -27.4             153.        686 03d44a01-7863-469… Todiramphus (…\n10           -27.4             153.        686 03dee6d8-4ae9-46a… Todiramphus (…\n# ℹ 32,523 more rows\n# ℹ 9 more variables: taxonConceptID &lt;chr&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   species &lt;chr&gt;, cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n\n\n\n\nIn the above tibble our results show that there are just over 27,000 records that overlap spatially with duplicate coordinates. That seems like a lot! It would be rare to remove duplicates so broadly without considering why we need to remove duplicates; we don’t necessarily want to remove all of them.\nInstead, if we are interested in comparing species in our data, it might be more useful to find duplicate spatial records for each species. We can split our data by species and remove records where there is more than one observation of the same species in the same location. This should leave one observation for each species in each location.\nTo filter our duplicate data by species, we can first split our data by species…\n\nbirds |&gt;\n  group_split(species)\n\n\n\n&lt;list_of&lt;\n  tbl_df&lt;\n    recordID        : character\n    scientificName  : character\n    taxonConceptID  : character\n    decimalLatitude : double\n    decimalLongitude: double\n    eventDate       : datetime&lt;UTC&gt;\n    occurrenceStatus: character\n    dataResourceName: character\n    family          : character\n    genus           : character\n    species         : character\n    cl22            : character\n    month           : double\n  &gt;\n&gt;[11]&gt;\n[[1]]\n# A tibble: 2,080 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0007f679-255f… Ceyx azureus   https://biodi…           -35.3             149.\n 2 00237f72-7b95… Ceyx azureus   https://biodi…           -33.6             151.\n 3 002d4683-fdeb… Ceyx azureus   https://biodi…           -22.8             151.\n 4 0030b417-ad83… Ceyx azureus   https://biodi…           -23.5             151.\n 5 005c21b0-3066… Ceyx azureus   https://biodi…           -16.2             145.\n 6 00671765-ed23… Ceyx azureus   https://biodi…           -36.1             145.\n 7 0086cd20-926a… Ceyx azureus   https://biodi…           -35.6             150.\n 8 00a29f49-65aa… Ceyx azureus   https://biodi…           -34.9             151.\n 9 00a39798-5118… Ceyx azureus   https://biodi…           -17.1             146.\n10 00c02d79-58ef… Ceyx azureus   https://biodi…           -16.2             145.\n# ℹ 2,070 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[2]]\n# A tibble: 198 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 00b3fbaf-20d1… Ceyx pusillus  https://biodi…           -12.3             131.\n 2 02ec2065-820c… Ceyx pusillus  https://biodi…           -12.4             131.\n 3 02f2b1e9-f706… Ceyx pusillus  https://biodi…           -16.9             146.\n 4 030dd9ae-3f67… Ceyx pusillus  https://biodi…           -12.4             131.\n 5 03a15b6a-b666… Ceyx pusillus  https://biodi…           -16.9             146.\n 6 04c838f4-8641… Ceyx pusillus  https://biodi…           -12.4             131.\n 7 058ef10d-247b… Ceyx pusillus  https://biodi…           -12.6             131.\n 8 078b046a-9cf3… Ceyx pusillus  https://biodi…           -12.8             143.\n 9 0791d280-a26c… Ceyx pusillus  https://biodi…           -12.4             131.\n10 0843ea42-367f… Ceyx pusillus  https://biodi…           -16.1             145.\n# ℹ 188 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[3]]\n# A tibble: 1,379 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 00085f92-58d1… Dacelo (Dacel… https://biodi…           -14.2             132.\n 2 005e94f6-d0d7… Dacelo (Dacel… https://biodi…           -12.7             143.\n 3 0083fbfd-3f14… Dacelo (Dacel… https://biodi…           -17.5             141.\n 4 00bd28e3-20aa… Dacelo (Dacel… https://biodi…           -13.4             132.\n 5 00bde3fa-6095… Dacelo (Dacel… https://biodi…           -19.4             147.\n 6 00c8ff2c-9282… Dacelo (Dacel… https://biodi…           -16.7             146.\n 7 01462284-b0aa… Dacelo (Dacel… https://biodi…           -12.4             131.\n 8 01db4718-55f5… Dacelo (Dacel… https://biodi…           -16.5             145.\n 9 0268d927-927e… Dacelo (Dacel… https://biodi…           -14.5             132.\n10 02712b54-8b8f… Dacelo (Dacel… https://biodi…           -19.4             147.\n# ℹ 1,369 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[4]]\n# A tibble: 28,186 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 00018120-2238… Dacelo (Dacel… https://biodi…           -27.4             153.\n 2 0005aa70-a30f… Dacelo (Dacel… https://biodi…           -25.3             153.\n 3 0006ff02-853a… Dacelo (Dacel… https://biodi…           -37.9             145.\n 4 00076c8d-957e… Dacelo (Dacel… https://biodi…           -28.0             153.\n 5 00080e38-ee2d… Dacelo (Dacel… https://biodi…           -33.1             150.\n 6 000c7c7c-3603… Dacelo (Dacel… https://biodi…           -38.5             144.\n 7 000f692d-8013… Dacelo (Dacel… https://biodi…           -19.3             147.\n 8 000f87c2-9028… Dacelo (Dacel… https://biodi…           -35.3             149.\n 9 0010012d-435e… Dacelo (Dacel… https://biodi…           -16.8             146.\n10 001021bd-b8f1… Dacelo (Dacel… https://biodi…           -27.5             153.\n# ℹ 28,176 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[5]]\n# A tibble: 155 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0120314d-38b4… Syma torotoro  https://biodi…           -12.6             143.\n 2 04b2e915-4419… Syma torotoro  https://biodi…           -12.8             143.\n 3 04d3acf0-acdb… Syma torotoro  https://biodi…           -12.7             143.\n 4 0bf14fe4-01fc… Syma torotoro  https://biodi…           -12.7             143.\n 5 0c0a3bc9-431f… Syma torotoro  https://biodi…           -12.7             143.\n 6 0e428bdf-d6fb… Syma torotoro  https://biodi…           -10.8             142.\n 7 0f29d245-adc8… Syma torotoro  https://biodi…           -12.6             143.\n 8 0ff604e2-fbe3… Syma torotoro  https://biodi…           -10.8             142.\n 9 1121aa01-3173… Syma torotoro  https://biodi…           -12.8             143.\n10 131d66ad-46d8… Syma torotoro  https://biodi…           -12.8             143.\n# ℹ 145 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[6]]\n# A tibble: 566 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 004c61ec-ed26… Tanysiptera (… https://biodi…           -16.6             145.\n 2 014b3666-a322… Tanysiptera (… https://biodi…           -16.6             145.\n 3 0152bed4-9459… Tanysiptera (… https://biodi…           -12.8             143.\n 4 01685613-fe2f… Tanysiptera (… https://biodi…           -12.7             143.\n 5 019804dd-c3fc… Tanysiptera (… https://biodi…           -16.6             145.\n 6 02a51caa-861f… Tanysiptera (… https://biodi…           -12.7             143.\n 7 02f21d71-27c2… Tanysiptera (… https://biodi…           -10.8             142.\n 8 02f96918-b627… Tanysiptera (… https://biodi…           -12.7             143.\n 9 044df2a6-7d32… Tanysiptera (… https://biodi…           -16.2             145.\n10 04baf9c0-fd82… Tanysiptera (… https://biodi…           -16.6             145.\n# ℹ 556 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[7]]\n# A tibble: 12 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 3aa845a0-902e… Todiramphus (… https://biodi…            1.32             104.\n 2 5f59e40a-87d2… Todiramphus (… https://biodi…            1.28             104.\n 3 789e7794-af27… Todiramphus (… https://biodi…            1.32             104.\n 4 7c6e2ffa-73a8… Todiramphus (… https://biodi…          -28.2              154.\n 5 806d0434-8d8f… Todiramphus (… https://biodi…            1.28             104.\n 6 83d392d7-a15f… Todiramphus (… https://biodi…            1.28             104.\n 7 85bd0100-ea5d… Todiramphus (… https://biodi…            1.28             104.\n 8 aeda1763-cd85… Todiramphus (… https://biodi…            1.28             104.\n 9 dac72d12-bf2c… Todiramphus (… https://biodi…            1.28             104.\n10 e156dd38-95f5… Todiramphus (… https://biodi…            1.28             104.\n11 e5574549-7cec… Todiramphus (… https://biodi…            1.28             104.\n12 fd6435b4-32d6… Todiramphus (… https://biodi…            1.31             104.\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[8]]\n# A tibble: 2,374 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0024aef4-4a8b… Todiramphus (… https://biodi…           -19.4             147.\n 2 004b8b6c-8a89… Todiramphus (… https://biodi…           -12.4             131.\n 3 007b39cf-2660… Todiramphus (… https://biodi…           -27.4             153.\n 4 00993728-10d2… Todiramphus (… https://biodi…           -27.1             153.\n 5 009e7664-1b3e… Todiramphus (… https://biodi…           -27.4             153.\n 6 00b1c419-0612… Todiramphus (… https://biodi…           -26.2             153.\n 7 00cdcbdf-36a6… Todiramphus (… https://biodi…           -12.5             131.\n 8 00deabe0-1d59… Todiramphus (… https://biodi…           -12.3             131.\n 9 0120a6ea-66f1… Todiramphus (… https://biodi…           -30.4             153.\n10 012e4a46-ead1… Todiramphus (… https://biodi…           -20.0             146.\n# ℹ 2,364 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[9]]\n# A tibble: 296 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 001c48ef-8329… Todiramphus (… https://biodi…           -31.9             142.\n 2 016ec933-df3e… Todiramphus (… https://biodi…           -23.7             134.\n 3 01833f43-b3d5… Todiramphus (… https://biodi…           -28.0             146.\n 4 01e0d185-50ed… Todiramphus (… https://biodi…           -29.8             151.\n 5 02d54da5-cfb0… Todiramphus (… https://biodi…           -19.0             146.\n 6 033bf94d-cd11… Todiramphus (… https://biodi…           -20.0             140.\n 7 06d7a1fc-9464… Todiramphus (… https://biodi…           -23.5             144.\n 8 06e22048-0569… Todiramphus (… https://biodi…           -18.3             143.\n 9 07fc074c-fff9… Todiramphus (… https://biodi…           -31.9             141.\n10 09e67cf4-3fbf… Todiramphus (… https://biodi…           -17.7             140.\n# ℹ 286 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[10]]\n# A tibble: 9,871 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 00030a7e-a6cc… Todiramphus (… https://biodi…           -35.1             147.\n 2 0005e748-e148… Todiramphus (… https://biodi…           -29.3             149.\n 3 00072b9e-b843… Todiramphus (… https://biodi…           -33.7             151.\n 4 00280b9f-8fc4… Todiramphus (… https://biodi…           -27.5             153.\n 5 002e666e-a69c… Todiramphus (… https://biodi…           -19.2             147.\n 6 002fcf2c-7a6c… Todiramphus (… https://biodi…           -33.1             151.\n 7 003327aa-c684… Todiramphus (… https://biodi…           -36.5             147.\n 8 0036208a-7764… Todiramphus (… https://biodi…           -32.8             117.\n 9 0036fdd3-947e… Todiramphus (… https://biodi…           -35.3             149.\n10 003ba830-1f22… Todiramphus (… https://biodi…           -27.3             153.\n# ℹ 9,861 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n[[11]]\n# A tibble: 1,008 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0034efe7-4a01… Todiramphus    https://biodi…           -27.2             153.\n 2 00478798-95f7… Todiramphus    https://biodi…           -28.2             154.\n 3 0064cb36-4eee… Todiramphus    https://biodi…           -27.5             153.\n 4 00bcefdb-f852… Todiramphus    https://biodi…           -25.6             153.\n 5 00ebd2bb-0c34… Todiramphus    https://biodi…           -27.3             153.\n 6 0116442d-a7f6… Todiramphus    https://biodi…           -16.9             146.\n 7 01d19d01-c721… Todiramphus    https://biodi…           -27.5             153.\n 8 020b9283-447f… Todiramphus    https://biodi…           -16.9             146.\n 9 02511840-3813… Todiramphus    https://biodi…           -16.9             146.\n10 03a9e4bd-37db… Todiramphus    https://biodi…           -25.6             153.\n# ℹ 998 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n\n\n\n\n\nTodiramphus (Todiramphus) sanctus collecting a crab for lunch. Photo by Peter and Shelly CC-BY-NC 4.0 (Int)\n\n…and use purrr::map()1 to remove duplicates for each species group, binding our dataframes together again with bind_rows().\n\nlibrary(purrr)\n\n\nAttaching package: 'purrr'\n\n\nThe following object is masked from 'package:base':\n\n    %||%\n\nbirds |&gt;\n  group_split(species) |&gt;\n  map(\\(df) \n      df |&gt; \n        filter(duplicated(decimalLongitude) & duplicated(decimalLatitude))\n      ) |&gt;\n  bind_rows()\n\n# A tibble: 23,788 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 04b5c741-1afb… Ceyx azureus   https://biodi…           -37.8             145.\n 2 06eb5cd7-413f… Ceyx azureus   https://biodi…           -34.5             151.\n 3 083ec28b-68d3… Ceyx azureus   https://biodi…           -26.3             153.\n 4 087d63fc-2505… Ceyx azureus   https://biodi…           -27.5             153.\n 5 0afd32d4-c759… Ceyx azureus   https://biodi…           -37.8             145.\n 6 0b2b6aab-1283… Ceyx azureus   https://biodi…           -28.8             154.\n 7 0b8ea27e-2ca2… Ceyx azureus   https://biodi…           -34.5             151.\n 8 0ba0afc4-1cf2… Ceyx azureus   https://biodi…           -27.3             153.\n 9 0c570ead-3759… Ceyx azureus   https://biodi…           -33.0             151.\n10 0c9f8e48-1c44… Ceyx azureus   https://biodi…           -27.3             153.\n# ℹ 23,778 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n\nSplitting by species has reduced the total number of duplicate records by ~3,500 rows because we’ve made it possible for multiple species to have records with the same spatial coordinates.",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Duplicates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/duplicates.html#remove-duplicates",
    "href": "2_general-cleaning/duplicates.html#remove-duplicates",
    "title": "4  Duplicates",
    "section": "4.2 Remove duplicates",
    "text": "4.2 Remove duplicates\nTo now remove these duplicates from our dataframe, we can use the ! operator to return records that are not duplicated, rather than those that are.\n\nbirds_filtered &lt;- birds |&gt;\n  group_split(species) |&gt;\n  map(\\(df) \n      df |&gt;\n        filter(!duplicated(decimalLongitude) & !duplicated(decimalLatitude))) |&gt;\n  bind_rows()\nbirds_filtered\n\n# A tibble: 22,128 × 13\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0007f679-255f… Ceyx azureus   https://biodi…           -35.3             149.\n 2 00237f72-7b95… Ceyx azureus   https://biodi…           -33.6             151.\n 3 002d4683-fdeb… Ceyx azureus   https://biodi…           -22.8             151.\n 4 0030b417-ad83… Ceyx azureus   https://biodi…           -23.5             151.\n 5 005c21b0-3066… Ceyx azureus   https://biodi…           -16.2             145.\n 6 00671765-ed23… Ceyx azureus   https://biodi…           -36.1             145.\n 7 0086cd20-926a… Ceyx azureus   https://biodi…           -35.6             150.\n 8 00a29f49-65aa… Ceyx azureus   https://biodi…           -34.9             151.\n 9 00a39798-5118… Ceyx azureus   https://biodi…           -17.1             146.\n10 00c02d79-58ef… Ceyx azureus   https://biodi…           -16.2             145.\n# ℹ 22,118 more rows\n# ℹ 8 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n\nTo check our results, we can grab a random row from our unfiltered dataframe…\n\ntest_row &lt;- birds |&gt;\n  filter(duplicated(decimalLongitude) & duplicated(decimalLatitude)) |&gt;\n  slice(10)\n\ntest_row |&gt;\n  select(species, decimalLatitude, decimalLongitude, recordID) # show relevant columns\n\n# A tibble: 1 × 4\n  species             decimalLatitude decimalLongitude recordID                 \n  &lt;chr&gt;                         &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;                    \n1 Todiramphus sanctus           -19.2             147. 01006006-78b2-4d19-bb99-…\n\n\n…and see whether any rows in birds_filtered have the same combination of longitude and latitude coordinates.\n\nbirds_filtered |&gt;\n  filter(\n    decimalLatitude %in% test_row$decimalLatitude & \n      decimalLongitude %in% test_row$decimalLongitude\n    ) |&gt;\n  select(species, decimalLatitude, decimalLongitude, recordID) # show relevant columns\n\n# A tibble: 4 × 4\n  species               decimalLatitude decimalLongitude recordID               \n  &lt;chr&gt;                           &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;                  \n1 Dacelo leachii                  -19.2             147. 0bac3731-116a-4f7b-8b2…\n2 Dacelo novaeguineae             -19.2             147. 161a96bb-e9af-4a6b-ae3…\n3 Todiramphus macleayii           -19.2             147. 0208aa99-b3ce-449a-99d…\n4 Todiramphus sanctus             -19.2             147. 00c3f294-01dd-4f66-b8a…\n\n\nAs expected, there are a few species with those latitude and longitude coordinates, but we now only have 1 row for each species in that location in birds_filtered.\nUsing %in% can be a powerful tool for finding duplicates in your dataframe. Extracting rows like we did above with our test_row example above (or a list of values in a column) can help you weed out more specific duplicate records you are interested in.\nOur kingfisher data, birds_filtered, is now clean from spatially duplicated records!\n\n\nCode\nbirds_filtered |&gt;\n  rmarkdown::paged_table()\n\n\n\n  \n\n\n\n\n\n\n\nCeyx azureus perched on a log. Photo by andrewpavlov CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Duplicates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/duplicates.html#summary",
    "href": "2_general-cleaning/duplicates.html#summary",
    "title": "4  Duplicates",
    "section": "4.3 Summary",
    "text": "4.3 Summary\nThis chapter has introduced some ways to find duplicated records, remove them from datasets, and check if the changes were correctly made. These methods can be more broadly applied to other types of data as well, not just spatial data. Depending on your analysis, you may need to use bespoke methods for handling duplicates. Later chapters like Taxonomic validation and Geospatial cleaning cover more advanced detection and cleaning methods.\nIn the next chapter, we will discuss ways of handling missing values in your dataset.",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Duplicates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/duplicates.html#footnotes",
    "href": "2_general-cleaning/duplicates.html#footnotes",
    "title": "4  Duplicates",
    "section": "",
    "text": "We have used \\(df) as shorthand within purrr::map(). This shorthand can be rewritten as map(.x = df, function(.x) {}). We provide an input, in this case the piped dataframe which we’ve called df, and use it in a custom function (defined within {}). This function is run over each dataframe in our list of dataframes.Check out this description from a recent purrr package update for another example.↩︎",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Duplicates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/missing-values.html",
    "href": "2_general-cleaning/missing-values.html",
    "title": "5  Missing values",
    "section": "",
    "text": "5.0.1 Prerequisites\nIn this chapter, we will use gecko occurrence data since 2009 from the ALA using galah.\n# packages\nlibrary(galah)\nlibrary(dplyr)\nlibrary(tidyr)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\ngeckos &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.722b9bc1-34d9-4fe4-92e0-a93b041df1b1\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/missing-values.html#find-missing-values",
    "href": "2_general-cleaning/missing-values.html#find-missing-values",
    "title": "5  Missing values",
    "section": "5.1 Find missing values",
    "text": "5.1 Find missing values\nThere are numerous ways to identify missing values in your data. Here we illustrate a few ways with very different output types.\n\nsummary()skim()viz_miss()\n\n\nThe summary() function (base r) provides summary statistics for each column in your table. The output includes the number of missing values in each column (NA's). Here, we can tell that there are missing values in the columns: decimalLatitude, decimalLongitude, eventDate, and month.\n\nsummary(geckos) \n\n   recordID         scientificName     taxonConceptID     decimalLatitude \n Length:28514       Length:28514       Length:28514       Min.   :-39.03  \n Class :character   Class :character   Class :character   1st Qu.:-31.98  \n Mode  :character   Mode  :character   Mode  :character   Median :-26.77  \n                                                          Mean   :-24.32  \n                                                          3rd Qu.:-15.82  \n                                                          Max.   : 44.76  \n                                                          NA's   :153     \n decimalLongitude   eventDate                      occurrenceStatus  \n Min.   :-171.8   Min.   :2009-01-01 00:00:00.00   Length:28514      \n 1st Qu.: 132.4   1st Qu.:2013-11-13 00:00:00.00   Class :character  \n Median : 140.6   Median :2017-11-29 12:00:00.00   Mode  :character  \n Mean   : 139.2   Mean   :2017-07-22 10:34:21.99                     \n 3rd Qu.: 146.9   3rd Qu.:2021-09-05 10:41:03.50                     \n Max.   : 177.4   Max.   :2024-07-13 10:55:15.00                     \n NA's   :153      NA's   :684                                        \n dataResourceName     kingdom             phylum             order          \n Length:28514       Length:28514       Length:28514       Length:28514      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n    class              family             genus             species         \n Length:28514       Length:28514       Length:28514       Length:28514      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n     cl22               month       \n Length:28514       Min.   : 1.000  \n Class :character   1st Qu.: 4.000  \n Mode  :character   Median : 7.000  \n                    Mean   : 6.718  \n                    3rd Qu.:10.000  \n                    Max.   :12.000  \n                    NA's   :675     \n\n\n\n\nThe skimr package provides a fast and simple way to identify columns with missing values and quantify the amount of missing data. The output shows that there are 7 columns with missing values, shown in skim_variable, along with information about the number of missing values in n_missing and the proportion of non-missing values in complete_rate.\n\nlibrary(skimr)\n\ngeckos |&gt;\n  skim() |&gt;\n  filter(n_missing &gt; 0) |&gt; \n  as_tibble()\n\n# A tibble: 7 × 21\n  skim_type skim_variable    n_missing complete_rate POSIXct.min        \n  &lt;chr&gt;     &lt;chr&gt;                &lt;int&gt;         &lt;dbl&gt; &lt;dttm&gt;             \n1 POSIXct   eventDate              684         0.976 2009-01-01 00:00:00\n2 character genus                  726         0.975 NA                 \n3 character species               2188         0.923 NA                 \n4 character cl22                  1265         0.956 NA                 \n5 numeric   decimalLatitude        153         0.995 NA                 \n6 numeric   decimalLongitude       153         0.995 NA                 \n7 numeric   month                  675         0.976 NA                 \n# ℹ 16 more variables: POSIXct.max &lt;dttm&gt;, POSIXct.median &lt;dttm&gt;,\n#   POSIXct.n_unique &lt;int&gt;, character.min &lt;int&gt;, character.max &lt;int&gt;,\n#   character.empty &lt;int&gt;, character.n_unique &lt;int&gt;,\n#   character.whitespace &lt;int&gt;, numeric.mean &lt;dbl&gt;, numeric.sd &lt;dbl&gt;,\n#   numeric.p0 &lt;dbl&gt;, numeric.p25 &lt;dbl&gt;, numeric.p50 &lt;dbl&gt;, numeric.p75 &lt;dbl&gt;,\n#   numeric.p100 &lt;dbl&gt;, numeric.hist &lt;chr&gt;\n\n\n\n\nThe visdat package contains functions to visualise different aspects of dataframes. vis_miss() allows users to visualise the extent and location of missing data throughout a dataframe, with additional arguments for customising the visual output through clustering or sorting the missing data. The output provides a visual summary of which columns have missing data and relatively how many rows have missing values.\n\nlibrary(visdat)\n\nvis_miss(geckos)\n\n\n\n\n\n\n\n\n\n\n\nFrom here we can return all rows with a missing variable.\n\ngeckos |&gt; \n  filter(if_any(everything(), is.na)) |&gt;\n  select(scientificName, genus, \n         species, cl22, everything()) # reorder columns\n\n# A tibble: 3,604 × 17\n   scientificName    genus species cl22  recordID taxonConceptID decimalLatitude\n   &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                    &lt;dbl&gt;\n 1 Gehyra            Gehy… &lt;NA&gt;    Sout… 001949e… https://biodi…          -28.1 \n 2 Gehyra            Gehy… &lt;NA&gt;    Nort… 001ab80… https://biodi…          -16.1 \n 3 Gehyra australis  Gehy… Gehyra… Nort… 002f70c… https://biodi…          -13.1 \n 4 Lepidodactylus p… Lepi… Lepido… &lt;NA&gt;  00336d7… https://biodi…           -8.81\n 5 Christinus        Chri… &lt;NA&gt;    Sout… 003e84f… https://biodi…          -35.0 \n 6 Gehyra            Gehy… &lt;NA&gt;    Quee… 0046174… https://biodi…          -26.7 \n 7 Gehyra nana       Gehy… Gehyra… &lt;NA&gt;  005ea26… https://biodi…           NA   \n 8 GEKKONIDAE        &lt;NA&gt;  &lt;NA&gt;    Quee… 007172d… https://biodi…          -19.3 \n 9 Gehyra            Gehy… &lt;NA&gt;    Nort… 0073628… https://biodi…          -22.2 \n10 Gehyra punctata   Gehy… Gehyra… &lt;NA&gt;  007a329… https://biodi…           NA   \n# ℹ 3,594 more rows\n# ℹ 10 more variables: decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, order &lt;chr&gt;, class &lt;chr&gt;, family &lt;chr&gt;, month &lt;dbl&gt;\n\n\nOr we can specify a column to find rows with NA values (in this case column cl22).\n\ngeckos |&gt; \n  filter(if_any(cl22, is.na)) |&gt; \n  select(scientificName, genus, \n         species, cl22, everything()) # reorder columns\n\n# A tibble: 1,265 × 17\n   scientificName    genus species cl22  recordID taxonConceptID decimalLatitude\n   &lt;chr&gt;             &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;                    &lt;dbl&gt;\n 1 Lepidodactylus p… Lepi… Lepido… &lt;NA&gt;  00336d7… https://biodi…           -8.81\n 2 Gehyra nana       Gehy… Gehyra… &lt;NA&gt;  005ea26… https://biodi…           NA   \n 3 Gehyra punctata   Gehy… Gehyra… &lt;NA&gt;  007a329… https://biodi…           NA   \n 4 Christinus marmo… Chri… Christ… &lt;NA&gt;  009be60… https://biodi…          -32.1 \n 5 Cyrtodactylus     Cyrt… &lt;NA&gt;    &lt;NA&gt;  00a3522… https://biodi…           -5.73\n 6 Hemidactylus fre… Hemi… Hemida… &lt;NA&gt;  00c6832… https://biodi…            1.29\n 7 Cyrtodactylus     Cyrt… &lt;NA&gt;    &lt;NA&gt;  00fdca4… https://biodi…           -7.42\n 8 Cyrtodactylus sa… Cyrt… Cyrtod… &lt;NA&gt;  012e94f… https://biodi…          -10.5 \n 9 Christinus marmo… Chri… Christ… &lt;NA&gt;  0143054… https://biodi…          -32.0 \n10 Hemidactylus fre… Hemi… Hemida… &lt;NA&gt;  01aae23… https://biodi…           16.0 \n# ℹ 1,255 more rows\n# ℹ 10 more variables: decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, order &lt;chr&gt;, class &lt;chr&gt;, family &lt;chr&gt;, month &lt;dbl&gt;",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/missing-values.html#remove-na-values",
    "href": "2_general-cleaning/missing-values.html#remove-na-values",
    "title": "5  Missing values",
    "section": "5.2 Remove NA values",
    "text": "5.2 Remove NA values\n\n5.2.1 Missing coordinates\nIf you are intending to make a map or run spatial analyses, it’s a good idea to exclude records with missing coordinates. Missing coordinate data often leads to one of the following: a function error, an undesirable map, or the (unintentional) exclusion of data points (many of which you might wish to include in other maps or analyses).\nIt’s good practice to tally and identify rows that have missing data before excluding them. We can use the same method as above to identify the records with missing coordinates.\n\ngeckos |&gt; \n  filter(if_any(c(decimalLongitude, decimalLatitude), is.na)) |&gt;\n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   153\n\ngeckos |&gt; \n  filter(if_any(c(decimalLongitude, decimalLatitude), is.na)) |&gt;\n  select(scientificName, decimalLongitude, \n         decimalLatitude, everything()) # reorder columns\n\n# A tibble: 153 × 17\n   scientificName      decimalLongitude decimalLatitude recordID  taxonConceptID\n   &lt;chr&gt;                          &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;         \n 1 Gehyra nana                       NA              NA 005ea268… https://biodi…\n 2 Gehyra punctata                   NA              NA 007a3298… https://biodi…\n 3 Heteronotia binoei                NA              NA 03a123ed… https://biodi…\n 4 Gehyra australis                  NA              NA 05bef070… https://biodi…\n 5 Gehyra occidentalis               NA              NA 0846001e… https://biodi…\n 6 GEKKONIDAE                        NA              NA 0a078043… https://biodi…\n 7 Gehyra xenopus                    NA              NA 0ad77ff9… https://biodi…\n 8 Gehyra occidentalis               NA              NA 0c5390b2… https://biodi…\n 9 Gehyra punctata                   NA              NA 11bbc940… https://biodi…\n10 Gehyra nana                       NA              NA 12d9f935… https://biodi…\n# ℹ 143 more rows\n# ℹ 12 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;,\n#   class &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;, cl22 &lt;chr&gt;,\n#   month &lt;dbl&gt;\n\n\nIf we decide we are happy to exclude these records, we can use drop_na() to remove missing values from our dataset.\n\ngeckos_filtered &lt;- geckos |&gt;\n  drop_na(decimalLongitude, decimalLatitude)\n\n\n\n\n\nGehyra dubia camouflaged over rocks. Photo by Nick Talbot CC-BY-NC 4.0 (Int)\n\nWe can check that drop_na() worked correctly by comparing the number of records in our initial data and our filtered data, specifically that geckos_filtered is smaller by the same number of NA values we found above.\n\nnrow(geckos) - nrow(geckos_filtered)\n\n[1] 153",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/missing-values.html#taxonomic-values",
    "href": "2_general-cleaning/missing-values.html#taxonomic-values",
    "title": "5  Missing values",
    "section": "5.3 Taxonomic values",
    "text": "5.3 Taxonomic values\n\n5.3.1 Missing higher rank\nSometimes data can be missing information in columns with higher taxonomic rankings, even if observations have been taxonomically identified down to the species level. In this case, the goal isn’t only to remove the missing values, but to fill in the gaps with the correct information.\nAs an example, we’ll use a slightly modified geckos_missing dataset with some missing data added into the higher columns1. Below is a preview, and you’ll notice that there are NA values in the class and family columns as you skim across the pages.\n\n\nCode\nset.seed(87654) # for reproducibility\n\n# randomly replace some row's class & family names with NAs\ngeckos_missing &lt;- geckos |&gt;\n  mutate(class = replace(class, \n                         sample(row_number(), \n                                size = ceiling(0.15 * n())), \n                         NA),\n         family = replace(family, \n                          sample(row_number(), \n                                 size = ceiling(0.15 * n())), \n                          NA))\n\n\n\ngeckos_missing |&gt;\n  select(scientificName, class, family, genus, species, everything())\n\n# A tibble: 28,514 × 17\n   scientificName        class    family   genus species recordID taxonConceptID\n   &lt;chr&gt;                 &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;         \n 1 Gehyra dubia          Reptilia Gekkoni… Gehy… Gehyra… 00002a3… https://biodi…\n 2 Christinus marmoratus Reptilia Gekkoni… Chri… Christ… 0002970… https://biodi…\n 3 Heteronotia binoei    Reptilia Gekkoni… Hete… Hetero… 0007fcc… https://biodi…\n 4 Gehyra australis      Reptilia Gekkoni… Gehy… Gehyra… 00087c0… https://biodi…\n 5 Hemidactylus frenatus Reptilia Gekkoni… Hemi… Hemida… 000c00b… https://biodi…\n 6 Heteronotia binoei    Reptilia Gekkoni… Hete… Hetero… 000cd36… https://biodi…\n 7 Christinus marmoratus Reptilia Gekkoni… Chri… Christ… 0018b78… https://biodi…\n 8 Gehyra                Reptilia Gekkoni… Gehy… &lt;NA&gt;    001949e… https://biodi…\n 9 Heteronotia binoei    Reptilia Gekkoni… Hete… Hetero… 0019729… https://biodi…\n10 Gehyra                Reptilia Gekkoni… Gehy… &lt;NA&gt;    001ab80… https://biodi…\n# ℹ 28,504 more rows\n# ℹ 10 more variables: decimalLatitude &lt;dbl&gt;, decimalLongitude &lt;dbl&gt;,\n#   eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, cl22 &lt;chr&gt;, month &lt;dbl&gt;\n\n\nIf you have a list of taxonomic names with complete ranking information from your preferred taxonomic naming authority, you can use this information to back-fill your missing data columns. In our case, we can use names from ALA’s taxonomic backbone.\nFirst we’ll get the complete list of Gekkonidae species taxonomic rank names using galah.\n\ngeckos_species_list &lt;- galah_call() |&gt;\n  identify(\"gekkonidae\") |&gt;\n  atlas_species()\n\nhead(geckos_species_list)\n\n# A tibble: 6 × 11\n  taxon_concept_id species_name scientific_name_auth…¹ taxon_rank kingdom phylum\n  &lt;chr&gt;            &lt;chr&gt;        &lt;chr&gt;                  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; \n1 https://biodive… Heteronotia… (Gray, 1845)           species    Animal… Chord…\n2 https://biodive… Christinus … (Gray, 1845)           species    Animal… Chord…\n3 https://biodive… Gehyra vari… (Duméril & Bibron, 18… species    Animal… Chord…\n4 https://biodive… Hemidactylu… Duméril & Bibron, 1836 species    Animal… Chord…\n5 https://biodive… Gehyra dubia (Macleay, 1877)        species    Animal… Chord…\n6 https://biodive… Gehyra vers… Hutchinson, Sistrom, … species    Animal… Chord…\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 5 more variables: class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   vernacular_name &lt;chr&gt;\n\n\nTo match the complete names in geckos_species_list with the missing names in geckos_missing, we can use a strategy of match-and-merge.\n\n\n\n\n\n\nNote\n\n\n\n\n\nFor some taxonomic groups like birds this will not work because subgenus is almost always included in scientificName. In this scenario, you might need to use more advanced methods like those in the Taxonomic Validation chapter to match and back-fill taxonomic information.\n\n\n\nUsing a reference column, we’ll merge our complete names data to our missing data. The information in the species_name column of geckos_species_list contains both the genus and species names; this is just like the scientificName column of our geckos_missing dataset2. We can use these columns as our reference columns.\n\ngeckos_species_list |&gt; select(species_name) |&gt; slice(10:15) # see sample of data\n\n# A tibble: 6 × 1\n  species_name           \n  &lt;chr&gt;                  \n1 Lepidodactylus lugubris\n2 Gehyra montium         \n3 Gehyra lazelli         \n4 Nactus pelagicus       \n5 Nactus eboracensis     \n6 Gehyra punctata        \n\ngeckos_missing |&gt; select(scientificName) |&gt; slice(10:15) # see sample of data\n\n# A tibble: 6 × 1\n  scientificName         \n  &lt;chr&gt;                  \n1 Gehyra                 \n2 Gehyra versicolor      \n3 Gehyra variegata       \n4 Hemidactylus frenatus  \n5 Christinus marmoratus  \n6 Lepidodactylus lugubris\n\n\nNow we’ll select the subset of columns from geckos_species_list that we wish to join with geckos_missing (and our reference column, species_name).\n\nlist_subset &lt;- geckos_species_list |&gt;\n  select(species_name, class, family)\n\nWe can use left_join() to merge list_subset to geckos_missing. Records that are identified at least down to the family level now have the correct rank information in the class_new and family_new columns [^3].\nThis hasn’t worked for every row, however, because scientificName contains the name of the lowest taxonomic rank the occurrence is identified to. Names like Christinus and Gehyra are genus names, so in these cases scientificName won’t match our reference species_name column!\n\ngeckos_missing |&gt;\n  left_join(list_subset, \n            by = join_by(scientificName == species_name), \n            suffix = c(\"_old\", \"_new\")) |&gt;\n  select(scientificName, class_old, family_old, class_new, family_new) |&gt;\n  slice(20:30) # see sample of data\n\n# A tibble: 11 × 5\n   scientificName         class_old family_old class_new family_new\n   &lt;chr&gt;                  &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;     \n 1 Gehyra australis       Reptilia  &lt;NA&gt;       Reptilia  Gekkonidae\n 2 Lepidodactylus pumilus Reptilia  Gekkonidae Reptilia  Gekkonidae\n 3 Heteronotia binoei     Reptilia  Gekkonidae Reptilia  Gekkonidae\n 4 Christinus marmoratus  Reptilia  Gekkonidae Reptilia  Gekkonidae\n 5 Christinus             Reptilia  Gekkonidae &lt;NA&gt;      &lt;NA&gt;      \n 6 Heteronotia binoei     Reptilia  Gekkonidae Reptilia  Gekkonidae\n 7 Nactus eboracensis     Reptilia  Gekkonidae Reptilia  Gekkonidae\n 8 Heteronotia binoei     Reptilia  Gekkonidae Reptilia  Gekkonidae\n 9 Gehyra                 Reptilia  Gekkonidae &lt;NA&gt;      &lt;NA&gt;      \n10 Heteronotia binoei     &lt;NA&gt;      &lt;NA&gt;       Reptilia  Gekkonidae\n11 Christinus marmoratus  Reptilia  Gekkonidae Reptilia  Gekkonidae\n\n\n\n\n5.3.2 Insufficient taxonomic identification\nIf a record is not identified down to the necessary taxonomic level required for your analysis (e.g. down to species or sub-species level), then the record should be removed.\nOne handy tip you can use with the galah package is to add the column taxonRank. This column usefully shows the taxonomic level of names in scientificName3. taxonRank can be useful because we can filter to only include records down to a specific rank.\n\ngeckos_rank &lt;- galah_call() |&gt;\n  identify(\"gekkonidae\") |&gt;\n  filter(year == 2013) |&gt;\n  select(group = \"basic\",\n         taxonRank) |&gt; # add column\n  atlas_occurrences()\n\n# return records identified to species level\ngeckos_rank |&gt;\n  filter(taxonRank == \"species\") |&gt;\n  select(taxonRank, scientificName, everything()) # reorder columns\n\n# A tibble: 1,825 × 9\n   taxonRank scientificName        recordID       taxonConceptID decimalLatitude\n   &lt;chr&gt;     &lt;chr&gt;                 &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;\n 1 species   Gehyra variegata      001c2b9f-34c8… https://biodi…           -22.7\n 2 species   Heteronotia binoei    0069dbdc-3b6a… https://biodi…           -16.4\n 3 species   Gehyra versicolor     0076a197-d0ee… https://biodi…           -21.5\n 4 species   Gehyra punctata       007a3298-fc44… https://biodi…            NA  \n 5 species   Heteronotia binoei    00a0405a-7852… https://biodi…           -12.6\n 6 species   Gehyra chimera        00aaed8f-218c… https://biodi…           -17.1\n 7 species   Heteronotia binoei    00b95296-ff57… https://biodi…           -12.7\n 8 species   Christinus marmoratus 00c15ed1-873e… https://biodi…           -35.4\n 9 species   Christinus marmoratus 00d886f8-1ee4… https://biodi…           -35.0\n10 species   Gehyra variegata      00e80fcb-843d… https://biodi…           -29.9\n# ℹ 1,815 more rows\n# ℹ 4 more variables: decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;\n\n\nHowever, it is still possible to filter records using the tools above without using the taxonRank column. In this case we remove records not identified down to the genus.\n\ngeckos_filtered &lt;- geckos |&gt;\n  drop_na(genus) |&gt;\n  select(scientificName, genus, species, everything()) # reorder columns\n\ngeckos_filtered\n\n# A tibble: 27,788 × 17\n   scientificName        genus   species recordID taxonConceptID decimalLatitude\n   &lt;chr&gt;                 &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;                    &lt;dbl&gt;\n 1 Gehyra dubia          Gehyra  Gehyra… 00002a3… https://biodi…           -24.1\n 2 Christinus marmoratus Christ… Christ… 0002970… https://biodi…           -34.7\n 3 Heteronotia binoei    Hetero… Hetero… 0007fcc… https://biodi…           -12.6\n 4 Gehyra australis      Gehyra  Gehyra… 00087c0… https://biodi…           -14.4\n 5 Hemidactylus frenatus Hemida… Hemida… 000c00b… https://biodi…           -27.5\n 6 Heteronotia binoei    Hetero… Hetero… 000cd36… https://biodi…           -13.3\n 7 Christinus marmoratus Christ… Christ… 0018b78… https://biodi…           -36.1\n 8 Gehyra                Gehyra  &lt;NA&gt;    001949e… https://biodi…           -28.1\n 9 Heteronotia binoei    Hetero… Hetero… 0019729… https://biodi…           -12.7\n10 Gehyra                Gehyra  &lt;NA&gt;    001ab80… https://biodi…           -16.1\n# ℹ 27,778 more rows\n# ℹ 11 more variables: decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, order &lt;chr&gt;, class &lt;chr&gt;, family &lt;chr&gt;, cl22 &lt;chr&gt;,\n#   month &lt;dbl&gt;\n\n\n\n\n\n\nChristinus marmoratus camouflaged over lichen.  Photo by Edward CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/missing-values.html#summary-1",
    "href": "2_general-cleaning/missing-values.html#summary-1",
    "title": "5  Missing values",
    "section": "5.4 Summary",
    "text": "5.4 Summary\nThis chapter showed ways to find and remove different types of missing records from your dataset. It’s important to note that there might not be a single cleaned dataset without any missing values. You might find that in the same workflow, you will clean your dataset in multiple ways to preserve rows that are missing some, but not all, information. For example, some records may have complete taxonomic identification but lack spatial coordinates, while others have spatial coordinates but lack taxonomic information. Depending on the type of analysis you intend to perform, you may need to adjust your data cleaning approach accordingly.\nIn the next chapter we will address working with strings (character sequences). Strings often involve correcting for things like typos or extra spacing that are difficult to pick up at a first glance.",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/missing-values.html#footnotes",
    "href": "2_general-cleaning/missing-values.html#footnotes",
    "title": "5  Missing values",
    "section": "",
    "text": "The Atlas of Living Australia matches taxonomic names when data is ingested from data providers. This process means that it’s very rare for a species to be missing higher taxonomic rank names. This might not be the case for other data sources, though!↩︎\nThis column contains the name of the lowest taxonomic rank the occurrence is identified to.↩︎\nThis column contains the name of the lowest taxonomic rank the occurrence is identified to.↩︎",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/strings.html",
    "href": "2_general-cleaning/strings.html",
    "title": "6  Strings",
    "section": "",
    "text": "6.0.1 Prerequisites\nIn this chapter, we will use tree kangaroo (Dendrolagus) occurrence data from the ALA and a subset of bee (Apidae) data taken from the Curated Plant and Invertebrate Data for Bushfire Modelling data set, saved in the bees.parquet file.\n# packages\nlibrary(galah)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\nlibrary(arrow)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\ntree_kangaroo &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.ae089212-80fa-48d4-84cf-17ba3c4e8ba4\") |&gt;\n  atlas_occurrences()\n\nbees &lt;- read_parquet(here(\"path\", \"to\", \"bees.parquet\"))",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/strings.html#basic-string-manipulation",
    "href": "2_general-cleaning/strings.html#basic-string-manipulation",
    "title": "6  Strings",
    "section": "6.1 Basic string manipulation",
    "text": "6.1 Basic string manipulation\nThe stringr package provides a number of useful functions for working with strings.\n\nlibrary(stringr)\n\n\nTrim\nTrim whitespace on either side of a string.\n\nstr_trim(\"  Genus specificus  \")\n\n[1] \"Genus specificus\"\n\n\nOr just one side.\n\nstr_trim(\"  Genus specificus  \", side = \"left\")\n\n[1] \"Genus specificus  \"\n\n\n\n\nSquish\nSquish strings into sentence spacing.\n\nstr_squish(\"  Genus   specificus  \")\n\n[1] \"Genus specificus\"\n\n\n\n\nTruncate\nTruncate a long string to a specified length.\n\nstr_trunc(\"Genus specificus\", width = 10, side = \"right\")\n\n[1] \"Genus s...\"\n\n\n\n\nSplit\nSplit a string into separate pieces based on a specified character.\n\nstr_split(\"Genus specificus\", \" \")\n\n[[1]]\n[1] \"Genus\"      \"specificus\"\n\n\n\n\nConcatenate\nConcatenate (i.e. join) separate strings into one string separated by a specified character.\n\nstr_c(\"Genus\", \"specificus\", sep = \"_\")\n\n[1] \"Genus_specificus\"",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/strings.html#matching",
    "href": "2_general-cleaning/strings.html#matching",
    "title": "6  Strings",
    "section": "6.2 Matching",
    "text": "6.2 Matching\nMatching strings using patterns can be a powerful way to identify or filter records during the data cleaning process.\n\n6.2.1 Detect a pattern\nDetect a pattern within a string.\n\n# detect if a pattern exists\nstr_detect(\"Genus specificus\", \"Genus\")\n\n[1] TRUE\n\n\nUse str_detect() to filter your data.frame. Here, we filter the species names to only those containing the pattern \"lum\".\n\n# 3 possible names in scientificName column\ntree_kangaroo |&gt; distinct(scientificName)\n\n# A tibble: 3 × 1\n  scientificName          \n  &lt;chr&gt;                   \n1 Dendrolagus lumholtzi   \n2 Dendrolagus             \n3 Dendrolagus bennettianus\n\n\n\n# detect names matching \"lum\"\ntree_kangaroo |&gt;\n  filter(str_detect(scientificName, \"lum\")) |&gt;\n  select(scientificName)\n\n# A tibble: 813 × 1\n   scientificName       \n   &lt;chr&gt;                \n 1 Dendrolagus lumholtzi\n 2 Dendrolagus lumholtzi\n 3 Dendrolagus lumholtzi\n 4 Dendrolagus lumholtzi\n 5 Dendrolagus lumholtzi\n 6 Dendrolagus lumholtzi\n 7 Dendrolagus lumholtzi\n 8 Dendrolagus lumholtzi\n 9 Dendrolagus lumholtzi\n10 Dendrolagus lumholtzi\n# ℹ 803 more rows\n\n\n\n\n6.2.2 Remove a pattern\nRemove a pattern from a string.\n\n# remove match for Genus (followed by a whitespace)\nstr_remove(\"Genus specificus\", pattern = \"Genus \")\n\n[1] \"specificus\"\n\n\nUse str_remove() to clean or extract names. Here, we remove the genus name from scientificName and save the result in a new species column.\n\ntree_kangaroo |&gt;\n  mutate(\n    species = ifelse(scientificName != \"Dendrolagus\",\n                     str_remove(scientificName, \"Dendrolagus \"),\n                     NA)\n  ) |&gt;\n  select(scientificName, species)\n\n# A tibble: 1,302 × 2\n   scientificName           species     \n   &lt;chr&gt;                    &lt;chr&gt;       \n 1 Dendrolagus lumholtzi    lumholtzi   \n 2 Dendrolagus lumholtzi    lumholtzi   \n 3 Dendrolagus lumholtzi    lumholtzi   \n 4 Dendrolagus lumholtzi    lumholtzi   \n 5 Dendrolagus              &lt;NA&gt;        \n 6 Dendrolagus bennettianus bennettianus\n 7 Dendrolagus lumholtzi    lumholtzi   \n 8 Dendrolagus lumholtzi    lumholtzi   \n 9 Dendrolagus              &lt;NA&gt;        \n10 Dendrolagus bennettianus bennettianus\n# ℹ 1,292 more rows\n\n\n\n\n6.2.3 Locate a pattern\nLocate the position of a pattern within a string. We’ll create an example dataset below.\n\nrecords &lt;- c(\"Genus\", \n             \"species\", \n             \"ZZGenus species\", \n             \"Difgenus difspecies\")\n\nFind the start and end position of a pattern.\n\nstr_locate(records, \"Genus\")\n\n     start end\n[1,]     1   5\n[2,]    NA  NA\n[3,]     3   7\n[4,]    NA  NA\n\n\nFind which indices match a pattern. Here, the first and third strings in records contain the pattern \"Genus\".\n\nstr_which(records, \"Genus\")\n\n[1] 1 3\n\n\nAdd pattern location information to a data.frame.\n\ntree_kangaroo |&gt;\n  mutate(\n1    start = str_locate(scientificName, \"lum\")[, 1],\n2    end = str_locate(scientificName, \"lum\")[, 2]\n  ) |&gt;\n  select(scientificName, start, end)\n\n\n1\n\n[, 1] returns column 1 of str_locate() output\n\n2\n\n[, 2] returns column 2 of str_locate() output\n\n\n\n\n# A tibble: 1,302 × 3\n   scientificName           start   end\n   &lt;chr&gt;                    &lt;int&gt; &lt;int&gt;\n 1 Dendrolagus lumholtzi       13    15\n 2 Dendrolagus lumholtzi       13    15\n 3 Dendrolagus lumholtzi       13    15\n 4 Dendrolagus lumholtzi       13    15\n 5 Dendrolagus                 NA    NA\n 6 Dendrolagus bennettianus    NA    NA\n 7 Dendrolagus lumholtzi       13    15\n 8 Dendrolagus lumholtzi       13    15\n 9 Dendrolagus                 NA    NA\n10 Dendrolagus bennettianus    NA    NA\n# ℹ 1,292 more rows\n\n\n\n\n\n\nDendrolagus bennettianus grasping a tree branch.Photo by David White CC-BY\n\n\n\n6.2.4 Regex matching\nThe examples above demonstrate the use of basic patterns. But for cases that need more specific or advanced matching, we can use regular expressions (or “regex”). Regex is a powerful tool used to match patterns, replace characters, and extract text from strings. Regex can be complex and unintuitive, but there are websites available, such as Regex 101[^regex-link], that are extremely helpful. ChatGPT is also great for building more complex regex snippets.\n[^regex-link: Snippets from this website need additional editing to work correctly in R.]\nHere we explore a few basic examples, and keep in mind that these methods can be applied to both column name strings and column values.\nThe str_view() function is a useful way to see what a regular expression will return. The results are shown in the console, and elements matched by the regex are surrounded with angle brackets &lt; &gt;.\n\n# Match the first word in the string (the genus)\n1str_view(tree_kangaroo$scientificName, \"^[A-Z][a-z]+\")\n\n\n1\n\nThis regex reads “Match and omit all letters (capitalised or not) after word one.”\n\n\n\n\n [1] │ &lt;Dendrolagus&gt; lumholtzi\n [2] │ &lt;Dendrolagus&gt; lumholtzi\n [3] │ &lt;Dendrolagus&gt; lumholtzi\n [4] │ &lt;Dendrolagus&gt; lumholtzi\n [5] │ &lt;Dendrolagus&gt;\n [6] │ &lt;Dendrolagus&gt; bennettianus\n [7] │ &lt;Dendrolagus&gt; lumholtzi\n [8] │ &lt;Dendrolagus&gt; lumholtzi\n [9] │ &lt;Dendrolagus&gt;\n[10] │ &lt;Dendrolagus&gt; bennettianus\n[11] │ &lt;Dendrolagus&gt; lumholtzi\n[12] │ &lt;Dendrolagus&gt;\n[13] │ &lt;Dendrolagus&gt;\n[14] │ &lt;Dendrolagus&gt; lumholtzi\n[15] │ &lt;Dendrolagus&gt; bennettianus\n[16] │ &lt;Dendrolagus&gt; lumholtzi\n[17] │ &lt;Dendrolagus&gt;\n[18] │ &lt;Dendrolagus&gt; lumholtzi\n[19] │ &lt;Dendrolagus&gt; lumholtzi\n[20] │ &lt;Dendrolagus&gt; lumholtzi\n... and 1282 more\n\n\n\n# Match only the second word (species name)\n1str_view(tree_kangaroo$scientificName, \"(?&lt;=\\\\s)[a-z]+\")\n\n\n1\n\nThis regex reads “Remove everything until and including the space. Return all uncapitalised letters.”\n\n\n\n\n [1] │ Dendrolagus &lt;lumholtzi&gt;\n [2] │ Dendrolagus &lt;lumholtzi&gt;\n [3] │ Dendrolagus &lt;lumholtzi&gt;\n [4] │ Dendrolagus &lt;lumholtzi&gt;\n [6] │ Dendrolagus &lt;bennettianus&gt;\n [7] │ Dendrolagus &lt;lumholtzi&gt;\n [8] │ Dendrolagus &lt;lumholtzi&gt;\n[10] │ Dendrolagus &lt;bennettianus&gt;\n[11] │ Dendrolagus &lt;lumholtzi&gt;\n[14] │ Dendrolagus &lt;lumholtzi&gt;\n[15] │ Dendrolagus &lt;bennettianus&gt;\n[16] │ Dendrolagus &lt;lumholtzi&gt;\n[18] │ Dendrolagus &lt;lumholtzi&gt;\n[19] │ Dendrolagus &lt;lumholtzi&gt;\n[20] │ Dendrolagus &lt;lumholtzi&gt;\n[21] │ Dendrolagus &lt;lumholtzi&gt;\n[24] │ Dendrolagus &lt;lumholtzi&gt;\n[25] │ Dendrolagus &lt;bennettianus&gt;\n[27] │ Dendrolagus &lt;lumholtzi&gt;\n[28] │ Dendrolagus &lt;lumholtzi&gt;\n... and 899 more\n\n\n\n\n6.2.5 Replace\nAnother common way to clean strings is to match and replace specific patterns. Here are several examples using the stringr package and base R.\n\nstr_replace()gsub()\n\n\nIn stringr, the str_replace() function can be used to replace the first match of a string. The str_replace_all() function can be used to replace all matches.\n\nrecords &lt;- c(\"Genus\", \n             \"species\", \n             \"ZZGenus species\", \n             \"Difgenus difspecies\")\n\n\nstr_replace(records, \"[aeiou]\", \"-\")     # first match\n\n[1] \"G-nus\"               \"sp-cies\"             \"ZZG-nus species\"    \n[4] \"D-fgenus difspecies\"\n\nstr_replace_all(records, \"[aeiou]\", \"-\") # all matches\n\n[1] \"G-n-s\"               \"sp-c--s\"             \"ZZG-n-s sp-c--s\"    \n[4] \"D-fg-n-s d-fsp-c--s\"\n\n\nReplace a matched pattern in a dataframe.\n\ntree_kangaroo |&gt;\n  mutate(\n    name_updated = str_replace(\n1      scientificName, \"^[A-Z][a-z]+\", \"new_name\"\n      )\n  ) |&gt;\n  select(scientificName, name_updated)\n\n\n1\n\nThis regex reads “Match and omit all letters (capitalised or not) after word one.” We then replace this with “new_name”.\n\n\n\n\n# A tibble: 1,302 × 2\n   scientificName           name_updated         \n   &lt;chr&gt;                    &lt;chr&gt;                \n 1 Dendrolagus lumholtzi    new_name lumholtzi   \n 2 Dendrolagus lumholtzi    new_name lumholtzi   \n 3 Dendrolagus lumholtzi    new_name lumholtzi   \n 4 Dendrolagus lumholtzi    new_name lumholtzi   \n 5 Dendrolagus              new_name             \n 6 Dendrolagus bennettianus new_name bennettianus\n 7 Dendrolagus lumholtzi    new_name lumholtzi   \n 8 Dendrolagus lumholtzi    new_name lumholtzi   \n 9 Dendrolagus              new_name             \n10 Dendrolagus bennettianus new_name bennettianus\n# ℹ 1,292 more rows\n\n\n\n\nIn base R the gsub() function can be used for pattern replacement.\n\nrecords &lt;- c(\"Genus\", \n             \"species\", \n             \"ZZGenus species\", \n             \"Difgenus difspecies\")\n\n\ngsub(\"[aeiou]\", \"-\", records) # all matches\n\n[1] \"G-n-s\"               \"sp-c--s\"             \"ZZG-n-s sp-c--s\"    \n[4] \"D-fg-n-s d-fsp-c--s\"\n\n\nReplace a matched pattern in a dataframe.\n\ntree_kangaroo$name_updated &lt;- gsub(\n  pattern = \"Dendrolagus\",\n  replacement = \"new_name\",\n  x = tree_kangaroo$scientificName\n)\n\ntree_kangaroo[,c(\"scientificName\", \"name_updated\")]\n\n# A tibble: 1,302 × 2\n   scientificName           name_updated         \n   &lt;chr&gt;                    &lt;chr&gt;                \n 1 Dendrolagus lumholtzi    new_name lumholtzi   \n 2 Dendrolagus lumholtzi    new_name lumholtzi   \n 3 Dendrolagus lumholtzi    new_name lumholtzi   \n 4 Dendrolagus lumholtzi    new_name lumholtzi   \n 5 Dendrolagus              new_name             \n 6 Dendrolagus bennettianus new_name bennettianus\n 7 Dendrolagus lumholtzi    new_name lumholtzi   \n 8 Dendrolagus lumholtzi    new_name lumholtzi   \n 9 Dendrolagus              new_name             \n10 Dendrolagus bennettianus new_name bennettianus\n# ℹ 1,292 more rows",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/strings.html#capitalisation",
    "href": "2_general-cleaning/strings.html#capitalisation",
    "title": "6  Strings",
    "section": "6.3 Capitalisation",
    "text": "6.3 Capitalisation\nCapitalisation (also called case style) can vary between data providers. Each data provider can have their own naming conventions, and even small differences in conventions must be standardised in order to use a dataset. There are some basic functions available to change the case of strings in stringr:\n\n# example\ntree_kangaroo$scientificName[1]\n\n[1] \"Dendrolagus lumholtzi\"\n\n\n\nstr_to_lower(tree_kangaroo$scientificName[1])\n\n[1] \"dendrolagus lumholtzi\"\n\nstr_to_upper(tree_kangaroo$scientificName[1])\n\n[1] \"DENDROLAGUS LUMHOLTZI\"\n\nstr_to_title(tree_kangaroo$scientificName[1])\n\n[1] \"Dendrolagus Lumholtzi\"\n\nstr_to_sentence(tree_kangaroo$scientificName[1])\n\n[1] \"Dendrolagus lumholtzi\"\n\n\nNormally names of higher taxonomy ranks are capitalised e.g. Myrtaceae, Aves. Capitalisation errors are usually easy to spot when you print the data object. Alternatively, you can use str_subset() to return capitalisation matches in columns you expect to have capital letters.\nFor example, in our bees dataset (downloaded at the start of this chapter) some higher taxonomy columns don’t capitalise names. The code below subsets out unique values for the variable class that have uppercase letters. Notice that no matches are found.\n\nstr_subset(unique(bees$class), \"[:upper:]\")\n\ncharacter(0)\n\n\n\n\n\n\nApis (Apis) mellifera looking for some pollen.Photo by Reiner Richter CC-BY\n\nWe can verify that there are no uppercase matches by looking at the unique values containing lowercase letters. This reveals that Insecta is entirely in lowercase.\n\nstr_subset(unique(bees$class), \"[:lower:]\")\n\n[1] \"insecta\"\n\n\nWe can correct the lowercase formatting as shown below. Remember to verify the correction before overwriting or removing the erroneous column(s).\n\nbees |&gt;\n  mutate(class_corrected = str_to_sentence(class)) |&gt;\n  select(starts_with(\"class\"))\n\n# A tibble: 1,139 × 2\n   class   class_corrected\n   &lt;chr&gt;   &lt;chr&gt;          \n 1 insecta Insecta        \n 2 insecta Insecta        \n 3 insecta Insecta        \n 4 insecta Insecta        \n 5 insecta Insecta        \n 6 insecta Insecta        \n 7 insecta Insecta        \n 8 insecta Insecta        \n 9 insecta Insecta        \n10 insecta Insecta        \n# ℹ 1,129 more rows\n\nbees_corrected &lt;- bees |&gt;\n  mutate(class_corrected = str_to_sentence(class)) |&gt;\n  select(-class) |&gt;               # Remove erroneous column\n  rename(class = class_corrected) # Rename new column to `class`",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/strings.html#summary",
    "href": "2_general-cleaning/strings.html#summary",
    "title": "6  Strings",
    "section": "6.4 Summary",
    "text": "6.4 Summary\nIn this chapter, we explored how to identify and clean strings and character pattern data. As you may have noticed, there are many ways in which strings could be formatted, which is why there are so many tools and functions for detecting and modifying them.\nIn the next chapter, we’ll look at how to clean date and time data.",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/dates.html",
    "href": "2_general-cleaning/dates.html",
    "title": "7  Dates",
    "section": "",
    "text": "7.0.1 Prerequisites\nIn this chapter, we will use Spider flower (Grevillea) occurrence records in the ALA.\n# packages\nlibrary(galah)\nlibrary(dplyr)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\nplants &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.27544a26-31b5-4a36-955d-30a1bb8a4636\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/dates.html#basic-date-manipulation",
    "href": "2_general-cleaning/dates.html#basic-date-manipulation",
    "title": "7  Dates",
    "section": "7.1 Basic date manipulation",
    "text": "7.1 Basic date manipulation\nOne of the most useful data cleaning packages for dates is the lubridate package. Below are some examples of common date cleaning functions.\n\nlibrary(lubridate)\n\n\n7.1.1 Reformat\nWe can use functions in the lubridate package to reformat dates written in different ways to YYYY-MM-DD format.\n\ndate(\"2017-10-11T14:02:00\")\n\n[1] \"2017-10-11\"\n\ndmy(\"11 October 2020\")\n\n[1] \"2020-10-11\"\n\nmdy(\"10/11/2020\")\n\n[1] \"2020-10-11\"\n\n\nSometimes dates are presented in formats that do not translate cleanly into R. For example, the following date format isn’t converted correctly when we try to convert it to a date.\n\ndf &lt;- tibble(\n  date = c(\"X2020.01.22\",\n           \"X2020.01.22\",\n           \"X2020.01.22\",\n           \"X2020.01.22\")\n)\n\ndf |&gt; \n  mutate(\n    date = as_date(date)\n  )\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `date = as_date(date)`.\nCaused by warning:\n! All formats failed to parse. No formats found.\n\n\n# A tibble: 4 × 1\n  date  \n  &lt;date&gt;\n1 NA    \n2 NA    \n3 NA    \n4 NA    \n\n\nWe can use % to be more explicit about what information is in each part of our date column, specifying where the 4-digit year (%Y), 2-digit month (%m) and 2 digit day (%d) are within each string. Learn more about date formats in the dates chapter in R for Data Science.\n\ndf |&gt; \n  mutate(\n    date = as_date(date, format = \"X%Y.%m.%d\")\n  )\n\n# A tibble: 4 × 1\n  date      \n  &lt;date&gt;    \n1 2020-01-22\n2 2020-01-22\n3 2020-01-22\n4 2020-01-22\n\n\n\n\n7.1.2 Extract\nSometimes we might need to extract certain elements of a longer date-time value for summarising, filtering, or plotting data.\n\nDate information\n\nyear(\"2017-11-28T14:02:00\")\n\n[1] 2017\n\nmonth(\"2017-11-28T14:02:00\")\n\n[1] 11\n\nweek(\"2017-11-28T14:02:00\")\n\n[1] 48\n\nday(\"2017-11-28T14:02:00\")\n\n[1] 28\n\n\n\n\nTime information\n\nymd_hms(\"2017-11-28T14:02:00\")\n\n[1] \"2017-11-28 14:02:00 UTC\"\n\nymd_hms(\"2017-11-28T14:02:00\", tz = \"Australia/Melbourne\")\n\n[1] \"2017-11-28 14:02:00 AEDT\"\n\nymd_hms(\"2017-11-28T14:02:00\") |&gt; hour()\n\n[1] 14\n\nymd_hms(\"2017-11-28T14:02:00\") |&gt; minute()\n\n[1] 2\n\nam(\"2017-11-28T14:02:00\")\n\n[1] TRUE\n\npm(\"2017-11-28T14:02:00\")\n\n[1] FALSE\n\n\n\n\n\n7.1.3 An example using galah\nData downloaded using the galah package are loaded into R as date and time data (class POSIXct). As a result, you can immediately begin extracting date/time information using the functions above.\n\nplants |&gt;\n  mutate(\n    year = year(eventDate),\n    month = month(eventDate),\n    week = isoweek(eventDate),\n    day_julian = yday(eventDate)\n    ) |&gt;\n  select(eventDate, year, month, \n         week, day_julian)\n\n# A tibble: 194,926 × 5\n   eventDate            year month  week day_julian\n   &lt;dttm&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1 2018-07-08 00:00:00  2018     7    27        189\n 2 2019-11-14 00:00:00  2019    11    46        318\n 3 2003-09-19 00:00:00  2003     9    38        262\n 4 2019-09-06 00:00:00  2019     9    36        249\n 5 2022-08-31 00:00:00  2022     8    35        243\n 6 1996-10-30 00:00:00  1996    10    44        304\n 7 1948-09-20 00:00:00  1948     9    39        264\n 8 1988-10-13 00:00:00  1988    10    41        287\n 9 2022-10-10 00:00:00  2022    10    41        283\n10 2020-10-21 00:00:00  2020    10    43        295\n# ℹ 194,916 more rows\n\n\n\n\n\n\nGrevillea acanthifolia just beginning to flower.Photo by Fagg, M. CC-BY 4.0 (Int)",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/dates.html#filter",
    "href": "2_general-cleaning/dates.html#filter",
    "title": "7  Dates",
    "section": "7.2 Filter",
    "text": "7.2 Filter\nWe can filter datasets to include or exclude data from certain dates or date ranges.\n\n# return records after 2015\nplants |&gt;\n  filter(eventDate &gt;= ymd(\"2016-01-01\"))\n\n# A tibble: 57,771 × 8\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 00005eb8-4b84… Grevillea mur… https://id.bi…           -35.8             138.\n 2 000143a7-20e2… Grevillea jun… https://id.bi…           -33.7             151.\n 3 00020893-9823… Grevillea aqu… https://id.bi…           -37.3             142.\n 4 0002cd90-4099… Grevillea tre… https://id.bi…           -30.9             134.\n 5 00040117-eae2… Grevillea par… https://id.bi…           -32.8             152.\n 6 00045361-870d… Grevillea bux… https://id.bi…           -33.7             151.\n 7 00053e34-1bdb… Grevillea ros… https://id.bi…           -37.7             145.\n 8 0006e628-69d5… Grevillea rhi… https://id.bi…           -29.5             152.\n 9 00075a74-e3de… Grevillea par… https://id.bi…           -34.2             151.\n10 0008295a-79de… Grevillea cel… https://id.bi…           -37.7             148.\n# ℹ 57,761 more rows\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;\n\n\n\n# return records between 2015 & 2018\nplants |&gt; \n  filter(eventDate &gt;= ymd(\"2016-01-01\") & \n           eventDate &lt;= ymd(\"2017-12-31\"))\n\n# A tibble: 9,246 × 8\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 000b499b-dc80… Grevillea bux… https://id.bi…           -33.7             151.\n 2 000e2c2b-953e… Grevillea hil… https://id.bi…            NA                NA \n 3 0014b88f-ecc5… Grevillea gut… https://id.bi…           -32.5             152.\n 4 001ac6ed-1de5… Grevillea ser… https://id.bi…           -32.2             150.\n 5 001c6599-0f27… Grevillea aca… https://id.bi…           -33.4             150.\n 6 001f301f-0192… Grevillea dry… https://id.bi…           -12.5             131.\n 7 002a8fb4-e1f9… Grevillea cal… https://id.bi…           -33.7             151.\n 8 002e9fb9-ff3b… Grevillea cal… https://id.bi…           -33.7             151.\n 9 0038f556-0591… Grevillea lin… https://id.bi…           -33.7             151.\n10 003d2b67-6db4… Grevillea par… https://id.bi…           -34.3             151.\n# ℹ 9,236 more rows\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "2_general-cleaning/dates.html#summary",
    "href": "2_general-cleaning/dates.html#summary",
    "title": "7  Dates",
    "section": "7.3 Summary",
    "text": "7.3 Summary\nIn this chapter, we introduced common functions for cleaning dates and times in ecological datasets. For some data cleaning tasks, you may need to explore more advanced workflows to handle specific date and time formatting requirements.\nIn the next chapter, we look at issues that require more advanced ecological data cleaning techniques.",
    "crumbs": [
      "General data cleaning",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html",
    "href": "3_ecological-cleaning/taxonomic-validation.html",
    "title": "8  Taxonomic validation",
    "section": "",
    "text": "8.0.1 Prerequisites\nIn this chapter we will use several datasets:\n# packages\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(janitor)\nlibrary(galah)\ngalah_config(email = \"your-email-here\",       # ALA-registered email\n             username = \"your-email-here\",    # GBIF account email\n             password = \"your-password-here\") # GBIF account password\n\nbirds &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.d3365af7-e802-4ef6-8fee-8d067ae855d4\") |&gt;\n  atlas_occurrences()\n\nlegless_lizards &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.6bea9b2e-b1d8-4547-b63d-20bd2cd89f3a\") |&gt;\n  atlas_occurrences()\n\ninverts &lt;- arrow::read_parquet(\n  here(\"path\", \"to\", \"inverts.parquet\"))\n\neucalypts &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.43003f6e-f8ad-45f2-bd85-d368c1b33e5d\") |&gt;\n  atlas_occurrences()\n\ngbif_species_list &lt;- arrow::read_parquet(\n  here(\"path\", \"to\", \"gbif_eucalyptus.parquet\"))",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#preview-names",
    "href": "3_ecological-cleaning/taxonomic-validation.html#preview-names",
    "title": "8  Taxonomic validation",
    "section": "8.1 Preview names",
    "text": "8.1 Preview names\nOne of the simplest ways to determine whether there are any immediate issues with taxonomic names is to preview a subset of the names. Most biodiversity datasets will have a field for the scientific names of taxa (e.g. scientificName, scientific_name), describing the lowest taxonomic level to which taxa have been identified. Looking at scientificName in our birds data, we can observe some characteristics of the names in this dataset, namely that:\n\nRecords have been identified to different taxonomic ranks (family, genus, species, subspecies)\nSome names are in uppercase, others are in sentence case\nWhere subgenera are included, they appear within parentheses\n\n\nbirds |&gt;\n  distinct(scientificName) |&gt;\n  print(n = 25)\n\n# A tibble: 22 × 1\n   scientificName                            \n   &lt;chr&gt;                                     \n 1 Dacelo (Dacelo) novaeguineae              \n 2 Todiramphus (Todiramphus) sanctus         \n 3 Ceyx azureus                              \n 4 Todiramphus (Lazulena) macleayii          \n 5 Dacelo (Dacelo) leachii                   \n 6 Tanysiptera (Uralcyon) sylvia             \n 7 Ceyx pusillus                             \n 8 Todiramphus (Cyanalcyon) pyrrhopygius     \n 9 Syma torotoro                             \n10 Todiramphus                               \n11 ALCEDINIDAE                               \n12 Dacelo (Dacelo) novaeguineae novaeguineae \n13 Dacelo (Dacelo) leachii leachii           \n14 Todiramphus (Todiramphus) sanctus sanctus \n15 Todiramphus (Todiramphus) chloris         \n16 Todiramphus (Todiramphus) sanctus vagans  \n17 Ceyx azureus azureus                      \n18 Dacelo                                    \n19 Ceyx azureus diemenensis                  \n20 Todiramphus (Lazulena) macleayii macleayii\n21 Todiramphus (Lazulena) macleayii incinctus\n22 Ceyx azureus ruficollaris",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#name-format",
    "href": "3_ecological-cleaning/taxonomic-validation.html#name-format",
    "title": "8  Taxonomic validation",
    "section": "8.2 Name format",
    "text": "8.2 Name format\nDifferent data providers might use different formats in their taxonomic names to delineate between taxonomic ranks. It doesn’t matter which format your data uses as long as it is consistent.\n\nExample 1: Subspecies\nAs an example, the ALA uses \"subsp.\" to designate subspecies of Acacia observations in the scientific name, whereas subspecies of bird observations simply include the subspecific epithet after the specific epithet.\n\nacacia_2018 &lt;- galah_call() |&gt;\n  identify(\"Acacia\") |&gt;\n  filter(year == 2018) |&gt;\n  atlas_occurrences()\n\nacacia_2018 |&gt;\n  filter(str_detect(scientificName, \"Acacia brunioides\")) |&gt;\n  distinct(scientificName)\n\n# A tibble: 2 × 1\n  scientificName                     \n  &lt;chr&gt;                              \n1 Acacia brunioides subsp. brunioides\n2 Acacia brunioides                  \n\nbirds_2023 &lt;- galah_call() |&gt;\n  identify(\"alcedinidae\") |&gt;\n  filter(year == 2023) |&gt;\n  atlas_occurrences()\n  \nbirds_2023 |&gt;\n  filter(str_detect(scientificName, \"Dacelo\")) |&gt;\n  distinct(scientificName)\n\n# A tibble: 6 × 1\n  scientificName                           \n  &lt;chr&gt;                                    \n1 Dacelo (Dacelo) novaeguineae             \n2 Dacelo (Dacelo) leachii                  \n3 Dacelo (Dacelo) novaeguineae novaeguineae\n4 Dacelo                                   \n5 Dacelo (Dacelo) leachii occidentalis     \n6 Dacelo (Dacelo) leachii leachii          \n\n\nAlthough both are correct, be sure to check your data to make sure that this naming format is consistent. Other taxonomic names (like subgenera) can differ between taxonomic groups, too.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#matching-names-to-a-species-list",
    "href": "3_ecological-cleaning/taxonomic-validation.html#matching-names-to-a-species-list",
    "title": "8  Taxonomic validation",
    "section": "8.3 Matching names to a species list",
    "text": "8.3 Matching names to a species list\nMany investigations rely on taxonomic lists of species or groups to identify relevant species. A common example is using lists of introduced, invasive, threatened, or sensitive species to identify records of interest.\nThere are several ways to filter records to match names on a species list. First, we’ll use a species list accessed via galah to filter records, which also provides additional functionality for filtering data prior to download. Then, we’ll use an external species list loaded into R to filter records.\n\ngalah\nThe ALA contains both national and state-based conservation status lists. For example, if we want to use the Victorian Restricted Species list, we can perform a text search for available lists using the term “victoria” with search_all(lists, \"victoria\").\n\nlist_search &lt;- search_all(lists, \"victoria\")\nlist_search\n\n# A tibble: 33 × 21\n   species_list_uid listName       listType dateCreated lastUpdated lastUploaded\n   &lt;chr&gt;            &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;       \n 1 dr1266           \"2 b) Protect… LOCAL_L… 2014-07-31… 2017-02-15… 2017-02-15T…\n 2 dr1782           \"Advisory Lis… CONSERV… 2014-10-27… 2022-03-16… 2022-03-16T…\n 3 dr967            \"Advisory Lis… CONSERV… 2013-11-12… 2023-06-12… 2023-06-12T…\n 4 dr2504           \"ALT Waterbug… LOCAL_L… 2015-09-08… 2016-06-14… 2016-06-14T…\n 5 dr2683           \"Dung beetles… LOCAL_L… 2016-01-15… 2020-08-20… 2020-08-20T…\n 6 dr4890           \"Endangered P… CONSERV… 2016-05-07… 2016-06-14… 2016-06-14T…\n 7 dr17134          \"Endangered S… CONSERV… 2021-03-30… 2022-11-21… 2022-11-21T…\n 8 dr6635           \"Gippsland’s … LOCAL_L… 2016-11-15… 2016-11-15… 2016-11-15T…\n 9 dr9802           \"Great Victor… LOCAL_L… 2018-11-29… 2018-11-29… 2018-11-29T…\n10 dr7749           \"IBRA Great V… PROFILE  2017-06-19… 2017-07-03… 2017-07-03T…\n# ℹ 23 more rows\n# ℹ 15 more variables: lastMatched &lt;chr&gt;, username &lt;chr&gt;, itemCount &lt;int&gt;,\n#   region &lt;chr&gt;, isAuthoritative &lt;lgl&gt;, isInvasive &lt;lgl&gt;, isThreatened &lt;lgl&gt;,\n#   isBIE &lt;lgl&gt;, isSDS &lt;lgl&gt;, wkt &lt;chr&gt;, category &lt;chr&gt;, generalisation &lt;chr&gt;,\n#   authority &lt;chr&gt;, sdsType &lt;chr&gt;, looseSearch &lt;lgl&gt;\n\n\nFiltering our results to authoritative lists only can help us find official state lists.\n\nlist_search |&gt; \n  filter(isAuthoritative == TRUE)\n\n# A tibble: 2 × 21\n  species_list_uid listName        listType dateCreated lastUpdated lastUploaded\n  &lt;chr&gt;            &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;       \n1 dr655            Victoria : Con… CONSERV… 2015-04-04… 2024-06-19… 2024-06-19T…\n2 dr490            Victorian Rest… SENSITI… 2013-06-23… 2024-05-30… 2024-05-30T…\n# ℹ 15 more variables: lastMatched &lt;chr&gt;, username &lt;chr&gt;, itemCount &lt;int&gt;,\n#   region &lt;chr&gt;, isAuthoritative &lt;lgl&gt;, isInvasive &lt;lgl&gt;, isThreatened &lt;lgl&gt;,\n#   isBIE &lt;lgl&gt;, isSDS &lt;lgl&gt;, wkt &lt;chr&gt;, category &lt;chr&gt;, generalisation &lt;chr&gt;,\n#   authority &lt;chr&gt;, sdsType &lt;chr&gt;, looseSearch &lt;lgl&gt;\n\n\nNow that we’ve found our list, we can view the contents of the list using show_values().\n\n1vic_species_list &lt;- search_all(lists, \"dr490\") |&gt;\n  show_values()\n\n\n1\n\nWe are using the list ID dr490 (specified in the species_list_uid column) to make sure we return the correct list\n\n\n\n\n• Showing values for 'dr490'.\n\nvic_species_list\n\n# A tibble: 137 × 6\n        id name                  commonName scientificName lsid  dataResourceUid\n     &lt;int&gt; &lt;chr&gt;                 &lt;chr&gt;      &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;          \n 1 5920169 Engaeus australis     Lilly Pil… Engaeus austr… http… dr490          \n 2 5920143 Engaeus fultoni       Otway Bur… Engaeus fulto… http… dr490          \n 3 5920250 Engaeus mallacoota    Mallacoot… Engaeus malla… http… dr490          \n 4 5920180 Engaeus phyllocercus  Narracan … Engaeus phyll… http… dr490          \n 5 5920240 Engaeus rostrogaleat… Strzeleck… Engaeus rostr… http… dr490          \n 6 5920203 Engaeus sericatus     Hairy Bur… Engaeus seric… http… dr490          \n 7 5920217 Engaeus sternalis     Warragul … Engaeus stern… http… dr490          \n 8 5920238 Engaeus strictifrons  Portland … Engaeus stric… http… dr490          \n 9 5920170 Engaeus urostrictus   Dandenong… Engaeus urost… http… dr490          \n10 5920214 Euastacus bidawalus   East Gipp… Euastacus bid… http… dr490          \n# ℹ 127 more rows\n\n\nWe can now compare the taxa in vic_species_list to those in our legless_lizards dataset to identify any restricted species.\n\nlegless_lizards_filtered &lt;- legless_lizards |&gt;\n  filter(!scientificName %in% vic_species_list$scientificName)\n\nlegless_lizards_filtered\n\n# A tibble: 2,128 × 8\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 001129f4-4824… Pygopus lepid… https://biodi…           -34.0             151.\n 2 0031c737-922a… Pygopus lepid… https://biodi…           -36.0             150.\n 3 005dfdd2-4a93… Lialis burton… https://biodi…           -29.1             152.\n 4 0063af2c-e070… Pygopus lepid… https://biodi…           -34.9             139.\n 5 0081dbcb-6af7… Delma impar    https://biodi…           -36.3             149.\n 6 00a9ffcd-ec03… Lialis burton… https://biodi…           -27.5             153.\n 7 00dc4542-426a… Aprasia pseud… https://biodi…           -34.7             139.\n 8 010eb86a-7bd4… Lialis burton… https://biodi…           -30.2             153.\n 9 013cb1b9-dc93… Aprasia strio… https://biodi…           -35.0             118.\n10 0157207c-3a91… Pygopus lepid… https://biodi…           -33.7             150.\n# ℹ 2,118 more rows\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;\n\n\n\n\n\n\nParadelma orientalis smiling at the camera.Photo by dhfischer CC-BY-NC 4.0 (Int)\n\nThis process has removed more than 140 records from our dataset.\n\nnrow(legless_lizards) - nrow(legless_lizards_filtered)\n\n[1] 149\n\n\nWe can also filter our queries prior to downloading data in galah by adding a filter specifying species_list_uid == dr490 to our query.\n\ngalah_call() |&gt;\n  identify(\"Pygopodidae\") |&gt;\n1  filter(species_list_uid == dr490) |&gt;\n  group_by(species) |&gt;\n  atlas_counts()\n\n\n1\n\nWe are using the list ID dr490 (specified in the species_list_uid column) to make sure we return the correct list\n\n\n\n\n# A tibble: 2 × 2\n  species               count\n  &lt;chr&gt;                 &lt;int&gt;\n1 Aprasia parapulchella   688\n2 Aprasia aurita          103\n\n\n\n\nUsing an external list\nWe can also use lists downloaded outside of galah to filter our data. As an example, let’s filter our taxonomic names to include only Australian names from the Global Register of Introduced and Invasive Species (GRIIS). After downloading this list and saving it in your working directory, we can read the list into R. Taxonomic names are stored in columns with an accepted_name prefix.\n\n1griis &lt;- read_csv(here(\"griis_australia_20240712.csv\"))\n\nglimpse(griis)\n\n\n1\n\nWe renamed the downloaded file from record 20240712-155356.csv to griis_australia_20240712.csv\n\n\n\n\n\n\nRows: 2,979\nColumns: 16\n$ scientific_name                  &lt;chr&gt; \"Oenothera longiflora L.\", \"Lampranth…\n$ scientific_name_type             &lt;chr&gt; \"species\", \"species\", \"species\", \"spe…\n$ kingdom                          &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ establishment_means              &lt;chr&gt; \"alien\", \"alien\", \"alien\", \"alien\", \"…\n$ is_invasive                      &lt;chr&gt; \"null\", \"null\", \"null\", \"null\", \"null…\n$ occurrence_status                &lt;chr&gt; \"present\", \"present\", \"present\", \"pre…\n$ checklist.name                   &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\"…\n$ checklist.iso_countrycode_alpha3 &lt;chr&gt; \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"A…\n$ accepted_name.species            &lt;chr&gt; \"Oenothera longiflora\", \"Lampranthus …\n$ accepted_name.kingdom            &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ accepted_name.phylum             &lt;chr&gt; \"Tracheophyta\", \"Tracheophyta\", \"Trac…\n$ accepted_name.class              &lt;chr&gt; \"Magnoliopsida\", \"Magnoliopsida\", \"Ma…\n$ accepted_name.order              &lt;chr&gt; \"Myrtales\", \"Caryophyllales\", \"Erical…\n$ accepted_name.family             &lt;chr&gt; \"Onagraceae\", \"Aizoaceae\", \"Ericaceae…\n$ accepted_name.habitat            &lt;chr&gt; \"[\\\"terrestrial\\\"]\", \"[\\\"terrestrial\\…\n$ accepted_name                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nNow we can check which species names in our legless_lizards dataset match names in griis.\n\n# Check which species matched the GRIIS list\nmatches &lt;- legless_lizards |&gt; \n  filter(scientificName %in% griis$accepted_name.species)\n\nmatches\n\n# A tibble: 0 × 8\n# ℹ 8 variables: recordID &lt;chr&gt;, scientificName &lt;chr&gt;, taxonConceptID &lt;chr&gt;,\n#   decimalLatitude &lt;dbl&gt;, decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;\n\n\nAfter reviewing the matches and confirming we’re happy with the list of matched species, we can exclude these taxa from our data by removing the identified rows.\n\nlegless_lizards_filtered &lt;- legless_lizards |&gt;\n  filter(!scientificName %in% matches)\n\nlegless_lizards_filtered\n\n# A tibble: 2,277 × 8\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 001129f4-4824… Pygopus lepid… https://biodi…           -34.0             151.\n 2 0027660b-3e75… Aprasia parap… https://biodi…           -35.4             149 \n 3 0031c737-922a… Pygopus lepid… https://biodi…           -36.0             150.\n 4 005dfdd2-4a93… Lialis burton… https://biodi…           -29.1             152.\n 5 0063af2c-e070… Pygopus lepid… https://biodi…           -34.9             139.\n 6 0081dbcb-6af7… Delma impar    https://biodi…           -36.3             149.\n 7 00a9ffcd-ec03… Lialis burton… https://biodi…           -27.5             153.\n 8 00dc4542-426a… Aprasia pseud… https://biodi…           -34.7             139.\n 9 010eb86a-7bd4… Lialis burton… https://biodi…           -30.2             153.\n10 013cb1b9-dc93… Aprasia strio… https://biodi…           -35.0             118.\n# ℹ 2,267 more rows\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can apply this concept of filtering to any list of species, or other fields, that you would like to exclude.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#taxonomic-names-matching",
    "href": "3_ecological-cleaning/taxonomic-validation.html#taxonomic-names-matching",
    "title": "8  Taxonomic validation",
    "section": "8.4 Taxonomic names matching",
    "text": "8.4 Taxonomic names matching\n\n8.4.1 Missing higher taxonomic information\nIt’s not uncommon to receive data that are missing information at some taxonomic levels, but this can make it tricky to summarise data or create visualisations based on taxonomy later on.\nAs an example, here is a small sample of our inverts dataset. You’ll notice that we only have information on scientific_name, class, and family.\n\ninverts_sample &lt;- inverts |&gt;\n  slice(1234:1271)\n\ninverts_sample |&gt; print(n = 5)\n\n# A tibble: 38 × 9\n  record_id      scientific_name class family  year latitude longitude sensitive\n  &lt;chr&gt;          &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;int&gt;\n1 76213a64-ed41… Helicotylenchu… chro… hoplo…    NA    -23.1      151.         0\n2 e74ec2f0-4cef… Iravadia (Irav… gast… irava…  1903    -16.5      140.         0\n3 340c2b82-6b85… Monomorium bic… inse… formi…  1998    -24.7      150.         0\n4 e7dc1fa1-6524… Saprosites men… inse… scara…  2004    -43.1      147.         0\n5 316ad303-efc6… Amitermes darw… inse… termi…  1953    -21.9      118.         0\n# ℹ 33 more rows\n# ℹ 1 more variable: project &lt;chr&gt;\n\n\n\n\n\n\nParalaoma mucoides on a rock.Photo by Nick Porch CC-BY-NC 4.0 (Int)\n\nOne way to fill in values at the missing taxonomic levels (e.g. phylum, order) is to get this information from a data infrastructure like the ALA, which has its own taxonomic backbone. We’ll start by extracting the scientific names of taxa in inverts_sample and saving these as taxa_sample_names.\n\ntaxa_sample_names &lt;- inverts_sample |&gt;\n  select(scientific_name) |&gt;\n  distinct() |&gt;\n  pull()\n\ntaxa_sample_names[1:5] # first 5 names\n\n[1] \"Helicotylenchus multicinctus\"        \"Iravadia (Iravadia) carpentariensis\"\n[3] \"Monomorium bicorne\"                  \"Saprosites mendax\"                  \n[5] \"Amitermes darwini\"                  \n\n\nWe can then search for those names in the ALA using using search_taxa() from galah. We’ll save the results in names_matches_ala. The results contain complete taxonomic information from kingdom to species.\n\n\n\n\n\n\nSearch tip\n\n\n\n\n\nAnytime you search for taxonomic matches using names, it’s good practice to double check the urls returned in taxon_concept_id to make sure your results match the names you expected!\n\n\n\n\nnames_matches_ala &lt;- search_taxa(taxa_sample_names)\nnames_matches_ala\n\n# A tibble: 38 × 15\n   search_term     scientific_name scientific_name_auth…¹ taxon_concept_id rank \n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;\n 1 Helicotylenchu… Helicotylenchu… (Cobb, 1893)           https://biodive… spec…\n 2 Iravadia (Irav… Iravadia (Irav… (Hedley, 1912)         https://biodive… spec…\n 3 Monomorium bic… Chelaner bicor… (Forel, 1907)          https://biodive… spec…\n 4 Saprosites men… Saprosites men… (Blackburn, 1892)      https://biodive… spec…\n 5 Amitermes darw… Amitermes darw… (Hill, 1922)           https://biodive… spec…\n 6 Schedorhinoter… Schedorhinoter… (Hill, 1933)           https://biodive… spec…\n 7 Sorama bicolor  Sorama bicolor  Walker, 1855           https://biodive… spec…\n 8 Windbalea warr… Windbalea warr… Rentz, 1993            https://biodive… spec…\n 9 Tholymis tilla… Tholymis tilla… (Fabricius, 1798)      https://biodive… spec…\n10 Costellipitar … Costellipitar … (Hedley, 1923)         https://biodive… spec…\n# ℹ 28 more rows\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 10 more variables: match_type &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;,\n#   class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   vernacular_name &lt;chr&gt;, issues &lt;chr&gt;\n\n\nNow we can merge this information into our inverts_sample dataset.\nFirst, let’s select the columns from names_matches_ala that we want, and rename those so we can differentiate between the columns in inverts_sample and the ones we just downloaded using galah. We’ll suffix the columns in names_matches_ala with \"_ala\".\n\nnames_matches_renamed &lt;- names_matches_ala |&gt;\n  select(scientific_name, kingdom:species) |&gt;\n1  rename_with(\\(column_name) paste0(column_name, \"_ala\"),\n              kingdom:species)\nnames_matches_renamed\n\n\n1\n\nThis line uses shorthand to write a function to append a suffix to a column name. An equivalent way of writing this is: function(column_name) {paste0(column_name, \"_ala)}This is applied to each column name from kingdom to species in the names_matches_ala dataframe.\n\n\n\n\n# A tibble: 38 × 8\n   scientific_name         kingdom_ala phylum_ala class_ala order_ala family_ala\n   &lt;chr&gt;                   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     \n 1 Helicotylenchus multic… Animalia    Nematoda   Chromado… Panagrol… Hoplolaim…\n 2 Iravadia (Iravadia) ca… Animalia    Mollusca   Gastropo… Hypsogas… Iravadiid…\n 3 Chelaner bicorne        Animalia    Arthropoda Insecta   Hymenopt… Formicidae\n 4 Saprosites mendax       Animalia    Arthropoda Insecta   Coleopte… Scarabaei…\n 5 Amitermes darwini       Animalia    Arthropoda Insecta   Blattodea Termitidae\n 6 Schedorhinotermes actu… Animalia    Arthropoda Insecta   Blattodea Rhinoterm…\n 7 Sorama bicolor          Animalia    Arthropoda Insecta   Lepidopt… Notodonti…\n 8 Windbalea warrooa       Animalia    Arthropoda Insecta   Orthopte… Tettigoni…\n 9 Tholymis tillarga       Animalia    Arthropoda Insecta   Odonata   Libelluli…\n10 Costellipitar inconsta… Animalia    Mollusca   Bivalvia  Cardiida  Veneridae \n# ℹ 28 more rows\n# ℹ 2 more variables: genus_ala &lt;chr&gt;, species_ala &lt;chr&gt;\n\n\nNow let’s join our matched names in names_matches_renamed to our inverts_sample data. This adds all higher taxonomic names columns to our inverts_sample data.\n\ninverts_sample_with_ranks &lt;- names_matches_renamed |&gt;\n  right_join(inverts_sample,\n             join_by(scientific_name == scientific_name))\n\ninverts_sample_with_ranks\n\n# A tibble: 38 × 16\n   scientific_name         kingdom_ala phylum_ala class_ala order_ala family_ala\n   &lt;chr&gt;                   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     \n 1 Helicotylenchus multic… Animalia    Nematoda   Chromado… Panagrol… Hoplolaim…\n 2 Iravadia (Iravadia) ca… Animalia    Mollusca   Gastropo… Hypsogas… Iravadiid…\n 3 Saprosites mendax       Animalia    Arthropoda Insecta   Coleopte… Scarabaei…\n 4 Amitermes darwini       Animalia    Arthropoda Insecta   Blattodea Termitidae\n 5 Schedorhinotermes actu… Animalia    Arthropoda Insecta   Blattodea Rhinoterm…\n 6 Sorama bicolor          Animalia    Arthropoda Insecta   Lepidopt… Notodonti…\n 7 Windbalea warrooa       Animalia    Arthropoda Insecta   Orthopte… Tettigoni…\n 8 Tholymis tillarga       Animalia    Arthropoda Insecta   Odonata   Libelluli…\n 9 Costellipitar inconsta… Animalia    Mollusca   Bivalvia  Cardiida  Veneridae \n10 Placamen lamellosum     Animalia    Mollusca   Bivalvia  Cardiida  Veneridae \n# ℹ 28 more rows\n# ℹ 10 more variables: genus_ala &lt;chr&gt;, species_ala &lt;chr&gt;, record_id &lt;chr&gt;,\n#   class &lt;chr&gt;, family &lt;chr&gt;, year &lt;int&gt;, latitude &lt;dbl&gt;, longitude &lt;dbl&gt;,\n#   sensitive &lt;int&gt;, project &lt;chr&gt;\n\n\nWe can verify the join worked correctly by checking that names in the original family column are identical to those in the new family_ala column. If there were mismatches, the join would produce more rows than initially occurred in inverts_sample: rows not matching to a scientific name would have returned columns with NA values, which would not join to those in inverts_sample.\nTo double check that our join worked correctly by making sure names in our original family column all match our new family_ala column. If the join did not work correctly, we would expect many rows to be returned because there would be NA values in any rows that didn’t match a scientific_name.\nNothing is returned, meaning the names in family_ala and family all match and our join worked correctly!\n\ninverts_sample_with_ranks |&gt;\n  select(scientific_name, family_ala, family) |&gt;\n  mutate(family = stringr::str_to_sentence(family)) |&gt; # match formatting\n  filter(family_ala != family)\n\n# A tibble: 0 × 3\n# ℹ 3 variables: scientific_name &lt;chr&gt;, family_ala &lt;chr&gt;, family &lt;chr&gt;\n\n\n\n\n8.4.2 Identifying mismatches in species lists\nHigher taxonomy from different data providers may not always match. If this is the case, you will need to back-fill the higher taxonomic ranks using data from your preferred taxonomic naming authority.\nLet’s use data of Eucalyptus observations we downloaded from the ALA as an example.\n\neucalypts\n\n# A tibble: 8,476 × 16\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0009ba6a-8e8e… Eucalyptus re… https://id.bi…           -17.6             145.\n 2 002b74ab-b8ce… Eucalyptus ca… https://id.bi…           -34.2             141.\n 3 002bde6c-3a7f… Eucalyptus co… https://id.bi…           -30.1             146.\n 4 002cb2ce-c8a1… Eucalyptus ca… https://id.bi…           -37.1             141.\n 5 0031022c-8e9e… Eucalyptus la… https://id.bi…           -34.4             142.\n 6 00407506-383e… Eucalyptus pa… https://id.bi…           -34.1             151.\n 7 004413ca-5a95… Eucalyptus po… https://id.bi…           -35.3             149.\n 8 005371a8-047e… Eucalyptus ca… https://id.bi…           -35.7             145.\n 9 00560db1-bb66… Eucalyptus da… https://id.bi…           -36.3             148.\n10 005fcf1f-3c6f… Eucalyptus no… https://id.bi…           -30.4             152.\n# ℹ 8,466 more rows\n# ℹ 11 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;, class &lt;chr&gt;,\n#   order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;, taxonRank &lt;chr&gt;\n\n\n\n\n\n\nEucalyptus leucoxylon leaves and flowers.Photo by davidsando CC-BY-NC 4.0 (Int)\n\nThis occurrence data contains observations of over 300 species.\n\neucalypts |&gt;\n  filter(taxonRank != \"genus\") |&gt;\n  distinct(species) |&gt; \n  count(name = \"n_species\")\n\n# A tibble: 1 × 1\n  n_species\n      &lt;int&gt;\n1       311\n\n\nLet’s say we want to compare these observations to data retrieved outside of the ALA and decide that we’d prefer to use GBIF’s1 taxonomy. ALA data uses its own taxonomic backbone that differs to GBIF’s (depending on the taxonomic group), so we will need to amend our taxonomic names to match GBIF’s.\nLet’s go through the steps to match our taxonomy in our eucalypts data to GBIF’s taxonomy. We can download a species list of Eucalyptus from GBIF. This list returns nearly 1,700 species names.\n\n\nDownload the gbif_species_list.parquet file from the Data in this book chapter.\n\n\n\n\n\n\nOriginal download query\n\n\n\n\n\nNote: This is the original query to download this species list from GBIF. It takes several minutes to download, if you would like to download the most up-to-date version of this list.\n\nlibrary(galah)\ngbif_species_list &lt;- request_data(\"species\") |&gt;\n  identify(\"Eucalyptus\") |&gt;\n  collect()\n\ngbif_species_list\n\n\n\n\n\ngbif_species_list\n\n# A tibble: 1,695 × 22\n   taxonKey scientificName               acceptedTaxonKey acceptedScientificName\n *    &lt;dbl&gt; &lt;chr&gt;                                   &lt;dbl&gt; &lt;chr&gt;                 \n 1  3176716 Eucalyptus calcicola Brooker          3176716 Eucalyptus calcicola …\n 2  3176802 Eucalyptus salicola Brooker           3176802 Eucalyptus salicola B…\n 3  3176920 Eucalyptus crebra F.Muell.            3176920 Eucalyptus crebra F.M…\n 4  3177269 Eucalyptus stricta Sieber e…          3177269 Eucalyptus stricta Si…\n 5  3717566 Eucalyptus alpina Lindl.              3717566 Eucalyptus alpina Lin…\n 6  8164544 Eucalyptus hemiphloia var. …          7908015 Eucalyptus albens Miq.\n 7  9292334 Eucalyptus goniocalyx subsp…          9292334 Eucalyptus goniocalyx…\n 8 11127669 Eucalyptus griffithii Maiden         11127669 Eucalyptus griffithii…\n 9  3176297 Eucalyptus camfieldii Maiden          3176297 Eucalyptus camfieldii…\n10  3176473 Eucalyptus macrorhyncha sub…          3176473 Eucalyptus macrorhync…\n# ℹ 1,685 more rows\n# ℹ 18 more variables: numberOfOccurrences &lt;dbl&gt;, taxonRank &lt;chr&gt;,\n#   taxonomicStatus &lt;chr&gt;, kingdom &lt;chr&gt;, kingdomKey &lt;dbl&gt;, phylum &lt;chr&gt;,\n#   phylumKey &lt;dbl&gt;, class &lt;chr&gt;, classKey &lt;dbl&gt;, order &lt;chr&gt;, orderKey &lt;dbl&gt;,\n#   family &lt;chr&gt;, familyKey &lt;dbl&gt;, genus &lt;chr&gt;, genusKey &lt;dbl&gt;, species &lt;chr&gt;,\n#   speciesKey &lt;dbl&gt;, iucnRedListCategory &lt;chr&gt;\n\n\nTo investigate whether the complete taxonomy—from kingdom to species—matches between our ALA data and GBIF species list, let’s get the columns with taxonomic information from our eucalypts dataframe and our gbif_species_list to compare.\nFirst, we can select columns containing taxonomic names in our ALA eucalypts dataframe (kingdom to species) and use distinct() to remove duplicate rows. This will leave us with one row for each distinct species in our dataset (very similar to a species list).\n\nala_names &lt;- eucalypts |&gt;\n  select(kingdom:species) |&gt;\n  distinct()\n\nala_names\n\n# A tibble: 312 × 7\n   kingdom phylum     class         order    family    genus      species       \n   &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;         \n 1 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus re…\n 2 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus ca…\n 3 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus co…\n 4 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus la…\n 5 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus pa…\n 6 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus po…\n 7 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus da…\n 8 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus no…\n 9 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus pl…\n10 Plantae Charophyta Equisetopsida Myrtales Myrtaceae Eucalyptus Eucalyptus me…\n# ℹ 302 more rows\n\n\nNow let’s filter gbif_species_list to only “accepted” names2 and select the same taxonomic names columns.\n\ngbif_names &lt;- gbif_species_list |&gt;\n  filter(taxonomicStatus == \"ACCEPTED\") |&gt; # accepted names\n  select(kingdom:species) |&gt; \n  select(!contains(\"Key\")) |&gt; # remove Key columns\n1  distinct()\n\ngbif_names\n\n\n1\n\nWe added distinct() to remove duplicate rows of species names. These duplicates appear because there might be multiple subspecies under the same species name. For example, Eucalyptus mannifera has 4 subspecies; Eucalyptus wimmerensis has 5. We aren’t interested in identifying species at that level, and so we remove these duplicates to simplify our species list.\n\n\n\n\n# A tibble: 989 × 7\n   kingdom phylum       class         order    family    genus      species     \n   &lt;chr&gt;   &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;       \n 1 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 2 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 3 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 4 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 5 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 6 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 7 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 8 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n 9 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n10 Plantae Tracheophyta Magnoliopsida Myrtales Myrtaceae Eucalyptus Eucalyptus …\n# ℹ 979 more rows\n\n\nWe can merge our two names data frames together, matching by species name, which will allow us to compare them. We’ll distinguish which columns came from each data frame by appending an \"_ala\" or \"_gbif\" suffix to each column name.\n\nmatched_names &lt;- ala_names |&gt;\n  left_join(gbif_names, \n            join_by(species == species), \n            suffix = c(\"_ala\", \"_gbif\")) |&gt;\n  select(species, everything()) # reorder columns\n\nmatched_names now contains the full taxonomy from the ALA and GBIF for all matched species3.\n\nrmarkdown::paged_table( # print paged table\n  matched_names\n  )\n\n\n  \n\n\n\nWe are now ready to compare taxonomic names to find mismatches. We can start by finding any species with a mismatch in their kingdom name by filtering to return rows where kingdom_ala and kingdom_gbif are not equal. Our returned tibble is empty, meaning there were no mismatches.\n\nmatched_names |&gt;\n  filter(kingdom_ala != kingdom_gbif)\n\n# A tibble: 0 × 13\n# ℹ 13 variables: species &lt;chr&gt;, kingdom_ala &lt;chr&gt;, phylum_ala &lt;chr&gt;,\n#   class_ala &lt;chr&gt;, order_ala &lt;chr&gt;, family_ala &lt;chr&gt;, genus_ala &lt;chr&gt;,\n#   kingdom_gbif &lt;chr&gt;, phylum_gbif &lt;chr&gt;, class_gbif &lt;chr&gt;, order_gbif &lt;chr&gt;,\n#   family_gbif &lt;chr&gt;, genus_gbif &lt;chr&gt;\n\n\nIf we do the same for phylum and class, however, we return quite a few results. It turns out that there is a difference between the ALA and GBIF in their higher taxonomic ranks of Eucalyptus plants.\n\nphylumclass\n\n\n\nmatched_names |&gt;\n  filter(phylum_ala != phylum_gbif) |&gt;\n  select(species, phylum_ala, phylum_gbif)\n\n# A tibble: 303 × 3\n   species                   phylum_ala phylum_gbif \n   &lt;chr&gt;                     &lt;chr&gt;      &lt;chr&gt;       \n 1 Eucalyptus resinifera     Charophyta Tracheophyta\n 2 Eucalyptus camaldulensis  Charophyta Tracheophyta\n 3 Eucalyptus coolabah       Charophyta Tracheophyta\n 4 Eucalyptus largiflorens   Charophyta Tracheophyta\n 5 Eucalyptus parramattensis Charophyta Tracheophyta\n 6 Eucalyptus polyanthemos   Charophyta Tracheophyta\n 7 Eucalyptus dalrympleana   Charophyta Tracheophyta\n 8 Eucalyptus nobilis        Charophyta Tracheophyta\n 9 Eucalyptus planchoniana   Charophyta Tracheophyta\n10 Eucalyptus melliodora     Charophyta Tracheophyta\n# ℹ 293 more rows\n\n\n\n\n\nmatched_names |&gt;\n  filter(class_ala != class_gbif) |&gt;\n  select(species, class_ala, class_gbif)\n\n# A tibble: 303 × 3\n   species                   class_ala     class_gbif   \n   &lt;chr&gt;                     &lt;chr&gt;         &lt;chr&gt;        \n 1 Eucalyptus resinifera     Equisetopsida Magnoliopsida\n 2 Eucalyptus camaldulensis  Equisetopsida Magnoliopsida\n 3 Eucalyptus coolabah       Equisetopsida Magnoliopsida\n 4 Eucalyptus largiflorens   Equisetopsida Magnoliopsida\n 5 Eucalyptus parramattensis Equisetopsida Magnoliopsida\n 6 Eucalyptus polyanthemos   Equisetopsida Magnoliopsida\n 7 Eucalyptus dalrympleana   Equisetopsida Magnoliopsida\n 8 Eucalyptus nobilis        Equisetopsida Magnoliopsida\n 9 Eucalyptus planchoniana   Equisetopsida Magnoliopsida\n10 Eucalyptus melliodora     Equisetopsida Magnoliopsida\n# ℹ 293 more rows\n\n\n\n\n\nIn GBIF, Eucalyptus sits in the phylum Tracheophyta and the class Magnoliopsida…\n\n\nCode\n# Use GBIF\ngalah_config(atlas = \"gbif\")\n\n# Search for taxonomic information\ngbif_taxa &lt;- search_taxa(\"eucalyptus\")\n\n# Show relevant columns\ngbif_taxa |&gt;\n  select(scientific_name, phylum, class, order)\n\n\n# A tibble: 1 × 4\n  scientific_name   phylum       class         order   \n  &lt;chr&gt;             &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;   \n1 Eucalyptus L'Hér. Tracheophyta Magnoliopsida Myrtales\n\n\n…whereas in the ALA, Eucalyptus sits in the phylum Charophyta and the class Equisetopsida.\n\n\nCode\n# Switch to download from the ALA\ngalah_config(atlas = \"ala\")\n\n# Search for taxonomic information\nala_taxa &lt;- search_taxa(\"Eucalyptus\")\n\n# Show relevant columns\nala_taxa |&gt;\n  select(scientific_name, phylum, class, order)\n\n\n# A tibble: 1 × 4\n  scientific_name phylum     class         order   \n  &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;         &lt;chr&gt;   \n1 Eucalyptus      Charophyta Equisetopsida Myrtales\n\n\nWe might not know about this issue when we first decide to match GBIF’s taxonomic names to our data. So it’s important to investigate how well these names match (and where there are any mismatches) before merging them to our complete eucalypts data.\nNow that we are aware of the differences between GBIF and ALA names, if we would like to use GBIF’s taxonomic names, we can join the columns with the suffix _gbif to our eucalypt occurrences data, and then replace the old taxonomic names columns with the GBIF names columns4.\n\neucalypts_updated_names &lt;- matched_names |&gt;\n  # select columns and join to eucalypts data\n  select(species, kingdom_gbif:genus_gbif) |&gt;\n  right_join(eucalypts,\n             join_by(species == species)) |&gt;\n  select(-(kingdom:genus)) |&gt; # remove ALA taxonomic columns\n  rename_with(                # rename columns...\n    ~ str_remove(., \"_gbif\"), # ...by removing \"_gbif\" suffix \n    kingdom_gbif:genus_gbif\n    ) \n\neucalypts_updated_names |&gt; \n  rmarkdown::paged_table()    # paged table output",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#detecting-synonyms",
    "href": "3_ecological-cleaning/taxonomic-validation.html#detecting-synonyms",
    "title": "8  Taxonomic validation",
    "section": "8.5 Detecting synonyms",
    "text": "8.5 Detecting synonyms\nScientific discoveries and advances in our understanding of evolutionary relationships can cause changes in taxonomy. These taxonomic changes can sometimes result in synonyms being created. Taxonomic synonyms refer to two or more names of the same rank, that denote the same taxon. It can be difficult to spot synonyms in your dataset, but ignoring them can result in errors during analysis, such as artificially inflated numbers of taxa or assuming misleading relationships among taxa.\nHere are some examples of synonyms.\n\n\n\nLitoria caerulea sitting on some tiles.Photo by Thomas Mesaglio CC-BY 4.0 (Int)\n\n\n\n\nAndrocalva rosea flowering.Photo by Will Cornwell CC-BY 4.0 (Int)\n\n\nFrogsMallows\n\n\nRanoidea caerulea is a synonym of Litoria caerulea, a species of frog. The genus and species returned differs between GBIF and the ALA.\n\ngalah_config(atlas = \"gbif\")\ngbif_taxa &lt;- search_taxa(\"Litoria caerulea\")\n\ngbif_taxa |&gt; \n  select(scientific_name, genus, species)\n\n# A tibble: 1 × 3\n  scientific_name                genus    species          \n  &lt;chr&gt;                          &lt;chr&gt;    &lt;chr&gt;            \n1 Litoria caerulea (White, 1790) Ranoidea Ranoidea caerulea\n\n\n\ngalah_config(atlas = \"ala\")\nala_taxa &lt;- search_taxa(\"Litoria caerulea\")\n\nala_taxa |&gt;\n  select(scientific_name, genus, species)\n\n# A tibble: 1 × 3\n  scientific_name  genus   species         \n  &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt;           \n1 Litoria caerulea Litoria Litoria caerulea\n\n\n\n\n\nCommersonia rosea is a synonym of Androcalva rosea, a species of mallow. The scientific name returned differs between GBIF and the ALA (ALA autocorrects this synonym whereas GBIF retains its synonym name).\n\ngalah_config(atlas = \"gbif\")\ngbif_taxa &lt;- search_taxa(\"commersonia rosea\")\n\ngbif_taxa |&gt; \n  select(scientific_name, genus, species)\n\n# A tibble: 1 × 3\n  scientific_name                           genus      species         \n  &lt;chr&gt;                                     &lt;chr&gt;      &lt;chr&gt;           \n1 Commersonia rosea S.A.J.Bell & L.M.Copel. Androcalva Androcalva rosea\n\n\n\ngalah_config(atlas = \"ala\")\nala_taxa &lt;- search_taxa(\"commersonia rosea\")\n\nala_taxa |&gt; \n  select(scientific_name, genus, species)\n\n# A tibble: 1 × 3\n  scientific_name  genus      species         \n  &lt;chr&gt;            &lt;chr&gt;      &lt;chr&gt;           \n1 Androcalva rosea Androcalva Androcalva rosea\n\n\n\n\n\n\nIn the above examples, taxonomic searches match correctly in GBIF because GBIF uses a special, massive database of accepted and superseded names and synonyms. This massive names database allows GBIF to match lots of different names. ALA, on the other hand, uses a much smaller taxonomic names database that matches its current taxonomic backbone. This names database is smaller, making it easier to store, but less complete than GBIF’s.\nUsing tools like search_taxa() in galah is a useful way to check whether a search returns the taxonomic information you expect.\n\n8.5.1 Checking for synonyms\nSome species lists return accepted names and synonyms. For example, here is a species list of Eucalyptus downloaded from GBIF (which we used earlier in the chapter).\n\n\nDownload the gbif_species_list.parquet file from the Data in this book chapter.\n\n\n\n\n\n\nOriginal download query\n\n\n\n\n\nNote: This is the original query to download this species list from GBIF. It takes several minutes to download, if you would like to download the most up-to-date version of this list.\n\nlibrary(galah)\ngbif_species_list &lt;- request_data(\"species\") |&gt;\n  identify(\"Eucalyptus\") |&gt;\n  collect()\n\ngbif_species_list\n\n\n\n\n\ngbif_species_list\n\n# A tibble: 1,695 × 22\n   taxonKey scientificName               acceptedTaxonKey acceptedScientificName\n *    &lt;dbl&gt; &lt;chr&gt;                                   &lt;dbl&gt; &lt;chr&gt;                 \n 1  3176716 Eucalyptus calcicola Brooker          3176716 Eucalyptus calcicola …\n 2  3176802 Eucalyptus salicola Brooker           3176802 Eucalyptus salicola B…\n 3  3176920 Eucalyptus crebra F.Muell.            3176920 Eucalyptus crebra F.M…\n 4  3177269 Eucalyptus stricta Sieber e…          3177269 Eucalyptus stricta Si…\n 5  3717566 Eucalyptus alpina Lindl.              3717566 Eucalyptus alpina Lin…\n 6  8164544 Eucalyptus hemiphloia var. …          7908015 Eucalyptus albens Miq.\n 7  9292334 Eucalyptus goniocalyx subsp…          9292334 Eucalyptus goniocalyx…\n 8 11127669 Eucalyptus griffithii Maiden         11127669 Eucalyptus griffithii…\n 9  3176297 Eucalyptus camfieldii Maiden          3176297 Eucalyptus camfieldii…\n10  3176473 Eucalyptus macrorhyncha sub…          3176473 Eucalyptus macrorhync…\n# ℹ 1,685 more rows\n# ℹ 18 more variables: numberOfOccurrences &lt;dbl&gt;, taxonRank &lt;chr&gt;,\n#   taxonomicStatus &lt;chr&gt;, kingdom &lt;chr&gt;, kingdomKey &lt;dbl&gt;, phylum &lt;chr&gt;,\n#   phylumKey &lt;dbl&gt;, class &lt;chr&gt;, classKey &lt;dbl&gt;, order &lt;chr&gt;, orderKey &lt;dbl&gt;,\n#   family &lt;chr&gt;, familyKey &lt;dbl&gt;, genus &lt;chr&gt;, genusKey &lt;dbl&gt;, species &lt;chr&gt;,\n#   speciesKey &lt;dbl&gt;, iucnRedListCategory &lt;chr&gt;\n\n\nGBIF species lists include a taxonomicStatus column that supplies information of whether a taxonomic name is accepted or a synonym. A good example is the list of names for Eucalyptus leucoxylon, which has a number of accepted subspecies names and synonyms.\n\ngbif_species_list |&gt;\n  filter(species == \"Eucalyptus leucoxylon\") |&gt;\n  select(species, taxonRank, taxonomicStatus, acceptedScientificName)\n\n# A tibble: 18 × 4\n   species               taxonRank  taxonomicStatus acceptedScientificName      \n   &lt;chr&gt;                 &lt;chr&gt;      &lt;chr&gt;           &lt;chr&gt;                       \n 1 Eucalyptus leucoxylon VARIETY    SYNONYM         Eucalyptus leucoxylon subsp…\n 2 Eucalyptus leucoxylon SPECIES    SYNONYM         Eucalyptus leucoxylon subsp…\n 3 Eucalyptus leucoxylon SUBSPECIES ACCEPTED        Eucalyptus leucoxylon subsp…\n 4 Eucalyptus leucoxylon SPECIES    ACCEPTED        Eucalyptus leucoxylon F.Mue…\n 5 Eucalyptus leucoxylon SUBSPECIES ACCEPTED        Eucalyptus leucoxylon subsp…\n 6 Eucalyptus leucoxylon VARIETY    SYNONYM         Eucalyptus leucoxylon F.Mue…\n 7 Eucalyptus leucoxylon SPECIES    SYNONYM         Eucalyptus leucoxylon subsp…\n 8 Eucalyptus leucoxylon VARIETY    SYNONYM         Eucalyptus leucoxylon subsp…\n 9 Eucalyptus leucoxylon SUBSPECIES ACCEPTED        Eucalyptus leucoxylon subsp…\n10 Eucalyptus leucoxylon VARIETY    ACCEPTED        Eucalyptus leucoxylon var. …\n11 Eucalyptus leucoxylon SUBSPECIES ACCEPTED        Eucalyptus leucoxylon subsp…\n12 Eucalyptus leucoxylon SUBSPECIES ACCEPTED        Eucalyptus leucoxylon subsp…\n13 Eucalyptus leucoxylon VARIETY    SYNONYM         Eucalyptus leucoxylon subsp…\n14 Eucalyptus leucoxylon SUBSPECIES ACCEPTED        Eucalyptus leucoxylon subsp…\n15 Eucalyptus leucoxylon SUBSPECIES ACCEPTED        Eucalyptus leucoxylon subsp…\n16 Eucalyptus leucoxylon SPECIES    SYNONYM         Eucalyptus leucoxylon subsp…\n17 Eucalyptus leucoxylon UNRANKED   ACCEPTED        SH0881366.09FU              \n18 Eucalyptus leucoxylon VARIETY    SYNONYM         Eucalyptus leucoxylon subsp…\n\n\nAll names under species are Eucalyptus leucoxylon, and yet there are **lots* of names associated with varieties, subspecies and species. The main takeaway from this example is that some species can have many accepted names and synonyms depending on the taxonomic level you are interested in. GBIF species lists are one useful way to determine what accepted names might be suitable for your data.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#detecting-homonyms",
    "href": "3_ecological-cleaning/taxonomic-validation.html#detecting-homonyms",
    "title": "8  Taxonomic validation",
    "section": "8.6 Detecting homonyms",
    "text": "8.6 Detecting homonyms\nHomonyms are identical names that are used to refer to different taxa. For example, the name Morganella is a genus of bacteria, a genus of fungi, a genus of scale insect, and a genus of brachiopod from the Devonian period5!\nWhen you search for names with search_taxa() from the galah package, you’ll receive a warning if there is a homonym issue.\n\nsearch_taxa(\"morganella\")\n\nWarning: Search returned multiple taxa due to a homonym issue.\nℹ Please provide another rank in your search to clarify taxa.\nℹ Use a `tibble` to clarify taxa, see `?search_taxa`.\n✖ Homonym issue with \"morganella\".\n\n\n# A tibble: 1 × 2\n  search_term issues \n  &lt;chr&gt;       &lt;chr&gt;  \n1 morganella  homonym\n\n\nYou can specify your query by providing other taxonomic ranks in a tibble. In a piped workflow, using the taxon_concept_id rather than the name will enable you to retrieve data for the correct taxon.\n\ntaxa &lt;- search_taxa(tibble(kingdom = \"Fungi\", genus = \"Morganella\"))\n\ntaxa |&gt; rmarkdown::paged_table()\n\n\n  \n\n\n# Return record counts, grouped by species\ngalah_call() |&gt;\n  identify(taxa$taxon_concept_id) |&gt;\n  group_by(species) |&gt;\n  atlas_counts()\n\n# A tibble: 2 × 2\n  species                 count\n  &lt;chr&gt;                   &lt;int&gt;\n1 Morganella compacta        88\n2 Morganella purpurascens    38\n\n\nFor more information on advanced taxonomic filtering in galah, you can read this vignette on the package website.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#packages",
    "href": "3_ecological-cleaning/taxonomic-validation.html#packages",
    "title": "8  Taxonomic validation",
    "section": "8.7 Packages",
    "text": "8.7 Packages\nThere are several packages available that can be used to query different taxonomic databases and check for synonyms.\n\nDownload the worms.csv file from the Data in this book chapter.\n\ntaxizeworrms\n\n\nThe taxize package allows users to search across many taxonomic data sources for hierarchical taxonomic information, such as species names (scientific and common), to resolve synonyms and homonyms.\n\nSynonyms\nWe can match names against up to 118 data sources including GBIF, Catalogue of Life, World Register of Marine Species using gnr_resolve() and return one or more names scored by how well-matched they are to these sources.\nLet’s search for any synonyms of Litoria caerulea as an example.\n\nlibrary(taxize)\n\n# Resolve names\nresolved &lt;- gnr_resolve(unique(\"litoria caerulea\"), best_match_only = TRUE)\nresolved\n\n# A tibble: 1 × 5\n  user_supplied_name submitted_name   matched_name     data_source_title score\n* &lt;chr&gt;              &lt;chr&gt;            &lt;chr&gt;            &lt;chr&gt;             &lt;dbl&gt;\n1 litoria caerulea   Litoria caerulea Litoria caerulea Wikispecies       0.988\n\n\nUsing the resolved name, we can search for its Taxonomic Serial Number using get_tsn(), which taxize uses to as a taxonomic identifier. Then we can search for existing synonyms by supplying the tsn to the synonyms() function.\n\n\n\n# Retrieve synonyms\ntsn &lt;- get_tsn(resolved$matched_name) # timed out as of 2024-07-26\nsynonyms(tsn) \n\n\n\nHomonyms\nIf a name matches multiple names, get_tsn_() will return all matches.\n\n# resolve morganella name\nresolved &lt;- gnr_resolve(\"morganella\", best_match_only = TRUE)\n\n# Retrieve matches\n# tsn &lt;- get_tsn_(resolved$matched_name) # timed out as of 2024-07-26\n# tsn\n\nYou can then use each tsn number to return the complete classification of the taxonomic name.\n\n# Retrieve upstream taxonomy\n1classification(tsn$Morganella$tsn[1],\n               upto = \"family\", \n2               db = \"itis\"\n               )\n\n\n1\n\nIndexes the first number in the tsn column \"200902\"\n\n2\n\nSpecifies database\n\n\n\n\n\nIf you are using a list of many names, you can use the other names to establish taxonomic context for matching by adding with_context = TRUE to gnr_resolve(). This context reduces the chances of returning taxonomic homonyms.\n\n# example:\nlist_of_names &lt;- c(\"name1\", \"name2\", \"name3\", ...)\n\nresolved &lt;- gnr_resolve(list_of_names, with_context = TRUE)\n\n\n\n\nThe worrms package is the R interface to the World Register of Marine Species (WoRMS). When working with data from this database, the worrms R package has the ability to cross-check synonyms in their database using their taxonomic ID (AphiaID).\nFor example, we can return existing synonyms for Lupocyclus inaequalis by supplying its AphiaID to the wm_synonyms() function. We’ll use a subset of the WoRMS dataset, saved in the worms.csv file.\n\n\nlibrary(worrms)\n\nmarine_sp &lt;- read_csv(here::here(\"worms.csv\")) \n\nmarine_sp |&gt;\n  filter(scientificname == \"Lupocyclus inaequalis\") |&gt;\n  select(AphiaID, scientificname, status)\n\n\n\n# A tibble: 1 × 3\n  AphiaID scientificname        status  \n    &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;   \n1  208785 Lupocyclus inaequalis accepted\n\n\nOur search returns a superseded synonym Goniosoma inaequale.\n\nmarine_sp |&gt;\n  filter(scientificname == \"Lupocyclus inaequalis\") |&gt;\n  pull(AphiaID) |&gt;\n  wm_synonyms() |&gt;\n  select(AphiaID, scientificname, status)\n\n# A tibble: 1 × 3\n  AphiaID scientificname      status                \n    &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;                 \n1  453207 Goniosoma inaequale superseded combination",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#input-from-experts",
    "href": "3_ecological-cleaning/taxonomic-validation.html#input-from-experts",
    "title": "8  Taxonomic validation",
    "section": "8.8 Input from experts",
    "text": "8.8 Input from experts\nProgrammatic solutions for validating taxonomy can only go so far. To obtain a high quality species list, it’s good practice to seek validation from experts. Museums or taxonomic societies are great sources of knowledge.\nHere is a list of some Australian taxonomic society groups to help validate taxonomies.\n\n8.8.1 Australian taxonomic society groups\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists\n\n\n\n8.8.2 Global taxonomy\n\nGBIF taxonomic backbone - Uses over 100 different sources\nIntegrated Taxonomic Information System, ITIS - Authoritative taxonomic information on plants, animals, fungi, and microbes\nCatalogue of Life - Global taxonomic catalogue\n\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/taxonomic-validation.html#footnotes",
    "href": "3_ecological-cleaning/taxonomic-validation.html#footnotes",
    "title": "8  Taxonomic validation",
    "section": "",
    "text": "Global Biodiversity Infrastructure Facility (GBIF)↩︎\nGBIF’s species list is quite comprehensive, and it includes the taxonomicStatus of a name as “accepted”, “synonym”, “variety” or “doubtful”. To keep our example simpler, we are only using the accepted names.↩︎\nSeveral species names did not match to GBIF. In a complete data cleaning workflow, these should be investigated as the ALA and GBIF might use synonym names to describe the same species or subspecies.↩︎\nThere were some names that did not match GBIF, meaning their taxonomic columns contain NA values. Be sure to either fix these NA values before merging dataframes, or back-fill after merging dataframes. Otherwise, you might add missing data in your data set unintentionally!↩︎\nReferred to as “the Age of Fishes”, the Devonian Period occurred ~419 to ~359 million years ago.↩︎",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-investigation.html",
    "href": "3_ecological-cleaning/geospatial-investigation.html",
    "title": "9  Geospatial investigation",
    "section": "",
    "text": "9.0.1 Prerequisites\nIn this chapter we’ll use data of Banksia serrata occurrence records since 2022 and quokka occurrence records from the ALA.\n# packages\nlibrary(galah)\nlibrary(dplyr)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\nbanksia &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.461d2169-48a7-47fe-9419-13ba1b93160a\") |&gt;\n  atlas_occurrences()\n\nquokkas &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.5b75fbae-6bd8-481d-aea7-c5112f2345e1\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial investigation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-investigation.html#quick-visualisation",
    "href": "3_ecological-cleaning/geospatial-investigation.html#quick-visualisation",
    "title": "9  Geospatial investigation",
    "section": "9.1 Quick visualisation",
    "text": "9.1 Quick visualisation\nMentioned in the Inspect chapter, one of the most straightforward ways to check for spatial errors is to plot your data onto a map. More obvious spatial errors are much easier to spot visually.\nIn most spatial datasets, the most important columns are decimalLatitude and decimalLongitude (or similarly named columns). These contain the latitude and longitude of each observation in decimal form (rather than degrees).\n\n# Retrieve map of Australia\naus &lt;- st_transform(ozmap_country, 4326)\n\n# A quick plot of banksia occurrences\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) + \n  geom_point(data = banksia, \n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             colour = \"orchid\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nIn a quick glance, we can check whether there are any records in places that they shouldn’t be. Are there records in the ocean? Are there records in states/territories where our species definitely doesn’t live? Is the data too sparse to use for our expected analysis plan?\nLucky for us, the banksia data we just plotted doesn’t seem to have any obvious issues!",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial investigation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-investigation.html#precision",
    "href": "3_ecological-cleaning/geospatial-investigation.html#precision",
    "title": "9  Geospatial investigation",
    "section": "9.2 Precision",
    "text": "9.2 Precision\nNot all observations have the same degree of precision. Coordinate precision can vary between data sources and recording equipment. For example, coordinates recorded with a GPS unit or a phone generally have higher precision than coordinates recorded manually from a locality description.\nThe degree of precision you require will depend on the granularity of your research question and analysis. A fine-scale question will require data measured at a fine-scale to answer it. National or global scale questions require less precise data.\nWhen downloading data from the ALA with the galah package, it’s possible to include the coordinatePrecision field with your data; this provides a decimal representation of the precision of coordinates for each observation.\n\nbanksia |&gt;\n  select(scientificName, \n         coordinatePrecision\n         ) |&gt;\n1  filter(!is.na(coordinatePrecision))\n\n\n1\n\nNot all records have this information recorded, so we also filter to only records with a coordinatePrecision value.\n\n\n\n\n# A tibble: 84 × 2\n   scientificName  coordinatePrecision\n   &lt;chr&gt;                         &lt;dbl&gt;\n 1 Banksia serrata         0.000000001\n 2 Banksia serrata         0.000000001\n 3 Banksia serrata         0.000000001\n 4 Banksia serrata         0.000000001\n 5 Banksia serrata         0.000000001\n 6 Banksia serrata         0.000000001\n 7 Banksia serrata         0.000000001\n 8 Banksia serrata         0.000000001\n 9 Banksia serrata         0.000000001\n10 Banksia serrata         0.000000001\n# ℹ 74 more rows\n\n\nOnly a few records have coordinatePrecision recorded, but that subset of records are very precise.\n\nbanksia |&gt; \n  group_by(coordinatePrecision) |&gt;\n  count()\n\n# A tibble: 2 × 2\n# Groups:   coordinatePrecision [2]\n  coordinatePrecision     n\n                &lt;dbl&gt; &lt;int&gt;\n1         0.000000001    84\n2        NA             804\n\n\nFilter your records to only those under a specific measure of precision.\n\n# Filter by number of decimal places\nbanksia &lt;- banksia |&gt;\n  filter(coordinatePrecision &lt;= 0.001)",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial investigation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-investigation.html#uncertainty",
    "href": "3_ecological-cleaning/geospatial-investigation.html#uncertainty",
    "title": "9  Geospatial investigation",
    "section": "9.3 Uncertainty",
    "text": "9.3 Uncertainty\n\nSimilarly, not all observations have the same degree of accuracy. An organism’s exact location will likely have an area of uncertainty around it, which can grow or shrink depending on the method of observation and the species observed, similar to coordinate precision. However, a main distinction between record uncertainty and record precision is that data infrastructures like the ALA can add uncertainty to a record. Obscuring a record’s exact location is usually for sensitivity purposes. Although obscuring data is important for protecting individual species, uncertainty inevitably affects how robust the results from species distribution models are, so it is important to be aware of location uncertainty.\nWhen downloading data from the ALA with the galah package, it’s possible to include the coordinateUncertaintyInMeters field with your data. This refers to the margin of error, represented as a circular area, around the true location of the recorded observation. We added this column in our original galah query.\n\nbanksia |&gt;\n  select(scientificName,\n         coordinateUncertaintyInMeters\n         )\n\n# A tibble: 888 × 2\n   scientificName  coordinateUncertaintyInMeters\n   &lt;chr&gt;                                   &lt;dbl&gt;\n 1 Banksia serrata                           316\n 2 Banksia serrata                            10\n 3 Banksia serrata                          2268\n 4 Banksia serrata                            NA\n 5 Banksia serrata                            NA\n 6 Banksia serrata                            NA\n 7 Banksia serrata                            15\n 8 Banksia serrata                             4\n 9 Banksia serrata                            NA\n10 Banksia serrata                            NA\n# ℹ 878 more rows\n\n\nThere is a range of coordinate uncertainty in our data, with many falling within 10m of uncertainty.\n\nbanksia |&gt; \n  count(coordinateUncertaintyInMeters) \n\n# A tibble: 173 × 2\n   coordinateUncertaintyInMeters     n\n                           &lt;dbl&gt; &lt;int&gt;\n 1                             1     4\n 2                             2    10\n 3                             3    38\n 4                             4   156\n 5                             5    59\n 6                             6    21\n 7                             7    15\n 8                             8    29\n 9                             9    23\n10                            10    76\n# ℹ 163 more rows\n\n\nIf your analysis requires greater certainty, you can then filter your records to a smaller area of uncertainty.\n\n# Filter by number of decimal places\nbanksia &lt;- banksia |&gt;\n  filter(coordinateUncertaintyInMeters &lt;= 5)",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial investigation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-investigation.html#obscured-location",
    "href": "3_ecological-cleaning/geospatial-investigation.html#obscured-location",
    "title": "9  Geospatial investigation",
    "section": "9.4 Obscured location",
    "text": "9.4 Obscured location\nOccurrence records of sensitive, endangered, or critically endangered species may be deliberately obscured (i.e. generalised or obfuscated) to protect the true locations of these species. This process blurs an organism’s actual location to avoid risks like poaching or capture while still allowing their data to be included in broader summaries.\nIn the ALA, the field dataGeneralizations indicates whether a record has been has been obscured and provides information on the size of the area to which the point has been generalised.\n\n\n\n\n\n\nNote on dataGeneralizations\n\n\n\n\n\nThe dataGeneralizations field will only be available to use or download when there are records in your query that have been generalised/obscured.\n\n\n\n\nsearch_all(fields, \"dataGeneralization\")\n\n# A tibble: 2 × 3\n  id                      description                        type  \n  &lt;chr&gt;                   &lt;chr&gt;                              &lt;chr&gt; \n1 dataGeneralizations     Data Generalised during processing fields\n2 raw_dataGeneralizations &lt;NA&gt;                               fields\n\n\nFor example, the Western Swamp Tortoise is a critically endangered species in Western Australia. There are 127 records of this species in the ALA.\n\ngalah_call() |&gt;\n  identify(\"Pseudemydura umbrina\") |&gt;\n  atlas_counts()\n\n# A tibble: 1 × 1\n  count\n  &lt;int&gt;\n1   127\n\n\nGrouping record counts by the dataGeneralizations column shows that 126 of the 127 records have been obscured by 10 km.\n\ngalah_call() |&gt;\n  identify(\"Pseudemydura umbrina\") |&gt;\n  group_by(dataGeneralizations) |&gt;\n  atlas_counts()\n\n# A tibble: 1 × 2\n  dataGeneralizations                                                      count\n  &lt;chr&gt;                                                                    &lt;int&gt;\n1 Record is Critically Endangered in Western Australia. Generalised to 10…   126\n\n\n\nWhat do obscured data look like?\nQuokka data offer a nice example of what to look for when data points have been obscured. When plotted, obscured occurrence data appear as if points were placed onto a grid 1.\n\n# remove records with missing coordinates\nquokkas &lt;- quokkas |&gt;\n  tidyr::drop_na(decimalLatitude, decimalLongitude)\n\n# aus map\naus &lt;- ozmap_country |&gt; st_transform(4326)\n\n# map quokka occurrences\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) + \n  geom_point(data = quokkas, \n             aes(x = decimalLongitude,\n                 y = decimalLatitude,\n                 colour = dataGeneralizations |&gt;\n                   str_wrap(18))) +\n  scale_colour_manual(values = c(\"sienna3\", \"snow4\"),\n                      guide = guide_legend(position = \"bottom\")) +\n  guides(colour = guide_legend(title = \"Data\\ngeneralizations\")) +\n  xlim(114,120) + \n  ylim(-36,-31)\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nKeep in mind that survey data can also appear gridded if survey locations were evenly spaced, so be sure to double check before assuming data have been obscured!\nFor more information, check out the ALA’s support article about working with threatened, migratory and sensitive species.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial investigation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-investigation.html#summary",
    "href": "3_ecological-cleaning/geospatial-investigation.html#summary",
    "title": "9  Geospatial investigation",
    "section": "9.5 Summary",
    "text": "9.5 Summary\nIn this chapter, we showed some ways to investigate the geospatial coordinates of your data and determine the level of precision, uncertainty (accuracy?), or obfucsation.\nIn the next chapter, we’ll see examples of issues with coordinates that require correcting or removing.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial investigation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-investigation.html#footnotes",
    "href": "3_ecological-cleaning/geospatial-investigation.html#footnotes",
    "title": "9  Geospatial investigation",
    "section": "",
    "text": "This is what actually happened—locations have been “snapped” onto a grid determined by the generalised distance.↩︎",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Geospatial investigation</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-cleaning.html",
    "href": "3_ecological-cleaning/geospatial-cleaning.html",
    "title": "10  Geospatial cleaning",
    "section": "",
    "text": "10.0.1 Prerequisites\nIn this chapter we’ll use several datasets:\n# packages\nlibrary(galah)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ozmaps)\nlibrary(tidyr)\nlibrary(stringr)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\ndesert_plant &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.96e26768-a725-490f-a4cf-fb92919e16fe\") |&gt;\n  atlas_occurrences()\n\nfrogs &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.625b3655-9fb7-4b0e-acff-30dc820c2272\") |&gt;\n  atlas_occurrences()\n\nnative_mice &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.4af234e0-4cec-4720-917a-f12ccfb83c4f\") |&gt;\n  atlas_occurrences()\n\nacacias &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.19951ce0-9f3f-4692-b079-02f4f0fd0a6d\") |&gt;\n  atlas_occurrences()\n\nbutterflies &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.b28aaf66-4d18-41f6-8e84-e420656923c9\") |&gt;\n  atlas_occurrences()\n\nbitter_peas &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.44089ead-b5da-41c7-bdbb-761aec1c8825\") |&gt;\n  atlas_occurrences()",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial cleaning</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-cleaning.html#missing-coordinates",
    "href": "3_ecological-cleaning/geospatial-cleaning.html#missing-coordinates",
    "title": "10  Geospatial cleaning",
    "section": "10.1 Missing coordinates",
    "text": "10.1 Missing coordinates\nAs discussed in Missing Values chapter, many spatial analytical tools are not compatible with missing coordinate data. We recommend identifying the rows that have missing data before deciding to exclude them.\n\n# Identify missing data in coordinates\ndesert_plant |&gt; \n  filter(is.na(decimalLatitude) | is.na (decimalLongitude))\n\n# A tibble: 74 × 9\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 000d4874-8c74… Eremophila ma… https://id.bi…              NA               NA\n 2 050653b6-a41c… Eremophila ma… https://id.bi…              NA               NA\n 3 06e69581-7d6d… Eremophila ma… https://id.bi…              NA               NA\n 4 0eead38f-0c16… Eremophila ma… https://id.bi…              NA               NA\n 5 0f52e34b-a803… Eremophila ma… https://id.bi…              NA               NA\n 6 1190b3b9-90d8… Eremophila ma… https://id.bi…              NA               NA\n 7 18d11ae3-e558… Eremophila ma… https://id.bi…              NA               NA\n 8 19426c52-9d49… Eremophila ma… https://id.bi…              NA               NA\n 9 205d432e-c6bc… Eremophila ma… https://id.bi…              NA               NA\n10 2ab6846b-00cb… Eremophila ma… https://id.bi…              NA               NA\n# ℹ 64 more rows\n# ℹ 4 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, PRESUMED_SWAPPED_COORDINATE &lt;lgl&gt;\n\n\n\n\n\n\nYou can use drop_na() to remove missing values from your dataset.\n\n# Excluding them\ndesert_plant &lt;- desert_plant |&gt; \n1  tidyr::drop_na(decimalLatitude, decimalLongitude)\n\n\n1\n\nYou could also use filter(!is.na(decimalLatitude), !is.na(decimalLongitude)) to achieve the same thing",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial cleaning</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-cleaning.html#correcting-fixable-coordinate-errors",
    "href": "3_ecological-cleaning/geospatial-cleaning.html#correcting-fixable-coordinate-errors",
    "title": "10  Geospatial cleaning",
    "section": "10.2 Correcting fixable coordinate errors",
    "text": "10.2 Correcting fixable coordinate errors\n\nSpatial outliers can sometimes result from taxonomic misidentification, but not always. Occasionally, records that appear as outliers are true observations of a species but contain mistakes in their coordinates. To avoid unnecessarily deleting data, it’s good practice to use multiple sources of spatial information to decide whether an unexpected data point is due to a small but fixable error in coordinates.\nMany coordinate issues can be solved through data manipulation rather than discarding the data. Here are several coordinate issues that can be identified and corrected.\n\n10.2.1 Swapped numeric sign\nIf you notice a cluster of points mirrored in the opposite hemisphere, consider correcting the sign instead of discarding the points.\nLet’s use MacDonnell’s desert fuschia occurrence records for our example. Including the PRESUMED_SWAPPED_COORDINATE assertion column when downloading records using the galah package allows us to identify records flagged as potentially having swapped coordinates.\n\n\n\n\nEremophila macdonnellii aka MacDonnell’s desert fuschia.Photo by M. Fagg CC-BY 3.0 (Au)\n\n\ndesert_plant &lt;- desert_plant |&gt;\n  drop_na(decimalLongitude, decimalLatitude) # remove NA coordinates\n\ndesert_plant |&gt;\n  select(PRESUMED_SWAPPED_COORDINATE, everything())\n\n# A tibble: 890 × 9\n   PRESUMED_SWAPPED_COO…¹ recordID scientificName taxonConceptID decimalLatitude\n   &lt;lgl&gt;                  &lt;chr&gt;    &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;\n 1 FALSE                  0009009… Eremophila ma… https://id.bi…           -22.8\n 2 FALSE                  002e372… Eremophila ma… https://id.bi…           -25.3\n 3 FALSE                  0034dc0… Eremophila ma… https://id.bi…           -23.9\n 4 FALSE                  0063223… Eremophila ma… https://id.bi…           -24.5\n 5 FALSE                  00d15a5… Eremophila ma… https://id.bi…           -27.8\n 6 FALSE                  013049a… Eremophila ma… https://id.bi…           -25.2\n 7 FALSE                  015571a… Eremophila ma… https://id.bi…           -22.1\n 8 FALSE                  01b5e44… Eremophila ma… https://id.bi…           -25.2\n 9 FALSE                  02524e1… Eremophila ma… https://id.bi…           -25.1\n10 FALSE                  026c225… Eremophila ma… https://id.bi…           -25.8\n# ℹ 880 more rows\n# ℹ abbreviated name: ¹​PRESUMED_SWAPPED_COORDINATE\n# ℹ 4 more variables: decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;\n\n\nIf we plot these records on a map and colour the points based on values in the PRESUMED_SWAPPED_COORDINATE assertion column, we can see that there is a single record (in orange) that looks like its coordinates have been mirrored across hemispheres.\n\n# Retrieve map of Australia\naus &lt;- st_transform(ozmap_country, 4326)\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = desert_plant,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude,\n                 colour = PRESUMED_SWAPPED_COORDINATE)) + \n  pilot::scale_color_pilot()\n\n\n\n\n\n\n\n\nWe can correct the numeric signs using if_else() from dplyr. The first statement updates our decimalLongitude column so that when decimalLongitude is less than 0, we remove the negative symbol by multiplying by -1, otherwise we keep the original longitude value. The second statement updates our decimalLatitude column using the same process.\n\ndesert_plant_filtered &lt;- desert_plant |&gt;\n  mutate(\n    decimalLongitude = if_else(decimalLongitude &lt; 0,\n      decimalLongitude * -1,\n      decimalLongitude\n    ),\n    decimalLatitude = if_else(decimalLatitude &gt; 0,\n      decimalLatitude * -1,\n      decimalLatitude\n    )\n  )\n\nAnd here’s the updated map, with the corrected coordinates.\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = desert_plant_filtered,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude,\n                 colour = PRESUMED_SWAPPED_COORDINATE)) + \n  pilot::scale_color_pilot()\n\n\n\n\n\n\n\n\n\n\n10.2.2 Location description doesn’t match coordinates\nMisalignment between location metadata and coordinates could indicate errors in the dataset, but it’s sometimes possible to rectify these. Let’s use red-eyed tree frog data as an example.\n\n\n\n\nLitoria chloris standing on leaves.Photo by Reiner Richter CC-BY\n\n\nfrogs &lt;- frogs |&gt;\n  drop_na(decimalLatitude, decimalLongitude) # remove NA values\n\nfrogs\n\n# A tibble: 30 × 14\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0bbcdc4a-5638… Litoria chlor… https://biodi…           -28.4             153.\n 2 16ecde94-6b9b… Litoria chlor… https://biodi…           -28.4             153.\n 3 22b115c9-f799… Litoria chlor… https://biodi…           -28.2             153.\n 4 236bda61-799f… Litoria chlor… https://biodi…           -20.3             149.\n 5 2ba9c818-e81a… Litoria chlor… https://biodi…           -27.4             152.\n 6 4a1b77fa-3538… Litoria chlor… https://biodi…           -30.1             153.\n 7 4d3274a4-f9cd… Litoria chlor… https://biodi…           -27.4             153.\n 8 4e87c52b-2b80… Litoria chlor… https://biodi…           -28.2             153.\n 9 52c1043c-5f79… Litoria chlor… https://biodi…           -29.7             152.\n10 52d5551a-816d… Litoria chlor… https://biodi…           -29.9             153.\n# ℹ 20 more rows\n# ℹ 9 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, countryCode &lt;chr&gt;, locality &lt;chr&gt;, family &lt;chr&gt;,\n#   genus &lt;chr&gt;, species &lt;chr&gt;, cl22 &lt;chr&gt;\n\n\nWhen we plot the coordinates of our red-eyed tree frog occurrences, there is an unexpected observation near Japan (or where Japan would appear if we had plotted more countries and not just Australia). This is quite surprising—red-eyed tree frogs are not native to Japan!\n\n# Get a map of aus, transform projection\naus &lt;- st_transform(ozmap_country, 4326)\n\n# Map\nggplot() +\n  geom_sf(data = aus,\n          colour = \"grey60\") +\n  geom_point(data = frogs,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             colour = \"#557755\")\n\n\n\n\n\n\n\n\nLet’s check the countryCode column to see whether this might be an Australian record with a mistake in the coordinates. Using distinct(), we can see that there are 2 country codes…\n\nfrogs |&gt;\n  distinct(countryCode)\n\n# A tibble: 2 × 1\n  countryCode\n  &lt;chr&gt;      \n1 AU         \n2 JP         \n\n\n…and filtering to Japan (\"JP\") identifies our stray data point.\n\nfrogs |&gt;\n  filter(countryCode == \"JP\")\n\n# A tibble: 1 × 14\n  recordID        scientificName taxonConceptID decimalLatitude decimalLongitude\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 c08e641e-cf01-… Litoria chlor… https://biodi…            24.5             152.\n# ℹ 9 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, countryCode &lt;chr&gt;, locality &lt;chr&gt;, family &lt;chr&gt;,\n#   genus &lt;chr&gt;, species &lt;chr&gt;, cl22 &lt;chr&gt;\n\n\nSo far this observation does seem to be in Japan. To be extra certain, we can also use the column locality, which provides additional information from the data collector about the record’s location.\n\nfrogs |&gt;\n  filter(countryCode == \"JP\") |&gt;\n  select(countryCode, locality, scientificName, decimalLatitude, decimalLongitude)\n\n# A tibble: 1 × 5\n  countryCode locality scientificName  decimalLatitude decimalLongitude\n  &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;                     &lt;dbl&gt;            &lt;dbl&gt;\n1 JP          mt bucca Litoria chloris            24.5             152.\n\n\nThe locality column reveals the observation was made in “mt bucca”. This is surprising to see because Mt Bucca is a mountain in Queensland!\nWhen we look at our Japan data point’s decimalLongitude and decimalLatitude alongside other values in our data, it becomes clear that the Japan data point seems to sit within the same numerical range as other points, but the decimalLatitude is positive rather than negative.\n\nfrogs |&gt;\n  arrange(desc(countryCode)) |&gt;\n  select(countryCode, decimalLongitude, decimalLatitude) |&gt;\n  print(n = 5)\n\n# A tibble: 30 × 3\n  countryCode decimalLongitude decimalLatitude\n  &lt;chr&gt;                  &lt;dbl&gt;           &lt;dbl&gt;\n1 JP                      152.            24.5\n2 AU                      153.           -28.4\n3 AU                      153.           -28.4\n4 AU                      153.           -28.2\n5 AU                      149.           -20.3\n# ℹ 25 more rows\n\n\nAll of this evidence suggests that our Japan “outlier” might instead be an occurrence point with a mis-entered latitude coordinate.\nLet’s fix this by adding a negative symbol (-) to the record’s latitude coordinate number. We’ll use case_when() from dplyr to specify that if the countryCode == \"JP\", then we’ll multiply the decimalLatitude by -1, reversing the symbol.\n\nfrogs_fixed &lt;- frogs |&gt;\n  mutate(\n    decimalLatitude = case_when(\n      countryCode == \"JP\" ~ decimalLatitude * -1, \n      .default = decimalLatitude \n    ))\n\nfrogs_fixed |&gt;\n  filter(countryCode == \"JP\") |&gt; \n  select(decimalLatitude, decimalLongitude, countryCode)\n\n# A tibble: 1 × 3\n  decimalLatitude decimalLongitude countryCode\n            &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;      \n1           -24.5             152. JP         \n\n\nMapping our data again shows our outlier is an outlier no longer!\n\n\nCode\nggplot() +\n  geom_sf(data = aus,\n          colour = \"grey60\") +\n  geom_point(data = frogs_fixed,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             colour = \"#557755\")",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial cleaning</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-cleaning.html#excluding-unfixable-coordinate-errors",
    "href": "3_ecological-cleaning/geospatial-cleaning.html#excluding-unfixable-coordinate-errors",
    "title": "10  Geospatial cleaning",
    "section": "10.3 Excluding unfixable coordinate errors",
    "text": "10.3 Excluding unfixable coordinate errors\nSome coordinates issues cannot be fixed or inferred. In this case, it is important that you identify which records have issues and remove them prior to analysis. Here are some examples of geospatial errors that might need to be identified and removed in your dataset.\n\n10.3.1 Flipped coordinates\nRecords with flipped coordinates typically appear as a group of points in an unexpected location. Although sometimes they can be fixed, this is not always the case.\nLet’s use occurrence records of Kowari (a native, carnivorous mouse species) as an example. Including the COUNTRY_COORDINATE_MISMATCH assertion column when downloading records using the galah package allows us to identify records flagged as having mismatches between coordinates and country metadata.\n\n\n\n\nDasyuroides byrnei pair captured in red light.Photo by Ged Tranter CC-BY\n\n\nnative_mice &lt;- native_mice |&gt;\n  drop_na(decimalLongitude, decimalLatitude)\n  \nnative_mice |&gt;\n  select(COUNTRY_COORDINATE_MISMATCH, everything())\n\n# A tibble: 1,334 × 131\n   COUNTRY_COORDINATE_MISMATCH scientificName   decimalLongitude decimalLatitude\n   &lt;lgl&gt;                       &lt;chr&gt;                       &lt;dbl&gt;           &lt;dbl&gt;\n 1 FALSE                       Dasyuroides byr…             140.           -24.1\n 2 FALSE                       Dasyuroides byr…             141.           -23.8\n 3 FALSE                       Dasyuroides byr…             140.           -27.0\n 4 FALSE                       Dasyuroides byr…             139.           -26.8\n 5 FALSE                       Dasyuroides byr…             140.           -27.0\n 6 FALSE                       Dasyuroides byr…             140.           -26.9\n 7 FALSE                       Dasyuroides byr…             141.           -23.8\n 8 FALSE                       Dasyuroides byr…             139.           -26.8\n 9 FALSE                       Dasyuroides byr…             139.           -25.7\n10 FALSE                       Dasyuroides byr…             140.           -26.9\n# ℹ 1,324 more rows\n# ℹ 127 more variables: eventDate &lt;dttm&gt;, country &lt;chr&gt;, countryCode &lt;chr&gt;,\n#   locality &lt;chr&gt;, AMBIGUOUS_COLLECTION &lt;lgl&gt;, AMBIGUOUS_INSTITUTION &lt;lgl&gt;,\n#   BASIS_OF_RECORD_INVALID &lt;lgl&gt;, biosecurityIssue &lt;lgl&gt;,\n#   COLLECTION_MATCH_FUZZY &lt;lgl&gt;, COLLECTION_MATCH_NONE &lt;lgl&gt;,\n#   CONTINENT_COORDINATE_MISMATCH &lt;lgl&gt;, CONTINENT_COUNTRY_MISMATCH &lt;lgl&gt;,\n#   CONTINENT_DERIVED_FROM_COORDINATES &lt;lgl&gt;, …\n\n\nSometimes, flipped coordinates can be fixed by switching the latitude and longitude coordinates. Other times, like in this example, the way to fix the coordinates isn’t obvious.\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = native_mice,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude,\n             colour = COUNTRY_COORDINATE_MISMATCH)) + \n  pilot::scale_color_pilot()\n\n\n\n\n\n\n\n\nTo remove these data, we can filter the dataset to exclude records that do not fall within Australia’s minimum and maximum coordinates.\n\nnative_mice_filtered &lt;- native_mice |&gt;\n  filter(decimalLongitude &gt; 100,\n         decimalLongitude &lt; 155,\n         decimalLatitude &gt; -45,\n         decimalLatitude &lt; -10)\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = native_mice_filtered,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude,\n             colour = COUNTRY_COORDINATE_MISMATCH)) + \n  pilot::scale_color_pilot()\n\n\n\n\n\n\n\n\n\n\n10.3.2 Zero coordinates\nSometimes latitude and/or longitude data are recorded as having zero values; these values are not accurate representations of locations and thus should be removed.\nLet’s use acacia data as an example. Including the ZERO_COORDINATE assertion column to your download allows us to identify records flagged as having zero values in the coordinate fields.\n\n\n\n\nAcacia aneura flowering.Photo by rachbaxter CC-BY-NC 4.0 (Int)\n\n\nacacias &lt;- acacias |&gt;\n  drop_na(decimalLatitude, decimalLongitude) # remove NA values\n\nacacias |&gt;\n  select(ZERO_COORDINATE, everything())\n\n# A tibble: 10,804 × 11\n   ZERO_COORDINATE recordID        scientificName taxonConceptID decimalLatitude\n   &lt;lgl&gt;           &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;\n 1 FALSE           0013ae12-fda4-… Acacia aneura  https://id.bi…           -31.5\n 2 FALSE           00197d65-f235-… Acacia aneura  https://id.bi…           -29.5\n 3 FALSE           001a3cbb-a370-… Acacia aneura… https://id.bi…           -28.0\n 4 FALSE           00238db7-6c4e-… Acacia aneura… https://id.bi…           -34.1\n 5 FALSE           00276566-b590-… Acacia aneura  https://id.bi…           -29.7\n 6 FALSE           0029f3cf-b541-… Acacia aneura  https://id.bi…           -29.0\n 7 FALSE           0034f771-a3e1-… Acacia aneura  https://id.bi…           -31.1\n 8 FALSE           0035cb4f-85e5-… Acacia aneura… https://id.bi…           -29.5\n 9 FALSE           003cce3b-f3f8-… Acacia aneura  https://id.bi…           -29.1\n10 FALSE           0049bcbb-c8c2-… Acacia aneura  https://id.bi…           -25.5\n# ℹ 10,794 more rows\n# ℹ 6 more variables: decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;,\n#   occurrenceStatus &lt;chr&gt;, dataResourceName &lt;chr&gt;, countryCode &lt;chr&gt;,\n#   locality &lt;chr&gt;\n\n\nWe can see the flagged record in orange on our map.\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = acacias,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude,\n                 colour = ZERO_COORDINATE)) +\n  pilot::scale_color_pilot()\n\n\n\n\n\n\n\n\nWe can remove this record by filtering our dataset to remove records with longitude or latitude coordinates that equal zero.\n\nacacias_filtered &lt;- acacias |&gt;\n  filter(decimalLongitude != 0,\n         decimalLatitude != 0)\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = acacias_filtered,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude,\n                 colour = ZERO_COORDINATE)) +\n  pilot::scale_color_pilot()\n\n\n\n\n\n\n\n\n\n\n10.3.3 Centroids\nCentroids, or coordinates that mark the exact centre point of an area, are sometimes assigned to an occurrence record when the original observation location was provided as a description. If a record was collected using a vague locality description or through incorrect geo-referencing, centroids can be used to categorise the record into broadly the correct area1.\nLet’s use common brown butterfly data for our example. Including the COORDINATES_CENTRE_OF_COUNTRY and/or COORDINATES_CENTRE_OF_STATEPROVINCE assertions columns to your download allows us to identify records flagged as containing centroid coordinates.\n\n\n\n\nHeteronympha merope merope resting on leaf litter.Photo by Mononymous CC-BY-NC 4.0 (Int)\n\n\nbutterflies &lt;- butterflies |&gt;\n  drop_na(decimalLatitude, decimalLongitude) # remove NA values\n\nbutterflies |&gt;\n  select(COORDINATES_CENTRE_OF_COUNTRY,\n         COORDINATES_CENTRE_OF_STATEPROVINCE,\n         everything())\n\n# A tibble: 338 × 12\n   COORDINATES_CENTRE_OF_COUNTRY COORDINATES_CENTRE_OF…¹ recordID scientificName\n   &lt;lgl&gt;                         &lt;lgl&gt;                   &lt;chr&gt;    &lt;chr&gt;         \n 1 FALSE                         FALSE                   018f5a5… Heteronympha …\n 2 FALSE                         FALSE                   02eef43… Heteronympha …\n 3 FALSE                         FALSE                   03b39bb… Heteronympha …\n 4 FALSE                         FALSE                   04c2ac2… Heteronympha …\n 5 FALSE                         FALSE                   05cced1… Heteronympha …\n 6 FALSE                         FALSE                   05ceb8b… Heteronympha …\n 7 FALSE                         FALSE                   06679b8… Heteronympha …\n 8 FALSE                         FALSE                   0704e7b… Heteronympha …\n 9 FALSE                         FALSE                   0756bd4… Heteronympha …\n10 FALSE                         FALSE                   0774f2e… Heteronympha …\n# ℹ 328 more rows\n# ℹ abbreviated name: ¹​COORDINATES_CENTRE_OF_STATEPROVINCE\n# ℹ 8 more variables: taxonConceptID &lt;chr&gt;, decimalLatitude &lt;dbl&gt;,\n#   decimalLongitude &lt;dbl&gt;, eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, countryCode &lt;chr&gt;, locality &lt;chr&gt;\n\n\nFiltering our data to flagged records, we return one record.\n\nbutterflies |&gt;\n  filter(\n    COORDINATES_CENTRE_OF_COUNTRY == TRUE |\n    COORDINATES_CENTRE_OF_STATEPROVINCE == TRUE\n    )\n\n# A tibble: 1 × 12\n  recordID        scientificName taxonConceptID decimalLatitude decimalLongitude\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 89186e67-be72-… Heteronympha … https://biodi…           -31.3             147.\n# ℹ 7 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, countryCode &lt;chr&gt;, locality &lt;chr&gt;,\n#   COORDINATES_CENTRE_OF_COUNTRY &lt;lgl&gt;,\n#   COORDINATES_CENTRE_OF_STATEPROVINCE &lt;lgl&gt;\n\n\nThe flagged record is the single orange point on our map.\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = butterflies,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude,\n                 colour = COORDINATES_CENTRE_OF_STATEPROVINCE)) +\n  pilot::scale_color_pilot() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWe can remove this data point by excluding this record from our dataset.\n\nbutterflies_filtered &lt;- butterflies |&gt;\n  filter(COORDINATES_CENTRE_OF_STATEPROVINCE == FALSE)\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = butterflies_filtered,\n             aes(x = decimalLongitude, \n                 y = decimalLatitude,\n                 colour = COORDINATES_CENTRE_OF_STATEPROVINCE)) +\n  pilot::scale_color_pilot() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n10.3.4 Cities, zoos, aquariums, museums & herbaria\nSome observations are recorded in locations where animals and plants live but do not naturally occur. A common example is observations recorded at public facilities like zoos, aquariums, and botanic gardens.\nOther times, observations are recorded in places where specimens of animals and plants might be stored, but not where they were observed. Common examples are museums and herbaria.\nIn some cases, like with records of the Gorse Bitter-pea, these locations can appear suspicious but not overly obvious. When we map these observations, there is a tailing distribution of points in Western Australia with several points located near the west coast of Australia.\n\n\n\n\nDaviesia ulicifolia ruscifolia flowering.Photo by Warren Tomlinson CC-BY-NC 4.0 (Int)\n\n\nbitter_peas &lt;- bitter_peas |&gt;\n  drop_na(decimalLongitude, decimalLatitude) # remove NA values\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = bitter_peas,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             colour = \"#204466\")\n\n\n\n\n\n\n\n\nSuspiciously, if we Google the coordinates of the Western Australia Herbarium, the coordinates overlap with one of the points. We have highlighted this point in orange.\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = bitter_peas,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             colour = \"#204466\") +\n  geom_point(aes(x = 115.8, y = -31.9), # point coordinates\n             colour = \"#f28100\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFiltering our data to the two left-most data points reveals that the data resources that supplied those records are both state herbaria.\n\nbitter_peas |&gt;\n  filter(decimalLongitude &lt; 120) |&gt;\n  select(dataResourceName)\n\n# A tibble: 2 × 1\n  dataResourceName                             \n  &lt;chr&gt;                                        \n1 National Herbarium of Victoria (MEL) AVH data\n2 NSW AVH feed                                 \n\n\nHaving identified this, these records can now be removed from our dataset.\n\nbitter_peas_filtered &lt;- bitter_peas |&gt;\n  filter(decimalLongitude &gt; 120)\n\nggplot() + \n  geom_sf(data = aus) +\n  geom_point(data = bitter_peas_filtered,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             colour = \"#204466\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUse basisOfRecord\n\n\n\n\n\nYou can use the field basisOfRecord to avoid including records from museums and herbaria when creating your query in galah.\n\nlibrary(galah)\n\n# Show values in `basisOfRecord` field\nsearch_all(fields, \"basisOfRecord\") |&gt;\n  show_values()\n\n# Filter basis of record to only human observations\ngalah_call() |&gt;\n  identify(\"Daviesia ulicifolia\") |&gt;\n  filter(basisOfRecord == \"HUMAN_OBSERVATION\") |&gt;\n  atlas_counts()",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial cleaning</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-cleaning.html#packages",
    "href": "3_ecological-cleaning/geospatial-cleaning.html#packages",
    "title": "10  Geospatial cleaning",
    "section": "10.4 Packages",
    "text": "10.4 Packages\nOther packages exist to make identifying and cleaning geospatial coordinates more streamlined. The advantage of using these packages is that they can run many checks over coordinates at one time, rather than identifying each error separately like we did over this chapter. This process can make finding possible spatial outliers faster. The disadvantage is that checks might be more difficult to tweak compared to manual checks. Manual checks can also make the steps you made to clean your data clearer (and easier to edit later) in a complete data cleaning workflow.\nChoose the package (or mix of packages and functions) that work best for you and your data cleaning needs.\n\nCoordinateCleaner\nThe CoordinateCleaner package is a package for automated flagging of common spatial and temporal errors of biological and palaentological data. It is particularly useful for cleaning data from GBIF.\nHere is an example of a general cleaning function, but there are many more bespoke options that the package offers.\n\nlibrary(CoordinateCleaner)\n\n# Run record-level tests\ncoordinate_tests &lt;- clean_coordinates(x = butterflies, \n                                      species = \"scientificName\")\n\nReading layer `ne_50m_land' from data source \n  `C:\\Users\\KEL329\\AppData\\Local\\Temp\\RtmpgHhuph\\ne_50m_land.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1420 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -180 ymin: -89.99893 xmax: 180 ymax: 83.59961\nGeodetic CRS:  WGS 84\n\nsummary(coordinate_tests)\n\n    .val     .equ     .zer     .cap     .cen     .sea     .otl     .gbf \n       0        0        0       22        0       11       60        0 \n   .inst .summary \n      13      100 \n\nplot(coordinate_tests)",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial cleaning</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-cleaning.html#summary",
    "href": "3_ecological-cleaning/geospatial-cleaning.html#summary",
    "title": "10  Geospatial cleaning",
    "section": "10.5 Summary",
    "text": "10.5 Summary\nEach of the cleaning steps in this chapter do not have to be run in order, or even at all. Whether they are used is context- and taxon-dependent. As an example, what is one species that has many “wrong” coordinates based on many of the steps listed above?\nThe Great White Shark.\n\n\n\n\nCarcharodon carcharias swimming off the South Australian coast.Photo by Coffin Bay Scuba Co. CC-BY-NC 4.0 (Int)\n\n\n\nCode\n# Download occurrence records\nsharks &lt;- galah_call() |&gt;\n  identify(\"Carcharodon carcharias\") |&gt;\n  filter(basisOfRecord == \"HUMAN_OBSERVATION\") |&gt;\n  apply_profile(ALA) |&gt;\n  atlas_occurrences()\n\n# Retrieve map of Australia\naus &lt;- st_transform(ozmap_country, 4326)\n\n# Map occurrences\nsharks |&gt;\n  drop_na(decimalLongitude, decimalLatitude) |&gt;\n  ggplot() + \n  geom_sf(data = aus,\n          colour = \"grey60\",\n          fill = \"white\") +\n  geom_point(data = sharks,\n             aes(x = decimalLongitude,\n                 y = decimalLatitude),\n             colour = \"#135277\") +\n  theme_light()\n\n\n\n\n\n\n\n\n\nThe difficulty with cleaning Great White Shark occurrence data is that these sharks have a massive habitat range, and these locations along (what appear to be) the North American coast and Madagascar could very well be true occurrences. Be sure to consider the taxonomic and spatial range of your species before jumping into data cleaning!\n\n\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial cleaning</span>"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/geospatial-cleaning.html#footnotes",
    "href": "3_ecological-cleaning/geospatial-cleaning.html#footnotes",
    "title": "10  Geospatial cleaning",
    "section": "",
    "text": "This can happen when record locations are incorrectly given as the physical location of the specimen, or because they represent individuals from captivity or grown in horticulture (but were not clearly labelled as such).↩︎",
    "crumbs": [
      "Ecological data cleaning",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Geospatial cleaning</span>"
    ]
  },
  {
    "objectID": "4_appendices/where-to-get-data.html",
    "href": "4_appendices/where-to-get-data.html",
    "title": "Appendix A — Where to get data",
    "section": "",
    "text": "A.0.1 Prerequisites\nFirst, we’ll load packages that we’ll need to display data and figures over the chapter.\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyterra)\nlibrary(terra)\nlibrary(here)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Where to get data</span>"
    ]
  },
  {
    "objectID": "4_appendices/where-to-get-data.html#open-source-data",
    "href": "4_appendices/where-to-get-data.html#open-source-data",
    "title": "Appendix A — Where to get data",
    "section": "A.1 Open-source data",
    "text": "A.1 Open-source data\nOpen-source data are data made openly accessible for editing and use, licensed under an open license. The following are some places where you can find open-source data.\n\nA.1.1 Biodiversity data\n\nLiving AtlasesGBIFBiocollectionsData providers\n\n\nLiving Atlases are national or regional infrastructures that aggregate biodiversity data from many different sources. These sources include research projects, government monitoring programs, museums & herbaria, and citizen science apps like iNaturalist and eBird. Some examples are:\n\n\n\nCountry/Region\nName\nAcronym\n\n\n\n\nAustralia\nAtlas of Living Australia\nALA\n\n\nAustria\nBiodiversitäts-Atlas Österreich\nBAO\n\n\nBrazil\nSistema de Informação sobre a Biodiversidade Brasileira\nSiBBr\n\n\nEstonia\neElurikkus\n\n\n\nFrance\nPortail français d’accès aux données d’observation sur les espèces\nOpenObs\n\n\nGuatemala\nSistema Nacional de Información sobre Diversidad Biológica de Guatemala\nSNIBgt\n\n\nPortugal\nGBIF Portugal\nGBIF.pt\n\n\nSpain\nGBIF Spain\nGBIF.es\n\n\nSweden\nSwedish Biodiversity Data Infrastructure\nSBDI\n\n\nUnited Kingdom\nNational Biodiversity Network\nNBN\n\n\n\nLiving Atlases work with local data providers to ingest and standardise open-source data, and some even use a specific taxonomic backbone. If your project is focused on a specific region, downloading data directly from a regional node may be more appropriate.\nSee a complete list of existing national and regional Living Atlases.\n\n\nThe Global Biodiversity Information Facility (GBIF) is an international data infrastructure and a network that aggregates biodiversity data from the many Living Atlases around the world. GBIF acts as an overarching organisation to store and provide these data from the Living Atlas “nodes” using a unified data standard.\nAt present, GBIF manages and serves over 2.6 billion occurrence data points!\nSee a complete list of national and regional nodes that contribute to GBIF.\n\n\nBiocollections are data infrastructures that hold specimen data from museums and collections.\nSome examples include:\n\n\n\nName\nDescription\n\n\n\n\nIntegrated Digitzed Biocollections\nHolds data of biological specimens that have been made electronically available (i.e., digitised)\n\n\nVertNet\nHolds data of vertebrate specimens from more than 400 collections & 120 publishers\n\n\nAustralasian Virtual Herbarium (AVH)\nHolds over eight million plant, algae and fungi specimens\n\n\n\n\n\nIf your project relates to data from a specific data provider, it also might be best to download data directly from the source.\nFor example, a common citizen science tool to collect species observations is iNaturalist. Downloading directly from the original data source can help to ensure you don’t have any stray data from other sources in your download. You can directly contact data providers to ensure the data hasn’t been pre-filtered before downloading.\n\n\n\n\n\n\n\n\n\n\n\nWhy do we still have to clean data from data infrastructures?\n\n\n\n\n\nData infrastructures like the Atlas of Living Australia ingest, aggregate and standardise millions of rows of data from thousands of data providers. Some data comes from large providers with standardised workflows, like state government monitoring programs, iNaturalist Australia or eBird. These data providers use workflows that attempt to remove suspicious records prior to sharing data with a Living Atlas, and, in general, these workflows catch many issues that otherwise might need fixing.\nHowever, not all data providers have standardised workflows. Some data has been transcribed from written survey records and provided by a small or independent data provider. Other data might have been transcribed from archived written records in a museum, or even in a scientists backlog from a long-lost research project. These data are valuable but inevitably prone to errors that are difficult to fix—handwriting can be smudged or difficult to read, records might be lacking important details about their location or time of observation. Even in data from standardised workflows, errors like taxonomic misidentification or flipped geospatial coordinates can slip through the cracks because expert knowledge is required to identify and amend individual records. These records can also range in their precision or level of detail, and might not be suitable for every type of analysis.\nUltimately, it’s a team effort to remove or fix data issues. Although a data infrastructure can use programmatic data quality checks to try to remove more extreme outliers, many errors are context dependent and require verification from the original data provider. This means that the responsibility to fix records usually falls on the data provider because only the data provider has knowledge required to amend their original data. Inevitably, there will be errors in data from many different sources, and equipped with this knowledge, we still need to clean data from data infrastructures to be suitable for our research question or analysis.\n\n\n\n\n\n\n\nA.1.2 Spatial data\nSpatial data contain information that corresponds to an area on the globe and can be plotted onto a map. Spatial data can be represented as vector or raster data.\nThere are two types of spatial data that you will probably use:\n\nVectorsRasters\n\n\nVectors are data for drawing points, lines and shapes. They contain a geometry column which contains information to draw points, lines or polygons onto a map.\nCountry or region outlines are often saved as vectors, which are typically loaded using an R package like {rnaturalearth} or by reading in a .shp file using the {sf} package.\n\nstate_outline &lt;- sf::st_read(\"path/to/file.shp\")\n\nHere is an example of what vector data looks like in R…\n\nozmaps::ozmap_states\n\nSimple feature collection with 9 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 105.5507 ymin: -43.63203 xmax: 167.9969 ymax: -9.229287\nGeodetic CRS:  GDA94\n# A tibble: 9 × 2\n  NAME                                                                  geometry\n* &lt;chr&gt;                                                       &lt;MULTIPOLYGON [°]&gt;\n1 New South Wales              (((150.7016 -35.12286, 150.6611 -35.11782, 150.6…\n2 Victoria                     (((146.6196 -38.70196, 146.6721 -38.70259, 146.6…\n3 Queensland                   (((148.8473 -20.3457, 148.8722 -20.37575, 148.85…\n4 South Australia              (((137.3481 -34.48242, 137.3749 -34.46885, 137.3…\n5 Western Australia            (((126.3868 -14.01168, 126.3625 -13.98264, 126.3…\n6 Tasmania                     (((147.8397 -40.29844, 147.8902 -40.30258, 147.8…\n7 Northern Territory           (((136.3669 -13.84237, 136.3339 -13.83922, 136.3…\n8 Australian Capital Territory (((149.2317 -35.222, 149.2346 -35.24047, 149.271…\n9 Other Territories            (((167.9333 -29.05421, 167.9188 -29.0344, 167.93…\n\n\n…and what it looks like when plotted with ggplot2.\n\nggplot() + \n  geom_sf(data = ozmaps::ozmap_states) + \n  theme_void()\n\n\n\n\n\n\n\n\n\n\nRasters are data for drawing a layer of data values over a gridded area. They contain values of a variable (like temperature) for each pixel of a grid, and Each pixel of the grid represents a square area (e.g., 1 km2). Just like how the smaller each pixel is on a TV screen the higher its definition, the smaller each square is in a raster layer the higher its resolution.\nClimate data is often saved as a raster, which is typically loaded using an R package like {geodata} or by reading in a .tif file using the {terra} package.\n\n\nworld_clim_raster &lt;- rast(here(\"data\", \"rasters\", \"aggregated_bioclim.tif\"))\n\nHere is an example of what raster data looks like in R…\n\nworld_clim_raster\n\nclass       : SpatRaster \ndimensions  : 86, 87, 19  (nrow, ncol, nlyr)\nresolution  : 0.5416667, 0.5416667  (x, y)\nextent      : 112.5, 159.625, -55.58333, -9  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : aggregated_bioclim.tif \nnames       : wc2.1~bio_1, wc2.1~bio_2, wc2.1~bio_3, wc2.1~bio_4, wc2.1~bio_5, wc2.1~bio_6, ... \nmin values  :    7.499508,    7.540306,    41.79295,    85.12752,    18.11505,   -2.798391, ... \nmax values  :   28.209095,   16.710342,    80.15718,   676.51477,    41.65941,   18.436970, ... \n\n\n…and what it looks like when plotted with tidyterra and ggplot2. This map displays Australia’s annual mean temperature (BioClim 1) in low-resolution.\n\nggplot() +\n  geom_spatraster(data = world_clim_raster,\n                  mapping = aes(fill = wc2.1_30s_bio_1)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\nHere are some examples of where to download spatial data.\n\nClimate dataShapefiles\n\n\nWorldClim is a database of global gridded climate and weather data for historic, current and future conditions.\nEcologists and biologists tend to work specifically with Bioclimatic variables (BioClim). which are typically more meaningful variables for understanding biological things, derived from fluctuations in temperature and rainfall.\nExamples of BioClim variables include Temperature Annual Range, Annual Precitipation, or Precipitation in the Wettest or Driest month. See the complete list of BioClim variables.\nRasters are read into R as a .tif file.\n\n\nShapefiles are vector data with information to draw the outline of one or more specific areas or regions.\nOne of the best ways to search for shapefiles is Google. Some of the safest places to find up-to-date shapefiles are on national or regional government websites. For example, the Australian Bureau of Statistics (ABS) holds shapefiles with many levels of regional boundaries, ranging from states/territories to local government areas.\nShapefiles are read into R as a .shp file. These .shp files are usually within a folder (often a zipped folder) that contains several other files that help to build the .shp file when it is loaded. Here is an example of the contents of an unzipped folder containing a shapefile:\n\n\n\nA folder containing the shapefile for local government areas\n\n\nThey are then read into R using a function like st_read() from the sf package.\n\nlibrary(sf)\nlibrary(rmapshaper)\n\nshapefile &lt;- st_read(here(\"path\",\n                          \"to\",\n                          \"shapefile.shp\"),\n                     quiet = TRUE) |&gt;\n1  ms_simplify(keep = 0.1)\n\n\n1\n\nMany shapefiles are a large file size. ms_simplify() from the rmapshaper package simplifies the shapefile by reducing the number of points that make up the polygon while maintaining its overall shape. This is a handy way to reduce the size of your shapefile in R.\n\n\n\n\n\n\n\n\n\nA.1.3 Taxonomic data\nTaxonomy is a complex and broad field of investigation. A comprehensive look into taxonomy is well outside the scope of this book. However, It’s a good idea to consider the taxonomic classification of the organism(s) you’re interested in and any potential naming differences between data sources.\nWe do advise that before deciding on a final taxonomy to download or use, it’s worth being aware of what naming authority your data is using as its taxonomic backbone. In some taxonomic groups, names can vary widely depending on what taxonomic authority is used. Double check your data after your download them to make sure the classifications you expect are what you finding. This check will help prevent errors later on (though you might still need to re-code data manually).\nWe discuss these considerations in more detail in the Taxonomic Validation chapter.\nHere are some examples of where to find Australian taxonomic information.\n\n\n\nName\nDescription\n\n\n\n\nThe Australian Faunal Directory (AFD)\nAn online catologue of nomenclature and taxonomy of animal species known to occur in Australia\n\n\nThe Australian Plant Name Index (APNI)\nA tool for the botanical community containing accepted scientific names of plants\n\n\nThe Australian Plant Census\nContains the currently accepted scientific names for Australian vascular flora.\n\n\n\n\n\nA.1.4 Trait data\nTrait data contains measurements of organisms’ morphological or behavioural traits (e.g., stem length, leaf size, egg size, migratory distance, soil carbon). These data are useful for comparing spatial or temporal differences between individuals, groups or species.\nThe following are some examples of where to find trait data.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nAustraits\nA plant trait database that synthesises data from field surveys, published literature, taxonomic monographs, and individual taxon descriptions. The database holds nearly 500 traits across more than 30,000 taxa.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Where to get data</span>"
    ]
  },
  {
    "objectID": "4_appendices/where-to-get-data.html#packages-for-downloading-data",
    "href": "4_appendices/where-to-get-data.html#packages-for-downloading-data",
    "title": "Appendix A — Where to get data",
    "section": "A.2 Packages for downloading data",
    "text": "A.2 Packages for downloading data\nThere are a range of R packages available for accessing biodiversity data. These packages serve as convenient interfaces to various data providers by making respective APIs usable directly within R. The functionality offered by these packages typically ranges from querying species occurrence records, to more comprehensive taxonomic and spatial download queries.\nBelow, we highlight some commonly used packages. We encourage users to explore the documentation of each package to understand their capabilities, which will help you select one (or more!) that align with your specific needs.\n\nA.2.1 Occurrence data\n\ngalah\ngalah is an interface for accessing biodiversity data like occurrences, counts, species and media (e.g., images & sounds) from the Living Atlases and GBIF.\nIn the majority of examples over this book we will be using the galah package. One benefit of using galah is that it uses tidy syntax (much like dplyr) to edit & filter download queries. Additionally, galah can access data from 10 other Living Atlases and GBIF.\n\nlibrary(galah)\n\ngalah_config(email = \"your-email-here\") # Registered ALA email\n\ngalah_call() |&gt;\n  identify(\"perameles\") |&gt;\n  filter(year == 2001) |&gt;\n  atlas_occurrences()\n\n\n\n# A tibble: 344 × 8\n   recordID       scientificName taxonConceptID decimalLatitude decimalLongitude\n   &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n 1 0053a1f3-b5e1… Perameles nas… https://biodi…           -34.4             151.\n 2 0135db9a-80ff… Perameles nas… https://biodi…           -33.3             151.\n 3 013b9cb6-7d89… Perameles nas… https://biodi…           -28.2             153.\n 4 01c5d084-f4a5… Perameles nas… https://biodi…           -29.2             153.\n 5 02943584-050a… Perameles nas… https://biodi…           -33.3             151.\n 6 02af5fdd-4800… Perameles nas… https://biodi…           -29.3             152.\n 7 02c5d0db-913f… Perameles nas… https://biodi…           -31.2             153.\n 8 04ad578b-af11… Perameles nas… https://biodi…           -26.7             152.\n 9 0518bfb9-cf9d… Perameles nas… https://biodi…           -34.3             151.\n10 05496ff9-d61e… Perameles nas… https://biodi…           -33.3             151.\n# ℹ 334 more rows\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;\n\n\n\n\nOther packages\n\nrgbifrinatrebirdspocc\n\n\nrgbif searches and retrieves data from the Global Biodiversity Information Facility (GBIF).\n\nlibrary(rgbif)\n\n# Download occurrences\nocc_search(scientificName = \"Calopteryx splendens\",\n           country = \"DK\",\n           year=\"1999,2005\")\n\n\n\nrinat is an R wrapper for accessing iNaturalist observations.\n\nlibrary(rinat)\n\n# Download occurrences\nget_inat_obs(taxon_name = \"Colibri\",\n             quality = \"research\",\n             maxresults = 500)\n\n\n\nrebird provides access to the eBird web services.\n\nlibrary(rebird)\n\n# Download occurrences\nebirdgeo(species = species_code('spinus tristis'), \n         lat = 42, \n         lng = -76)\n\n\n\nspocc queries and collects species occurrence data from a variety of sources, including GBIF, the ALA, iDigBio and VertNet. spocc is particularly useful because it allows for a single download request in R to query and return data from multiple data sources in a single nested dataframe.\n\nlibrary(spocc)\n\n# Download occurrences\ndf &lt;- occ(query = 'Accipiter striatus', \n          from = c('gbif', 'idigbio'), \n          limit = 25)\nocc2df(df)\n\n\n\n\n\n\n\nA.2.2 Spatial data\n\ngeodataozmapsrnaturalearthelevatr\n\n\ngeodata contains data of climate, elevation, soil, crop, species occurrence and administrative boundaries.\n\n# Download world climate data\nworldclim &lt;- worldclim_country(\n    country = \"Australia\",\n    var = \"bio\",\n    res = 5,\n    path = here::here(\"path\", \"to\", \"folder\")\n  )\n\n\n\nozmaps contains simple features (sf) data for plotting maps of Australia and its regions.\n\nlibrary(ozmaps)\n\naus &lt;- ozmap_data(data = \"states\")\n\nggplot() +\n  geom_sf(data = aus) + \n  theme_void()\n\n\n\nrnaturalearth contains simple features (sf) data for plotting world maps, countries, sovereign states and map units.\n\nlibrary(rnaturalearth)\n\n# Download outline of Brazil\nbrazil &lt;- ne_countries(scale = \"medium\", \n                       continent = 'south america', \n                       returnclass = \"sf\") |&gt;\n  filter(name == \"Brazil\")\n\nggplot() +\n  geom_sf(data = brazil) +\n  theme_void()\n\n\n\nelevatr downloads elevation data from various sources like AWS Open Data Terrain Tiles.\n\nlibrary(elevatr)\nlibrary(rnaturalearth)\n\n# Download outline of Cambodia\ncambodia &lt;- ne_countries(scale = \"medium\", \n                         continent = 'asia', \n                         returnclass = \"sf\") |&gt;\n  filter(name == \"Cambodia\")\n\n# Download elevation data for Cambodia\ncambodia_elev &lt;- get_elev_raster(locations = cambodia, \n                                 z = 11, \n                                 clip = \"locations\", \n                                 neg_to_na = \"TRUE\")\n\n\n\n\n\n\nA.2.3 Trait data\n\naustraits\n\n\naustraits allows users to access, explore and wrangle plant trait data from the AusTraits database, which synthesises 500 traits across more than 30,000 taxa.\n\nlibrary(austraits)\n\n# load database\naustraits &lt;- load_austraits(version = \"4.0.1\", \n                            path = \"path/to/folder\")\n\n# extract data by trait\nwood_density &lt;- austraits |&gt; \n  extract_trait(\"wood_density\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Where to get data</span>"
    ]
  },
  {
    "objectID": "4_appendices/where-to-get-data.html#summary",
    "href": "4_appendices/where-to-get-data.html#summary",
    "title": "Appendix A — Where to get data",
    "section": "A.3 Summary",
    "text": "A.3 Summary\nOver this chapter, we hope you have found some ideas of where to access biodiversity data. The following chapter will help explain how to work with large datasets in R.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Where to get data</span>"
    ]
  },
  {
    "objectID": "4_appendices/big-data.html",
    "href": "4_appendices/big-data.html",
    "title": "Appendix B — Big data",
    "section": "",
    "text": "B.0.1 Prerequisites\nIn this chapter, we will use Pardalote occurrence data. You will need to save the pardalotes data locally (i.e. write to disk) as a csv file to use over this chapter.\n# packages\nlibrary(galah)\nlibrary(here)\nlibrary(readr)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\ngalah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.4730caca-0570-4e63-9652-22f92d0b2e1a\") |&gt;\n  atlas_occurrences() |&gt;\n  write_csv(here(\"data\", \"pardalotes.csv\"))",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Big data</span>"
    ]
  },
  {
    "objectID": "4_appendices/big-data.html#footnotes",
    "href": "4_appendices/big-data.html#footnotes",
    "title": "Appendix B — Big data",
    "section": "",
    "text": "The dataset used in this example is relatively small (~ half a million rows), but the benefits of using arrow become obvious once the number of rows in your dataset approaches tens or hundreds of millions.↩︎\nParquet files use a columnar storage format (rather than a row storage format, as csv files do) and provide an especially efficient way to store and retrieve large datasets.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Big data</span>"
    ]
  },
  {
    "objectID": "4_appendices/data-scope.html",
    "href": "4_appendices/data-scope.html",
    "title": "Appendix C — Data scope",
    "section": "",
    "text": "Data scope refers to the type and extent of data needed for your project. Defining your scope is an essential part of forming a research question, ultimately impacting what data you will use in your project. Availability of data may therefore influence your scope and research question.\nFor example, you might have a question about several species in the same area. However, data for one or more of those species could be limited because observations are rare, surveying the area where it lives is difficult, or only several historical records exist.\nWithout narrowing your data scope, you might find yourself downloading more data than you need, which can needlessly increase how much time is spent processing data prior to analyses. Alternatively, you might find there isn’t enough data to answer your question.\nWhile there are workable methods to analyse small sets of biodiversity data (e.g. hulls), it’s worth thinking critically about whether the amount of data available will allow you to sufficiently answer your research question.\nTo start, some initial questions you might ask are:\n\nWhat is the temporal unit relevant for your research question?\nAm I only interested in more recent data? Is there data that are too old to be relevant for my question?\nWhat is the taxonomic unit of your proposed research question?\nIs my question specific to one or more species in the same taxonomic group? Does it compare between higher taxonomic levels like genus, family or order?\nWhat is the spatial scale of your proposed research question?\nIs my question relevant at a global or national level, or is it specific to a region or ecosystem?\n\nQuestions like these will help you define what data is most relevant for your research question, and help you begin to think about how much evidence available, and the trade-offs you might make between the specificity of your question and the certainty of your answer.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Data scope</span>"
    ]
  },
  {
    "objectID": "4_appendices/joins.html",
    "href": "4_appendices/joins.html",
    "title": "Appendix D — Joins",
    "section": "",
    "text": "D.0.1 Prerequisites\nIn this chapter, we will use starling occurrence data from September 2015 in the ALA.\n# packages\nlibrary(galah)\nlibrary(dplyr)\nlibrary(here)\nlibrary(ggplot2)\ngalah_config(email = \"your-email-here\") # ALA-registered email\n\nstarlings &lt;- galah_call() |&gt;\n  filter(doi == \"https://doi.org /10.26197/ala.98d038d3-2058-4294-b683-fcb51a11f018\") |&gt;\n  atlas_occurrences()\n\nstarlings_taxonomy &lt;- galah_call() |&gt;\n  identify(\"Sturnidae\") |&gt;\n  atlas_species()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "4_appendices/joins.html#keys",
    "href": "4_appendices/joins.html#keys",
    "title": "Appendix D — Joins",
    "section": "D.1 Keys",
    "text": "D.1 Keys\nJoining dataframes relies on setting a key—one or more columns that exist in a primary table that correspond to one or more columns in a secondary table. Two datasets that we intend to join are matched according to the designated key.\nAs a simple example, let’s say we want to add complete taxonomic information to our starlings dataframe, which contains occurrence records with some, but not all, levels of taxonomic information. starlings_taxonomy contains complete taxonomic information for Sturnidae.\n\nstarlingsstarlings_taxonomy\n\n\n\nstarlings\n\n# A tibble: 3,944 × 8\n   genus        species         scientificName cl22   year month decimalLatitude\n   &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;           &lt;dbl&gt;\n 1 Acridotheres Acridotheres t… Acridotheres … Quee…  2015     9           -16.9\n 2 Acridotheres Acridotheres t… Acridotheres … Quee…  2015     9           -16.9\n 3 Acridotheres Acridotheres t… Acridotheres … New …  2015     9           -33.8\n 4 Acridotheres Acridotheres t… Acridotheres … Vict…  2015     9           -37.7\n 5 Acridotheres Acridotheres t… Acridotheres … Aust…  2015     9           -35.2\n 6 Acridotheres Acridotheres t… Acridotheres … Quee…  2015     9           -27.2\n 7 Acridotheres Acridotheres t… Acridotheres … Vict…  2015     9           -38.0\n 8 Acridotheres Acridotheres t… Acridotheres … Quee…  2015     9           -16.9\n 9 Acridotheres Acridotheres t… Acridotheres … New …  2015     9           -33.9\n10 Acridotheres Acridotheres t… Acridotheres … Aust…  2015     9           -35.3\n# ℹ 3,934 more rows\n# ℹ 1 more variable: decimalLongitude &lt;dbl&gt;\n\n\n\n\n\nstarlings_taxonomy\n\n# A tibble: 5 × 11\n  taxon_concept_id species_name scientific_name_auth…¹ taxon_rank kingdom phylum\n  &lt;chr&gt;            &lt;chr&gt;        &lt;chr&gt;                  &lt;chr&gt;      &lt;chr&gt;   &lt;chr&gt; \n1 https://biodive… Sturnus (St… Linnaeus, 1758         species    Animal… Chord…\n2 https://biodive… Acridothere… (Linnaeus, 1766)       species    Animal… Chord…\n3 https://biodive… Aplonis (La… (Temminck, 1824)       species    Animal… Chord…\n4 https://biodive… Aplonis (Ap… (G.R. Gray, 1861)      species    Animal… Chord…\n5 https://biodive… Aplonis (Ap… Gould, 1836            species    Animal… Chord…\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 5 more variables: class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   vernacular_name &lt;chr&gt;\n\n\n\n\n\nLet’s join our starlings dataframe with starlings_taxonomy. The column genus in starlings appears to contain the same information in column genus in starlings_taxonomy.\n\nstarlings$genusstarlings_taxonomy$genus\n\n\n\nstarlings |&gt;\n  select(genus) |&gt; \n  distinct()\n\n# A tibble: 3 × 1\n  genus       \n  &lt;chr&gt;       \n1 Acridotheres\n2 Aplonis     \n3 Sturnus     \n\n\n\n\n\nstarlings_taxonomy |&gt;\n  select(genus) \n\n# A tibble: 5 × 1\n  genus       \n  &lt;chr&gt;       \n1 Sturnus     \n2 Acridotheres\n3 Aplonis     \n4 Aplonis     \n5 Aplonis     \n\n\n\n\n\nWe can use this genus column as a key to add the extra levels of taxonomic information to the table containing starling occurrence records1.\n\nstarlings |&gt;\n  left_join(starlings_taxonomy, \n            join_by(genus)) |&gt;\n  \n  rmarkdown::paged_table() # paged output\n\nWarning in left_join(starlings, starlings_taxonomy, join_by(genus)): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1805 of `x` matches multiple rows in `y`.\nℹ Row 2 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\n  \n\n\n\nNote that we received some warnings indicating that some rows had multiple matches. Make sure to read these warning messages carefully if you ever receive them because they might tell you that something unexpected happened during your join! In our case, the warnings are the result of several genera in starlings_taxonomy having the same genus name, which is something we already knew about and doesn’t worry us.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "4_appendices/joins.html#basic-types-of-joins",
    "href": "4_appendices/joins.html#basic-types-of-joins",
    "title": "Appendix D — Joins",
    "section": "D.2 Basic types of joins",
    "text": "D.2 Basic types of joins\nThere are many types of joins that can help you in all kinds of situations! Join types generally fall within two categories:\n\nMutating joins combine variables from two tables (e.g., left_join(), right_join(), full_join())\nFiltering joins combine variables, and additionally keep or remove rows that do not match the key column (e.g., semi_join(), anti_join())\n\nBelow are a few common examples of join types. Examples and animations are taken from Garrick Aden-Buie’s tidyexplain animations.\n\nx &lt;- tibble(id = c(1, 2, 3),\n            x = c(\"x1\", \"x2\", \"x3\"))\n\ny &lt;- tibble(id = c(1, 2, 4),\n            y = c(\"y1\", \"y2\", \"y4\"))\n\n\nLeft joinRight joinFull joinSemi joinAnti join\n\n\n\n\nleft_join(x, y, join_by(id))\n\n# A tibble: 3 × 3\n     id x     y    \n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    &lt;NA&gt; \n\n\n\n\n\n\nright_join(x, y, join_by(id))\n\n# A tibble: 3 × 3\n     id x     y    \n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n3     4 &lt;NA&gt;  y4   \n\n\n\n\n\n\nfull_join(x, y, join_by(id))\n\n# A tibble: 4 × 3\n     id x     y    \n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 x1    y1   \n2     2 x2    y2   \n3     3 x3    &lt;NA&gt; \n4     4 &lt;NA&gt;  y4   \n\n\n\n\n\n\nsemi_join(x, y, join_by(id))\n\n# A tibble: 2 × 2\n     id x    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 x1   \n2     2 x2   \n\n\n\n\n\n\nanti_join(x, y, join_by(id))\n\n# A tibble: 1 × 2\n     id x    \n  &lt;dbl&gt; &lt;chr&gt;\n1     3 x3",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "4_appendices/joins.html#spatial-joins",
    "href": "4_appendices/joins.html#spatial-joins",
    "title": "Appendix D — Joins",
    "section": "D.3 Spatial joins",
    "text": "D.3 Spatial joins\nSummarising where species or taxonomic groups occur by grouping them by spatial regions (e.g. state, council area, bioregion) can be useful. To do this, records or summary statistics need to be linked to their corresponding regions. This typically requires joining a spatial object with a dataframe, or joining two spatial objects.\nAs a simple example, let’s download a shapefile of Australian states and territories using the ozmaps package. The aus object contains the name of each state/territory (NAME) and its shape (geometry)2.\n\nlibrary(sf)\nlibrary(ozmaps)\n\naus &lt;- ozmap_states |&gt;\n1  st_transform(4326)\n\naus\n\n\n1\n\nThis line transforms the CRS projection of our map to match the CRS projection of ALA data.\n\n\n\n\nSimple feature collection with 9 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 105.5507 ymin: -43.63203 xmax: 167.9969 ymax: -9.229287\nGeodetic CRS:  WGS 84\n# A tibble: 9 × 2\n  NAME                                                                  geometry\n* &lt;chr&gt;                                                       &lt;MULTIPOLYGON [°]&gt;\n1 New South Wales              (((150.7016 -35.12286, 150.6611 -35.11782, 150.6…\n2 Victoria                     (((146.6196 -38.70196, 146.6721 -38.70259, 146.6…\n3 Queensland                   (((148.8473 -20.3457, 148.8722 -20.37575, 148.85…\n4 South Australia              (((137.3481 -34.48242, 137.3749 -34.46885, 137.3…\n5 Western Australia            (((126.3868 -14.01168, 126.3625 -13.98264, 126.3…\n6 Tasmania                     (((147.8397 -40.29844, 147.8902 -40.30258, 147.8…\n7 Northern Territory           (((136.3669 -13.84237, 136.3339 -13.83922, 136.3…\n8 Australian Capital Territory (((149.2317 -35.222, 149.2346 -35.24047, 149.271…\n9 Other Territories            (((167.9333 -29.05421, 167.9188 -29.0344, 167.93…\n\n\nOur starlings data also contains the state/territory of each occurrence in column cl22. We can group by state/territory and summarise the number of occurrences to get an overall count by state/territory.\n\ncounts_by_state &lt;- starlings |&gt;\n  group_by(cl22) |&gt;\n  count()\n\ncounts_by_state\n\n# A tibble: 7 × 2\n# Groups:   cl22 [7]\n  cl22                             n\n  &lt;chr&gt;                        &lt;int&gt;\n1 Australian Capital Territory   482\n2 New South Wales                779\n3 Queensland                     669\n4 South Australia                196\n5 Tasmania                        91\n6 Victoria                      1664\n7 &lt;NA&gt;                            63\n\n\nTo prepare our data for mapping, we can join counts_by_state to aus using the state/territory name as our key.\n\naus_counts &lt;- aus |&gt;\n  left_join(counts_by_state,\n            join_by(NAME == cl22))\n\naus_counts\n\nSimple feature collection with 9 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 105.5507 ymin: -43.63203 xmax: 167.9969 ymax: -9.229287\nGeodetic CRS:  WGS 84\n# A tibble: 9 × 3\n  NAME                                                            geometry     n\n  &lt;chr&gt;                                                 &lt;MULTIPOLYGON [°]&gt; &lt;int&gt;\n1 New South Wales              (((150.7016 -35.12286, 150.6611 -35.11782,…   779\n2 Victoria                     (((146.6196 -38.70196, 146.6721 -38.70259,…  1664\n3 Queensland                   (((148.8473 -20.3457, 148.8722 -20.37575, …   669\n4 South Australia              (((137.3481 -34.48242, 137.3749 -34.46885,…   196\n5 Western Australia            (((126.3868 -14.01168, 126.3625 -13.98264,…    NA\n6 Tasmania                     (((147.8397 -40.29844, 147.8902 -40.30258,…    91\n7 Northern Territory           (((136.3669 -13.84237, 136.3339 -13.83922,…    NA\n8 Australian Capital Territory (((149.2317 -35.222, 149.2346 -35.24047, 1…   482\n9 Other Territories            (((167.9333 -29.05421, 167.9188 -29.0344, …    NA\n\n\nNow we can use these data to create a choropleth map3.\n\nggplot() +\n  geom_sf(data = aus_counts,\n          aes(fill = n)) + \n  guides(fill = guide_coloursteps(title = \"Number of\\nObservations\")) +\n  scale_fill_viridis_c(option = \"G\") +\n  theme_void()\n\n\n\n\n\n\n\n\nThe sf package also has specialised functions for spatial joins like st_join(), which can be especially useful for joins using points (e.g., POINT) and shapes (e.g., POLYGON, MULTIPOLYGON). Below is a small example where we use the point location to join with the state/territory. Note that we lose the POINT location in favour of the state MULTIPOLYGON shape, held in the column geometry.\n\n# convert record coordinates to sf POINT class\nstarlings_sf &lt;- starlings |&gt;\n  tidyr::drop_na() |&gt;\n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326)\n\n# join points to aus states that intersect spatially\nstates_with_species &lt;- st_join(x = aus,\n                               y = starlings_sf,\n                               join = st_intersects,\n                               left = FALSE)\n\nstates_with_species |&gt;\n  rmarkdown::paged_table() # paged output",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "4_appendices/joins.html#footnotes",
    "href": "4_appendices/joins.html#footnotes",
    "title": "Appendix D — Joins",
    "section": "",
    "text": "Using genus is also a better choice than species or scientificName in this instance because they appear to contain similar but not exactly the same information to starlings_taxonomy$species_name. Using these columns as a key for our join would result in missing information after joining due to mismatches.↩︎\nThis shapefile contains state/territory outlines as vectors. See this section on vectors to learn more about what a vector is.↩︎\nFor more advanced examples of making choropleth maps, check out the ALA Labs articles counting points in shapefiles and using multiple colour scales.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Joins</span>"
    ]
  },
  {
    "objectID": "4_appendices/reproducible-workflows.html",
    "href": "4_appendices/reproducible-workflows.html",
    "title": "Appendix E — Reproducible workflows",
    "section": "",
    "text": "E.1 What does reproducibility mean?\nReproducibility refers to the ability for a result or output to be reliably returned again when the same workflow is run again. Reproducibility is important for scientific progress because if others can’t reproduce a result, it’s impossible to verify whether that result is true, or not (and whether we should update our opinion as a result).\nData cleaning is an essential step of an analytic workflow. However, there are many different ways people can choose to go about data cleaning. Without knowing how a “clean” dataset was produced from raw data, or without the ability to reproduce the cleaned dataset yourself, entire analyses can go to waste because they can’t be run again, much less reproduce an individual result!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Reproducible workflows</span>"
    ]
  },
  {
    "objectID": "4_appendices/reproducible-workflows.html#what-does-reproducibility-mean",
    "href": "4_appendices/reproducible-workflows.html#what-does-reproducibility-mean",
    "title": "Appendix E — Reproducible workflows",
    "section": "",
    "text": "Example scenario\n\n\n\n\n\nLet’s say a scientific paper claims that a species of frog has an 80% probability of shifting its distribution southward by 60 kilometres. Without being able to reproduce the result (or the data on which that result is based), it’s difficult to know how trustworthy this statistic really is or the extent that this result should affect our understanding of this species. What factors are influencing this statistic? What is the sample population that this statistic was derived from? What data cleaning steps were made prior to analysis?\nA reproducible workflow—from raw data to analysis to the the final result—allows us to at least attempt to answer some of these questions!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Reproducible workflows</span>"
    ]
  },
  {
    "objectID": "4_appendices/reproducible-workflows.html#reproducible-environments",
    "href": "4_appendices/reproducible-workflows.html#reproducible-environments",
    "title": "Appendix E — Reproducible workflows",
    "section": "E.2 Reproducible environments",
    "text": "E.2 Reproducible environments\nTo allow coding scripts to run again, it’s important to be able to reproduce the environment in which the original code was successfully run. In R, this usually involves setting your working directory correctly so that files and packages can be located and loaded1. Below are several ways to make working environments better for sharing.\n\nE.2.1 R projects\nR projects are the best way to set project directories when using R Studio. R Projects create .Rproj files that tell R Studio what the top directory is for a project. Opening an R project (either in R Studio or by opening the Rproj file) then automatically opens the project directory and sets the working directory. All file paths will stem from that top directory while using that R project.\nTo create a new R Project, use File –&gt; New Project.\n\n\n\nR Project set-up. Source: https://r4ds.hadley.nz/workflow-scripts#rstudio-projects\n\n\nWithout R projects, the default directory is automatically set to wherever your R package library is stored locally.\n\n# Without R Projects\ngetwd()\n\n\n\n[1] \"#&gt; [1] /Users/UserName/Documents/\"\n\n\nWith R Projects, the default directory is automatically set to start at the top folder of your project directory.\n\n# With R Projects\ngetwd()\n\n\n\n[1] \"#&gt; [1] /Users/UserName/Documents/Projects/my-project-name/\"\n\n\nR projects simplify folder/file paths and allow projects to be shared more easily between different users on different machines.\n\n\nE.2.2 here\nFile paths can be fragile. Small mistakes can prevent a file from being found, including misspellings or the use of a / rather than a \\. The here package sets safe file paths for project-oriented workflows. The here package sets the path relative to the top-level directory, meaning it works seamlessly with R Projects.\n\nlibrary(here)\nhere()\n\n\n\n[1] \"C:/Users/Dax/Documents/Github/my-project\"\n\n\nThe here package also automatically adds slashes for better compatibility across operating systems, and a lower chance of small mistakes breaking file paths.\n\nhere(\"data\", \"file-name.csv\")\n\n\n\n[1] \"C:/Users/Dax/Documents/Github/my-project/data/file-name.csv\"\n\n\n\n\nE.2.3 renv\nThe renv package helps users create reproducible environments for R projects. The package documents the packages and package versions used in a project in a lock.file. This file can be used by renv to restore the environment and packages used to run the original script.\nThere are three main, simple functions used by renv:\n\nrenv::init()     # initialise a renv library & lockfile\nrenv::snapshot() # update lockfile with current package library\nrenv::restore()  # restore environment in lockfile",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Reproducible workflows</span>"
    ]
  },
  {
    "objectID": "4_appendices/reproducible-workflows.html#version-control",
    "href": "4_appendices/reproducible-workflows.html#version-control",
    "title": "Appendix E — Reproducible workflows",
    "section": "E.3 Version control",
    "text": "E.3 Version control\nResearch and data science projects evolve over time. Many versions of files are saved, updated and revised over a project’s lifetime. Tools like Git and Github, outlined in the Git chapter, help with version control of files in a repository. Using version control allows file changes to be updated, and allows file versions to be reverted to an old version that previously ran if an issue arises. Git and Github have become incredibly useful tools for collaboration in the research and data science communities.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Reproducible workflows</span>"
    ]
  },
  {
    "objectID": "4_appendices/reproducible-workflows.html#documentation",
    "href": "4_appendices/reproducible-workflows.html#documentation",
    "title": "Appendix E — Reproducible workflows",
    "section": "E.4 Documentation",
    "text": "E.4 Documentation\nAlthough you might know the context of your analytic decisions at the time of analysis, other people who use your workflow (or even your future-self) might not. Clear documentation makes a huge difference to reproducibility.\nUse clear object names and function names to make analyses easier to read or understand. Document decisions and what code blocks/chunks are meant to do. Similarly, document interpretations of any analytic output and any decisions made in response to a result.\n\n\n\nExamples of “Meh” or “Yay” object names and function names. Source: https://communities.springernature.com/posts/improving-code-reproducibility-small-steps-with-big-impacts\n\n\n\nE.4.1 Quarto\nQuarto is a scientific and technical publishing toolset made by Posit. Quarto makes it possible to convert coding scripts and projects into articles, presentations and books (like this one!).\nQuarto files are useful for reproducibility because they make it possible to render final version of a script or analysis. Over the process of building websites to document our own code for analyses and visualisations, we discovered that rendered documents are useful for documenting and sharing workflows. We recommend rendering final analyses (Quarto defaults already look very nice) and saving rendered files in one place. Rendered documents will allow faster lookup, easier sharing, and documentation of analyses that ran from start to finish (which makes fixing future issues easier).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Reproducible workflows</span>"
    ]
  },
  {
    "objectID": "4_appendices/reproducible-workflows.html#code-review",
    "href": "4_appendices/reproducible-workflows.html#code-review",
    "title": "Appendix E — Reproducible workflows",
    "section": "E.5 Code review",
    "text": "E.5 Code review\nOutside of data science tools to improve reproducibility, code review can be revolutionary for improving code reproducibility. Asking others to review your code, though scary, can provide opportunity to identify ways to make code more efficient and stable.\n\n\n\n\nCulina, Antica, Ilona Van Den Berg, Simon Evans, and Alfredo Sánchez-Tójar. 2020. “Low Availability of Code in Ecology: A Call for Urgent Action.” PLOS Biology 18 (7): e3000763. https://doi.org/10.1371/journal.pbio.3000763.\n\n\nKimmel, Kaitlin, Meghan L. Avolio, and Paul J. Ferraro. 2023. “Empirical Evidence of Widespread Exaggeration Bias and Selective Reporting in Ecology.” Nature Ecology & Evolution, August. https://doi.org/10.1038/s41559-023-02144-3.\n\n\nRoche, Dominique G., Loeske E. B. Kruuk, Robert Lanfear, and Sandra A. Binning. 2015. “Public Data Archiving in Ecology and Evolution: How Well Are We Doing?” PLOS Biology 13 (11): e1002295. https://doi.org/10.1371/journal.pbio.1002295.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Reproducible workflows</span>"
    ]
  },
  {
    "objectID": "4_appendices/reproducible-workflows.html#footnotes",
    "href": "4_appendices/reproducible-workflows.html#footnotes",
    "title": "Appendix E — Reproducible workflows",
    "section": "",
    "text": "A common way to first learn to set a working directory in R is to use the dropdown toolbar to navigate to Session –&gt; Set Working Directory, or use setwd(). Both of these methods are poor practice for reproducibility because they require users to manually enter paths that are prone to break when the script is opened on another computer or in a new location.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Reproducible workflows</span>"
    ]
  },
  {
    "objectID": "4_appendices/git.html",
    "href": "4_appendices/git.html",
    "title": "Appendix F — Git",
    "section": "",
    "text": "F.1 Using Git\nGit commands may be executed in a shell using a command line (e.g., Git Bash), but there are a number of user-friendly Git clients (e.g. Github Desktop, RStudio git pane, GitKraken) that make the process of learning git less daunting if you are just getting started. Below are some examples and links to download.\nFor additional useful Git clients, check out the GUI page of the Git website.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Git</span>"
    ]
  },
  {
    "objectID": "4_appendices/git.html#using-git",
    "href": "4_appendices/git.html#using-git",
    "title": "Appendix F — Git",
    "section": "",
    "text": "Git BashGitHub DesktopR StudioGitKraken\n\n\nGit Bash is the default way to interact with Git from the command line.\n\n\n\nExample of Git Bash. Source: https://gitforwindows.org/\n\n\n\n\nGitHub Desktop is a more visual point-and-click interface to using Git and GitHub.\n\n\n\nExample of GitHub Desktop. Source: https://desktop.github.com/\n\n\n\n\nThe git pane in R Studio integrates Git functionality into R Studio.\n\n\n\nExample of the R Studio git pane. Source: https://docs.posit.co/ide/user/ide/guide/tools/version-control.html\n\n\n\n\nGitKraken is a popular third-party Git client with an all-in-one interface.\n\n\n\nExample of GitKraken Client. Source: https://www.gitkraken.com/git-client",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Git</span>"
    ]
  },
  {
    "objectID": "4_appendices/git.html#footnotes",
    "href": "4_appendices/git.html#footnotes",
    "title": "Appendix F — Git",
    "section": "",
    "text": "If you’ve ever tried to work out which of draft_ms_final, draft_ms_last_edits, and ms_last_edits_final_final is the most updated version of a document, Git is for you.↩︎",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Git</span>"
    ]
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "Appendix G — Packages",
    "section": "",
    "text": "G.1 General cleaning",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "packages.html#general-cleaning",
    "href": "packages.html#general-cleaning",
    "title": "Appendix G — Packages",
    "section": "",
    "text": "G.1.1 dplyr\ndplyr is a popular package for data manipulation, providing a consistent set of verbs (e.g., filter(), select(), mutate(), group_by()) to restructure your data.\n\n\n\n\n  \n\n\nG.1.2 tidyr\ntidyr is a package to help you make “tidy data”, where each variable is a column, each observation is a row, and each value is a cell.\n\n\n\n\n  \n\n\nG.1.3 stringr\nstringr is a package with a cohesive set of functions to filter, match, and prepare, and correct strings.\n\n\n\n\n\n \n\n\nG.1.4 janitor\njanitor is a package with a collection of helper functions for initial data exploration, summarising, and data cleaning.\n\n\n\n\n\n \n\n\nG.1.5 ggplot2\nggplot2 is a package for visualising data using The Grammar of Graphics, where users assign variables to display, the type of graphics to use, and additional aesthetics or theme formatting.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "packages.html#taxonomic-validation",
    "href": "packages.html#taxonomic-validation",
    "title": "Appendix G — Packages",
    "section": "G.2 Taxonomic validation",
    "text": "G.2 Taxonomic validation\n\n\n\n \n\n\nG.2.1 taxize\ntaxize allows users the ability to search taxonomic names over many taxonomic data sources using scientific and common names to resolve synonyms in their data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>G</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Appendix H — References",
    "section": "",
    "text": "Chapman, Arthur D. 2005. Principles and Methods of Data\nCleaning. GBIF.\n\n\nCulina, Antica, Ilona Van Den Berg, Simon Evans, and Alfredo\nSánchez-Tójar. 2020. “Low Availability of Code in Ecology:\nA Call for Urgent Action.” PLOS Biology 18\n(7): e3000763. https://doi.org/10.1371/journal.pbio.3000763.\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi,\nand Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys\nSpecies (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of\nFresh Water Habitats by Macrodasyids.” Scientific\nReports 9 (1): 2067.\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David\nAlbrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021.\n“Implications of the 2019–2020 Megafires for the Biogeography and\nConservation of Australian Vegetation.” Nature\nCommunications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning\nTaxonomic and Geographic Errors in Occurrence Data Archived in\nBiodiversity Databases.” Global Ecology and Conservation\n21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nKimmel, Kaitlin, Meghan L. Avolio, and Paul J. Ferraro. 2023.\n“Empirical Evidence of Widespread Exaggeration Bias and Selective\nReporting in Ecology.” Nature Ecology & Evolution,\nAugust. https://doi.org/10.1038/s41559-023-02144-3.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville,\nLibby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts\nof the 2019-20 Wildfires of Southern and Eastern Australia on\nInvertebrate Species Final Report.”\n\n\nRibeiro, Bruno, Santiago Velazco, Karlo Guidoni-Martins, Geiziane\nTessarolo, and Lucas Jardim. 2024. Bdc: Biodiversity\nData Cleaning. https://brunobrr.github.io/bdc/\n(website) https://github.com/brunobrr/bdc.\n\n\nRoche, Dominique G., Loeske E. B. Kruuk, Robert Lanfear, and Sandra A.\nBinning. 2015. “Public Data Archiving in\nEcology and Evolution: How\nWell Are We\nDoing?” PLOS Biology 13 (11): e1002295. https://doi.org/10.1371/journal.pbio.1002295.\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset:\nExpert-Validated Occurrence Records of Australia’s Frogs Collected by\nCitizen Scientists.” ZooKeys 912: 139.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>H</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "1_exploring/1_intro.html",
    "href": "1_exploring/1_intro.html",
    "title": "Exploring biodiversity data",
    "section": "",
    "text": "This section details how to get an initial glimpse of your dataset, explore its structure, and create summaries of the different types of data within it. The first chapter shows how to check metadata and data structure. The second chapter introduces functions for summarising data in galah like atlas_counts() and demonstrates ways to quickly visualise different aspects of your data.\n\n\n\nAn uninformative, artistic representation of seasonal observations of bowerbirds over the year\n\n\n\n\n\n\n\n\n\nPtilonorhynchus violaceus perched on a wooden stump. Photo by Michael Hains CC-BY-NC 3.0 (Au)",
    "crumbs": [
      "Exploring biodiversity data"
    ]
  },
  {
    "objectID": "2_general-cleaning/1_intro.html",
    "href": "2_general-cleaning/1_intro.html",
    "title": "General data cleaning",
    "section": "",
    "text": "This section details some steps and functions for cleaning a dataset in preparation for analysis. The aim is to address issues arising from data formatting through general cleaning tasks, such as removing duplicates, correcting dates, and handling missing or unexpected values.\nThe steps provided here are not meant to be followed in linear order. Instead, think of this section as a checklist or roadmap for data cleaning, rather than a comprehensive, step-by-step guide.\n\n\n\nAn uninformative, artistic representation of kingfisher records near Sydney, New South Wales, Australia\n\n\n\n\n\n\n\n\n\nTodiramphus (Cyanalcyon) pyrrhopygius diving through the air. Photo by diana_shang CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "General data cleaning"
    ]
  },
  {
    "objectID": "3_ecological-cleaning/1_intro.html",
    "href": "3_ecological-cleaning/1_intro.html",
    "title": "Ecological data cleaning",
    "section": "",
    "text": "This section addresses data cleaning methods that leverage ecological and biological expertise. Not every step will be relevant to every dataset; the applicability of each step depends on the particular taxonomic groups and species included in your data.\nThe first chapter explains ways to search your taxonomy and verify there are no inconsistencies in taxonomic names. The second chapter covers methods to determine uncertainty in your data’s spatial coordinates. The third chapter demonstrates how to identify and resolve various geospatial issues in your data.\n\n\n\n\nAn uninformative, artistic representation of the top 5 most recorded legume/bean (Fabaceae) species in the ALA\n\n\n\n\n\n\n\n\n\nHardenbergia violacea (Native Lilac) flowering. Photo by Kaitlyn CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "Ecological data cleaning"
    ]
  }
]