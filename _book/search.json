[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA Data Cleaning",
    "section": "",
    "text": "Data cleaning is the exploration, detection and correction of data which may be errornous, unsuitably formatted, or otherwise unsuited for use in your project. The definition of ‘clean’ data therefore varies depending on the project and data sources, and as such there is no ‘one-size-fits-all’ approach. Nevertheless, there are some common processes and concepts that can be applied to many data cleaning workflows.\nHowever, these processes typically require the use of a programming language, which can be a barrier of entry for many. Therefore, our goal in creating this resource is to assist researchers and decision makers that may have limited experience with cleaning geo-referenced biodiversity data. The language used will be R, which is commonly used in ecological projects, and has a rich ecosystem of packages for data cleaning.\nIn this book, we provide an overview of a typical data cleaning workflow - from acquisition, identifying potential errors, to correction. These processes are broken down into chapters, whithin each we include practical guidelines, example R code, and additional resources that may aid with each data cleaning step.\nThe content of this book was informed by the current state of biodiversity literature surrounding data preparation for species distribution modelling. For more details about how this was done, please refer to the Appendix. All resources that were used can be found in the References page.\n\n\n\ngetting started and getting an overview of steps with examples\nquick reference\n\n\n\n\nWe would like to preface that we are not experts in data cleaning, but felt there was need for a consolidated resource to guide data cleaning decisions.\nContributions to this document are welcome. For any questions, feedback, or other issues, please open an issue on our GitHub repository. If you would like to make changes to the content of the website, you are welcome to submit a pull request containing your proposed changes. Please note, it is considered best practice to open an issue before working on a pull request, to allow discussion surrounding the proposed changes. Our contributing guidelines can be found here.\n\n\n\nYou can cite this book as: Kar, F., Fenker, J., Schneider, M., Westgate, M. (2023). Cleaning biodiversity data in R. Retrieved Month dd, yyyy, from https://atlasoflivingaustralia.github.io/cleaning_data/\n\n\nThis book is available free to read, and is licenced under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\n\n\n\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA)\nAuthors listed in alphabetic order: - Fonti Kar - Jessica Fenker - Margot Schneider - Martin Westgate\n\nTODO:\nthe preface or somewhere should have a little background on who, why, types of research etc. The title is also just data cleaning perhaps need more specific"
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "ALA Data Cleaning",
    "section": "How to contribute",
    "text": "How to contribute\nWe would like to preface that we are not experts in data cleaning, but felt there was need for a consolidated resource to guide data cleaning decisions.\nContributions to this document are welcome. For any questions, feedback, or other issues, please open an issue on our GitHub repository. If you would like to make changes to the content of the website, you are welcome to submit a pull request containing your proposed changes. Please note, it is considered best practice to open an issue before working on a pull request, to allow discussion surrounding the proposed changes. Our contributing guidelines can be found here."
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "ALA Data Cleaning",
    "section": "How to cite",
    "text": "How to cite\nYou can cite this book as: Kar, F., Fenker, J., Schneider, M., Westgate, M. (2023). Cleaning biodiversity data in R. Retrieved Month dd, yyyy, from https://atlasoflivingaustralia.github.io/cleaning_data/\n\n\nThis book is available free to read, and is licenced under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ALA Data Cleaning",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA)\nAuthors listed in alphabetic order: - Fonti Kar - Jessica Fenker - Margot Schneider - Martin Westgate"
  },
  {
    "objectID": "intro.html#outline-what-you-will-learn",
    "href": "intro.html#outline-what-you-will-learn",
    "title": "Introduction",
    "section": "Outline: What you will learn",
    "text": "Outline: What you will learn\nCleaning open-access biodiversity data involves a few steps:\n{mermaid} %%| label: fig-1 %%| fig-cap: The cleaning process %%| fig-align: center flowchart TB A(Narrow data scope) --> B(Import data) --> C(Investigate metadata) C --> D{Cleaning} D --> E(Taxonomic issues) D --> F(Spatial issues)\nOnce data have been narrowed, imported and formatted correctly we can then start the major cleaning steps. We will focus on how to deal with the most common issues with biodiversity data:"
  },
  {
    "objectID": "intro.html#what-you-wont-learn",
    "href": "intro.html#what-you-wont-learn",
    "title": "Introduction",
    "section": "What you won’t learn",
    "text": "What you won’t learn\nThere are many important subject areas that this book will not cover. We won’t be teaching you:\n\nHow to clean environmental data that isn’t occurrence / biodiversity data: e.g. trait data - How to run a species distribution model - Hypothesis testing or experimental design"
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "Introduction",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nUser accounts\nTo get data out of data infrastructures such as the Atlas of living Australia (ALA) or the Global Biodiversity Information (GBIF) you’ll need to first create an account.\nYou’ll want to sign up for an account with the relevant data infrastructure. This book will use ALA and GBIF data as examples.\nYou can do this for the Atlas of Living Australia here -\nand for the Global Biodiversity Information Facility here.\n\n\nR\nDownload R from CRAN for your operating system and install it on your device. Major updates for R come out yearly, with a few minor releases throughout the year - so make sure to update semi regularly.\n\n\nRStudio\nRStudio is an integrated development environment (IDE) for R programming. R operatees within R studio, so to code, you will need both R and RStudio. Download and install RStudio for your operating system here.\n\n\n\n\nRodrigues, A. V., Nakamura, G., Staggemeier, V. G., & Duarte, L. (2022). Species misidentification affects biodiversity metrics: Dealing with this issue using the new R package naturaList. Ecological Informatics, 69, 101625. https://doi.org/10.1016/j.ecoinf.2022.101625"
  },
  {
    "objectID": "scope.html#an-example-question",
    "href": "scope.html#an-example-question",
    "title": "Data scope",
    "section": "An example question",
    "text": "An example question\nAs an example, let’s imagine we were interested in understanding more about the distribution of several Jewel beetles in the genus Lampromicra. Let’s see some ways we might investigate what data are available about them in Australia.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nCurious what a Jewel beetle looks like? Here is a Lampromicra senator perched on a leaf by Matthew Connors CC-BY-NC 4.0 (Int)"
  },
  {
    "objectID": "scope.html#temporal-scope",
    "href": "scope.html#temporal-scope",
    "title": "Data scope",
    "section": "Temporal scope",
    "text": "Temporal scope\nA good first step to understanding what data are available is to check how many observations there are over different time periods. We can check how many total observations there are in the Atlas of Living Australia (the largest biodiversity data aggregator in Australia) with the following query:\n\nlibrary(galah)\n\n\nlibrary(galah)\n\natlas_counts()\n\n# A tibble: 1 × 1\n      count\n      <int>\n1 130703781\n\n\nNow let’s check how many total insect records there are.\n\ngalah_call() |>\n  galah_identify(\"insecta\") |>\n  atlas_counts()\n\n# A tibble: 1 × 1\n    count\n    <int>\n1 5773381\n\n\nNow let’s see how many insects have been observed each year over the last 10 years. We’ll order this by descending year using dplyr::arrange() and dplyr::desc().\n\nlibrary(dplyr)\n\ngalah_call() |>\n  galah_identify(\"insecta\") |>\n  galah_filter(year >= 2013) |>\n  galah_group_by(year) |>\n  atlas_counts() |>\n  dplyr::arrange(dplyr::desc(year))\n\n# A tibble: 11 × 2\n   year   count\n   <chr>  <int>\n 1 2023  343074\n 2 2022  448132\n 3 2021  356581\n 4 2020  265427\n 5 2019  186059\n 6 2018  228862\n 7 2017  194881\n 8 2016  170033\n 9 2015  124965\n10 2014  126879\n11 2013  116493\n\n\nNow that we have an idea of the total amount of data in the Atlas of Living Australia, let’s try checking how many observations exist of the genus Lampromicra. We’ll first make sure the scientific name Lampromicra returns the taxon information we expect with search_taxa().\n\nsearch_taxa(\"Lampromicra\")\n\n# A tibble: 1 × 13\n  search_term scientific_name scientific_name_authorship taxon_concept_id  rank \n  <chr>       <chr>           <chr>                      <chr>             <chr>\n1 Lampromicra Lampromicra     Stål, 1873                 https://biodiver… genus\n# ℹ 8 more variables: match_type <chr>, kingdom <chr>, phylum <chr>,\n#   class <chr>, order <chr>, family <chr>, genus <chr>, issues <chr>\n\n\nThis looks correct! Next let’s see how many total observations there are of Lampromicra and how many observations there were in each of the last 10 years.\n\ngalah_call() |>\n  galah_identify(\"Lampromicra\") |>\n  atlas_counts()\n\n# A tibble: 1 × 1\n  count\n  <int>\n1  1364\n\ngalah_call() |>\n  galah_identify(\"Lampromicra\") |>\n  galah_filter(year >= 2013) |>\n  galah_group_by(year) |>\n  atlas_counts() |>\n  dplyr::arrange(dplyr::desc(year))\n\n# A tibble: 11 × 2\n   year  count\n   <chr> <int>\n 1 2023    133\n 2 2022    229\n 3 2021    220\n 4 2020    151\n 5 2019     75\n 6 2018     53\n 7 2017     44\n 8 2016     42\n 9 2015     14\n10 2014     14\n11 2013      6\n\n\nThere are a growing number of observations from 2012 to 2023 of Jewel beetles in the Atlas of Living Australia, with fewer than 100 observations each year prior to 2020.\nWith this information, we might choose to combine data from all years in our analysis (rather than separating them by year). Alternatively, we might decide to only include data since 2020, which might be sufficient to represent where Lampromicra are found and be more relevant because they are more recent observations. These are decisions that might affect the granularity of the research question we ask."
  },
  {
    "objectID": "scope.html#taxonomic-scope",
    "href": "scope.html#taxonomic-scope",
    "title": "Data scope",
    "section": "Taxonomic scope",
    "text": "Taxonomic scope\nTaxonomy refers to ways by which we classify an organism and its relationship to all other organisms. Typically, your research question will be concerned with one or more taxonomic groups, ranging from a single species to an entire kingdom (e.g. Plantae).\nIn our example, we are interested in understanding more about Jewel beetles in the genus Lampromicra.\nWe first might want to know what species there are in the genus Lampromicra and view some additional taxonomic information about them. We can do this by adding atlas_species() to the end of a query in {galah}.\n\n\n\n\n\n\nNote\n\n\n\nYou will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information.\n\n\n\ngalah_config(email = \"oliviajane.t@hotmail.com\")\n\ngalah_call() |>\n  galah_identify(\"Lampromicra\") |>\n  atlas_species() |>\n  select(family:species_guid)\n\n# A tibble: 3 × 5\n  family        genus       species             author            species_guid  \n  <chr>         <chr>       <chr>               <chr>             <chr>         \n1 Scutelleridae Lampromicra Lampromicra senator (Fabricius, 1803) https://biodi…\n2 Scutelleridae Lampromicra Lampromicra aerea   (Distant, 1892)   https://biodi…\n3 Scutelleridae Lampromicra Lampromicra regia   Bergroth, 1895    https://biodi…\n\n\nOur query returned three species in the genus Lampromicra. We can enter the urls returned under species_guid in a web browser if we wished to know more information about any of them.\nWe might also wish to check the total number of observations of each of these species. We can check this by grouping our counts by species using galah_group_by(species)\n\ngalah_call() |>\n  galah_identify(\"Lampromicra\") |>\n  galah_group_by(species) |>\n  atlas_counts()\n\n# A tibble: 3 × 2\n  species             count\n  <chr>               <int>\n1 Lampromicra senator  1117\n2 Lampromicra aerea     173\n3 Lampromicra regia      14\n\n\nOur result shows that the majority of observations of Lampromicra are of the species Lampromicra senator.\nGiven this information, we might consider whether our question needs to be made at the species level, or whether we might increase the taxonomic scope to the genus or family level to use more data. Ultimately, the taxonomic scope of your data will depend on how important it is to your question to compare specific taxonomic groups."
  },
  {
    "objectID": "scope.html#spatial-scope",
    "href": "scope.html#spatial-scope",
    "title": "Data scope",
    "section": "Spatial scope",
    "text": "Spatial scope\nIt’s useful to investigate the spatial range of available data for your taxonomic group(s) of interest. How specific your question can be may change depending on whether the majority of data is in only a few locations or evenly spread over the entire distribution of a species or taxonomic group.\nFor our example question about Lampromicra, we may wish to map where observations in Australia have been made. We can do this by using the {ozmaps} package to download a nice map of Australia, plot it with sf::geom_sf(), and add our observation points on top with geom_point(). We can separate the colours of our points by setting colour = scientificName within the aes() of geom_point().\n\n\n\n\n\n\nNote\n\n\n\nYou will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information.\n\n\n\n\nCode\n# old fonti code. not sure why it's saved?\n# beatles <- open_dataset(\"data/galah/lampromicra\") |> collect()\nlibrary(ozmaps)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(paletteer) # colour palettes\n\n# Download data\ngalah_config(email = \"oliviajane.t@hotmail.com\")\n\nbeetles <- galah_call() |>\n  galah_identify(\"lampromicra\") |>\n  atlas_occurrences() |>\n  tidyr::drop_na() # remove any NA values\n\n# Get map of australia, set to correct projection for data\naus <- st_transform(ozmaps::ozmap_country, 4326)\n\n# Map\nggplot() +\n  geom_sf(\n    data = aus,\n    colour = \"grey60\",\n    fill = \"white\",\n    alpha = 0.2\n  ) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude,\n      colour = scientificName\n    ),\n    size = 1.8,\n    alpha = 0.6\n  ) +\n  scale_color_paletteer_d(\"feathers::eastern_rosella\") +\n  coord_sf(\n    xlim = c(110, 155),\n    ylim = c(-45, -10)\n  ) +\n  theme_void()\n\n\n\n\n\nPlotting our points shows us that observations are spread along the northern and eastern coasts of Australia. We can also see that some observations are only identified to the genus level (e.g. Lampromicra), rather than to a specific species (e.g. Lampromicra aerea).\nThere are several places on the east coast of Australia where there are clumps of overlapping points. It’s difficult to tell how many observations there really are in those areas. To investigate, we can recreate this into a point density plot using the {ggpointdensity package}.\n\n\nCode\nlibrary(ggpointdensity)\n\nggplot() +\n  geom_sf(\n    data = aus,\n    colour = \"grey60\",\n    fill = \"white\",\n    alpha = 0.2\n  ) +\n  geom_pointdensity(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude\n    )\n  ) +\n  scale_color_paletteer_c(\"viridis::plasma\") +\n  coord_sf(\n    xlim = c(110, 155),\n    ylim = c(-45, -10)\n  ) +\n  theme_void()\n\n\n\n\n\nAdding the density of overlapping points to our map allows us to see that there is one area with many more observations—more than 400 observations are found in the light yellow area!\nUsing this information, we might decide to make our research question more specific to the region where there are the most records of Lampromicra.\nLet’s have a look at these records in the context of their IBRA bioregions (distinct areas defined on a common climate, geology, landform, native vegetation and species information).\nTo find out what region(s) the genus Lampromicra is most common, you can group_by the IBRA region field code in {galah} (use search_fields to see others).\n\nibra_counts <- galah_call() |>\n  galah_identify(\"Lampromicra\") |>\n  galah_group_by(\"cl1048\") |> # IBRA regions\n  atlas_counts()\n\ngt(head(ibra_counts))\n\n\n\n\n\n  \n    \n    \n      cl1048\n      count\n    \n  \n  \n    South Eastern Queensland\n498\n    Sydney Basin\n188\n    Victoria Bonaparte\n81\n    Brigalow Belt North\n74\n    Wet Tropics\n72\n    Einasleigh Uplands\n65\n  \n  \n  \n\n\n\n\n\nSouth Eastern Queensland (red), Sydney Basin (green)\n\n\n\n\n\n\nLooks like South Eastern Queensland has the most records followed by Sydney Basin.\nThis could be due to sampling bias in that Brisbane and Sydney are large metropolis areas. You might choose to investigate this bias further.\n\n\nCode\nshapefile <- st_read(\n  here(\n    \"data\",\n    \"shapefiles\",\n    \"IBRA7_regions\",\n    \"ibra7_regions.shp\"\n  ),\n  quiet = TRUE\n) |>\n  ms_simplify(keep = 0.1)\n\n\n# South Eastern Queensland\nggplot() +\n  geom_sf(\n    data = shapefile %>% filter(REG_NAME_7 == \"South Eastern Queensland\"),\n    aes(fill = \"red\"),\n    colour = \"grey60\",\n    alpha = 0.7\n  ) +\n  geom_sf(\n    data = shapefile %>% filter(REG_NAME_7 != \"South Eastern Queensland\"),\n    aes(fill = \"white\"),\n    colour = \"grey60\",\n    alpha = 0.2\n  ) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude\n    ),\n    size = 0.5\n  ) +\n  coord_sf(\n    xlim = c(140, 155),\n    ylim = c(-30, -10)\n  ) +\n  scale_fill_identity() +\n  theme_void()\n# Sydney Basin\nggplot() +\n  geom_sf(\n    data = aus,\n    colour = \"grey60\",\n    fill = \"white\",\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = shapefile %>% filter(REG_NAME_7 == \"Sydney Basin\"),\n    aes(fill = \"green\"),\n    colour = \"grey60\",\n    alpha = 0.7\n  ) +\n  geom_sf(\n    data = shapefile %>% filter(REG_NAME_7 != \"Sydney Basin\"),\n    aes(fill = \"white\"),\n    colour = \"grey60\",\n    alpha = 0.2\n  ) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude\n    ),\n    size = 0.5\n  ) +\n  coord_sf(\n    xlim = c(145, 155),\n    ylim = c(-37, -30)\n  ) +\n  scale_fill_identity() +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, we might decide that there isn’t enough data (or data of a good enough quality) to make accurate estimates about Lampromicra.\nDepending on the spatial specificity of your question, you might have to adjust your data scope or your question accordingly."
  },
  {
    "objectID": "scope.html#summary",
    "href": "scope.html#summary",
    "title": "Data scope",
    "section": "Summary",
    "text": "Summary\nThis chapter has demonstrated some ways to initially investigate the data available to answer a research question using the {galah} package. This is just a small example of how you might go about interogating the data to think critically about your data scope.\nThe next chapter will explain how you can download and save your data set to begin the first step of your analysis."
  },
  {
    "objectID": "download-data.html",
    "href": "download-data.html",
    "title": "2  Download data",
    "section": "",
    "text": "Once we have decided on our data scope, we can precede to download data. In this section, we will introduce a few common data infrastructures that offer open access biodiversity data and highlight some considerations when choosing one in the context of your data scope. We will then discuss some obstacles when consolidating data from multiple sources and the importance of metadata."
  },
  {
    "objectID": "download-data.html#where-to-get-data-from",
    "href": "download-data.html#where-to-get-data-from",
    "title": "2  Download data",
    "section": "2.1 Where to get data from",
    "text": "2.1 Where to get data from\n\n2.1.1 Global\nThe Global Biodiversity Information Facility (GBIF), an international network and data infrastructure, stores global biodiversity data from many sources around the world. GBIF consists of a series of ‘node’ organisations who collate biodiversity data from their own regions and countries, with GBIF acting as an overarching organisation to store data from all nodes. Users that are interested in obtaining data that has global coverage may want to download directly from GBIF.\n\n\n2.1.2 Regional\nAlternatively, using a regional node may be more relevant if your project is at a smaller scale. For example, the Atlas of Living Australia (ALA) is the Australian node, Sistema de Informação sobre a Biodiversidade Brasileira (SiBBr) is the Brazilian node, and GBIF Sweden is the Swedish node. Living Atlases like the ALA ingest and aggregate data from a broad range of providers such as government monitoring programs, museums and herbaria, research projects and citizen science initiatives.\nTo see what national and regional nodes exist, check out this page.\nSome regional nodes like the ALA and SiBBr use their own taxonomic backbone for classification, which might differ from the taxonomic backbone of other regional or global infrastructures like GBIF. These taxonomic classifications can be useful for classifying local flora and fauna, and accepted by experts of the region. It’s worth being aware of what Section 2.2.1.1 are used to error caused by classification later on.\n\n\n2.1.3 Data providers\nIf your project relates to data from a specific data provider, it might be best to download data directly from the source. For example, a common citizen science tool to collect species observations is iNaturalist. Downloading directly from the data provider may ensure you don’t have any stray data from other sources."
  },
  {
    "objectID": "download-data.html#how-to-download-data",
    "href": "download-data.html#how-to-download-data",
    "title": "2  Download data",
    "section": "2.2 How to download data",
    "text": "2.2 How to download data\n\n2.2.1 Using taxonomic information\n\n2.2.1.1 Naming authorities\n\n\n\n\n\n\n\n\n\n2.2.2 Choosing your taxonomic naming authority\nNaming authorities are the people or organisations that create updated or revised lists of species, and where they fit on the taxonomic tree. Species names and taxonomic groups in these lists vary as there may be disagreements between lists about what distinguishes a new genus, species, subspecies etc. Taxonomy is hard!\nSome data (especially from open source repositories) can contain data with conflicting taxonomies from different naming authorities. This difference can cause unexpected errors later in an analysis if you are unaware of which naming authorities were used in your data.\nChoosing a naming authority is, then, one one way to make decisions surrounding taxonomic categorisations of biodiversity data.\nBefore starting your analysis, it’s useful to:\n\nBe aware of which naming authority is accepted for your taxonomic group of interest.\nCheck changes in the taxonomy of your focus species.\nDouble check for updates, as most taxonomic society groups also release annual updates on taxonomy.\n\nIn the Atlas of Living Australia, the Australian Plant Name Index (APNI) is the primary naming authority for plants. With the Australian Faunal Directory (AFD) the main taxonomic catalog for animal species. For a full list, see the appendix.\nData that does not match the preferred naming authority or contains data from multiple naming authorities may need to be matched to a single taxonomic backbone  .\nNow that you’ve chosen a naming authority you can use it to ensure consistency across your data set, but also check you haven’t missed any species data from your download.\n\n2.2.2.1 Searching by classification\nInclude the original name that was recorded by the data provider in your download. This is often referred to as verbatimScientificName. or vernacularname\n\n\n\n\nInclude synonyms of the species names you’re interested in your download\n\n\nlibrary(galah)\n\ngalah_call() |>\n  galah_filter(year > 2019) |>\n  atlas_counts()\n\n# A tibble: 1 × 1\n     count\n     <int>\n1 26671180\n\n\nMany developers have created R packages to interact with each data infrastructures’s API to aid access to biodiversity data. Here are a few examples, we recommend taking a look at each package’s documentation to choose one that suits your project.\n\nrgbif an interface to GBIF\ngalah an interface to a number of living Atlases, as well as GBIF\nrinat an interface to iNaturalist observations\nrebird an interface with the eBird webservices.\nspocc a R package to query and collect species occurrence data from various sources including VertNet, iDigBio and others.\n\nOne benefit of using galah is that enables users to acquire not only species occurrence records but also taxonomic information, or associated media such as images or sounds. Below we have included some code blocks for downloading occurrence data with galah from GBIF and a Spain node.\n\n\n2.2.2.2 GBIF data via galah\nFirst, we have to configure galah. This is where you supply your account credentials and set the atlas to a particular region. See ?galah_config for more configuration options. You can save these credentials in your .Renviron so you don’t have to enter it explicitly in code.\nWe will be downloading all occurrences for the African Elephant from GBIF. This may take a while as it is around 12,000 records. Once downloaded, you can save the records locally in your desired format. For larger downloads, we recommend saving the data as parquets using arrow::write_parquet\n\ngalah_config(\n  email = Sys.getenv(\"ALA_EMAIL\"),\n  username = Sys.getenv(\"GBIF_USER\"),\n  password = Sys.getenv(\"GBIF_PWD\"),\n  atlas = \"Global\"\n)\n\nafrican_ele <- galah_call() %>%\n  galah_identify(\"Loxodonta africana\") %>%\n  atlas_occurrences()\n\narrow::write_parquet(african_ele, \"data/gbif/elephant\")\n\n\n\n# A tibble: 12,537 × 50\n      gbifID datasetKey     occurrenceID kingdom phylum class order family genus\n *     <dbl> <chr>          <chr>        <chr>   <chr>  <chr> <chr> <chr>  <chr>\n 1 924537719 95f132fe-f762… 73e088f2-f8… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 2 924537718 95f132fe-f762… 73e0ad3c-f8… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 3 924537717 95f132fe-f762… 73f0f6ec-f8… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 4 923926679 50c9509d-22c7… http://www.… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 5 923924124 50c9509d-22c7… http://www.… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 6 922237429 6ac3f774-d9fb… <NA>         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 7 922237412 6ac3f774-d9fb… <NA>         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 8 922237188 6ac3f774-d9fb… <NA>         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 9 922237135 6ac3f774-d9fb… <NA>         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n10 922237121 6ac3f774-d9fb… <NA>         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n# ℹ 12,527 more rows\n# ℹ 41 more variables: species <chr>, infraspecificEpithet <chr>,\n#   taxonRank <chr>, scientificName <chr>, verbatimScientificName <chr>,\n#   verbatimScientificNameAuthorship <chr>, countryCode <chr>, locality <chr>,\n#   stateProvince <chr>, occurrenceStatus <chr>, individualCount <dbl>,\n#   publishingOrgKey <chr>, decimalLatitude <dbl>, decimalLongitude <dbl>,\n#   coordinateUncertaintyInMeters <dbl>, coordinatePrecision <dbl>, …\n\n\n\n\n2.2.2.3 Regional node via galah\nIn order to access data from the Australia node, we will need to reconfigure galah so that our query points to Australia. After that, we will download all records for the Pink Robin.\n\ngalah_config(\n  email = Sys.getenv(\"ALA_EMAIL\"),\n  atlas = \"Australia\"\n)\n\npink_robin <- galah_call() %>%\n  galah_identify(\"Petroica rodinogaster\") %>%\n  atlas_occurrences()\n\n\n\n\n\n\n# A tibble: 11,992 × 8\n   decimalLatitude decimalLongitude eventDate           scientificName          \n *           <dbl>            <dbl> <dttm>              <chr>                   \n 1           -43.7             146. NA                  Petroica (Erythrodryas)…\n 2           -43.7             146. NA                  Petroica (Erythrodryas)…\n 3           -43.7             146. 1971-02-03 14:00:00 Petroica (Erythrodryas)…\n 4           -43.7             146. 2020-10-07 02:39:00 Petroica (Erythrodryas)…\n 5           -43.7             146. 2015-09-22 14:00:00 Petroica (Erythrodryas)…\n 6           -43.6             146. 2002-01-03 13:00:00 Petroica (Erythrodryas)…\n 7           -43.6             146. NA                  Petroica (Erythrodryas)…\n 8           -43.6             146. 2020-12-27 13:00:00 Petroica (Erythrodryas)…\n 9           -43.6             146. 2021-03-07 13:00:00 Petroica (Erythrodryas)…\n10           -43.6             146. 2020-12-26 13:00:00 Petroica (Erythrodryas)…\n# ℹ 11,982 more rows\n# ℹ 4 more variables: taxonConceptID <chr>, recordID <chr>,\n#   dataResourceName <chr>, occurrenceStatus <chr>\n\n\n\n\n\n2.2.3 Using spatial information\n\n\n\n\n\n2.2.3.1 Searching by region\nOne way to download data is by filtering to an area of interest using fields already in the ALA and {galah}.\n\n\n\n\n\n2.2.3.2 Searching by bounding box\nAnother way to download data is by filtering to return observations within a bounding box.\n\n\n\nThis can be useful when you want to be sure to include records on the border or just outside the border of a defined region (which might affect predictions of where species live in a model).\nIt can also be useful if you want to filter data yourself.\n\n\n2.2.3.3 Searching with a shapefile\nYou can use a shapefile to filter observations. Shapefiles are [a file with points to make an outline, they can be simple or complex].\n\n\n\nIn R, using shapefiles requires using a package for handling spatial data like the {sf} package. [This is because the sf package helps transform & edit our shapefile to be plotted using longitude and latitude using a specified coordinate reference system - define.]\nHere is a simple polygon we have constructed for a theoretical “site A”. We use st_as_sf() and st_set_crs() from the convert our shapefile to a spatial object in R, then set its coordinate reference system. This allows us to plot this object with {ggplot2}.\n\n\n\nUsing shapefiles allows us to return data for very specific shapes, and are useful for long-term analyses of observations in specific regions or areas."
  },
  {
    "objectID": "download-data.html#choosing-specific-data-columns",
    "href": "download-data.html#choosing-specific-data-columns",
    "title": "2  Download data",
    "section": "2.3 Choosing specific data columns",
    "text": "2.3 Choosing specific data columns\n\nBy default, atlas_occurrences will return a tibble with a selection of columns containing taxonomic and spatial data as well as other metadata. Alternatively, you can use galah_select to subset the columns that are relevant for your work. To see all available fields you can choose from:\n\nshow_all(fields)\n\n# A tibble: 628 × 4\n   id                  description                                   type  link \n   <chr>               <chr>                                         <chr> <chr>\n 1 _nest_parent_       <NA>                                          fiel… <NA> \n 2 _nest_path_         <NA>                                          fiel… <NA> \n 3 _root_              <NA>                                          fiel… <NA> \n 4 abcdTypeStatus      ABCD field in use by herbaria                 fiel… <NA> \n 5 acceptedNameUsage   http://rs.tdwg.org/dwc/terms/acceptedNameUsa… fiel… <NA> \n 6 acceptedNameUsageID http://rs.tdwg.org/dwc/terms/acceptedNameUsa… fiel… <NA> \n 7 accessRights        <NA>                                          fiel… <NA> \n 8 annotationsDoi      <NA>                                          fiel… <NA> \n 9 annotationsUid      <NA>                                          fiel… <NA> \n10 assertionUserId     User ID of the person who has made an assert… fiel… <NA> \n# ℹ 618 more rows\n\n\nHere, we will choose a smaller subsets of 8 columns to download for the Pink Robin\n\nproject_fields <- c(\n  \"recordID\",\n  \"eventDate\",\n  \"year\",\n  \"basisOfRecord\",\n  \"occurrenceStatus\",\n  \"scientificName\",\n  \"decimalLatitude\",\n  \"decimalLongitude\"\n)\n\npink_robin_projfields <- galah_call() %>%\n  galah_identify(\"Petroica rodinogaster\") %>%\n  galah_select(project_fields) %>%\n  atlas_occurrences()\n\n\n\n\n\n\n# A tibble: 11,992 × 8\n   recordID             eventDate            year basisOfRecord occurrenceStatus\n * <chr>                <dttm>              <dbl> <chr>         <chr>           \n 1 000fc2ef-b696-4576-… 1976-12-18 13:00:00  1976 HUMAN_OBSERV… PRESENT         \n 2 001410fd-3a01-43aa-… 1978-05-23 14:00:00  1978 HUMAN_OBSERV… PRESENT         \n 3 00164a76-0b3a-4b44-… 1977-12-15 13:00:00  1977 HUMAN_OBSERV… PRESENT         \n 4 001bfca5-4197-40a6-… 1940-12-31 14:00:00  1941 OBSERVATION   PRESENT         \n 5 001e33bd-bb15-4384-… 2002-10-17 14:00:00  2002 HUMAN_OBSERV… PRESENT         \n 6 0021cc7c-a371-4af6-… 2016-04-09 14:00:00  2016 OCCURRENCE    PRESENT         \n 7 00287e24-87b8-429a-… 2021-01-14 13:00:00  2021 HUMAN_OBSERV… PRESENT         \n 8 002e05a7-b1bf-4eba-… 2000-07-24 14:00:00  2000 OBSERVATION   PRESENT         \n 9 00327fc2-ae67-467b-… 1983-11-23 13:00:00  1983 PRESERVED_SP… PRESENT         \n10 0035016f-ae80-494a-… NA                     NA HUMAN_OBSERV… PRESENT         \n# ℹ 11,982 more rows\n# ℹ 3 more variables: scientificName <chr>, decimalLatitude <dbl>,\n#   decimalLongitude <dbl>"
  },
  {
    "objectID": "download-data.html#refining-your-data-download",
    "href": "download-data.html#refining-your-data-download",
    "title": "2  Download data",
    "section": "2.4 Refining your data download",
    "text": "2.4 Refining your data download\n\nOpen access biodiversity data comes from many different data sources, (eg. government monitoring programs, museums, herbaria, research projects, citizen science apps). As such, data type and quality can vary considerably. For example, museums harbour older records that are associated with a preserved specimens. These data often contain lots of extra information (metadata) about a specific specimen and its location. Alternatively, data sourced from citizen science apps like iNaturalist or eBird are associated with images or sounds captured from a smart phone. These data might contain less metadata of each observation, but, thanks to phones’ accurate location services, are quite accurate about the time and location of an observation.\nRefining your download query ensures higher quality data and also reduces the download size as many data infrastructures impose constraints to download size. Below we have illustrated how you can refine your query a few quality measures using galah_filter.\n\n2.4.0.1 By Year\nGenerally, old data records tend to be insufficient or less reliable as taxonomic knowledge and GPS tools were not readily available. For this reason, many users consider removing all occurrence records before a certain year to increase data precision (Gueta and Carmel 2016; Marsh et al. 2022) .\nChoosing the year ‘cut-off’ is relatively arbitary, but the most commonly used year is 1945 (Zizka et al. 2020; Führding-Potschkat, Kreft, and Ickert-Bond 2022), although some studies discard all data collected before 1990 (Gueta and Carmel 2016; Marsh et al. 2022).\nHere we will narrow the Pink Robin query from above to records after 1945 using galah_filter:\n\npink_robin_post1945 <- galah_call() %>%\n  galah_identify(\"Petroica rodinogaster\") %>%\n  galah_filter(year > 1945) %>%\n  atlas_occurrences()\n\n\n\n2.4.0.2 Basis of record\nBasis of record is a Darwin Core term that refers to the specific nature of the occurrence record. It can be used to refine your data download and ensure consistency when consolidating data from multiple organisations (Führding-Potschkat, Kreft, and Ickert-Bond 2022).\nThere are 6 different classes for basis of record:\n\nLiving Specimen - a specimen that is alive, e.g. a living plant in a national park\nPreserved Specimen - a specimen that has been preserved, for example, a dried plant on an herbarium sheet\nFossil Specimen - a preserved specimen that is a fossil\nMaterial Sample - a genetic or environmental sample\nMaterial Citation - A reference to, or citation of, a specimen in scholarly publications, e.g a citation of a physical specimen in a scientific journal\nHuman Observation - an output of human observation process e.g. evidence of an occurrence taken from field notes or an occurrence without any physical evidence\nMachine Observation - An output of a machine observation process e.g. a photograph, a video, an audio recording, a remote sensing image or an occurrence record based on telemetry.\n\nDepending on your data scope, it may be practical to limit data that can be traced to a physical specimen or observation (Godfree et al. 2021), which we do for the Pink Robin below\n\ntractable_records <- c(\n  \"LIVING_SPECIMEN\",\n  \"PRESERVED_SPECIMEN\",\n  \"MATERIAL_SAMPLE\",\n  \"MACHINE_OBSERVATION\"\n)\n\npink_robin_tractable <- galah_call() %>%\n  galah_identify(\"Petroica rodinogaster\") %>%\n  galah_filter(basisOfRecord == tractable_records) %>%\n  atlas_occurrences()\n\n\n\n2.4.0.3 Assertions\nData infrastructures use assertions to internally grade the quality, completeness and consistency of each occurrence record. Assertions take values of either 1 or 0, indicating the presence or absence of the data quality issue. Note that assertions may vary depending what atlas you have configured to. You can see the available assertions and their descriptions using:\n\nshow_all(\"assertions\")\n\n# A tibble: 114 × 4\n   id                                 description                 category type \n   <chr>                              <chr>                       <chr>    <chr>\n 1 AMBIGUOUS_COLLECTION               Ambiguous collection        Warning  asse…\n 2 AMBIGUOUS_INSTITUTION              Ambiguous institution       Warning  asse…\n 3 BASIS_OF_RECORD_INVALID            Basis of record badly form… Warning  asse…\n 4 biosecurityIssue                   Biosecurity issue           Error    asse…\n 5 COLLECTION_MATCH_FUZZY             Collection match fuzzy      Warning  asse…\n 6 COLLECTION_MATCH_NONE              Collection not matched      Warning  asse…\n 7 CONTINENT_COUNTRY_MISMATCH         Continent country mismatch  Warning  asse…\n 8 CONTINENT_DERIVED_FROM_COORDINATES Continent derived from coo… Warning  asse…\n 9 CONTINENT_INVALID                  Continent invalid           Warning  asse…\n10 COORDINATE_INVALID                 Coordinate invalid          Warning  asse…\n# ℹ 104 more rows\n\n\nOnce you have decided which assertions are important for your project you can further refine your download. To retrieve all the assertions for your query use galah_select(group = \"assertions\")"
  },
  {
    "objectID": "preclean.html#metadata",
    "href": "preclean.html#metadata",
    "title": "4  Pre-cleaning",
    "section": "4.1 Metadata",
    "text": "4.1 Metadata\nMetadata describes your data set: it defines each variable and its contents. This might be describing what units a variable has been measured in, or, the climate the occurrence was collected in and whether it is a marked outlier. Starting the process of pre-cleaning by briefing your metadata allows you to understand the kind of data you are working with and any potential biases that may limit what you can do with it. Similarly, these biases may need to be of consideration when creating models or when used in your work more broadly.\nData infrastructures that use Darwin Core terms will have interoperable metadata. This makes it easier to consolidate across data sets. All Darwin Core term definitions can be found here, we suggest using Ctrl/CMD F and searching your variable name on the webpage. Don’t hesitate to Google variable names if you are unsure what they represent.\nIt is also worth checking the metadata for the entire dataset to delineate if there is extra information about the data which may be relevant. You could Google the dataset name, or search the dataset or institution on the ALA. The metadata on the ALA is submitted with the data, of which the ALA as a repository and not an owner cannot change. This means low-quality metadata cannot necessarily be vetoed.\nAn example of some good metadata is FrogID from the Australian Museum. From reading FrogID’s metadata (Rowley and Callaghan 2020), you’ll find:\n\nThe data is acoustic data, the majority of the species recorded are therefore male\nBecause this is citizen science data, it is especially biased towards populated areas\nAudio is recorded via a smartphone app, the authors recommend if you require high coordinate precision to filter data to geographic uncertainty of <3000m\nThe data is presence only data\n\nMetadata can also be useful for understanding the license that the data falls under. This is mostly relevant for using or republishing multimedia associated with the data."
  },
  {
    "objectID": "preclean.html#initial-inspection",
    "href": "preclean.html#initial-inspection",
    "title": "4  Pre-cleaning",
    "section": "4.2 Initial inspection",
    "text": "4.2 Initial inspection\nA great way to get an initial overview of your data is to use the R package skimr. Importantly skimr produces tables of descriptive statistics, such as amount of missing data, for every variable\nThe output is also grouped by data type (numeric, character, date) so you can also check for any inconsistencies. As you are looking through the output, ask yourself whether the data is in line with your expectations. For example:\nIf you requested data for a group of species, are they all represented?\nAre the values for a variable reasonable? Looking at the quartiles will help you get the sense of the distribution of data.\nThese considerations will help you detect potential issues in the data.\n\nlibrary(skimr)\n\nskim(african_ele)\n\nHere is the skimr report for our African elephant dataset we downloaded earlier\n\n\n\nData summary\n\n\nName\nafrican_ele\n\n\nNumber of rows\n12537\n\n\nNumber of columns\n50\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n31\n\n\nlogical\n1\n\n\nnumeric\n15\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndatasetKey\n0\n1.00\n36\n36\n0\n132\n0\n\n\noccurrenceID\n708\n0.94\n1\n81\n0\n11787\n0\n\n\nkingdom\n0\n1.00\n8\n8\n0\n1\n0\n\n\nphylum\n0\n1.00\n8\n8\n0\n1\n0\n\n\nclass\n0\n1.00\n8\n8\n0\n1\n0\n\n\norder\n0\n1.00\n11\n11\n0\n1\n0\n\n\nfamily\n0\n1.00\n12\n12\n0\n1\n0\n\n\ngenus\n0\n1.00\n9\n9\n0\n1\n0\n\n\nspecies\n0\n1.00\n18\n18\n0\n1\n0\n\n\ninfraspecificEpithet\n12410\n0.01\n8\n13\n0\n2\n0\n\n\ntaxonRank\n0\n1.00\n7\n10\n0\n3\n0\n\n\nscientificName\n0\n1.00\n12\n37\n0\n5\n0\n\n\nverbatimScientificName\n3\n1.00\n12\n53\n0\n32\n0\n\n\nverbatimScientificNameAuthorship\n10964\n0.13\n2\n31\n0\n255\n0\n\n\ncountryCode\n1461\n0.88\n2\n2\n0\n44\n0\n\n\nlocality\n9211\n0.27\n3\n254\n0\n686\n0\n\n\nstateProvince\n3573\n0.72\n3\n43\n0\n182\n0\n\n\noccurrenceStatus\n0\n1.00\n6\n7\n0\n2\n0\n\n\npublishingOrgKey\n0\n1.00\n36\n36\n0\n102\n0\n\n\nbasisOfRecord\n0\n1.00\n10\n19\n0\n9\n0\n\n\ninstitutionCode\n1325\n0.89\n2\n76\n0\n103\n0\n\n\ncollectionCode\n1353\n0.89\n1\n41\n0\n164\n0\n\n\ncatalogNumber\n1553\n0.88\n1\n36\n0\n10866\n0\n\n\nrecordNumber\n12420\n0.01\n1\n37\n0\n77\n0\n\n\nidentifiedBy\n4646\n0.63\n2\n81\n0\n1464\n0\n\n\nlicense\n0\n1.00\n7\n12\n0\n3\n0\n\n\nrightsHolder\n4240\n0.66\n2\n56\n0\n1634\n0\n\n\nrecordedBy\n2138\n0.83\n1\n160\n0\n1972\n0\n\n\nestablishmentMeans\n12249\n0.02\n6\n6\n0\n1\n0\n\n\nmediaType\n5021\n0.60\n5\n16\n0\n4\n0\n\n\nissue\n397\n0.97\n15\n191\n0\n130\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntypeStatus\n12537\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ngbifID\n0\n1.00\n2535815516.94\n960444243.67\n49926810.00\n1802649142.00\n2465251941.00\n3.351048e+09\n4.029318e+09\n▁▅▇▅▇\n\n\nindividualCount\n10226\n0.18\n4.81\n14.03\n0.00\n1.00\n1.00\n2.000000e+00\n2.920000e+02\n▇▁▁▁▁\n\n\ndecimalLatitude\n1350\n0.89\n-10.01\n14.67\n-34.58\n-24.06\n-6.25\n4.800000e-01\n5.215000e+01\n▇▅▅▁▁\n\n\ndecimalLongitude\n1350\n0.89\n25.56\n12.35\n-122.33\n22.97\n31.08\n3.480000e+01\n4.053000e+01\n▁▁▁▂▇\n\n\ncoordinateUncertaintyInMeters\n3966\n0.68\n41636.59\n158053.45\n1.00\n29775.00\n30580.00\n3.142200e+04\n5.635548e+06\n▇▁▁▁▁\n\n\ncoordinatePrecision\n12512\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▁▁▇\n\n\nelevation\n12501\n0.00\n154.42\n421.59\n0.00\n0.00\n0.00\n1.375000e+01\n2.134000e+03\n▇▁▁▁▁\n\n\nelevationAccuracy\n12507\n0.00\n0.83\n3.73\n0.00\n0.00\n0.00\n0.000000e+00\n2.000000e+01\n▇▁▁▁▁\n\n\ndepth\n12509\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▇▁▁\n\n\ndepthAccuracy\n12509\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▇▁▁\n\n\nday\n1254\n0.90\n16.27\n8.74\n1.00\n9.00\n17.00\n2.400000e+01\n3.100000e+01\n▇▆▇▇▇\n\n\nmonth\n1191\n0.91\n6.92\n3.33\n1.00\n4.00\n7.00\n1.000000e+01\n1.200000e+01\n▆▅▅▇▇\n\n\nyear\n997\n0.92\n2011.05\n19.34\n1799.00\n2011.00\n2016.00\n2.019000e+03\n2.023000e+03\n▁▁▁▁▇\n\n\ntaxonKey\n0\n1.00\n2517047.48\n747546.46\n2435350.00\n2435350.00\n2435350.00\n2.435350e+06\n1.150335e+07\n▇▁▁▁▁\n\n\nspeciesKey\n0\n1.00\n2435350.00\n0.00\n2435350.00\n2435350.00\n2435350.00\n2.435350e+06\n2.435350e+06\n▁▁▇▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n997\n0.92\n1799-01-01 00:00:00\n2023-02-07 09:17:14\n2016-02-07 12:00:00\n8324\n\n\ndateIdentified\n4150\n0.67\n1783-01-01 00:00:00\n2023-02-07 21:51:36\n2020-04-16 19:35:25\n7242\n\n\nlastInterpreted\n0\n1.00\n2023-01-24 14:57:46\n2023-02-14 01:52:09\n2023-02-13 16:01:27\n10885"
  },
  {
    "objectID": "preclean.html#structural-inconsistencies",
    "href": "preclean.html#structural-inconsistencies",
    "title": "4  Pre-cleaning",
    "section": "4.3 Structural inconsistencies",
    "text": "4.3 Structural inconsistencies\n\n4.3.1 String inconsistencies and typographical errors\nString inconsistencies include misspellings, capitalisation errors, misplaced punctuation or trailing white spaces. We will use the janitor R package to explore whether our data has any of these issues. The function tabyl will compute a counts and percent of total rows for each unique value.\nWe recommend tabyl-ing any character strings that are relevant to your project. For example, here is the stateProvince in alphabetical order.\n\nlibrary(janitor)\n\nafrican_ele %>%\n  pull(stateProvince) %>% \n  tabyl() %>% \n  tibble() %>% \n  print(n = 20)\n\n\n\n# A tibble: 183 × 4\n   .                     n   percent valid_percent\n   <chr>             <int>     <dbl>         <dbl>\n 1 Agadez                1 0.0000798      0.000112\n 2 Al Qahirah            1 0.0000798      0.000112\n 3 Alibori             601 0.0479         0.0670  \n 4 Arusha              231 0.0184         0.0258  \n 5 Arusha Region         1 0.0000798      0.000112\n 6 Atacora             366 0.0292         0.0408  \n 7 Atakora             239 0.0191         0.0267  \n 8 Balaka                7 0.000558       0.000781\n 9 Bassila               1 0.0000798      0.000112\n10 Batha                 1 0.0000798      0.000112\n11 Bauchi                3 0.000239       0.000335\n12 Bengo                 3 0.000239       0.000335\n13 Borgou                7 0.000558       0.000781\n14 Budongo Forest        1 0.0000798      0.000112\n15 Bushenyi             61 0.00487        0.00680 \n16 Cabo Delgado          2 0.000160       0.000223\n17 Cape Prov.            2 0.000160       0.000223\n18 Cape Province         1 0.0000798      0.000112\n19 Central             113 0.00901        0.0126  \n20 Central Equatoria     2 0.000160       0.000223\n# ℹ 163 more rows\n\n\nFrom the tabyl output, we can see there are few different variations of Province, Prov., Prov. As an example, we will correct these with the tidyverse packages stringr, dplyr, tidyr as well as glue. If you are not very familiar with regular expressions, we highly recommend this cheatsheet\n\nlibrary(tidyverse)\nlibrary(glue)\n\n# Create a regular expression to match Prov. and Prov\n# The pattern below means Prov that is NOT followed by any lowercase letters\npattern = regex(\"Prov(?![:lower:])\")\n\n# Use `str_subset` to pull out the cases that match our pattern\n# Confirm that these are the problematic ones\n# Assign these into an object\nstr_subset(african_ele$stateProvince, pattern = pattern)\n\n [1] \"Cape Prov.\"        \"Cape Prov.\"        \"West Nile Prov.\"  \n [4] \"Central Prov\"      \"Central Prov\"      \"Coastal Prov\"     \n [7] \"Northeastern Prov\" \"Central Prov\"      \"Eastern Prov\"     \n[10] \"Coastal Prov\"     \n\ntypos_provinces <- str_subset(african_ele$stateProvince, pattern = pattern)\n\n# Create a new variable `stateProvince_clean` using `mutate`, `if_else`, `str_detect` and `glue`\n# `str_detect` will evaluate values of `stateProvince` that matches our pattern we defined earlier.\n# Matches will return TRUE, non-matches will return FALSE. \n# The `if_else` will then evaluate these logicals (TRUE/FALSE/NA) \n# for TRUE values, the `glue` function will take the first part of the province name enclosed in and join it with word Province.\n# for FALSE values , it will just take the corresponding value in stateProvince\n# Note that we are assigning these changes to a new object (`african_ele_2`)\nafrican_ele_2 <- african_ele %>% \n  mutate(stateProvince_clean = if_else(str_detect(stateProvince, pattern = pattern),\n                                      true = glue('{word(stateProvince, sep = \" P\")} Province'),\n                                      false = stateProvince)\n         ) \n\n# Once we've made the correction we want to check we've done it correctly.\n# ALWAYS CHECK YOUR CORRECTIONS\n# Use the `select` function to isolate columns that `starts_with` \"stateProvince\"\n# Use the `filter` function to subset our the problematic provinces \nafrican_ele_2 %>% \n  select(starts_with(\"stateProvince\")) %>% \n  filter(stateProvince %in% typos_provinces)\n\n# A tibble: 10 × 2\n   stateProvince     stateProvince_clean  \n   <chr>             <glue>               \n 1 Cape Prov.        Cape Province        \n 2 Cape Prov.        Cape Province        \n 3 West Nile Prov.   West Nile Province   \n 4 Central Prov      Central Province     \n 5 Central Prov      Central Province     \n 6 Coastal Prov      Coastal Province     \n 7 Northeastern Prov Northeastern Province\n 8 Central Prov      Central Province     \n 9 Eastern Prov      Eastern Province     \n10 Coastal Prov      Coastal Province     \n\n# Its good practice to check the other values were not affected by your corrections\n# Here we are removing the NA with `drop_na` and subsetting unique rows with `distinct`\nafrican_ele_2 %>% \n  select(starts_with(\"stateProvince\")) %>% \n  drop_na() %>% \n  distinct() \n\n# A tibble: 182 × 2\n   stateProvince    stateProvince_clean\n   <chr>            <glue>             \n 1 Southern         Southern           \n 2 Taita Taveta     Taita Taveta       \n 3 Mara             Mara               \n 4 Arusha           Arusha             \n 5 Simiyu           Simiyu             \n 6 Morogoro         Morogoro           \n 7 Mashonaland West Mashonaland West   \n 8 Mpumalanga       Mpumalanga         \n 9 KwaZulu-Natal    KwaZulu-Natal      \n10 Manicaland       Manicaland         \n# ℹ 172 more rows\n\n# Final check\n# Check with the original code that detected the issue\nafrican_ele_2 %>%\n  pull(stateProvince_clean) %>% \n  tabyl() %>% \n  tibble() %>% \n  print(n = 20)\n\n# A tibble: 181 × 4\n   .                     n   percent valid_percent\n   <glue>            <int>     <dbl>         <dbl>\n 1 Agadez                1 0.0000798      0.000112\n 2 Al Qahirah            1 0.0000798      0.000112\n 3 Alibori             601 0.0479         0.0670  \n 4 Arusha              231 0.0184         0.0258  \n 5 Arusha Region         1 0.0000798      0.000112\n 6 Atacora             366 0.0292         0.0408  \n 7 Atakora             239 0.0191         0.0267  \n 8 Balaka                7 0.000558       0.000781\n 9 Bassila               1 0.0000798      0.000112\n10 Batha                 1 0.0000798      0.000112\n11 Bauchi                3 0.000239       0.000335\n12 Bengo                 3 0.000239       0.000335\n13 Borgou                7 0.000558       0.000781\n14 Budongo Forest        1 0.0000798      0.000112\n15 Bushenyi             61 0.00487        0.00680 \n16 Cabo Delgado          2 0.000160       0.000223\n17 Cape Province         3 0.000239       0.000335\n18 Central             113 0.00901        0.0126  \n19 Central Equatoria     2 0.000160       0.000223\n20 Central Province      4 0.000319       0.000446\n# ℹ 161 more rows\n\n\nThere are some other issues that can be corrected in a similar approach:\n\nNorth West, North West District and North-Western\nÀfrica Central, Central Province and Central\nAtacora and Atakora\nCoastal Province and Coastal\n\nWe recommend consulting reputable sources that can help delineate or consolidate similar values. Googling and looking at Wikipedia’s sources are good places to find resources that you can verify accepted state and province names.\n\n\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset: Expert-Validated Occurrence Records of Australia’s Frogs Collected by Citizen Scientists.” ZooKeys 912: 139.\n\n\nstreamdna. 2020. “Sharing Is Caring: Working with Other People’s Data.” https://methodsblog.com/2020/09/04/sharing-is-caring-working-with-other-peoples-data/."
  },
  {
    "objectID": "taxonomy.html#taxonomy-preclean",
    "href": "taxonomy.html#taxonomy-preclean",
    "title": "5  Taxonomy",
    "section": "5.1 Taxonomy preclean",
    "text": "5.1 Taxonomy preclean\nSimilar to what we did in the previous chapter, we will apply a broad sweep pre-clean to taxonomic data. This will make dealing with synonyms go as smoothly as possible.\nThe process is to first identify the issue, correct it, check it, and then document the changes. The goal is to standardise and correct as many errors issues before removing records.\n\n5.1.1 Capitalisation\nNormally higher taxonomy are capitalised e.g. Myrtaceae or Aves. Capitalisation errors are usually quick to spot when you print the data object. Alternatively you can try using str_subset on columns you expect to have capital letters.\nThe code below subsets out unique values for the variable class that have upper case letters. Notice that no matches are found\n\nlibrary(tidyverse)\n\nstr_subset(unique(bees$class), \"[:upper:]\")\n\ncharacter(0)\n\n\nWe can confirm that there are no upper case matches by subsetting unique values that have lower case letters to see what is going on. This shows us that Insecta is inputted entirely in lowercase.\n\nstr_subset(unique(bees$class), \"[:lower:]\") \n\n[1] \"insecta\"\n\n\nWe can correct the lower case formatting as below, remember to check the fix before overwriting/removing the erroneous column(s)\n\nbees |> \n  mutate(class_corrected = str_to_sentence(class)) |>\n  select(starts_with(\"class\"))\n\n# A tibble: 1,139 × 2\n   class   class_corrected\n   <chr>   <chr>          \n 1 insecta Insecta        \n 2 insecta Insecta        \n 3 insecta Insecta        \n 4 insecta Insecta        \n 5 insecta Insecta        \n 6 insecta Insecta        \n 7 insecta Insecta        \n 8 insecta Insecta        \n 9 insecta Insecta        \n10 insecta Insecta        \n# ℹ 1,129 more rows\n\nbees_corrected <- bees |> \n  mutate(class_corrected = str_to_sentence(class)) |> \n  select(-class) |> # Remove erroreous column \n  rename(class = class_corrected) # Rename corrected column as the new 'class'\n\n\n\n5.1.2 Seperators\nIn a taxonomic data, separators such as, spaces and underscore are found in scientific names and are used to delineate the genus and species name. While it is personal choice which separator you use, it is good practice to be consistent with your choice. Consistency ensures that unique values of scientific name truly reflects unique species and not due to inconsistencies.\nTry tabyl-ing your taxonomic columns to check if you have any inconsistencies first\n\nlibrary(janitor)\n\nplants |> \n  pull(scientific_name) |> \n  tabyl() |> \n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants, scientific_name)`         n  percent\n   <chr>                               <int>    <dbl>\n 1 Acacia asparagoides                     2 0.000962\n 2 Acacia barakulensis                     1 0.000481\n 3 Acacia barringtonensis                  2 0.000962\n 4 Acacia beadleana                        1 0.000481\n 5 Acacia betchei                          6 0.00289 \n 6 Acacia blayana                          2 0.000962\n 7 Acacia brunioides                       1 0.000481\n 8 Acacia brunioides subsp. brunioides     6 0.00289 \n 9 Acacia brunioides subsp. granitica      1 0.000481\n10 Acacia bulgaensis                       3 0.00144 \n# ℹ 613 more rows\n\n\nConsistent taxonomic formatting may not be an issue if you are downloading data from one single source such as the ALA where scientific names are already formatted consistently e.g. “Moloch horridus”. This may not be the case when consolidating data from multiple sources.\nBelow is code to create an underscore scientific name from one that is separated with a space. Remember to check your changes\n\nplants_updated <- plants |> \n  mutate(scientific_name_undersc = str_replace_all(scientific_name, \" \", \"_\")) \n\nplants_updated |> \n  pull(scientific_name_undersc) |> \n  tabyl() |> \n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants_updated, scientific_name_undersc)`     n  percent\n   <chr>                                           <int>    <dbl>\n 1 Acacia_asparagoides                                 2 0.000962\n 2 Acacia_barakulensis                                 1 0.000481\n 3 Acacia_barringtonensis                              2 0.000962\n 4 Acacia_beadleana                                    1 0.000481\n 5 Acacia_betchei                                      6 0.00289 \n 6 Acacia_blayana                                      2 0.000962\n 7 Acacia_brunioides                                   1 0.000481\n 8 Acacia_brunioides_subsp._brunioides                 6 0.00289 \n 9 Acacia_brunioides_subsp._granitica                  1 0.000481\n10 Acacia_bulgaensis                                   3 0.00144 \n# ℹ 613 more rows\n\n\n\n\n5.1.3 Higher taxonomy\nHigher taxonomy such as phylum and class may be used to group species for analysis or data visualisations. Its important to check the spelling and formatting of these columns. Its always good to start with some a useful table of counts for each taxonomic level. Keep an eye out for spelling errors, formatting issues and missing data. Note that NA in the output represents missing\nAs an example:\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nplants |> \n  pull(class) |> \n  tabyl()\n\n pull(plants, class)    n     percent valid_percent\n         Cycadopsida    4 0.001924002   0.001937046\n       Equisetopsida  202 0.097162097   0.097820823\n      Lycopodiopsida   10 0.004810005   0.004842615\n       Magnoliopsida 1822 0.876382876   0.882324455\n           Pinopsida    2 0.000962001   0.000968523\n      Polypodiopsida   25 0.012025012   0.012106538\n                <NA>   14 0.006734007            NA\n\nplants |> \n  pull(order) |> \n  tabyl() |> \n  head()\n\n pull(plants, order)   n     percent valid_percent\n         Alismatales   6 0.002886003   0.002939735\n             Apiales  36 0.017316017   0.017638413\n         Asparagales  67 0.032227032   0.032827046\n           Asterales 158 0.075998076   0.077413033\n    Austrobaileyales   6 0.002886003   0.002939735\n          Canellales   5 0.002405002   0.002449780\n\nplants |> \n  pull(genus) |> \n  tabyl() |> \n  tail()\n\n pull(plants, genus)  n     percent valid_percent\n               Viola  5 0.002405002   0.002501251\n          Westringia 12 0.005772006   0.006003002\n           Xanthosia  9 0.004329004   0.004502251\n               Xyris  4 0.001924002   0.002001001\n              Zieria 14 0.006734007   0.007003502\n                <NA> 80 0.038480038            NA\n\n\n\nMissing higher taxonomy\nIf you noticed you have missing data in these columns, you can usually back fill this information using your chosen naming authority or retrieving this information from a living atlas such as the ALA.\nThe code below demonstrates how you can isolate the scientific_names of taxa with missing data and searching for taxonomic information from ALA\n\n\n\nlibrary(galah)\n\n# Configure galah to point to Australia node\ngalah_config(atlas = \"Australia\",\n             email = Sys.getenv(\"ALA_EMAIL\"))\n\n# These are the taxa missing `class` information\nto_search <- inverts |> \n  filter(is.na(class)) |> \n  select(scientific_name) |> \n  distinct()\n\n# Reformat scientific_name to scientificName as the latter is the ALA format\nbackfilled_taxa <- to_search|>\n  rename(scientificName = scientific_name) |> \n  search_taxa(to_search) |> tibble()\n\nbackfilled_taxa\n\n# A tibble: 818 × 15\n   search_term     scientific_name scientific_name_auth…¹ taxon_concept_id rank \n   <chr>           <chr>           <chr>                  <chr>            <chr>\n 1 Idiosoma manst… Idiosoma manst… (Pocock, 1897)         https://biodive… spec…\n 2 Holonuncia rec… Holonuncia rec… Hunt, 1992             https://biodive… spec…\n 3 Trachycosmus s… Trachycosmus s… Simon, 1893            https://biodive… spec…\n 4 Pseudotyrannoc… Pseudotyrannoc… Beier, 1971            https://biodive… spec…\n 5 Phryganoporus … Phryganoporus … (L. Koch, 1872)        https://biodive… spec…\n 6 Latrodectus ha… Latrodectus ha… Thorell, 1870          https://biodive… spec…\n 7 Ascoschoengast… Ascoschoengast… (Hirst, 1915)          https://biodive… spec…\n 8 Chrestobunus f… Chrestobunus f… Hickman, 1958          https://biodive… spec…\n 9 Supunna picta   Nyssus colorip… Walckenaer, 1805       https://biodive… spec…\n10 Tasmanicosa le… Tasmanicosa le… (Thorell, 1870)        https://biodive… spec…\n# ℹ 808 more rows\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 10 more variables: match_type <chr>, kingdom <chr>, phylum <chr>,\n#   class <chr>, order <chr>, family <chr>, genus <chr>, species <chr>,\n#   issues <chr>, vernacular_name <chr>\n\n\n\n\nInsufficient taxonomic rank\nIf a record is not identified down to the taxonomic level that needed for the study e.g. species, then the record should be removed.\nDuring your data download, ensure you have requested for the column taxonRank, this variable tells us the lowest level of scientificName.\n\nlibrary(galah)\n\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"),\n             atlas = \"Australia\")\n\nhoneyeaters <- galah_call() |> \n  galah_identify(\"Meliphagidae\") |> \n  galah_filter(year == 2012 & stateProvince == \"New South Wales\") |> \n  galah_select(group = \"basic\", taxonRank) |> \n  atlas_occurrences()\n\nhoneyeaters$taxonRank |> unique()\n\nhoneyeaters |> filter(taxonRank == \"species\")\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\n# honeyeaters <- galah_call() |>\n#   galah_identify(\"Meliphagidae\") |>\n#   galah_filter(year == 2012 & stateProvince == \"New South Wales\") |>\n#   galah_select(group = \"basic\", taxonRank) |>\n#   atlas_occurrences()\n\n# write_parquet(honeyeaters, \"data/galah/honeyeater\")\n\nhoneyeaters <- open_dataset(\"data/galah/honeyeater\") |> collect()\n\nhoneyeaters$taxonRank |> unique()\n\n[1] \"species\"    \"genus\"      \"subgenus\"   \"subspecies\" \"family\"    \n\nhoneyeaters |> filter(taxonRank == \"species\")\n\n# A tibble: 43,684 × 9\n   decimalLatitude decimalLongitude eventDate           scientificName          \n             <dbl>            <dbl> <dttm>              <chr>                   \n 1           -37.4             150. 2012-09-26 14:00:00 Meliphaga (Meliphaga) l…\n 2           -37.4             150. 2012-09-26 14:00:00 Acanthorhynchus tenuiro…\n 3           -37.4             150. 2012-04-07 14:00:00 Acanthorhynchus tenuiro…\n 4           -37.4             150. 2012-04-07 14:00:00 Nesoptilotis leucotis   \n 5           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Meliornis…\n 6           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Phylidony…\n 7           -37.4             150. 2012-04-07 14:00:00 Nesoptilotis leucotis   \n 8           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Meliornis…\n 9           -37.4             150. 2012-04-07 14:00:00 Melithreptus (Melithrep…\n10           -37.4             150. 2012-04-07 14:00:00 Acanthorhynchus tenuiro…\n# ℹ 43,674 more rows\n# ℹ 5 more variables: taxonConceptID <chr>, recordID <chr>,\n#   dataResourceName <chr>, occurrenceStatus <chr>, taxonRank <chr>\n\n\n\n\nInconsistent higher taxonomy\nA great approach to detect inconsistencies in your taxonomic data is to compute counts for each level of taxonomic rank. These counts act as a check for you to verify that the data is in line with your expectation. This is particularly important when combining data from different sources where their taxonomy might vary. If you have detected inconsistencies as we have done below, you will have to correct accordingly, either by consulting a taxonomic expert or a naming authority and ensure this is reported in your methods.\n\n# Get counts for every species where they have more than 1 class\nplants |> \n  select(phylum:species, scientific_name) |> \n  distinct() |> \n  group_by(species) |> \n  summarise(n_class = length(unique(class))) |> \n  filter(n_class > 1) \n\n# A tibble: 1 × 2\n  species               n_class\n  <chr>                   <int>\n1 Allocasuarina distyla       2\n\n# Get the species that have more than 1 class\ninconsistent_taxa <- plants |> \n  select(phylum:species, scientific_name) |> \n  distinct() |> \n  group_by(species) |> \n  summarise(n_class = length(unique(class))) |> \n  filter(n_class > 1) |> \n  pull(species) \n\n# Filter species that have more than 1 class\nplants |> filter(species %in% inconsistent_taxa) |> \n  select(phylum:species, scientific_name) |> \n  arrange(species) |> \n  distinct() \n\n# A tibble: 2 × 7\n  phylum       class         order   family        genus species scientific_name\n  <chr>        <chr>         <chr>   <chr>         <chr> <chr>   <chr>          \n1 Tracheophyta Magnoliopsida Fagales Casuarinaceae Allo… Alloca… Allocasuarina …\n2 Tracheophyta Equisetopsida Fagales Casuarinaceae Allo… Alloca… Allocasuarina …"
  },
  {
    "objectID": "taxonomy.html#synonyms",
    "href": "taxonomy.html#synonyms",
    "title": "5  Taxonomy",
    "section": "5.2 Synonyms",
    "text": "5.2 Synonyms\nSynonyms is a complex issue when working with open source biodiversity data. Data infrastructures have their own taxonomic systems which may not align with researchers’ view or consistent with your chosen naming authority.\nKeeping in mind that there is no universal solution to synonymy. Best practice is to flag and correct synonyms in a clear and consistent manner. We recommend being explicit with your decisions about which names are retained and keeping a good record of the changes to aid transparency and reproducibility.\n\n{worrms}\nThe {worrms} is the R interface to the World Register of Marine Species and has a ability to cross check synonyms with their database for taxa that has an AphiaID. The function will return synonymous record(s) associated with another different AphiaID.\n\nlibrary(worrms)\n\nmarine_sp <- read_csv(\"data/worms/worms.csv\")\n\nmarine_sp |> \n  slice(7) |>\n  pull(AphiaID) |> \n  wm_synonyms()\n\n# A tibble: 1 × 27\n  AphiaID url   scientificname authority status unacceptreason taxonRankID rank \n    <int> <chr> <chr>          <chr>     <chr>  <lgl>                <int> <chr>\n1  453207 http… Goniosoma ina… Walker, … super… NA                     220 Spec…\n# ℹ 19 more variables: valid_AphiaID <int>, valid_name <chr>,\n#   valid_authority <chr>, parentNameUsageID <int>, kingdom <chr>,\n#   phylum <chr>, class <chr>, order <chr>, family <chr>, genus <chr>,\n#   citation <chr>, lsid <chr>, isMarine <int>, isBrackish <int>,\n#   isFreshwater <int>, isTerrestrial <int>, isExtinct <int>, match_type <chr>,\n#   modified <chr>\n\n\n\n\n{taxize}\n{taxize} allows users to search over many taxonomic data sources for species names (scientific and common) to resolve synonymy. The gnr_resolve() function matches your supplied list with up to 118 data sources including GBIF, Catalogue of Life, World Register of Marine Species and many more. The function scores how well matched your name is to these sources.\n\nlibrary(taxize)\n\n# Read in a naming authority list\nafd <- read_csv(\"data/naming/afd.csv\")\nunique(afd$VALID_NAME)\n\n [1] \"Prosphaerosyllis battiri\"         \"Clavellopsis parasargi\"          \n [3] \"Platypontonia hyotis\"             \"Palirhoeus eatoni\"               \n [5] \"Diastylis kapalae\"                \"Xenobates chinai\"                \n [7] \"Paratanais gaspodei\"              \"Paradexamine flindersi\"          \n [9] \"Prostebbingia brevicornis\"        \"Cythere lactea\"                  \n[11] \"Cythere melobesioides\"            \"Achelia transfugoides\"           \n[13] \"Halobates (Halobates) acherontis\" \"Quadraceps hopkinsi apophoretus\" \n[15] \"Anabarhynchus striatus\"           \"Australocytheridea vandenboldi\"  \n[17] \"Enigmaplax littoralis\"            \"Hyphalus insularis\"              \n[19] \"Plesiopenaeus armatus\"            \"Uroptychus brucei\"               \n[21] \"Caligus dasyaticus\"               \"Coralliophila tetragona\"         \n[23] \"Triphora alveolata\"               \"Clavus obliquatus\"               \n[25] \"Naria beckii\"                     \"Pharaonella rostrata\"            \n[27] \"Lasaea australis\"                 \"Cadulus rudmani\"                 \n[29] \"Bembicium flavescens\"             \"Mormula philippiana\"             \n[31] \"Turbonilla tiara\"                 \"Chlorodiloma crinita\"            \n[33] \"Mitrella merita\"                  \"Tritonoharpa antiquata\"          \n[35] \"Mauritia depressa dispersa\"       \"Laevidentalium zeidleri\"         \n[37] \"Conus (Harmoniconus) musicus\"     \"Marionia cyanobranchiata\"        \n[39] \"Tucetona flabellata\"              \"Neochromadora bilineata\"         \n[41] \"Desmoscolex membranosus\"          \"Echeneidocoelium indicum\"        \n[43] \"Indodidymozoon suttiei\"           \"Diploproctodaeum yosogi\"         \n[45] \"Pseudopecoelus japonicus\"         \"Pedibothrium lloydae\"            \n[47] \"Amphitethya stipitata\"            \"Pseudosuberites mollis\"          \n[49] \"Psammochela psammodes\"           \n\n# Resolve names\nresolved <- gnr_resolve(unique(afd$VALID_NAME), best_match_only = TRUE) \nresolved |> print(n = 50)\n\n# A tibble: 49 × 5\n   user_supplied_name        submitted_name matched_name data_source_title score\n * <chr>                     <chr>          <chr>        <chr>             <dbl>\n 1 Prosphaerosyllis battiri  Prosphaerosyl… Prosphaeros… National Center … 0.988\n 2 Clavellopsis parasargi    Clavellopsis … Clavellopsi… uBio NameBank     0.988\n 3 Platypontonia hyotis      Platypontonia… Platyponton… National Center … 0.988\n 4 Palirhoeus eatoni         Palirhoeus ea… Palirhoeus … Wikispecies       0.988\n 5 Diastylis kapalae         Diastylis kap… Diastylis k… Encyclopedia of … 0.988\n 6 Xenobates chinai          Xenobates chi… Xenobates c… Encyclopedia of … 0.988\n 7 Paratanais gaspodei       Paratanais ga… Paratanais … Wikispecies       0.988\n 8 Paradexamine flindersi    Paradexamine … Paradexamin… Encyclopedia of … 0.988\n 9 Prostebbingia brevicornis Prostebbingia… Prostebbing… Encyclopedia of … 0.988\n10 Cythere lactea            Cythere lactea Cythere lac… Encyclopedia of … 0.988\n11 Cythere melobesioides     Cythere melob… Cythere mel… Encyclopedia of … 0.988\n12 Achelia transfugoides     Achelia trans… Achelia tra… National Center … 0.988\n13 Halobates (Halobates) ac… Halobates (ha… Halobates (… CU*STAR           0.999\n14 Quadraceps hopkinsi apop… Quadraceps ho… Quadraceps … Catalogue of Lif… 0.999\n15 Anabarhynchus striatus    Anabarhynchus… Anabarhynch… Encyclopedia of … 0.988\n16 Australocytheridea vande… Australocythe… Australocyt… Encyclopedia of … 0.988\n17 Enigmaplax littoralis     Enigmaplax li… Enigmaplax … Encyclopedia of … 0.988\n18 Hyphalus insularis        Hyphalus insu… Hyphalus in… Wikispecies       0.988\n19 Plesiopenaeus armatus     Plesiopenaeus… Plesiopenae… Wikispecies       0.988\n20 Uroptychus brucei         Uroptychus br… Uroptychus … Wikispecies       0.988\n21 Caligus dasyaticus        Caligus dasya… Caligus das… Encyclopedia of … 0.988\n22 Coralliophila tetragona   Coralliophila… Coralliophi… Encyclopedia of … 0.988\n23 Triphora alveolata        Triphora alve… Triphora al… uBio NameBank     0.988\n24 Clavus obliquatus         Clavus obliqu… Clavus obli… Encyclopedia of … 0.988\n25 Naria beckii              Naria beckii   Naria beckii National Center … 0.988\n26 Pharaonella rostrata      Pharaonella r… Pharaonella… Arctos            0.988\n27 Lasaea australis          Lasaea austra… Lasaea aust… National Center … 0.988\n28 Cadulus rudmani           Cadulus rudma… Cadulus rud… Encyclopedia of … 0.988\n29 Bembicium flavescens      Bembicium fla… Bembicium f… National Center … 0.988\n30 Mormula philippiana       Mormula phili… Mormula phi… Encyclopedia of … 0.988\n31 Turbonilla tiara          Turbonilla ti… Turbonilla … Encyclopedia of … 0.988\n32 Chlorodiloma crinita      Chlorodiloma … Chlorodilom… National Center … 0.988\n33 Mitrella merita           Mitrella meri… Mitrella me… Encyclopedia of … 0.988\n34 Tritonoharpa antiquata    Tritonoharpa … Tritonoharp… National Center … 0.988\n35 Mauritia depressa disper… Mauritia depr… Mauritia de… National Center … 0.999\n36 Laevidentalium zeidleri   Laevidentaliu… Laevidental… Encyclopedia of … 0.988\n37 Conus (Harmoniconus) mus… Conus (harmon… Conus Linna… Catalogue of Lif… 0.75 \n38 Marionia cyanobranchiata  Marionia cyan… Marionia cy… National Center … 0.988\n39 Tucetona flabellata       Tucetona flab… Tucetona fl… Encyclopedia of … 0.988\n40 Neochromadora bilineata   Neochromadora… Neochromado… National Center … 0.988\n41 Desmoscolex membranosus   Desmoscolex m… Desmoscolex… Encyclopedia of … 0.988\n42 Echeneidocoelium indicum  Echeneidocoel… Echeneidoco… Integrated Taxon… 0.988\n43 Indodidymozoon suttiei    Indodidymozoo… Indodidymoz… National Center … 0.988\n44 Diploproctodaeum yosogi   Diploproctoda… Diploprocto… Encyclopedia of … 0.988\n45 Pseudopecoelus japonicus  Pseudopecoelu… Pseudopecoe… Integrated Taxon… 0.988\n46 Pedibothrium lloydae      Pedibothrium … Pedibothriu… Encyclopedia of … 0.988\n47 Amphitethya stipitata     Amphitethya s… Amphitethya… Wikispecies       0.988\n48 Pseudosuberites mollis    Pseudosuberit… Pseudosuber… Encyclopedia of … 0.988\n49 Psammochela psammodes     Psammochela p… Psammochela… Wikispecies       0.988\n\n# Retrieve synonyms\ntsn <- get_tsn(unique(afd$VALID_NAME)[1:5])\n\n══  5 queries  ═══════════════\n✖  Not Found:  Prosphaerosyllis battiri\n✖  Not Found:  Clavellopsis parasargi\n✔  Found:  Platypontonia hyotis\n✖  Not Found:  Palirhoeus eatoni\n✖  Not Found:  Diastylis kapalae\n══  Results  ═════════════════\n\n• Total: 5 \n• Found: 1 \n• Not Found: 4\n\nsynonyms(tsn)\n\n$<NA>\n[1] NA\n\n$<NA>\n[1] NA\n\n$`612530`\n  sub_tsn acc_tsn   syn_author                  syn_name syn_tsn\n1  612530  612530 Suzuki, 1971 Platypontonia pterostreae 1191962\n\n$<NA>\n[1] NA\n\n$<NA>\n[1] NA"
  },
  {
    "objectID": "taxonomy.html#input-from-experts",
    "href": "taxonomy.html#input-from-experts",
    "title": "5  Taxonomy",
    "section": "5.3 Input from experts",
    "text": "5.3 Input from experts\nProgrammatic solutions for resolving synonymy can only go so far. Seeking validation from experts is sensible if your goal is to obtain a high quality species list. Museums or taxonomic societies are extensive sources of knowledge. Below we have provided a list of some of Australian taxonomic society groups.\n\n5.3.1 Australian taxonomic society groups\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists\n\n\n\n5.3.2 Global taxonomy\n\nGBIF uses 100 different sources to assemble - their global taxonomic backbone\nAuthoritative taxonomic information on plants, animals, fungi, and microbes - Integrated Taxonomic Information System, ITIS\nGlobal taxonomic catalogue\nCatalogue of Life\n\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067."
  },
  {
    "objectID": "taxonomy-2.html#joining-datasets-from-different-infrastructures",
    "href": "taxonomy-2.html#joining-datasets-from-different-infrastructures",
    "title": "6  Taxonomy II",
    "section": "6.1 Joining datasets from different infrastructures",
    "text": "6.1 Joining datasets from different infrastructures\nIf you have downloaded data from different sources, you likely will need to collate your data into a singular database. It is important to make sure fields that have the same, are indeed the same variable, so prior to merging - take the time cross check the meta-data from different data providers (Ribeiro et al. 2022).\n\n6.1.1 Variable names and case format\nData providers will have their own naming conventions for variables. For example, World Register of Marine Species uses a combination of lower case e.g scientific_name and camel case e.g isExtinct. While the naming authority - Australian Fauna Directory (AFD) uses upper, snake case e.g. SCIENTIFIC_NAME. What format you choose is a matter of personal preference, the key is to be consistent.\nHere we will subset the variables we want, reformat them to the lower snake case names and then join by VALID_NAME\n\nlibrary(stringr)\n\nhabitat_data &lt;- worms %&gt;% \n  select(valid_name, starts_with(\"is\")) \n\nnames(habitat_data)[-1] \n\n[1] \"isMarine\"      \"isBrackish\"    \"isFreshwater\"  \"isTerrestrial\"\n[5] \"isExtinct\"    \n\nnew_names &lt;- str_split(names(habitat_data)[-1], pattern =  \"(?&lt;=[a-z])(?=[A-Z])\", n = 2) %&gt;%  # Seperate where case cases from lower to upper i.e. camel case\n  map(.x = ., \n      .f = ~tolower(.x)) %&gt;% # Convert to all lower case\n    map(.x = ., \n      .f = ~str_flatten(.x, \"_\")) %&gt;%  # Bind the two seperated elements\n  unlist()\n  \nnew_names\n\n[1] \"is_marine\"      \"is_brackish\"    \"is_freshwater\"  \"is_terrestrial\"\n[5] \"is_extinct\"    \n\n# Replace old with new\nnames(habitat_data)[-1] &lt;- new_names\n\n# Join habitat data by VALID_NAME\nafd %&gt;% left_join(habitat_data, by = join_by(VALID_NAME == valid_name))\n\n# A tibble: 49 × 37\n   GROUP_NAME HIGHER_CLASSIFICATION    KINGDOM PHYLUM SUBPHYLUM SUPERCLASS CLASS\n   &lt;chr&gt;      &lt;chr&gt;                    &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;lgl&gt;      &lt;chr&gt;\n 1 ANNELIDA   Phylum ANNELIDA, Class … ANIMAL… ANNEL… &lt;NA&gt;      NA         POLY…\n 2 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MAXI…\n 3 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 4 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… HEXAPODA  NA         INSE…\n 5 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 6 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… HEXAPODA  NA         INSE…\n 7 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 8 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 9 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n10 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         OSTR…\n# ℹ 39 more rows\n# ℹ 30 more variables: SUBCLASS &lt;chr&gt;, SUPERORDER &lt;chr&gt;, ORDER &lt;chr&gt;,\n#   SUBORDER &lt;chr&gt;, SUPERFAMILY &lt;chr&gt;, FAMILY &lt;chr&gt;, SUBFAMILY &lt;chr&gt;,\n#   SUPERTRIBE &lt;lgl&gt;, TRIBE &lt;chr&gt;, SUBTRIBE &lt;lgl&gt;, GENUS &lt;chr&gt;,\n#   SUB_GENUS &lt;chr&gt;, SPECIES &lt;chr&gt;, SUB_SPECIES &lt;chr&gt;, AUTHOR &lt;chr&gt;,\n#   YEAR &lt;dbl&gt;, CHANGED_COMBINATION &lt;chr&gt;, VALID_NAME &lt;chr&gt;,\n#   COMPLETE_NAME &lt;chr&gt;, SYNONYMS &lt;chr&gt;, CHANGED_COMB_NAMES &lt;chr&gt;, …\n\n\nOne issue you might face is that higher taxonomy from different providers may not match. If this is the case, we suggest choosing the data provider with the higher taxonomy that is consistent with your naming authority and use it to back fill the higher taxonomy of the other data sources\n\nhigher_taxonomy &lt;- inverts %&gt;%\n  select(scientificName) %&gt;% \n  distinct() %&gt;% \n  search_taxa()\n\nhigher_taxonomy\n\n# A tibble: 36 × 15\n   search_term     scientific_name scientific_name_auth…¹ taxon_concept_id rank \n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;\n 1 Palirhoeus eat… Palirhoeus eat… (C.O. Waterhouse, 187… https://biodive… spec…\n 2 Lasaea austral… Lasaea austral… (Lamarck, 1818)        https://biodive… spec…\n 3 Turbonilla tia… Turbonilla tia… May, 1911              https://biodive… spec…\n 4 Tucetona flabe… Tucetona flabe… (Tenison-Woods, 1878)  https://biodive… spec…\n 5 Achelia transf… Achelia transf… Stock, 1973            https://biodive… spec…\n 6 Coralliophila … Coralliophila … Kosuge, 1986           https://biodive… spec…\n 7 Amphitethya st… Amphitethya st… (Carter, 1886)         https://biodive… spec…\n 8 Australocyther… Australocyther… McKenzie, 1967         https://biodive… spec…\n 9 Plesiopenaeus … Plesiopenaeus … (Spence Bate, 1881)    https://biodive… spec…\n10 Chlorodiloma c… Chlorodiloma c… (Philippi, 1849)       https://biodive… spec…\n# ℹ 26 more rows\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 10 more variables: match_type &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;,\n#   class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   issues &lt;chr&gt;, vernacular_name &lt;chr&gt;\n\n\nRemember to always check your changes after!"
  },
  {
    "objectID": "taxonomy-2.html#extended-taxonomic-cleaning",
    "href": "taxonomy-2.html#extended-taxonomic-cleaning",
    "title": "6  Taxonomy II",
    "section": "6.2 Extended taxonomic cleaning",
    "text": "6.2 Extended taxonomic cleaning\nDepending on your project’s data scope, it may be necessary to remove certain groups of taxa. Below, we have provided a few examples. We will also briefly showcase CoordinateCleaner a useful R package for removing XX records.\n\n6.2.1 Introduced or Invasive species\nRemove non-native species: This step is a common requirement. A list can be obtained from the Global Register of Introduced and Invasive Species (GRIIS). The downloads are sorted my country. Once this list is read into R, you can proceed to exclude invasive species from your data as below:\n\nlibrary(tidyverse)\nlibrary(here)\n\ngriis_ls <- read_csv(here(\"data/lists/GRIIS_Australia_20230331-121730.csv\"))\n\nglimpse(griis_ls)\n\nRows: 2,979\nColumns: 16\n$ scientific_name                  <chr> \"Oenothera longiflora L.\", \"Lampranth…\n$ scientific_name_type             <chr> \"species\", \"species\", \"species\", \"spe…\n$ kingdom                          <chr> \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ establishment_means              <chr> \"alien\", \"alien\", \"alien\", \"alien\", \"…\n$ is_invasive                      <chr> \"null\", \"null\", \"null\", \"null\", \"null…\n$ occurrence_status                <chr> \"present\", \"present\", \"present\", \"pre…\n$ checklist.name                   <chr> \"Australia\", \"Australia\", \"Australia\"…\n$ checklist.iso_countrycode_alpha3 <chr> \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"A…\n$ accepted_name.species            <chr> \"Oenothera longiflora\", \"Lampranthus …\n$ accepted_name.kingdom            <chr> \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ accepted_name.phylum             <chr> \"Tracheophyta\", \"Tracheophyta\", \"Trac…\n$ accepted_name.class              <chr> \"Magnoliopsida\", \"Magnoliopsida\", \"Ma…\n$ accepted_name.order              <chr> \"Myrtales\", \"Caryophyllales\", \"Erical…\n$ accepted_name.family             <chr> \"Onagraceae\", \"Aizoaceae\", \"Ericaceae…\n$ accepted_name.habitat            <chr> \"[\\\"terrestrial\\\"]\", \"[\\\"terrestrial\\…\n$ accepted_name                    <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n# Note which species matched with GRIIS list\nmatches <- plants |> filter(scientific_name %in% griis_ls$accepted_name.species)\nmatches\n\n# A tibble: 2 × 13\n  record_id    scientific_name vernacular_name kingdom phylum class order family\n  <chr>        <chr>           <chr>           <chr>   <chr>  <chr> <chr> <chr> \n1 94df1223-4c… Lysimachia jap… Creeping Loose… Plantae Trach… Magn… Eric… Primu…\n2 8055e15e-36… Lysimachia jap… Creeping Loose… Plantae Trach… Magn… Eric… Primu…\n# ℹ 5 more variables: genus <chr>, species <chr>, subspecies <chr>,\n#   latitude <dbl>, longitude <dbl>\n\n# Exclude GRIIS matches\nplants_no_griis <- plants |> filter(! scientific_name %in% matches)\n\n\n\n6.2.2 Extinct species\nIn most cases, a year filter during in your download query should remove most extinct species.\nYou want to cross check for extinct species using the Interim Register of Marine and Nonmarine Genera (IRMNG). The list is comprehensive and actively maintained, the only caveat is that a lot of its data doesn’t go down to species level. As such, we recommend using the following approach to find potentially extinct taxa and further investigate the records that we are flagged.\nThe required files are organised by year and can be downloaded from here. Once you have unzipped the file in your projected directory, we need to process the list a littlerbefore we use it to exclude extinct species.\n\nlibrary(data.table)\nlibrary(janitor)\n\n# Taxonomic info\nirmng_taxa <- fread(\"data/lists/IRMNG_genera_DwCA_2023-05-19/taxon.txt\", na.strings = c(\"\"), quote=\"\")\n\n# Species profile\nirmng_sp <- fread(\"data/lists/IRMNG_genera_DwCA_2023-05-19/speciesprofile.txt\", na.strings = c(\"\"), quote=\"\")\n\n\n# Precleaning \nawc_pattern <- \"(awaiting allocation)\"\ninsed_pattern <- \"incertae sedis\"\n\ncleaned_irmng_taxa <- irmng_taxa |> \n  mutate(class = ifelse(str_detect(class, pattern = paste0(awc_pattern,\"|\", insed_pattern)),\n                        word(class), class) # Remove pesky values\n         ) |> \n  filter(taxonomicStatus == \"accepted\") |> # Filter to accepted names \n  filter(kingdom %in% c(\"Animalia\", \"Plantae\"),\n         ! kingdom == \"Questionable / non-biota (fossil)\") # Filter to Animal and plants - change if working with other kingdoms\n\n# Join with species profile, remove pesky values and filter to extinct taxa \nextinct_irmng <- irmng_taxa |> \n  left_join(irmng_sp, by = \"taxonID\") |> \n  filter(! scientificName == \"Questionable / non-biota (fossil)\") |> \n  filter(isExtinct == TRUE) \n\n# Summary of extinct species by taxonRank\nextinct_irmng$taxonRank |> tabyl()\n\n extinct_irmng$taxonRank     n      percent\n                   Class    14 5.926177e-04\n                  Family  1675 7.090247e-02\n                   Genus 21718 9.193193e-01\n              Infraclass     1 4.232983e-05\n                   Order   210 8.889265e-03\n                  Phylum     4 1.693193e-04\n                Subclass     2 8.465967e-05\n\n# Create genus \ninverts <- inverts |> \n  mutate(genus = word(scientificName, 1)) \n\n# Extract unique extinct genus and remove genus that have punctuation in them\nextinct_genus <- extinct_irmng |> \n  drop_na(genus) |> \n  filter(!str_detect(genus, pattern = regex(\"[:punct:]\"))) |> \n  pull(genus) |> \n  unique() \n \n# Check if there are any matches at genus level\ncheck <- inverts |> \nfilter(str_detect(genus, pattern = regex(paste0(extinct_genus, collapse=\"|\")))) |> \n  pull(scientificName) |> \n  unique() \n\ncheck\n\n[1] \"Halobates (Halobates) acherontis\"\n\n\nAlternatively, you can use the IUCN to retrieve a list of extinct species that are in their database\nhttps://apiv3.iucnredlist.org/api/v3/docs#species-category https://docs.ropensci.org/crul/articles/crul.html\n\nlibrary(rredlist)\nlibrary(skimr)\n\n# Create IUCN token\nrredlist::rl_use_iucn() # Application can take a day or two!\nusethis::edit_r_environ() # Place the approved token in your R environment\n\nextinct_iucn <- rl_sp_category('EX')\nskim(extinct_iucn)\n\nextinct_sp <- extinct_iucn$result |> tibble() # Note these are extinct species across the globe\n\n# Find matches\ninverts |> filter(scientificName %in% extinct_sp$scientific_name) # No matches\n\n\n\n6.2.3 Certain lifestges\n\nlibrary(galah)\nlibrary(skimr)\n\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"),\n             atlas = \"Australia\")\n\nbilby <- galah_call() |> \n  galah_identify(\"Macrotis lagotis\") |> \n  galah_filter(year == 2022) |> \n  galah_select(group = \"basic\", sex, lifeStage, reproductiveCondition) |> \n  atlas_occurrences()\n\nbilby |> filter(!sex == \"MALE\")\n\n\n\n# A tibble: 35 × 11\n   decimalLatitude decimalLongitude eventDate           scientificName  \n             <dbl>            <dbl> <dttm>              <chr>           \n 1           -34.2             143. 2022-06-16 14:00:00 Macrotis lagotis\n 2           -34.2             143. 2022-06-14 14:00:00 Macrotis lagotis\n 3           -34.2             143. 2022-03-22 13:00:00 Macrotis lagotis\n 4           -34.2             143. 2022-03-22 13:00:00 Macrotis lagotis\n 5           -34.2             143. 2022-03-22 13:00:00 Macrotis lagotis\n 6           -34.2             143. 2022-03-23 13:00:00 Macrotis lagotis\n 7           -34.2             143. 2022-03-21 13:00:00 Macrotis lagotis\n 8           -34.2             143. 2022-06-12 14:00:00 Macrotis lagotis\n 9           -34.2             143. 2022-03-23 13:00:00 Macrotis lagotis\n10           -34.2             143. 2022-06-12 14:00:00 Macrotis lagotis\n# ℹ 25 more rows\n# ℹ 7 more variables: taxonConceptID <chr>, recordID <chr>,\n#   dataResourceName <chr>, occurrenceStatus <chr>, sex <chr>, lifeStage <lgl>,\n#   reproductiveCondition <chr>\n\n\n\n\n6.2.4 Marine species\nRemove specific taxa/ depending on the study: For example, if working with terrestrial data, it is necessary to remove marine taxa.\n\nlibrary(worrms)\n\n# Obtain species list\nmy_species <- inverts |> \n  pull(scientificName) |>\n  unique()\n\n# Query WoRMs\nmarine_check <- map_dfr(my_species,\n       possibly(~worrms::wm_records_name(name = .x) |> mutate(search_term = .x))\n)\n\n# Filter species that are TRUE for isMarine\nmarine_inverts <- marine_check |> \n  filter(isMarine == TRUE) |> \n  select(search_term)\n\n# Exclude marine invertebrates\ninverts |> filter(!scientificName %in% marine_inverts)\n\n# A tibble: 2,637 × 9\n   decimalLatitude decimalLongitude eventDate           scientificName   \n             <dbl>            <dbl> <dttm>              <chr>            \n 1           -46.9             37.8 1983-04-01 00:00:00 Palirhoeus eatoni\n 2           -46.9             37.8 1984-09-01 00:00:00 Palirhoeus eatoni\n 3           -46.9             37.9 1986-04-01 00:00:00 Palirhoeus eatoni\n 4           -46.6             38.0 1985-04-01 00:00:00 Palirhoeus eatoni\n 5           -46.6             38.0 1983-05-01 00:00:00 Palirhoeus eatoni\n 6           -46.6             38.0 1984-09-01 00:00:00 Palirhoeus eatoni\n 7           -46.6             38.0 1984-04-01 00:00:00 Palirhoeus eatoni\n 8           -43.6            148.  NA                  Lasaea australis \n 9           -43.6            147.  2008-12-28 00:00:00 Lasaea australis \n10           -43.6            147.  2008-12-28 00:00:00 Lasaea australis \n# ℹ 2,627 more rows\n# ℹ 5 more variables: taxonConceptID <chr>, recordID <chr>,\n#   dataResourceName <chr>, occurrenceStatus <chr>, genus <chr>\n\n\n\n\n\n\nRibeiro, Bruno R., Santiago José Elías Velazco, Karlo Guidoni-Martins, Geiziane Tessarolo, Lucas Jardim, Steven P. Bachman, and Rafael Loyola. 2022. “Bdc: A Toolkit for Standardizing, Integrating and Cleaning Biodiversity Data.” Methods in Ecology and Evolution 13 (7): 1421–28. https://doi.org/10.1111/2041-210X.13868."
  },
  {
    "objectID": "spatial.html#coordinate-precision",
    "href": "spatial.html#coordinate-precision",
    "title": "7  Spatial data",
    "section": "7.1 Coordinate precision",
    "text": "7.1 Coordinate precision\nCoordinate precision describes the consistency of values if one were to record the coordinates of the same location, multiple times. Coordinate precision can vary between data sources and recording equipment. For example, coordinates recorded with a GPS unit or a phone generally has higher precision compared to those manually determined from locality descriptions.\nCoordinate precision below 100km represents the grain size of many macroecological analyses (Zizka et al. 2020).  Some studies have used a cut-off of spatial resolution >25,000m or precision with less than three decimal places (Godfree et al. 2021). Rasterised collections often have a significant proportion of records that might have low coordinate precision.\nDepending on the scope of your research question, you may need to limit your occurrence data to a certain level of coordinate.\nWe recommend first including coordinatePrecision in your download query and excluding its completeness and range before you exclude any data.\n\nlibrary(galah)\nlibrary(skimr)\n\nbanksia_serrata <- galah_call() |> \n  galah_identify(\"banksia_serrata\") |> \n  galah_filter(year > 2022) |>  \n  galah_select(group = \"basic\", coordinatePrecision) |> \n  atlas_occurrences()\n\n# banksia_serrata |> \n#   select(coordinatePrecision) |> \n#   skim()\n\n# Filter by number of decimal places\n# banksia_serrata |> \n#   filter(coordinatePrecision < XXX)"
  },
  {
    "objectID": "spatial.html#coordinate-uncertainty",
    "href": "spatial.html#coordinate-uncertainty",
    "title": "7  Spatial data",
    "section": "7.2 Coordinate Uncertainty",
    "text": "7.2 Coordinate Uncertainty\nAlternatively, you can refine your data using coordinate uncertainty which describes the possible circular area in meters where the true location is in.\n\nbanksia_serrata <- galah_call() |> \n  galah_identify(\"banksia_serrata\") |> \n  galah_filter(year > 2022) |>  \n  galah_select(group = \"basic\", coordinatePrecision, coordinateUncertaintyInMeters) |> \n  atlas_occurrences()\n\n# Filter by number of decimal places\n# banksia_serrata |> \n#   filter(coordinateUncertaintyInMeters < XXX) \n\n\n7.2.1 Missing coordinate data\nIf your research question requires spatial information, then it may be useful to exclude records that are missing coordinates data. Many spatial analytical tools are not compatible with missing coordinate data. We recommend tallying and identifying the rows that have missing data before excluding.\nYou can use drop_na() to remove missing values from your dataset.\n\nlibrary(dplyr)\n\n# Identify missing data in coordinates\nbanksia_serrata |> \n  filter(is.na(decimalLatitude) | is.na (decimalLongitude))\n\n# Excluding them\nbanksia_serrata |> \n  drop_na(decimalLatitude, decimalLongitude)"
  },
  {
    "objectID": "spatial.html#coordinate-correction",
    "href": "spatial.html#coordinate-correction",
    "title": "7  Spatial data",
    "section": "7.3 Coordinate correction",
    "text": "7.3 Coordinate correction\nSome of these steps may have been completed in a pre-cleaning step, however it’s now time to be more rigorous. As always we’ll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:\nFlipped coordinates: Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected. (Jin and Yang 2020)\n\n#example map of some flipped coordinates (what to look for) \n# https://www.gbif.org/occurrence/3013406216 this has flipped coordinates, which GBIF has corrected\n# https://www.gbif.org/occurrence/search?q=mammalia&continent=SOUTH_AMERICA&has_coordinate=true&has_geospatial_issue=false&issue=PRESUMED_SWAPPED_COORDINATE&advanced=1. ## the issue and flag is called 'presumed swapped coordinate' \n\nNumerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.\n\n#example map, like coordinates off the coast of japan\n\n# https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51360942&qualityProfile=CSDM&radius=50&lat=35.66845370835343&lon=138.9990234375#tab_recordsView\n\n# eucs <- galah_call() %>% \n#  galah_identify(\"Eucalyptus\") %>%\n#  galah_filter( year == 2005, \n#             dataResourceName == \"The University of Melbourne Herbarium (MELU) AVH data\") %>%\n#  atlas_occurrences()\n\nCountry field doesn’t match coordinates: The coordinates could be wrong or just the country listed.\n\n## this doesnt seem to be very common- atleast not in ALA data- because there is no neighboring country\n# https://biocache.ala.org.au/occurrences/a34fca43-9e7c-4b37-8fe4-07cc18369465 Australian coordinates, country listed as Trinidad and Tobago\n# https://www.gbif.org/occurrence/search?advanced=true&continent=SOUTH_AMERICA&geometry=POLYGON((-78.74961%20-8.25249,-76.29838%20-8.25249,-76.29838%20-4.74121,-78.74961%20-4.74121,-78.74961%20-8.25249))&has_coordinate=true&issue=COUNTRY_MISMATCH&locale=en&q=reptilia   # GBIF example- reptiles located in Peru, originally recorded as Ecuador\n\n\n7.3.1 Quick visualisation\nOne of the most straightforward ways to check for spatial errors is to plot your data onto a map. More obvious spatial errors are much easier to spot visually.\n\n\nlibrary(ggplot2)\nlibrary(ozmaps) \nlibrary(sf)\n\n# Retrieve map of Australia\naus <- st_transform(ozmap_country, 4326)\n\n# Remove missing coordinates in Banksia data\n# Then transform into 'sf' object\nbanksia_sf <- banksia_serrata |> \n  drop_na(starts_with(\"decimal\")) |> \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326)\n\n# A quick plot\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) + \n  geom_sf(data = banksia_sf)"
  },
  {
    "objectID": "spatial.html#coordinate-cleaning",
    "href": "spatial.html#coordinate-cleaning",
    "title": "7  Spatial data",
    "section": "7.4 Coordinate cleaning",
    "text": "7.4 Coordinate cleaning\nOnce you have fixed everything you can, it’s time to remove records that still have errors. This doesn’t mean removing all outliers, you must have more than “it’s far away from the others” to justify a records removal.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, check first, however likely will need to remove\nRemove records with zero coordinates: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\n\n#zero coordinates acacia \n\n#https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51382879&disableAllQualityFilters=true&qualityProfile=ALA&fq=spatiallyValid%3A%22false%22&radius=25&lat=-0.024032592068740033&lon=-0.06591796875#tab_recordsView"
  },
  {
    "objectID": "spatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "href": "spatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "title": "7  Spatial data",
    "section": "7.5 Remove records plotted away from the known area of distribution of the species.",
    "text": "7.5 Remove records plotted away from the known area of distribution of the species.\nIt is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it’s worth checking the literature before discarding records like these. These can also be mis-identified species, if you’re working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.\n\n\n\n\n\n\n\n7.5.1 Remove records with coordinates assigned to country and province centroids\nCentroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or grown in horticulture, which were not clearly labelled as such.\n\n\n7.5.2 Remove records from biological institutions\nsuch as botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and GBIF headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.\nIn a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\n\n\n7.5.3 CoordinateCleaner\n\n\n\n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 20192020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio Baez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus Colli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais Ferreira-Araújo. 2020. “No One-Size-Fits-All Solution to Clean GBIF.” PeerJ 8: e9916."
  },
  {
    "objectID": "outliers.html",
    "href": "outliers.html",
    "title": "8  Outliers",
    "section": "",
    "text": "An outlier is a point located at a significant distance from the majority of the species’ distribution or available data points. Outliers can be true outliers or data errors. Data errors can be caused by a variety of factors including mis-identified specimens or incorrect georeferencing. In the absence of a data error however, these outliers are considered to be a true point, and are not necessary to remove.\nOpen source data issues.\n“The Atlas of Living Australia is a data aggregator, we collate data from our providers making them available to our users. The ALA does not own the data we display. The data we receive come in different forms and of different qualities, bringing many challenges. Data errors can occur in multiple places from data collection through the ingestion process. Understanding that not all errors are the same can help users work with the data they receive from us.”\n“Conversely, others conclude that in a large majority of cases, high quantity, low quality data produce similar results to that of lower quantity, high quality data (Aceves-Bueno et al., 2017). Poor quality data have also been used to cost-effectively estimate risk levels for data deficient species using a double sampling methodology (see Bland et al., 2015). However, to date, the general consensus within the conservation community favors the use of high quality data (Cayuela et al., 2009; Wood, Sullivan, Lliff, Fink, & Kelling, 2011)”\nWith broad data accumulation data quality can be impacted. In response GBIF flags potential errors through its data validator (https://www.gbif.org/tools/data-validator). This is an automated process providing information on geographic discrepancies (e.g., whether coordinates fall within a stated country), meta-data structure and formatting issues, and suggests how the user may improve the quality of the data and associated meta-data before use.\nIncorrectly identified specimens can be difficult to identify with open source biodiversity data. Often these will be picked up by 1: an image of the species in question which does not match 2: If you notice a species outside of its geographic range, this could be a true outlier, it could be a spatial error, or it could be a different species. (see — for more info)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "9  References",
    "section": "",
    "text": "Führding-Potschkat, Petra, Holger Kreft, and Stefanie M. Ickert-Bond.\n2022. “Influence of Different Data Cleaning Solutions of\nPoint-Occurrence Records on Downstream Macroecological Diversity\nModels.” Ecology and Evolution 12 (8): e9168. https://doi.org/10.1002/ece3.9168.\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi,\nand Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys\nSpecies (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of\nFresh Water Habitats by Macrodasyids.” Scientific\nReports 9 (1): 2067.\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David\nAlbrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021a.\n“Implications of the 20192020 Megafires for the\nBiogeography and Conservation of Australian Vegetation.”\nNature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\n———, et al. 2021b. “Implications of the 2019–2020 Megafires for\nthe Biogeography and Conservation of Australian\nVegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nGueta, Tomer, and Yohay Carmel. 2016. “Quantifying the Value of\nUser-Level Data Cleaning for Big Data: A Case Study Using\nMammal Distribution Models.” Ecological Informatics 34\n(July): 139–45. https://doi.org/10.1016/j.ecoinf.2016.06.001.\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning\nTaxonomic and Geographic Errors in Occurrence Data Archived in\nBiodiversity Databases.” Global Ecology and Conservation\n21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville,\nLibby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts\nof the 2019-20 Wildfires of Southern and Eastern Australia on\nInvertebrate Species Final Report.”\n\n\nMarsh, Jessica R., Payal Bal, Hannah Fraser, Kate Umbers, Tanya Latty,\nAaron Greenville, Libby Rumpff, and John C. Z. Woinarski. 2022.\n“Accounting for the Neglected: Invertebrate Species\nand the 2019–2020 Australian Megafires.” Global\nEcology and Biogeography n/a (n/a). https://doi.org/10.1111/geb.13550.\n\n\nRibeiro, Bruno R., Santiago José Elías Velazco, Karlo Guidoni-Martins,\nGeiziane Tessarolo, Lucas Jardim, Steven P. Bachman, and Rafael Loyola.\n2022. “Bdc: A Toolkit for Standardizing, Integrating\nand Cleaning Biodiversity Data.” Methods in Ecology and\nEvolution 13 (7): 1421–28. https://doi.org/10.1111/2041-210X.13868.\n\n\nRodrigues, Arthur Vinicius, Gabriel Nakamura, Vanessa Graziele\nStaggemeier, and Leandro Duarte. 2022. “Species Misidentification\nAffects Biodiversity Metrics: Dealing with This Issue Using\nthe New R Package naturaList.” Ecological\nInformatics 69 (July): 101625. https://doi.org/10.1016/j.ecoinf.2022.101625.\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset:\nExpert-Validated Occurrence Records of Australia’s Frogs Collected by\nCitizen Scientists.” ZooKeys 912: 139.\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and\nLimitations of Climate-Matching Approaches in Detecting Different Types\nof Spatial Errors in Biodiversity Data.” Insect Conservation\nand Diversity 11 (5): 407–14.\n\n\nstreamdna. 2020. “Sharing Is Caring:\nWorking with Other People’s\nData.” https://methodsblog.com/2020/09/04/sharing-is-caring-working-with-other-peoples-data/.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio\nBaez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus\nColli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais\nFerreira-Araújo. 2020b. “No One-Size-Fits-All Solution to Clean\nGBIF.” PeerJ 8: e9916.\n\n\n———. 2020a. “No One-Size-Fits-All Solution to Clean GBIF.”\nPeerJ 8: e9916."
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "10  Appendix",
    "section": "",
    "text": "We don’t claim to be experts in data cleaning, therefore in order to ensure content for this book was current and relevant we undertook an informal literature review of both peer reviewed and grey literature. Key themes searched were:\n\nCleaning data for species distribution models\nCleaning open biodiversity data\nAustralian and global naming authorities\nR packages for biodiversity data cleaning\n\nAs this was not a comprehensive literature review recent papers were selected first as the R environment is a rapidly evolving space. Methods sections outlining data cleaning protocols were read and collated into a database. Papers which were frequently referenced were also chosen for review in order to not miss older seminal papers. Additionally our project partners outputs (Marsh et al. 2021; Godfree et al. 2021) have been investigated in detail to understand and streamline their data cleaning processes. This has included detailed review of their code base as well as meetings with the authors of the papers to understand their processes, issues and needs.\nAll steps for acquiring and cleaning data were then looked at together in order to understand what were essential steps, versus what was done in certain use cases. We also investigated the order in which steps were undertaken with the idea of developing a streamlined workflow. However the diagrams below show the complexity of this, with data cleaning being extremely iterative.\n \n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville, Libby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts of the 2019-20 Wildfires of Southern and Eastern Australia on Invertebrate Species Final Report.”"
  },
  {
    "objectID": "scope.html",
    "href": "scope.html",
    "title": "Data scope",
    "section": "",
    "text": "Data scope refers to the type and extent of data needed for your project. Defining your scope is an essential part of forming a research question, ultimately impacting what data you will use in your project. Availability of data may therefore influence your scope and research question.\nFor example, you might have a question about several species in the same area. However, data for one or more of those species could be limited because observations are rare, surveying the area where it lives is difficult, or only several historical records exist.\nWithout narrowing your data scope, you might find yourself downloading more data than you need, which can needlessly increase how much time is spent processing data prior to analyses. Alternatively, you might find there isn’t enough data to answer your question.\nWhile there are workable methods to analyse small sets of biodiversity data (e.g. hulls), it’s worth thinking critically about whether the amount of data available will allow you to sufficiently answer your research question.\nTo start, some initial questions you might ask are:\nQuestions like these will help you define what data is most relevant for your research question, and help you begin to think about how much evidence available, and the trade-offs you might make between the specificity of your question and the certainty of your answer."
  },
  {
    "objectID": "preclean.html",
    "href": "preclean.html",
    "title": "4  Pre-cleaning",
    "section": "",
    "text": "Pre-cleaning prepares the dataset(s) in a general manner to ensure logical and consistent formatting. It is a ‘broad sweep’ procedure that allows you to familiarise with the data, but it also makes the next stage of in-depth data cleaning proceed more smoothly (streamdna 2020). We will discuss some approaches on how to be curious with your data and how to detect and handle string inconsistencies or typography related errors, missing data, and outliers."
  },
  {
    "objectID": "taxonomy.html",
    "href": "taxonomy.html",
    "title": "5  Taxonomy",
    "section": "",
    "text": "Advances in taxonomy, especially in molecular biology has allowed researchers to describe new species more efficiently than ever before (Garraffoni et al. 2019). Modern approaches has also enabled reclassification of organisms that have been incorrectly described in the past. Unfortunately, multiple names (synonyms) for the same organism can arise when taxonomy is not unanimously agreed upon by researchers.\nHarmonising taxonomic names is a prevalent and complex issue and so far, no unifying solution has been put forward — making research with biodiversity data challenging. A potential solution would require pulling together domain knowledge from experts and compiling a database for where taxonomic history for describe species is traceable and linked with published literature.\nWhile there is no perfect solution, some tips, tricks and tools do exist. In this chapter we will go through some of these to clean taxonomic data and deal with synonyms."
  },
  {
    "objectID": "taxonomy-2.html",
    "href": "taxonomy-2.html",
    "title": "6  Taxonomy II",
    "section": "",
    "text": "If you have downloaded data from different sources, you likely will need to collate your data into a singular database. It is important to make sure fields that have the same, are indeed the same variable, so prior to merging - take the time cross check the meta-data from different data providers (Ribeiro et al. 2022).\n\n\nData providers will have their own naming conventions for variables. For example, World Register of Marine Species uses a combination of lower case e.g scientific_name and camel case e.g isExtinct. While the naming authority - Australian Fauna Directory (AFD) uses upper, snake case e.g. SCIENTIFIC_NAME. What format you choose is a matter of personal preference, the key is to be consistent.\nHere we will subset the variables we want, reformat them to the lower snake case names and then join by VALID_NAME\n\nlibrary(stringr)\n\nhabitat_data <- worms %>% \n  select(valid_name, starts_with(\"is\")) \n\nnames(habitat_data)[-1] \n\n[1] \"isMarine\"      \"isBrackish\"    \"isFreshwater\"  \"isTerrestrial\"\n[5] \"isExtinct\"    \n\nnew_names <- str_split(names(habitat_data)[-1], pattern =  \"(?<=[a-z])(?=[A-Z])\", n = 2) %>%  # Seperate where case cases from lower to upper i.e. camel case\n  map(.x = ., \n      .f = ~tolower(.x)) %>% # Convert to all lower case\n    map(.x = ., \n      .f = ~str_flatten(.x, \"_\")) %>%  # Bind the two seperated elements\n  unlist()\n  \nnew_names\n\n[1] \"is_marine\"      \"is_brackish\"    \"is_freshwater\"  \"is_terrestrial\"\n[5] \"is_extinct\"    \n\n# Replace old with new\nnames(habitat_data)[-1] <- new_names\n\n# Join habitat data by VALID_NAME\nafd %>% left_join(habitat_data, by = join_by(VALID_NAME == valid_name))\n\n# A tibble: 49 × 37\n   GROUP_NAME HIGHER_CLASSIFICATION    KINGDOM PHYLUM SUBPHYLUM SUPERCLASS CLASS\n   <chr>      <chr>                    <chr>   <chr>  <chr>     <lgl>      <chr>\n 1 ANNELIDA   Phylum ANNELIDA, Class … ANIMAL… ANNEL… <NA>      NA         POLY…\n 2 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MAXI…\n 3 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 4 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… HEXAPODA  NA         INSE…\n 5 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 6 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… HEXAPODA  NA         INSE…\n 7 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 8 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 9 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n10 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         OSTR…\n# ℹ 39 more rows\n# ℹ 30 more variables: SUBCLASS <chr>, SUPERORDER <chr>, ORDER <chr>,\n#   SUBORDER <chr>, SUPERFAMILY <chr>, FAMILY <chr>, SUBFAMILY <chr>,\n#   SUPERTRIBE <lgl>, TRIBE <chr>, SUBTRIBE <lgl>, GENUS <chr>,\n#   SUB_GENUS <chr>, SPECIES <chr>, SUB_SPECIES <chr>, AUTHOR <chr>,\n#   YEAR <dbl>, CHANGED_COMBINATION <chr>, VALID_NAME <chr>,\n#   COMPLETE_NAME <chr>, SYNONYMS <chr>, CHANGED_COMB_NAMES <chr>, …\n\n\nOne issue you might face is that higher taxonomy from different providers may not match. If this is the case, we suggest choosing the data provider with the higher taxonomy that is consistent with your naming authority and use it to back fill the higher taxonomy of the other data sources\n\nhigher_taxonomy <- inverts %>%\n  select(scientificName) %>% \n  distinct() %>% \n  search_taxa()\n\nhigher_taxonomy\n\n# A tibble: 36 × 15\n   search_term     scientific_name scientific_name_auth…¹ taxon_concept_id rank \n   <chr>           <chr>           <chr>                  <chr>            <chr>\n 1 Palirhoeus eat… Palirhoeus eat… (C.O. Waterhouse, 187… https://biodive… spec…\n 2 Lasaea austral… Lasaea austral… (Lamarck, 1818)        https://biodive… spec…\n 3 Turbonilla tia… Turbonilla tia… May, 1911              https://biodive… spec…\n 4 Tucetona flabe… Tucetona flabe… (Tenison-Woods, 1878)  https://biodive… spec…\n 5 Achelia transf… Achelia transf… Stock, 1973            https://biodive… spec…\n 6 Coralliophila … Coralliophila … Kosuge, 1986           https://biodive… spec…\n 7 Amphitethya st… Amphitethya st… (Carter, 1886)         https://biodive… spec…\n 8 Australocyther… Australocyther… McKenzie, 1967         https://biodive… spec…\n 9 Plesiopenaeus … Plesiopenaeus … (Spence Bate, 1881)    https://biodive… spec…\n10 Chlorodiloma c… Chlorodiloma c… (Philippi, 1849)       https://biodive… spec…\n# ℹ 26 more rows\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 10 more variables: match_type <chr>, kingdom <chr>, phylum <chr>,\n#   class <chr>, order <chr>, family <chr>, genus <chr>, species <chr>,\n#   issues <chr>, vernacular_name <chr>\n\n\nRemember to always check your changes after!"
  },
  {
    "objectID": "spatial.html",
    "href": "spatial.html",
    "title": "7  Spatial data",
    "section": "",
    "text": "library(galah)\n\nbanksia_serrata <- galah_call() |> \n  galah_identify(\"banksia_serrata\") |> \n  galah_filter(year > 2022) |>  \n  atlas_occurrences()\nYou’ve been through the taxonomic cleaning steps so now it’s time to clean up the spatial elements. You may have flagged records as being taxonomically incorrect, it’s important to keep those in mind as you go through the spatial cleaning steps as you might learn more about those records. We will discuss some different ways to check for spatial outliers as well as the removal of records in certain geographic areas known to be problematic."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Data from different sources vary widely in their structure, formatting and quality. As a result, collating and combining them into something usable to answer a research question can be both challenging and time consuming.\nThe idea that inputting flawed or nonsensical data produces an output of similar quality is well known in many scientific disciplines. In ecology and biodiversity research, however, scientists are particularly at risk of unintentionally using poor data because they often bring together lots of data from many sources to address their research questions.\nData cleaning, the process of identifying and fixing incompatible, incorrect or doubtful data, is an essential step in ecology and biodiversity research. Data cleaning improves data quality and the validity of scientific findings (Rodrigues et al., 2022).\n\n\n\n\nRodrigues, A. V., Nakamura, G., Staggemeier, V. G., & Duarte, L. (2022). Species misidentification affects biodiversity metrics: Dealing with this issue using the new R package naturaList. Ecological Informatics, 69, 101625. https://doi.org/10.1016/j.ecoinf.2022.101625"
  },
  {
    "objectID": "outliers.html#alternative-methods",
    "href": "outliers.html#alternative-methods",
    "title": "8  Outliers",
    "section": "8.1 Alternative methods",
    "text": "8.1 Alternative methods\nHere we document some other existing methods that can be used for outlier detection, and their limitations.\n\nSpecies Distribution Modelling for outlier detection:\n\nSimões and Peterson (2018)\nMaxiomum Entropy modelling (MaxEnt) was used to model habitat suitability for five species of leaf beetles in the genus Mesomphalia\nThe method relies on the assumption that an errornous point will have a lower habitat suitability value than a true point.\nFor their dataset, the method was useful for identifying geographical position errors, but not species level identification errors.\n\n\n\n\n\n\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and Limitations of Climate-Matching Approaches in Detecting Different Types of Spatial Errors in Biodiversity Data.” Insect Conservation and Diversity 11 (5): 407–14."
  },
  {
    "objectID": "scope.html#an-example-workflow",
    "href": "scope.html#an-example-workflow",
    "title": "Data scope",
    "section": "An example workflow",
    "text": "An example workflow\nAs an example, let’s imagine we were interested in understanding more about the distribution of several Jewel beetles in the genus Lampromicra. Let’s see some ways we might investigate what data are available about them in Australia.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nCurious what a Jewel beetle looks like? Here is a Lampromicra senator perched on a leaf by Matthew Connors CC-BY-NC 4.0 (Int)"
  },
  {
    "objectID": "scope.html#an-example-investigation",
    "href": "scope.html#an-example-investigation",
    "title": "Data scope",
    "section": "An example investigation",
    "text": "An example investigation\nAs an example, let’s imagine we were interested in understanding more about the distribution of several Jewel beetles in the genus Lampromicra. Let’s see some ways we might investigate what data are available about them in Australia.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nCurious what a Jewel beetle looks like? Here is a Lampromicra senator perched on a leaf by Matthew Connors CC-BY-NC 4.0 (Int)"
  },
  {
    "objectID": "scope.html#example-workflow",
    "href": "scope.html#example-workflow",
    "title": "Data scope",
    "section": "Example workflow",
    "text": "Example workflow\nAs an example, let’s imagine we were interested in understanding more about the distribution of several Jewel beetles in the genus Lampromicra. Let’s see some ways we might investigate what data are available about them in Australia.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nCurious what a Jewel beetle looks like? Here is a Lampromicra senator perched on a leaf by Matthew Connors CC-BY-NC 4.0 (Int)"
  },
  {
    "objectID": "scope.html#demonstration",
    "href": "scope.html#demonstration",
    "title": "Data scope",
    "section": "Demonstration",
    "text": "Demonstration\nAs an example, let’s imagine we were interested in understanding more about the distribution of several Jewel beetles in the genus Lampromicra. Let’s see some ways we might investigate what data are available about them in Australia.\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nCurious what a Jewel beetle looks like? Here is a Lampromicra senator perched on a leaf by Matthew Connors CC-BY-NC 4.0 (Int)"
  },
  {
    "objectID": "scope_temporal.html",
    "href": "scope_temporal.html",
    "title": "1  Temporal scope",
    "section": "",
    "text": "{r} library(galah)\n```{r} #| warning: false #| message: false library(galah)\natlas_counts() ```\nNow let’s check how many total insect records there are.\n{r} galah_call() |> galah_identify(\"insecta\") |> atlas_counts()\nNow let’s see how many insects have been observed each year over the last 10 years. We’ll order this by descending year using dplyr::arrange() and dplyr::desc().\n```{r} #| warning: false #| message: false library(dplyr)\ngalah_call() |> galah_identify(“insecta”) |> galah_filter(year >= 2013) |> galah_group_by(year) |> atlas_counts() |> dplyr::arrange(dplyr::desc(year)) ```\nNow that we have an idea of the total amount of data in the Atlas of Living Australia, let’s try checking how many observations exist of the genus Lampromicra. We’ll first make sure the scientific name Lampromicra returns the taxon information we expect with search_taxa().\n{r} search_taxa(\"Lampromicra\")\nThis looks correct! Next let’s see how many total observations there are of Lampromicra and how many observations there were in each of the last 10 years.\n```{r} galah_call() |> galah_identify(“Lampromicra”) |> atlas_counts()\ngalah_call() |> galah_identify(“Lampromicra”) |> galah_filter(year >= 2013) |> galah_group_by(year) |> atlas_counts() |> dplyr::arrange(dplyr::desc(year)) ```\nThere are a growing number of observations from 2012 to 2023 of Jewel beetles in the Atlas of Living Australia, with fewer than 100 observations each year prior to 2020.\nWith this information, we might choose to combine data from all years in our analysis (rather than separating them by year). Alternatively, we might decide to only include data since 2020, which might be sufficient to represent where Lampromicra are found and be more relevant because they are more recent observations. These are decisions that might affect the granularity of the research question we ask."
  },
  {
    "objectID": "scope_taxonomic.html",
    "href": "scope_taxonomic.html",
    "title": "2  Taxonomic scope",
    "section": "",
    "text": "In our example, we are interested in understanding more about Jewel beetles in the genus Lampromicra.\nWe first might want to know what species there are in the genus Lampromicra and view some additional taxonomic information about them. We can do this by adding atlas_species() to the end of a query in {galah}.\n:::{.callout-note} You will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information. :::\n```{r} galah_config(email = “youremail@here.com”)\ngalah_call() |> galah_identify(“Lampromicra”) |> atlas_species() |> select(family:species_guid) ```\nOur query returned three species in the genus Lampromicra. We can enter the urls returned under species_guid in a web browser if we wished to know more information about any of them.\nWe might also wish to check the total number of observations of each of these species. We can check this by grouping our counts by species using galah_group_by(species)\n{r} galah_call() |> galah_identify(\"Lampromicra\") |> galah_group_by(species) |> atlas_counts()\nOur result shows that the majority of observations of Lampromicra are of the species Lampromicra senator.\nGiven this information, we might consider whether our question needs to be made at the species level, or whether we might increase the taxonomic scope to the genus or family level to use more data. Ultimately, the taxonomic scope of your data will depend on how important it is to your question to compare specific taxonomic groups."
  },
  {
    "objectID": "scope_spatial.html",
    "href": "scope_spatial.html",
    "title": "3  Spatial scope",
    "section": "",
    "text": "For our example question about Lampromicra, we may wish to map where observations in Australia have been made. We can do this by using the {ozmaps} package to download a nice map of Australia, plot it with sf::geom_sf(), and add our observation points on top with geom_point(). We can separate the colours of our points by setting colour = scientificName within the aes() of geom_point().\n:::{.callout-note} You will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information. :::\n```{r} #| code-fold: true # old fonti code. not sure why it’s saved? # beatles <- open_dataset(“data/galah/lampromicra”) |> collect() library(ozmaps) library(sf) library(ggplot2) library(paletteer) # colour palettes\n\n4 Download data galah_config(email = “oliviajane.t@hotmail.com”)\nbeetles <- galah_call() |> galah_identify(“lampromicra”) |> atlas_occurrences() |> tidyr::drop_na() # remove any NA values\n\n\n5 Get map of australia, set to correct projection for data aus <-\nst_transform(ozmaps::ozmap_country, 4326)\n\n\n6 Map ggplot() + geom_sf( data = aus, colour = “grey60”, fill = “white”, alpha =\n0.2 ) + geom_point( data = beetles, mapping = aes( x = decimalLongitude, y = decimalLatitude, colour = scientificName ), size = 1.8, alpha = 0.6 ) + scale_color_paletteer_d(“feathers::eastern_rosella”) + coord_sf( xlim = c(110, 155), ylim = c(-45, -10) ) + theme_void() ```\nPlotting our points shows us that observations are spread along the northern and eastern coasts of Australia. We can also see that some observations are only identified to the genus level (e.g. Lampromicra), rather than to a specific species (e.g. Lampromicra aerea).\nThere are several places on the east coast of Australia where there are clumps of overlapping points. It’s difficult to tell how many observations there really are in those areas. To investigate, we can recreate this into a point density plot using the {ggpointdensity package}.\n```{r} #| code-fold: true library(ggpointdensity)\nggplot() + geom_sf( data = aus, colour = “grey60”, fill = “white”, alpha = 0.2 ) + geom_pointdensity( data = beetles, mapping = aes( x = decimalLongitude, y = decimalLatitude ) ) + scale_color_paletteer_c(“viridis::plasma”) + coord_sf( xlim = c(110, 155), ylim = c(-45, -10) ) + theme_void() ```\nAdding the density of overlapping points to our map allows us to see that there is one area with many more observations—more than 400 observations are found in the light yellow area!\nUsing this information, we might decide to make our research question more specific to the region where there are the most records of Lampromicra.\nLet’s have a look at these records in the context of their IBRA bioregions (distinct areas defined on a common climate, geology, landform, native vegetation and species information).\nTo find out what region(s) the genus Lampromicra is most common, you can group_by the IBRA region field code in {galah} (use search_fields to see others).\n```{r} ibra_counts <- galah_call() |> galah_identify(“Lampromicra”) |> galah_group_by(“cl1048”) |> # IBRA regions atlas_counts()\ngt(head(ibra_counts)) ```\n\nSouth Eastern Queensland (red), Sydney Basin (green)\n```{r} #| echo: false #| message: false #| warning: false\nshapefile <- st_read( here( “data”, “shapefiles”, “IBRA7_regions”, “ibra7_regions.shp” ), quiet = TRUE ) |> ms_simplify(keep = 0.1)\n\n\n7 IBRA Regions ggplot() + geom_sf( data = shapefile %>% filter(REG_NAME_7 ==\n“South Eastern Queensland”), aes(fill = “red”), colour = “black”, alpha = 0.7 ) + geom_sf( data = shapefile %>% filter(REG_NAME_7 == “Sydney Basin”), aes(fill = “green”), colour = “black”, alpha = 0.2 ) + geom_sf( data = shapefile %>% filter(REG_NAME_7 != c(“South Eastern Queensland”, “Sydney Basin”)), aes(fill = “white”), colour = “grey60”, alpha = 0.2 ) + geom_point( data = beetles, mapping = aes( x = decimalLongitude, y = decimalLatitude ), size = 0.05 ) + coord_sf( xlim = c(110, 155), ylim = c(-45, -10) ) + scale_fill_identity() + theme_void() ```\n\nLooks like South Eastern Queensland has the most records followed by Sydney Basin.\nThis could be due to sampling bias in that Brisbane and Sydney are large metropolis areas. You might choose to investigate this bias further.\n```{r} #| code-fold: true #| column: page #| fig-align: center #| layout-nrow: 1 #| message: false #| warning: false\nshapefile <- st_read( here( “data”, “shapefiles”, “IBRA7_regions”, “ibra7_regions.shp” ), quiet = TRUE ) |> ms_simplify(keep = 0.1)\n\n\n8 South Eastern Queensland ggplot() + geom_sf( data = shapefile %>%\nfilter(REG_NAME_7 == “South Eastern Queensland”), aes(fill = “red”), colour = “grey60”, alpha = 0.7 ) + geom_sf( data = shapefile %>% filter(REG_NAME_7 != “South Eastern Queensland”), aes(fill = “white”), colour = “grey60”, alpha = 0.2 ) + geom_point( data = beetles, mapping = aes( x = decimalLongitude, y = decimalLatitude ), size = 0.5 ) + coord_sf( xlim = c(140, 155), ylim = c(-30, -10) ) + scale_fill_identity() + theme_void()\n\n\n9 Sydney Basin ggplot() + geom_sf( data = aus, colour = “grey60”, fill =\n“white”, alpha = 0.2 ) + geom_sf( data = shapefile %>% filter(REG_NAME_7 == “Sydney Basin”), aes(fill = “green”), colour = “grey60”, alpha = 0.7 ) + geom_sf( data = shapefile %>% filter(REG_NAME_7 != “Sydney Basin”), aes(fill = “white”), colour = “grey60”, alpha = 0.2 ) + geom_point( data = beetles, mapping = aes( x = decimalLongitude, y = decimalLatitude ), size = 0.5 ) + coord_sf( xlim = c(145, 155), ylim = c(-37, -30) ) + scale_fill_identity() + theme_void() ```\nAlternatively, we might decide that there isn’t enough data (or data of a good enough quality) to make accurate estimates about Lampromicra.\nDepending on the spatial specificity of your question, you might have to adjust your data scope or your question accordingly."
  },
  {
    "objectID": "open_data.html",
    "href": "open_data.html",
    "title": "1  Open source data",
    "section": "",
    "text": "“Conversely, others conclude that in a large majority of cases, high quantity, low quality data produce similar results to that of lower quantity, high quality data (Aceves-Bueno et al., 2017). Poor quality data have also been used to cost-effectively estimate risk levels for data deficient species using a double sampling methodology (see Bland et al., 2015). However, to date, the general consensus within the conservation community favors the use of high quality data (Cayuela et al., 2009; Wood, Sullivan, Lliff, Fink, & Kelling, 2011)”\nWith broad data accumulation data quality can be impacted. In response GBIF flags potential errors through its data validator (https://www.gbif.org/tools/data-validator). This is an automated process providing information on geographic discrepancies (e.g., whether coordinates fall within a stated country), meta-data structure and formatting issues, and suggests how the user may improve the quality of the data and associated meta-data before use."
  },
  {
    "objectID": "how_to_use.html",
    "href": "how_to_use.html",
    "title": "How to use this book",
    "section": "",
    "text": "library(package)\nplot(data)"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Overview and structure",
    "section": "",
    "text": "The common steps associated with cleaning open-access biodiversity data are covered in this book:\n\ndata scope\ndownloading data\nexploring data and metadata\ncleaning data:\n\ngeneral cleaning\ntaxonomic names\nspatial data\n\n\nWe place particular emphasis on some of the most common issues encountered with biodiversity data:\nTaxonomic standardisation problems, such as:\n\nvaried species name synonyms\nnaming authorities and duplicates\n\nas well as spatial errors and issues, like:\n\nsuspicious outliers\nduplicates.\n\n\n\n\n\n\n\nThere is no one size fits all workflow.\nIn the literature, we found that data cleaning steps are frequently completed in entirely different orders. Not all steps are relevant or possible depending on the nature of the study, or, the area of expertise possessed. Therefore this book does not necessarily have to be used in a linear fashion. While some steps may logically come first, you may need to go back to them after completing another.\n\n\n\nThere are many important subject areas that this book will not cover. We won’t be teaching you:\n\nHow to clean environmental data that isn’t occurrence / biodiversity data: e.g. trait data - How to run a species distribution model - Hypothesis testing or experimental design"
  }
]