[
  {
    "objectID": "cleaning_intro.html#record-keeping",
    "href": "cleaning_intro.html#record-keeping",
    "title": "Archived: Cleaning data",
    "section": "Record keeping",
    "text": "Record keeping\nKeeping a complete record of your data cleaning steps is crucial and helps to maintain the integrity of your research. It ensures transparency in how the data were handled and processed, and allows for reproducibility, such that others may replicate your steps to achieve the same outcome. In practice, a record should include where data were sourced, and any changes made to the original data, such as correcting errors, removing duplicates, or filtering out data points.",
    "crumbs": [
      "Archived: Cleaning data"
    ]
  },
  {
    "objectID": "cleaning_intro.html#reproducible-workflows",
    "href": "cleaning_intro.html#reproducible-workflows",
    "title": "Archived: Cleaning data",
    "section": "Reproducible workflows",
    "text": "Reproducible workflows\nA reproducible workflow is code that given the same inputs, will produce the same outputs each time, regardless of when or where it is run. Meaning, it should be portable and work on any machine, without needing to make changes to the code such as changing local file paths. Reproducible workflows are recognised as a key component for research practices, and data science applications in general.\nUtilising notebooks or dynamic documents in R is a great first step towards reproducible workflows. We recommend using R Markdown, or the next-generation version called Quarto. These packages provide file formats that allow you to interleave plain text, code, and outputs, into a single document. Besides being a powerful way to communicate your work and colaborate with others, they offer a helpful way to integrate record keeping directly into your cleaning and analysis process.",
    "crumbs": [
      "Archived: Cleaning data"
    ]
  },
  {
    "objectID": "cleaning_intro.html#version-control",
    "href": "cleaning_intro.html#version-control",
    "title": "Archived: Cleaning data",
    "section": "Version control",
    "text": "Version control\nVersion control refers to the process of tracking and managing changes that are made to code. We recommend using a version control system like Git, and an online repository hosting service such as GitHub or GitLab, but there are many others to choose from. These services host your code files (privately or publicly), and track every modification made to your code. This is extremely useful in data cleaning, where you might make many small changes over time. If you encounter a problem or need to revisit a previous stage of your analysis, version control allows you to easily revert to earlier versions of your work. It also offers a safer way for multiple people to work on the same project, or share code with others.\n\n\n\n\n\n\nCaution\n\n\n\nGit is not a backup! It is a very useful version control system, but it is not advised to use it as a backup system. You should always maintain a separate, dedicated backup system for your files and data.",
    "crumbs": [
      "Archived: Cleaning data"
    ]
  },
  {
    "objectID": "1_accessing/where-to-get-data.html",
    "href": "1_accessing/where-to-get-data.html",
    "title": "1  Where to get data",
    "section": "",
    "text": "This section will detail what open source data is and suggest some places and packages for getting data of different types",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Where to get data</span>"
    ]
  },
  {
    "objectID": "1_accessing/large-downloads.html",
    "href": "1_accessing/large-downloads.html",
    "title": "2  Large downloads",
    "section": "",
    "text": "This will provide a basic example of how to use arrow (and other sql packages like tidysql or dtplyr?). Will be short and sweet, with the aim to just give a few ideas of what exists.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Large downloads</span>"
    ]
  },
  {
    "objectID": "1_accessing/merging.html",
    "href": "1_accessing/merging.html",
    "title": "3  Merging multiple datasets",
    "section": "",
    "text": "This is a common task when working with data. This chapter could provide some context about joins and using %in% and (maybe) some pointers of how to check that your joined dataset didn’t lose something you were expecting. Checking merged datasets could also be its own section, depending on what happens.\nThis could be a useful resource: https://github.com/gadenbuie/tidyexplain",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Merging multiple datasets</span>"
    ]
  },
  {
    "objectID": "intro.html#who-is-this-book-for",
    "href": "intro.html#who-is-this-book-for",
    "title": "Introduction",
    "section": "Who is this book for?",
    "text": "Who is this book for?\nIf you are new to working with biodiversity data in R, or hoping to add some tips and code examples to your toolbox, then this book is for you. By learning how to download and apply common data cleaning steps, you will also develop a better understanding of biodiversity data itself, and the common issues to be aware of.\nWe use R as it is commonly used across ecological projects, and has a rich ecosystem of packages for data cleaning and visualisation. A basic familiarity with the language is recommended.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#what-this-book-covers",
    "href": "intro.html#what-this-book-covers",
    "title": "Introduction",
    "section": "What this book covers",
    "text": "What this book covers\nIn this book, we provide an overview of a typical data cleaning workflow for cleaning open-access georeferenced biodiversity data - from acquisition, identifying potential errors, to correction. These processes are broken down into three sections. The chapters whithin each section include practical guidelines, example R code, and additional resources that may aid with each data cleaning step. An overview of the three sections and what they cover:\n\nData scope\n\nWhat is data scope?\nHow to determine the termporal, taxonomic, and spatial scope of available data for your study\n\nAccessing data\n\nWhere to get data from?\nHow to download data using R\nHow to refine download queries\nFirst steps in data inspection\n\nData cleaning\n\nString manipulation\nTaxonomic standardisation (synonyms, naming authorities, duplicates)\nSpatial data cleaning\nOutlier detection\n\n\n\n\n\n\n\n\nThere is no one size fits all workflow.\nData cleaning steps are frequently completed in entirely different orders. As such, this book should be regarded as just one example of a data cleaning workflow, rather than a strict framework. It does not need to be used in a linear fashion, although some steps may logically preceed others, or may need to be revisited after completing another. Nevertheless, if you are just stating out in this domain, working through the book sequentially is a great way to get started.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#what-we-dont-cover",
    "href": "intro.html#what-we-dont-cover",
    "title": "Introduction",
    "section": "What we don’t cover",
    "text": "What we don’t cover\nThe areas of research and uses of biodiversity data are many and varied. Here we have focused on just one facet - downloading and cleaning georeferenced occurrence / biodiversity data. As such, this book will not cover:\n\nHypothesis testing or experimental design\nHow to clean environmental data that is not occurrence / biodiversity data (e.g. trait data)\nHow to perform analyses (e.g. species distribution modelling)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#requirements",
    "href": "intro.html#requirements",
    "title": "Introduction",
    "section": "Requirements",
    "text": "Requirements\n\nUser accounts\nWe will be working with point-based species occurrence data retrieved from online infrastructures such as Global Biodiversity Information Facility (GBIF) and the Atlas of Living Australia (ALA). To retrieve data from these services, you will need to create a user account, if you do not already have one.\n\nAtlas of Living Australia account creation\nGlobal Biodiversity Information Facility account creation\n\n\n\nR\nTo get the most out of this book, a basic knowledge of using R and RStudio is recommended. If you are new to R or need a refresher, there are many high quality and freely available resources available online. Data Analysis and Visualisation in R for Ecologists, and R for Data Science are both excellent starting points.\nDownload R from CRAN, selecting the version that matches your operating system, and install it on your device.\n\n\nRStudio\nRStudio is an integrated development environment (IDE) for R programming. R studio provides a range of tools to make working with R easier, and you can download and install RStudio for your operating system here.\n\n\nPackages\nWe use a range of R packages throughout the book, primarily for data cleaning and visualisations. These packages will be noted at the beginning of a code block, typically at the start of a chapter. To access biodiversity data we will be working with the galah package. If you have collected your own occurrence data, you should still find this book useful.\n\nTODO link to the packages page",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#conventions",
    "href": "intro.html#conventions",
    "title": "Introduction",
    "section": "Conventions",
    "text": "Conventions\nDemonstrations and instructions throughout this book are accompanied by code blocks. These blocks show how a particular task was executed in R:\n# This is a code block with a comment\nlibrary(package)\nplot(data)\n\n\n\n\n\n\nYou can copy code by clicking the button in the top right corner of a code block.\n\n\n\nWhen performing a sequence of related actions, we use the native R pipe operator |&gt;. This allows multiple operations to be performed, without needing to save the intermediate results to a variable. You can learn more about the pipe in the R for Data Science book. Some code blocks may also be annotated, to help explain the sequence of steps. See the annotated example below:\n\n# This is a code block with annotation\n1mtcars |&gt;\n2   dplyr::group_by(cyl) |&gt;\n3   dplyr::summarise(mpg = mean(mpg))\n\n\n1\n\nUsing the pipe operator to pass the mtcars data frame to the group_by() function\n\n2\n\nGrouping the data frame by the cyl variable\n\n3\n\nPrint a summary of the filtered data frame using the summarise() function\n\n\n\n\n\n\n\n\ncyl\nmpg\n\n\n\n\n4\n26.66364\n\n\n6\n19.74286\n\n\n8\n15.10000\n\n\n\n\n\n\n\n\n\n\nRodrigues, A. V., Nakamura, G., Staggemeier, V. G., & Duarte, L. (2022). Species misidentification affects biodiversity metrics: Dealing with this issue using the new R package naturaList. Ecological Informatics, 69, 101625. https://doi.org/10.1016/j.ecoinf.2022.101625",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "2_exploring/1_intro.html#demonstration",
    "href": "2_exploring/1_intro.html#demonstration",
    "title": "Exploring biodiversity data",
    "section": "Demonstration",
    "text": "Demonstration\nAs an example, let’s imagine we were interested in understanding more about the distribution of several Jewel beetles in the genus Lampromicra. Let’s see some ways we might investigate what data are available about them in Australia.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nCurious what a Jewel beetle looks like? Here is a Lampromicra senator perched on a leaf by Matthew Connors CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "Exploring biodiversity data"
    ]
  },
  {
    "objectID": "2_exploring/initial-inspection.html#metadata-inspection",
    "href": "2_exploring/initial-inspection.html#metadata-inspection",
    "title": "4  Initial inspection",
    "section": "4.1 Metadata inspection",
    "text": "4.1 Metadata inspection\nMetadata describes your data set: it defines each variable and its contents. For example, describing a variables unit of measurement, climatic conditions at the time of observation, or whether the occurrence is a marked outlier. Reviewing the metadata of your dataset is a useful first step, as it allows you to understand the kind of data you are working with and any potential limitations of the data that could affect your analysis.\nData infrastructures that use Darwin Core terms will have interoperable metadata. This makes it easier to consolidate across data sets. All Darwin Core term definitions can be found here. We suggest using Ctrl/CMD F and searching your variable name on the webpage. Don’t hesitate to Google variable names if you are unsure what they represent.\nIt is also worth checking the available metadata for your dataset, to determine if there is extra information that may be relevant. You could Google the dataset name, or search the dataset or institution on the ALA. The metadata on the ALA is submitted with the data, and because the ALA is not the data owner, this data is immutable.\nAn example of well formatted metadata is FrogID from the Australian Museum. From reading FrogID’s metadata (Rowley and Callaghan 2020), you’ll find:\n\nThe data is acoustic data, the majority of the species recorded are therefore male.\nBecause this is citizen science data, it is especially biased towards populated areas.\nAudio is recorded via a smartphone app, and so the authors recommend filtering data to geographic uncertainty of &lt;3000m if you require high coordinate precision.\nThe data is presence only data.\n\nMetadata can also be useful for understanding the license that the data falls under. This is mostly relevant for using or republishing multimedia associated with the data.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "2_exploring/initial-inspection.html#data-inspection",
    "href": "2_exploring/initial-inspection.html#data-inspection",
    "title": "4  Initial inspection",
    "section": "4.2 Data inspection",
    "text": "4.2 Data inspection\nA great way to get an initial overview of your data is to use the R package skimr, which provides tables of descriptive statistics, such as amount of missing data, for each variable. The output is also grouped by data type (numeric, character, date) so you can also check for any inconsistencies.\nAs you are looking through the output, ask yourself whether the data is in line with your expectations. If you requested data for a group of species, are they all represented? Are the values for a variable reasonable? Looking at the quartiles can help you get the sense of the distribution of data. These considerations will help you detect potential issues in the data. Make sure you take note of any issues you find, to investigate further and later address.\nHere we will continue using the African elephant dataset that we downloaded in the previous chapter on downloading. You can create a report using the skimr package by running the following code: \n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.2\n\nafrican_ele &lt;- arrow::read_parquet(\"../data/gbif/elephant\")\nskim(african_ele)\n\n\nData summary\n\n\nName\nafrican_ele\n\n\nNumber of rows\n17825\n\n\nNumber of columns\n50\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n31\n\n\nlogical\n1\n\n\nnumeric\n15\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndatasetKey\n0\n1.00\n36\n36\n0\n150\n0\n\n\noccurrenceID\n806\n0.95\n1\n81\n0\n16818\n0\n\n\nkingdom\n0\n1.00\n8\n8\n0\n1\n0\n\n\nphylum\n0\n1.00\n8\n8\n0\n1\n0\n\n\nclass\n0\n1.00\n8\n8\n0\n1\n0\n\n\norder\n0\n1.00\n11\n11\n0\n1\n0\n\n\nfamily\n0\n1.00\n12\n12\n0\n1\n0\n\n\ngenus\n0\n1.00\n9\n9\n0\n1\n0\n\n\nspecies\n0\n1.00\n18\n18\n0\n1\n0\n\n\ninfraspecificEpithet\n17698\n0.01\n8\n13\n0\n2\n0\n\n\ntaxonRank\n0\n1.00\n7\n10\n0\n3\n0\n\n\nscientificName\n0\n1.00\n12\n37\n0\n5\n0\n\n\nverbatimScientificName\n3\n1.00\n12\n53\n0\n31\n0\n\n\nverbatimScientificNameAuthorship\n16258\n0.09\n2\n31\n0\n256\n0\n\n\ncountryCode\n1701\n0.90\n2\n2\n0\n46\n0\n\n\nlocality\n14434\n0.19\n3\n254\n0\n725\n0\n\n\nstateProvince\n6447\n0.64\n3\n43\n0\n196\n0\n\n\noccurrenceStatus\n0\n1.00\n6\n7\n0\n2\n0\n\n\npublishingOrgKey\n0\n1.00\n36\n36\n0\n106\n0\n\n\nbasisOfRecord\n0\n1.00\n10\n19\n0\n9\n0\n\n\ninstitutionCode\n4075\n0.77\n2\n76\n0\n111\n0\n\n\ncollectionCode\n4091\n0.77\n1\n41\n0\n169\n0\n\n\ncatalogNumber\n4292\n0.76\n1\n36\n0\n13418\n0\n\n\nrecordNumber\n17662\n0.01\n1\n37\n0\n114\n0\n\n\nidentifiedBy\n7519\n0.58\n1\n81\n0\n1899\n0\n\n\nlicense\n0\n1.00\n7\n12\n0\n3\n0\n\n\nrightsHolder\n7128\n0.60\n1\n56\n0\n2135\n0\n\n\nrecordedBy\n4967\n0.72\n1\n160\n0\n2485\n0\n\n\nestablishmentMeans\n17538\n0.02\n6\n9\n0\n2\n0\n\n\nmediaType\n8137\n0.54\n5\n16\n0\n4\n0\n\n\nissue\n3189\n0.82\n15\n191\n0\n148\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntypeStatus\n17825\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ngbifID\n0\n1.00\n2651173026.73\n1.085849e+09\n49926810.00\n1677294509.00\n2.45486e+09\n3817646721.00\n4.499724e+09\n▁▇▇▅▇\n\n\nindividualCount\n15550\n0.13\n4.90\n1.415000e+01\n0.00\n1.00\n1.00000e+00\n2.00\n2.920000e+02\n▇▁▁▁▁\n\n\ndecimalLatitude\n4174\n0.77\n-11.29\n1.430000e+01\n-34.58\n-24.28\n-1.58400e+01\n-0.13\n5.215000e+01\n▇▅▃▁▁\n\n\ndecimalLongitude\n4174\n0.77\n26.47\n1.137000e+01\n-111.97\n24.34\n3.13000e+01\n34.82\n4.053000e+01\n▁▁▁▁▇\n\n\ncoordinateUncertaintyInMeters\n6763\n0.62\n41707.41\n1.445170e+05\n1.00\n29981.00\n3.05980e+04\n31425.00\n5.635548e+06\n▇▁▁▁▁\n\n\ncoordinatePrecision\n17786\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n0.000000e+00\n▆▁▁▁▇\n\n\nelevation\n17789\n0.00\n154.42\n4.215900e+02\n0.00\n0.00\n0.00000e+00\n13.75\n2.134000e+03\n▇▁▁▁▁\n\n\nelevationAccuracy\n17795\n0.00\n0.83\n3.730000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n2.000000e+01\n▇▁▁▁▁\n\n\ndepth\n17797\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n0.000000e+00\n▁▁▇▁▁\n\n\ndepthAccuracy\n17797\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n0.000000e+00\n▁▁▇▁▁\n\n\nday\n4092\n0.77\n16.10\n8.790000e+00\n1.00\n9.00\n1.70000e+01\n24.00\n3.100000e+01\n▇▆▇▇▇\n\n\nmonth\n4027\n0.77\n6.94\n3.270000e+00\n1.00\n4.00\n7.00000e+00\n10.00\n1.200000e+01\n▆▅▅▇▇\n\n\nyear\n1017\n0.94\n2011.59\n1.677000e+01\n1799.00\n2008.00\n2.01500e+03\n2019.00\n2.023000e+03\n▁▁▁▁▇\n\n\ntaxonKey\n0\n1.00\n2493260.94\n6.308602e+05\n2435350.00\n2435350.00\n2.43535e+06\n2435350.00\n1.150335e+07\n▇▁▁▁▁\n\n\nspeciesKey\n0\n1.00\n2435350.00\n0.000000e+00\n2435350.00\n2435350.00\n2.43535e+06\n2435350.00\n2.435350e+06\n▁▁▇▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n1017\n0.94\n1799-01-01 00:00:00\n2023-12-12 14:22:24\n2015-05-22 00:00:00\n10716\n\n\ndateIdentified\n7025\n0.61\n1783-01-01 00:00:00\n2023-12-12 20:59:49\n2021-02-03 20:16:20\n9526\n\n\nlastInterpreted\n0\n1.00\n2023-08-25 11:37:02\n2023-12-24 01:51:40\n2023-12-19 07:41:11\n16810\n\n\n\n\n\n\n4.2.1 Evaluating the dataset\nHere are some starting points for evaluating a dataset. As you go through the skimr report and perform these checks, make detailed notes of your observations and any potential issues.\n\nConfirm the number of records:\n\nVerify if the number of records in the dataset matches your expectations. If the number is significantly higher or lower than anticipated, it may indicate an issue with the query or data source.\n\nChecking for the correct metadata columns:\n\nEnsure that all expected metadata columns are present. These might include species names, dates, locations, etc. The absence of key columns could suggest a problem with the data extraction process.\n\nAssessing missing data in critical fields:\n\nCheck the amount of missing data, especially in critical fields like latitude and longitude. A high number of missing values in these fields can significantly impact the usability of the dataset for geospatial analysis.\n\nReviewing geospatial data accuracy:\n\nLook for anomalies in geospatial data. Check if the coordinates are within plausible ranges and if they correspond to the geographic regions you expected.\n\nEvaluating data distribution and outliers:\n\nUse the quartiles and summary statistics provided by skimr to assess the distribution of key variables. Be on the lookout for outliers or unusual patterns that might need further investigation.\n\nConsistency and formatting of categorical data:\n\nCheck for consistency in categorical data, such as species names. Inconsistencies might arise from variations in spelling, capitalization, or use of synonyms.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "2_exploring/initial-inspection.html#next-steps",
    "href": "2_exploring/initial-inspection.html#next-steps",
    "title": "4  Initial inspection",
    "section": "4.3 Next steps",
    "text": "4.3 Next steps\nKeep in mind, we don’t expect a perfect dataset from a download. The goal of an initial inspection is to assess whether the download returned results in line with your expections based on your query. Some issues are expected, and may not signify an issue with the download itself but rather the actual data. The initial inspection is therefore a good opportunity to also start noting these issues, as they will be addressed during the cleaning phase.\nBased on your initial findings, consider whether you need to refine your download query. Perhaps you uncovered some additional metadata fields during your metadata inspection, and would like to adjust your query to include them. Or maybe you noticed missing data in specific time frames or locations that you expected from your query, or missing metadata fields. This could mean you need to adjust your download query parameters or investigate those issues further.\nWhen you are satisfied that the dataset is largely as expected, you are ready to move onto the data cleaning section. If you are working with multiple datasets from different sources, the next chapter will cover integration of datasets.\n\n\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset: Expert-Validated Occurrence Records of Australia’s Frogs Collected by Citizen Scientists.” ZooKeys 912: 139.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "2_exploring/scope_temporal.html",
    "href": "2_exploring/scope_temporal.html",
    "title": "5  Temporal scope",
    "section": "",
    "text": "A good first step to understanding what data are available is to check the number of observations across different time periods. To do this, we are using the galah package to query the Atlas of Living Australia (ALA), which is the largest biodiversity data aggregator in Australia.\nFirst we load the galah package, and provide our registered ALA email address to the galah_config() function.\n\n\nLoad required packages\nlibrary(galah)\nlibrary(tidyverse) # group of packages\n\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'tibble' was built under R version 4.3.2\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.3.2\n\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n\n# Provide your registered ALA email address\ngalah_config(email = \"youremail@here.com\")\n\nThe atlas_counts() function returns a count of records. By itself, it returns a count of all records in the Atlas of Living Australia, but we can narrow this query using galah helper functions. In this case, we narrow the search to only include insects.\n\n# Query all records\natlas_counts()\n\n# Query only insects\n1galah_call() |&gt;\n2  galah_identify(\"insecta\") |&gt;\n3  atlas_counts()\n\n\n1\n\nStart building a data query\n\n2\n\nNarrow the query with taxonomic identifiers\n\n3\n\nReturn the count of records\n\n\n\n\n# A tibble: 1 × 1\n      count\n      &lt;int&gt;\n1 132567229\n# A tibble: 1 × 1\n    count\n    &lt;int&gt;\n1 5954353\n\n\nNow let’s see how many insects have been observed each year over the last 10 years. We’ll order this by descending year using dplyr::arrange() and dplyr::desc().\n\ngalah_call() |&gt;\n  galah_identify(\"insecta\") |&gt;\n  galah_filter(year &gt;= 2013) |&gt;\n  galah_group_by(year) |&gt;\n  atlas_counts() |&gt;\n  dplyr::arrange(dplyr::desc(year))\n\n# A tibble: 12 × 2\n   year   count\n   &lt;chr&gt;  &lt;int&gt;\n 1 2024   12422\n 2 2023  503083\n 3 2022  450525\n 4 2021  357634\n 5 2020  266162\n 6 2019  186319\n 7 2018  229415\n 8 2017  195493\n 9 2016  170848\n10 2015  125795\n11 2014  127051\n12 2013  116723\n\n\nNow that we have an idea of the total amount of data in the Atlas of Living Australia, let’s try checking how many observations exist of the genus Lampromicra. We’ll first make sure the scientific name Lampromicra returns the taxon information we expect with search_taxa().\nksm search_taxa(\"Lampromicra\")\nThis looks correct! Next let’s see how many total observations there are of Lampromicra and how many observations there were in each of the last 10 years.\n\ngalah_call() |&gt; \n  galah_identify(\"Lampromicra\") |&gt; \n  atlas_counts()\n\n# A tibble: 1 × 1\n  count\n  &lt;int&gt;\n1  1445\n\ngalah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  galah_filter(year &gt;= 2013) |&gt;\n  galah_group_by(year) |&gt;\n  atlas_counts() |&gt;\n  dplyr::arrange(dplyr::desc(year))\n\n# A tibble: 12 × 2\n   year  count\n   &lt;chr&gt; &lt;int&gt;\n 1 2024     12\n 2 2023    193\n 3 2022    232\n 4 2021    222\n 5 2020    152\n 6 2019     75\n 7 2018     55\n 8 2017     44\n 9 2016     42\n10 2015     14\n11 2014     15\n12 2013      6\n\n\nThere are a growing number of observations from 2012 to 2023 of Jewel beetles in the Atlas of Living Australia, with fewer than 100 observations each year prior to 2020.\nWith this information, we might choose to combine data from all years in our analysis (rather than separating them by year). Alternatively, we might decide to only include data since 2020, which might be sufficient to represent where Lampromicra are found and be more relevant because they are more recent observations. These are decisions that might affect the granularity of the research question we ask.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Temporal scope</span>"
    ]
  },
  {
    "objectID": "2_exploring/scope_taxonomic.html",
    "href": "2_exploring/scope_taxonomic.html",
    "title": "6  Taxonomic scope",
    "section": "",
    "text": "Taxonomy refers to ways by which we classify an organism and its relationship to all other organisms. Typically, your research question will be concerned with one or more taxonomic groups, ranging from a single species to an entire kingdom (e.g. Plantae).\nFollowing on with our example, we are interested in understanding more about Jewel beetles in the genus Lampromicra.\nWe first might want to know what species there are in the genus Lampromicra and view some additional taxonomic information about them. We can do this by adding atlas_species() to the end of a query in {galah}.\n\n\n\n\n\n\nNote\n\n\n\nYou will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information.\n\n\n\nlibrary(galah)\n\n\nAttaching package: 'galah'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\n# Provide your registered ALA email address\ngalah_config(email = \"youremail@here.com\")\n\n\ngalah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  atlas_species() |&gt;\n  select(family:species_guid)\n\n# A tibble: 3 × 5\n  family        genus       species             author            species_guid  \n  &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;               &lt;chr&gt;             &lt;chr&gt;         \n1 Scutelleridae Lampromicra Lampromicra senator (Fabricius, 1803) https://biodi…\n2 Scutelleridae Lampromicra Lampromicra aerea   (Distant, 1892)   https://biodi…\n3 Scutelleridae Lampromicra Lampromicra regia   Bergroth, 1895    https://biodi…\n\n\nOur query returned three species in the genus Lampromicra. The URLs returned under species_guid can be entered in a web browser to see more information.\nWe might also wish to check the total number of observations of each of these species. We can check this by grouping our counts by species using galah_group_by(species)\n\ngalah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  galah_group_by(species) |&gt;\n  atlas_counts()\n\n# A tibble: 3 × 2\n  species             count\n  &lt;chr&gt;               &lt;int&gt;\n1 Lampromicra senator  1162\n2 Lampromicra aerea     197\n3 Lampromicra regia      14\n\n\nOur result shows that the majority of observations of Lampromicra are of the species Lampromicra senator.\nGiven this information, we might consider whether our question needs to be made at the species level, or whether we might increase the taxonomic scope to the genus or family level to use more data. Ultimately, the taxonomic scope of your data will depend on how important it is to your question to compare specific taxonomic groups.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Taxonomic scope</span>"
    ]
  },
  {
    "objectID": "2_exploring/scope_spatial.html",
    "href": "2_exploring/scope_spatial.html",
    "title": "7  Spatial scope",
    "section": "",
    "text": "It’s useful to investigate the spatial range of available data for your taxonomic group(s) of interest. How specific your question can be may change depending on whether the majority of data is in only a few locations or evenly spread over the entire distribution of a species or taxonomic group.\nFor our example question about Lampromicra, we may wish to map where observations in Australia have been made. We can do this by using the {ozmaps} package to download a nice map of Australia, plot it with sf::geom_sf(), and add our observation points on top with geom_point(). We can separate the colours of our points by setting colour = scientificName within the aes() of geom_point().\n\n\n\n\n\n\nNote\n\n\n\nYou will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information.\n\n\n\n\nLoad required packages\nlibrary(galah)\nlibrary(tidyr)\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nLoad required packages\nlibrary(sf)\n\n\nWarning: package 'sf' was built under R version 4.3.2\n\n\nLoad required packages\nlibrary(ggplot2)\nlibrary(paletteer) # colour palettes\nlibrary(ozmaps)\n\n\nWarning: package 'ozmaps' was built under R version 4.3.2\n\n\nLoad required packages\nlibrary(viridis)\n\n\nWarning: package 'viridis' was built under R version 4.3.2\n\n\nLoad required packages\nlibrary(gt)\n\n\nWarning: package 'gt' was built under R version 4.3.2\n\n\nLoad required packages\nlibrary(here)\n\n\nWarning: package 'here' was built under R version 4.3.2\n\n\nLoad required packages\nlibrary(rmapshaper)\n\n\nWarning: package 'rmapshaper' was built under R version 4.3.2\n\n\n\n# Provide your registered ALA email address\ngalah_config(email = \"youremail@here.com\")\n\n\nbeetles &lt;- galah_call() |&gt;\n  galah_identify(\"lampromicra\") |&gt;\n  atlas_occurrences() |&gt;\n  tidyr::drop_na() # remove any NA values\n\nRetrying in 1 seconds.\n\n# Get map of australia, and transform to WGS84\naus &lt;- st_transform(ozmaps::ozmap_country, 4326)\n\n# Plot the observations on our map of Australia\nggplot() +\n  geom_sf(data = aus, colour = \"grey60\", fill = \"white\", alpha = 0.2) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude, y = decimalLatitude, colour =\n        scientificName\n    ),\n    size = 1.8, alpha = 0.6\n  ) +\n  scale_color_paletteer_d(\"feathers::eastern_rosella\") +\n  coord_sf(xlim = c(110, 155), ylim = c(-45, -10)) +\n  theme_void()\n\n\n\n\n\n\n\n\nPlotting our points shows us that observations are spread along the northern and eastern coasts of Australia. We can also see that some observations are only identified to the genus level (e.g. Lampromicra), rather than to a specific species (e.g. Lampromicra aerea).\nThere are several places on the east coast of Australia where there are clumps of overlapping points. It’s difficult to tell how many observations there really are in those areas. To investigate, we can recreate this into a point density plot using the {ggpointdensity package}.\n\n\nCode\nlibrary(ggpointdensity)\n\n\nWarning: package 'ggpointdensity' was built under R version 4.3.2\n\n\nCode\nggplot() +\n  geom_sf(data = aus, colour = \"grey60\", fill = \"white\", alpha = 0.2) +\n  geom_pointdensity(\n    data = beetles,\n    mapping = aes(x = decimalLongitude, y = decimalLatitude)\n  ) +\n  scale_color_paletteer_c(\"viridis::plasma\") +\n  coord_sf(xlim = c(110, 155), ylim = c(-45, -10)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nAdding the density of overlapping points to our map allows us to see that there is one area with many more observations—more than 400 observations are found in the light yellow area!\nUsing this information, we might decide to make our research question more specific to the region where there are the most records of Lampromicra.\nLet’s have a look at these records in the context of their IBRA bioregions (distinct areas defined on a common climate, geology, landform, native vegetation and species information).\nTo find out what region(s) the genus Lampromicra is most common, you can group_by the IBRA region field code in {galah} (use search_fields to see others).\n\nibra_counts &lt;- galah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  galah_group_by(\"cl1048\") |&gt; # IBRA regions\n  atlas_counts()\ngt(head(ibra_counts))\n\n\n\n\n\n\n\ncl1048\ncount\n\n\n\n\nSouth Eastern Queensland\n536\n\n\nSydney Basin\n208\n\n\nVictoria Bonaparte\n82\n\n\nBrigalow Belt North\n79\n\n\nWet Tropics\n73\n\n\nEinasleigh Uplands\n67\n\n\n\n\n\n\n\n\nSouth Eastern Queensland (red), Sydney Basin (green)\n\n\n\n\n\n\n\n\n\n\nWe can see that South East Queensland has the most records followed by Sydney Basin. At this point, it would be useful to know if this is because of a sampling bias towards these large metropolitan areas, or if Lampromicra is actually more common in these areas. We will not cover the process here, but see this article on quantifying geographic sampling bias with {sampbias} to learn more.\nshapefile &lt;- st_read(\n  here(\n    \"data\",\n    \"shapefiles\",\n    \"IBRA7_regions\",\n    \"ibra7_regions.shp\"\n  ),\n  quiet = TRUE\n) |&gt;\n  ms_simplify(keep = 0.1)\n\n\n# South Eastern Queensland\nggplot() +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 == \"South Eastern Queensland\"),\n    aes(fill = \"red\"),\n    colour = \"grey60\",\n    alpha = 0.7\n  ) +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 != \"South Eastern Queensland\"),\n    aes(fill = \"white\"),\n    colour = \"grey60\",\n    alpha = 0.2\n  ) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude\n    ),\n    size = 0.5\n  ) +\n  coord_sf(\n    xlim = c(140, 155),\n    ylim = c(-30, -10)\n  ) +\n  scale_fill_identity() +\n  theme_void()\n# Sydney Basin\nggplot() +\n  geom_sf(\n    data = aus,\n    colour = \"grey60\",\n    fill = \"white\",\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 == \"Sydney Basin\"),\n    aes(fill = \"green\"),\n    colour = \"grey60\",\n    alpha = 0.7\n  ) +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 != \"Sydney Basin\"),\n    aes(fill = \"white\"),\n    colour = \"grey60\",\n    alpha = 0.2\n  ) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude\n    ),\n    size = 0.5\n  ) +\n  coord_sf(\n    xlim = c(145, 155),\n    ylim = c(-37, -30)\n  ) +\n  scale_fill_identity() +\n  theme_void()\n\n\n\nCode\n\n\n\n\n\n\n\n\n\nCode\n\n\n\n\n\n\n\n\n\n\nAlternatively, we might decide that there isn’t enough data (or data of a good enough quality) to make accurate estimates about Lampromicra.\nDepending on the spatial specificity of your question, you might have to adjust your data scope or your question accordingly.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial scope</span>"
    ]
  },
  {
    "objectID": "2_exploring/scope_summary.html",
    "href": "2_exploring/scope_summary.html",
    "title": "8  Data scope summary",
    "section": "",
    "text": "This section has demonstrated a few ways to perform an initial investigation of the data available to answer a research question using the {galah} package. This is a critical part of the research process, and should be conducted in the early stages of your project. Keep in mind that this was just a small example of examining available data, and our aim is to encourage readers to think critically about their own data scope, building on the steps have presented here. In the next section, we will explain how to download and save this data.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data scope summary</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/1_intro.html",
    "href": "3_cleaning_general/1_intro.html",
    "title": "Cleaning data: General",
    "section": "",
    "text": "This section shows tasks and functions that will be frequently used to clean datasets.\n\n\n\n\n\nDuplicates\n\n\n\n\n\nMissing values\n\n\n\n\n\nUnexpected values\n\n\n\n\n\nStrings\n\n\n\n\n\nDates\n\n\n\n\n\nColumn names + classes",
    "crumbs": [
      "Cleaning data: General"
    ]
  },
  {
    "objectID": "3_cleaning_general/duplicates.html",
    "href": "3_cleaning_general/duplicates.html",
    "title": "7  Duplicates",
    "section": "",
    "text": "Duplicates records can happen when using aggregated data sources. In this section we will cover detection and handling of duplicate records.\n\n# Check for duplicate records across the dataset\n# duplicated_records &lt;- merged_data[duplicated(merged_data), ]\n# Targeted checks\n# duplicated_records[which(duplicated(merged_data$occurrenceID)), ]",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Duplicates</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/missing-values.html#missing-values",
    "href": "3_cleaning_general/missing-values.html#missing-values",
    "title": "10  Missing values",
    "section": "10.1 Missing values",
    "text": "10.1 Missing values\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.2\n\niris %&gt;%\n  skim() %&gt;%\n  dplyr::filter(n_missing &gt; 0)\n\n# A tibble: 0 × 15\n# ℹ 15 variables: skim_type &lt;chr&gt;, skim_variable &lt;chr&gt;, n_missing &lt;int&gt;,\n#   complete_rate &lt;dbl&gt;, factor.ordered &lt;lgl&gt;, factor.n_unique &lt;int&gt;,\n#   factor.top_counts &lt;chr&gt;, numeric.mean &lt;dbl&gt;, numeric.sd &lt;dbl&gt;,\n#   numeric.p0 &lt;dbl&gt;, numeric.p25 &lt;dbl&gt;, numeric.p50 &lt;dbl&gt;, numeric.p75 &lt;dbl&gt;,\n#   numeric.p100 &lt;dbl&gt;, numeric.hist &lt;chr&gt;",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/missing-values.html#missing-coordinates",
    "href": "3_cleaning_general/missing-values.html#missing-coordinates",
    "title": "8  Missing values",
    "section": "8.2 Missing coordinates",
    "text": "8.2 Missing coordinates\nIf your research question requires spatial information, then it may be useful to exclude records that are missing coordinates data. Many spatial analytical tools are not compatible with missing coordinate data. We recommend tallying and identifying the rows that have missing data before excluding.\nYou can use drop_na() to remove missing values from your dataset.\n\nlibrary(galah)\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  atlas_occurrences()\n\nlibrary(dplyr)\n\n# Identify missing data in coordinates\nbanksia_serrata |&gt; \n  filter(is.na(decimalLatitude) | is.na (decimalLongitude))\n\n# Excluding them\nbanksia_serrata |&gt; \n  tidyr::drop_na(decimalLatitude, decimalLongitude)\n\n\nMissing higher taxonomy\nIf you noticed you have missing data in these columns, you can usually back fill this information using your chosen naming authority or retrieving this information from a living atlas such as the ALA.\nThe code below demonstrates how you can isolate the scientific_names of taxa with missing data and searching for taxonomic information from ALA\n\n\n\nlibrary(arrow)\nlibrary(tidyverse)\nlibrary(janitor)\n\nbees &lt;- read_parquet(\"../data/dap/bees.parquet\")\n\nplants &lt;- open_dataset(\"../data/dap/plants_subset\",\n  format = \"parquet\"\n) |&gt; collect()\n\n### Making some fake missing data for inverts in Class column\ninverts &lt;- open_dataset(\"../data/dap/inverts_subset\") |&gt; collect()\n\nset.seed(5)\ntobemissing &lt;- inverts |&gt;\n  filter(class == \"arachnida\") |&gt;\n  sample_frac(0.3) |&gt;\n  pull(scientific_name) |&gt;\n  unique()\n\ninverts &lt;- inverts |&gt;\n  mutate(class = ifelse(scientific_name %in% tobemissing, NA, class))\n\n\nlibrary(galah)\n\n\nAttaching package: 'galah'\n\n\nThe following object is masked from 'package:dplyr':\n\n    desc\n\n\nThe following object is masked from 'package:tidyr':\n\n    unnest\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n# Configure galah to point to Australia node\ngalah_config(\n  atlas = \"Australia\",\n  email = Sys.getenv(\"ALA_EMAIL\")\n)\n\n# These are the taxa missing `class` information\nto_search &lt;- inverts |&gt;\n  filter(is.na(class)) |&gt;\n  select(scientific_name) |&gt;\n  distinct()\n\n# Reformat scientific_name to scientificName as the latter is the ALA format\nbackfilled_taxa &lt;- to_search |&gt;\n  rename(scientificName = scientific_name) |&gt;\n  search_taxa(to_search) |&gt;\n  tibble()\n\nQuerying API ■■■                                5% |  ETA: 23s\n\n\nQuerying API ■■■■■■■                           20% |  ETA: 17s\n\n\nQuerying API ■■■■■■■■■■■                       33% |  ETA: 15s\n\n\nQuerying API ■■■■■■■■■■■■■■■                   47% |  ETA: 11s\n\n\nQuerying API ■■■■■■■■■■■■■■■■■■■■              64% |  ETA:  8s\n\n\nQuerying API ■■■■■■■■■■■■■■■■■■■■■■■■■         79% |  ETA:  4s\n\n\nQuerying API ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■    95% |  ETA:  1s\n\nbackfilled_taxa\n\n# A tibble: 409 × 15\n   search_term     scientific_name scientific_name_auth…¹ taxon_concept_id rank \n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;\n 1 Idiosoma manst… Idiosoma manst… (Pocock, 1897)         https://biodive… spec…\n 2 Holonuncia rec… Holonuncia rec… Hunt, 1992             https://biodive… spec…\n 3 Trachycosmus s… Trachycosmus s… Simon, 1893            https://biodive… spec…\n 4 Pseudotyrannoc… Pseudotyrannoc… Beier, 1971            https://biodive… spec…\n 5 Phryganoporus … Phryganoporus … (L. Koch, 1872)        https://biodive… spec…\n 6 Latrodectus ha… Latrodectus ha… Thorell, 1870          https://biodive… spec…\n 7 Ascoschoengast… Ascoschoengast… (Hirst, 1915)          https://biodive… spec…\n 8 Chrestobunus f… Chrestobunus f… Hickman, 1958          https://biodive… spec…\n 9 Supunna picta   Nyssus colorip… Walckenaer, 1805       https://biodive… spec…\n10 Tasmanicosa le… Tasmanicosa le… (Thorell, 1870)        https://biodive… spec…\n# ℹ 399 more rows\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 10 more variables: match_type &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;,\n#   class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   vernacular_name &lt;chr&gt;, issues &lt;chr&gt;\n\n\n\n\nInsufficient taxonomic rank\nIf a record is not identified down to the taxonomic level that needed for the study e.g. species, then the record should be removed.\nDuring your data download, ensure you have requested for the column taxonRank, this variable tells us the lowest level of scientificName.\n\nlibrary(galah)\n\ngalah_config(\n  email = Sys.getenv(\"ALA_EMAIL\"),\n  atlas = \"Australia\"\n)\n\nhoneyeaters &lt;- galah_call() |&gt;\n  galah_identify(\"Meliphagidae\") |&gt;\n  galah_filter(year == 2012 & stateProvince == \"New South Wales\") |&gt;\n  galah_select(group = \"basic\", taxonRank) |&gt;\n  atlas_occurrences()\n\nhoneyeaters$taxonRank |&gt; unique()\n\nhoneyeaters |&gt; filter(taxonRank == \"species\")\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\n# honeyeaters &lt;- galah_call() |&gt;\n#   galah_identify(\"Meliphagidae\") |&gt;\n#   galah_filter(year == 2012 & stateProvince == \"New South Wales\") |&gt;\n#   galah_select(group = \"basic\", taxonRank) |&gt;\n#   atlas_occurrences()\n\n# write_parquet(honeyeaters, \"data/galah/honeyeater\")\n\nhoneyeaters &lt;- open_dataset(\"../data/galah/honeyeater\") |&gt; collect()\n\nhoneyeaters$taxonRank |&gt; unique()\n\n[1] \"species\"    \"genus\"      \"subgenus\"   \"subspecies\" \"family\"    \n\nhoneyeaters |&gt; filter(taxonRank == \"species\")\n\n# A tibble: 43,684 × 9\n   decimalLatitude decimalLongitude eventDate           scientificName          \n             &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;                   \n 1           -37.4             150. 2012-09-26 14:00:00 Meliphaga (Meliphaga) l…\n 2           -37.4             150. 2012-09-26 14:00:00 Acanthorhynchus tenuiro…\n 3           -37.4             150. 2012-04-07 14:00:00 Acanthorhynchus tenuiro…\n 4           -37.4             150. 2012-04-07 14:00:00 Nesoptilotis leucotis   \n 5           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Meliornis…\n 6           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Phylidony…\n 7           -37.4             150. 2012-04-07 14:00:00 Nesoptilotis leucotis   \n 8           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Meliornis…\n 9           -37.4             150. 2012-04-07 14:00:00 Melithreptus (Melithrep…\n10           -37.4             150. 2012-04-07 14:00:00 Acanthorhynchus tenuiro…\n# ℹ 43,674 more rows\n# ℹ 5 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, taxonRank &lt;chr&gt;\n\n\n\n\nInconsistent higher taxonomy\nA great approach to detect inconsistencies in your taxonomic data is to compute counts for each level of taxonomic rank. These counts act as a check for you to verify that the data is in line with your expectation. This is particularly important when combining data from different sources where their taxonomy might vary. If you have detected inconsistencies as we have done below, you will have to correct accordingly, either by consulting a taxonomic expert or a naming authority and ensure this is reported in your methods.\n\n# Get counts for every species where they have more than 1 class\nplants |&gt;\n  select(phylum:species, scientific_name) |&gt;\n  distinct() |&gt;\n  group_by(species) |&gt;\n  summarise(n_class = length(unique(class))) |&gt;\n  filter(n_class &gt; 1)\n\n# A tibble: 1 × 2\n  species               n_class\n  &lt;chr&gt;                   &lt;int&gt;\n1 Allocasuarina distyla       2\n\n# Get the species that have more than 1 class\ninconsistent_taxa &lt;- plants |&gt;\n  select(phylum:species, scientific_name) |&gt;\n  distinct() |&gt;\n  group_by(species) |&gt;\n  summarise(n_class = length(unique(class))) |&gt;\n  filter(n_class &gt; 1) |&gt;\n  pull(species)\n\n# Filter species that have more than 1 class\nplants |&gt;\n  filter(species %in% inconsistent_taxa) |&gt;\n  select(phylum:species, scientific_name) |&gt;\n  arrange(species) |&gt;\n  distinct()\n\n# A tibble: 2 × 7\n  phylum       class         order   family        genus species scientific_name\n  &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          \n1 Tracheophyta Magnoliopsida Fagales Casuarinaceae Allo… Alloca… Allocasuarina …\n2 Tracheophyta Equisetopsida Fagales Casuarinaceae Allo… Alloca… Allocasuarina …",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/unexpected-values.html#unexpected-values",
    "href": "3_cleaning_general/unexpected-values.html#unexpected-values",
    "title": "9  Unexpected values",
    "section": "",
    "text": "Checking for unexpected values: this is a generic method but the resolution logic depends on the issue (taxonomic, categories, strings, etc.)\n\nContext: a merged dataset pertaining to a single species (using data frame from cleaning_integration.qmd). Species is L. chloris\n\nAssumption: species column contains only one species\n\nMethod: unique(merged_data$species)\nResult: two species names\nResolution: conform to one species name (assign)\n\nAssumption: country code contains only one country\n\nMethod: unique(merged_data$country_code)\nResult: AU, NA, JP\nResolution: Investigate NA and assign, investigate JP since chloris is an Australian species",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unexpected values</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/unexpected-values.html#summary",
    "href": "3_cleaning_general/unexpected-values.html#summary",
    "title": "9  Unexpected values",
    "section": "9.2 Summary",
    "text": "9.2 Summary\nIn this chapter, we learned a few basic checks for cleaning datasets, including methods to detect inconsistencies in date formats, coordinate systems, and units.",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unexpected values</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/strings.html#basic-string-manipulation",
    "href": "3_cleaning_general/strings.html#basic-string-manipulation",
    "title": "12  Strings",
    "section": "12.1 Basic string manipulation",
    "text": "12.1 Basic string manipulation\nThe stringr package provides a number of useful functions for manipulating strings, many of which are useful when dealing with biodiversity data.\n\nlibrary(stringr)\n\nWarning: package 'stringr' was built under R version 4.3.2\n\nstr_trim(\"  Genus specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trim(\"  Genus specificus  \", side = \"left\")\n\n[1] \"Genus specificus  \"\n\nstr_squish(\"  Genus   specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trunc(\"Genus specificus\", width = 10, side = \"right\")\n\n[1] \"Genus s...\"\n\nstr_split(\"Genus specificus\", \" \")\n\n[[1]]\n[1] \"Genus\"      \"specificus\"\n\nstr_c(\"Genus\", \"specificus\", sep = \"_\")\n\n[1] \"Genus_specificus\"",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/strings.html#matching",
    "href": "3_cleaning_general/strings.html#matching",
    "title": "10  Strings",
    "section": "10.2 Matching",
    "text": "10.2 Matching\nMatching strings is a common task when working with biodiversity data. etc etc.\n\n10.2.1 Basic matching\nThe stringr package provides a number of functions for matching strings using patterns.\n\n# detect and remove\nstr_detect(\"Genus specificus\", \"Genus\")\n\n[1] TRUE\n\nstr_remove(\"Genus specificus\", pattern = \"Genus \")\n\n[1] \"specificus\"\n\n# locate and subset\nrecords &lt;- c(\"Genus\", \"species\", \"Genus species\", \"Difgenus difspecies\")\nstr_locate(records, \"Genus\")\n\n     start end\n[1,]     1   5\n[2,]    NA  NA\n[3,]     1   5\n[4,]    NA  NA\n\nstr_subset(records, \"Genus\")\n\n[1] \"Genus\"         \"Genus species\"\n\n\n\n\n10.2.2 Regex matching\nThe examples above demonstrate the use of basic patterns. But for cases that need more specific or advanced matching we can use regular expressions (regex). Regex is a powerful tool used to match patterns in strings, replace characters in strings, and extract substrings from strings. Regex can be complex and unintuitive, but there are websites available, such as Regex Generator, that are extremely helpful. Here we explore a few basic examples, and keep in mind that these methods can be applied to both column name strings and column values. In the case of column names, regex can be useful when conforming datasets (see Integration) or to meet a stylistic requirement. Applied to column values, there is a range of utility, such as unifying the formatting of taxonomic or location names.\nThe str_view() function is particularly useful for exploring regular expressions to see pattern matches. The results are shown in the console, and elements matched by the regex are surrounded with angle brackets &lt; &gt;.\n\n# Match the first word in the string (the genus)\nstr_view(tree_kangaroo$scientificName, \"^[A-Z][a-z]+\")\n\n [1] │ &lt;Dendrolagus&gt; lumholtzi\n [2] │ &lt;Dendrolagus&gt; lumholtzi\n [3] │ &lt;Dendrolagus&gt; lumholtzi\n [4] │ &lt;Dendrolagus&gt; lumholtzi\n [5] │ &lt;Dendrolagus&gt;\n [6] │ &lt;Dendrolagus&gt; bennettianus\n [7] │ &lt;Dendrolagus&gt; lumholtzi\n [8] │ &lt;Dendrolagus&gt; lumholtzi\n [9] │ &lt;Dendrolagus&gt;\n[10] │ &lt;Dendrolagus&gt; bennettianus\n[11] │ &lt;Dendrolagus&gt; lumholtzi\n[12] │ &lt;Dendrolagus&gt;\n[13] │ &lt;Dendrolagus&gt;\n[14] │ &lt;Dendrolagus&gt; lumholtzi\n[15] │ &lt;Dendrolagus&gt; bennettianus\n[16] │ &lt;Dendrolagus&gt; lumholtzi\n[17] │ &lt;Dendrolagus&gt;\n[18] │ &lt;Dendrolagus&gt; lumholtzi\n[19] │ &lt;Dendrolagus&gt; lumholtzi\n[20] │ &lt;Dendrolagus&gt; lumholtzi\n... and 1237 more\n\n# Match only the second word (species name)\nstr_view(tree_kangaroo$scientificName, \"(?&lt;=\\\\s)[a-z]+\")\n\n [1] │ Dendrolagus &lt;lumholtzi&gt;\n [2] │ Dendrolagus &lt;lumholtzi&gt;\n [3] │ Dendrolagus &lt;lumholtzi&gt;\n [4] │ Dendrolagus &lt;lumholtzi&gt;\n [6] │ Dendrolagus &lt;bennettianus&gt;\n [7] │ Dendrolagus &lt;lumholtzi&gt;\n [8] │ Dendrolagus &lt;lumholtzi&gt;\n[10] │ Dendrolagus &lt;bennettianus&gt;\n[11] │ Dendrolagus &lt;lumholtzi&gt;\n[14] │ Dendrolagus &lt;lumholtzi&gt;\n[15] │ Dendrolagus &lt;bennettianus&gt;\n[16] │ Dendrolagus &lt;lumholtzi&gt;\n[18] │ Dendrolagus &lt;lumholtzi&gt;\n[19] │ Dendrolagus &lt;lumholtzi&gt;\n[20] │ Dendrolagus &lt;lumholtzi&gt;\n[21] │ Dendrolagus &lt;lumholtzi&gt;\n[24] │ Dendrolagus &lt;lumholtzi&gt;\n[25] │ Dendrolagus &lt;bennettianus&gt;\n[27] │ Dendrolagus &lt;lumholtzi&gt;\n[28] │ Dendrolagus &lt;lumholtzi&gt;\n... and 854 more\n\n\n\n\n10.2.3 Replacements\nIn base R the gsub() function can be used for pattern replacement. In stringr, the str_replace() function can be used to replace the first match of a string. The str_replace_all() function can be used to replace all matches.\n\n# str_replace() example\n\nBase example:\n\ntree_kangaroo$scientificName &lt;- gsub(\n  pattern = \"Dendrolagus\",\n  replacement = \"Newname\",\n  x = tree_kangaroo$scientificName\n)",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/strings.html#case-style",
    "href": "3_cleaning_general/strings.html#case-style",
    "title": "10  Strings",
    "section": "10.3 Case style",
    "text": "10.3 Case style\nCase style can vary across data providers due to variable naming conventions. There are some basic functions available to change the case of strings in stringr:\n\nstr_to_lower(plants$scientific_name[1])\n\n[1] \"hakea eriantha\"\n\nstr_to_upper(plants$scientific_name[1])\n\n[1] \"HAKEA ERIANTHA\"\n\nstr_to_title(plants$scientific_name[1])\n\n[1] \"Hakea Eriantha\"\n\n\nIn some cases a more specific detection and replacement is required. For example, the World Register of Marine Species (WoRMS) uses a combination of lower case (scientific_name) and camel case (isExtinct). However, the Australian Fauna Directory (AFD) uses screaming snake case e.g. SCIENTIFIC_NAME. To work with both, case differences can be conformed to a single style, but the format you choose is a matter of personal preference.\n\n\nworms_small &lt;- head(worms)\n\n# gsub is a base R function for replacing strings\ncolnames(worms_small) &lt;- sapply(colnames(worms_small), function(name) {\n  name &lt;- tolower(gsub(\"([a-z])([A-Z])\", \"\\\\1_\\\\2\", name))\n  gsub(\"^_\", \"\", name)\n})\n\n# stringr version of above (with a slightly different regex approach)\ncolnames(worms_small) &lt;- sapply(colnames(worms_small), function(name) {\n  str_to_lower(str_replace_all(name, \"(?&lt;=\\\\p{Ll})(\\\\p{Lu})\", \"_\\\\1\"))\n})",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/strings.html#taxonomy",
    "href": "3_cleaning_general/strings.html#taxonomy",
    "title": "10  Strings",
    "section": "10.4 Taxonomy",
    "text": "10.4 Taxonomy\n\nlibrary(arrow)\nlibrary(tidyverse)\nlibrary(janitor)\n\nbees &lt;- read_parquet(\"../data/dap/bees.parquet\")\n\nplants &lt;- open_dataset(\"../data/dap/plants_subset\",\n  format = \"parquet\"\n) |&gt; collect()\n\n### Making some fake missing data for inverts in Class column\ninverts &lt;- open_dataset(\"../data/dap/inverts_subset\") |&gt; collect()\n\nset.seed(5)\ntobemissing &lt;- inverts |&gt;\n  filter(class == \"arachnida\") |&gt;\n  sample_frac(0.3) |&gt;\n  pull(scientific_name) |&gt;\n  unique()\n\ninverts &lt;- inverts |&gt;\n  mutate(class = ifelse(scientific_name %in% tobemissing, NA, class))\n\nAdvances in taxonomy, especially in molecular biology has allowed researchers to describe new species more efficiently than ever before (Garraffoni et al. 2019). Modern approaches has also enabled reclassification of organisms that have been incorrectly described in the past. Unfortunately, multiple names (synonyms) for the same organism can arise when taxonomy is not unanimously agreed upon by researchers.\nHarmonising taxonomic names is a prevalent and complex issue and so far, no unifying solution has been put forward — making research with biodiversity data challenging. A potential solution would require pulling together domain knowledge from experts and compiling a database for where taxonomic history for describe species is traceable and linked with published literature.\nWhile there is no perfect solution, some tips, tricks and tools do exist. In this chapter we will go through some of these to clean taxonomic data and deal with synonyms.\n\n10.4.1 Capitalisation\nNormally higher taxonomy are capitalised e.g. Myrtaceae or Aves. Capitalisation errors are usually quick to spot when you print the data object. Alternatively you can try using str_subset on columns you expect to have capital letters.\nThe code below subsets out unique values for the variable class that have upper case letters. Notice that no matches are found\n\nlibrary(tidyverse)\n\nstr_subset(unique(bees$class), \"[:upper:]\")\n\ncharacter(0)\n\n\nWe can confirm that there are no upper case matches by subsetting unique values that have lower case letters to see what is going on. This shows us that Insecta is inputted entirely in lowercase.\n\nstr_subset(unique(bees$class), \"[:lower:]\")\n\n[1] \"insecta\"\n\n\nWe can correct the lower case formatting as below, remember to check the fix before overwriting/removing the erroneous column(s)\n\nbees |&gt;\n  mutate(class_corrected = str_to_sentence(class)) |&gt;\n  select(starts_with(\"class\"))\n\n# A tibble: 1,139 × 2\n   class   class_corrected\n   &lt;chr&gt;   &lt;chr&gt;          \n 1 insecta Insecta        \n 2 insecta Insecta        \n 3 insecta Insecta        \n 4 insecta Insecta        \n 5 insecta Insecta        \n 6 insecta Insecta        \n 7 insecta Insecta        \n 8 insecta Insecta        \n 9 insecta Insecta        \n10 insecta Insecta        \n# ℹ 1,129 more rows\n\nbees_corrected &lt;- bees |&gt;\n  mutate(class_corrected = str_to_sentence(class)) |&gt;\n  select(-class) |&gt; # Remove erroreous column\n  rename(class = class_corrected) # Rename corrected column as the new 'class'\n\n\n\n10.4.2 Seperators\nIn a taxonomic data, separators such as, spaces and underscore are found in scientific names and are used to delineate the genus and species name. While it is personal choice which separator you use, it is good practice to be consistent with your choice. Consistency ensures that unique values of scientific name truly reflects unique species and not due to inconsistencies.\nTry tabyl-ing your taxonomic columns to check if you have any inconsistencies first\n\nlibrary(janitor)\n\nplants |&gt;\n  pull(scientific_name) |&gt;\n  tabyl() |&gt;\n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants, scientific_name)`         n  percent\n   &lt;chr&gt;                               &lt;int&gt;    &lt;dbl&gt;\n 1 Acacia asparagoides                     2 0.000962\n 2 Acacia barakulensis                     1 0.000481\n 3 Acacia barringtonensis                  2 0.000962\n 4 Acacia beadleana                        1 0.000481\n 5 Acacia betchei                          6 0.00289 \n 6 Acacia blayana                          2 0.000962\n 7 Acacia brunioides                       1 0.000481\n 8 Acacia brunioides subsp. brunioides     6 0.00289 \n 9 Acacia brunioides subsp. granitica      1 0.000481\n10 Acacia bulgaensis                       3 0.00144 \n# ℹ 613 more rows\n\n\nConsistent taxonomic formatting may not be an issue if you are downloading data from one single source such as the ALA where scientific names are already formatted consistently e.g. “Moloch horridus”. This may not be the case when consolidating data from multiple sources.\nBelow is code to create an underscore scientific name from one that is separated with a space. Remember to check your changes\n\nplants_updated &lt;- plants |&gt;\n  mutate(scientific_name_undersc = str_replace_all(scientific_name, \" \", \"_\"))\n\nplants_updated |&gt;\n  pull(scientific_name_undersc) |&gt;\n  tabyl() |&gt;\n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants_updated, scientific_name_undersc)`     n  percent\n   &lt;chr&gt;                                           &lt;int&gt;    &lt;dbl&gt;\n 1 Acacia_asparagoides                                 2 0.000962\n 2 Acacia_barakulensis                                 1 0.000481\n 3 Acacia_barringtonensis                              2 0.000962\n 4 Acacia_beadleana                                    1 0.000481\n 5 Acacia_betchei                                      6 0.00289 \n 6 Acacia_blayana                                      2 0.000962\n 7 Acacia_brunioides                                   1 0.000481\n 8 Acacia_brunioides_subsp._brunioides                 6 0.00289 \n 9 Acacia_brunioides_subsp._granitica                  1 0.000481\n10 Acacia_bulgaensis                                   3 0.00144 \n# ℹ 613 more rows\n\n\n\nDax’s note\nI think we can delete the case study below for brevity. I’ve left it in case it generates any additional ideas for the chapter.",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/strings.html#simple-case-study",
    "href": "3_cleaning_general/strings.html#simple-case-study",
    "title": "10  Strings",
    "section": "10.5 Simple case study",
    "text": "10.5 Simple case study\nWe will use the janitor R package to explore whether our elephant data has any string issues. The function tabyl will compute a counts and percent of total rows for each unique value.\n\nlibrary(dplyr)\nlibrary(janitor)\nafrican_ele &lt;- arrow::read_parquet(\"../data/gbif/elephant\")\nafrican_ele |&gt;\n  pull(stateProvince) |&gt;\n  tabyl() |&gt;\n  tibble() |&gt;\n  print(n = 20)\n\n# A tibble: 199 × 4\n   `pull(african_ele, stateProvince)`     n   percent valid_percent\n   &lt;chr&gt;                              &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez                                 1 0.0000556     0.0000867\n 2 Al Qahirah                             1 0.0000556     0.0000867\n 3 Alibori                              601 0.0334        0.0521   \n 4 Arusha                               333 0.0185        0.0289   \n 5 Arusha Region                          1 0.0000556     0.0000867\n 6 Atacora                              366 0.0204        0.0317   \n 7 Atakora                              249 0.0139        0.0216   \n 8 Balaka                                 8 0.000445      0.000694 \n 9 Bassila                                1 0.0000556     0.0000867\n10 Batha                                  1 0.0000556     0.0000867\n11 Bauchi                                 7 0.000389      0.000607 \n12 Bengo                                  3 0.000167      0.000260 \n13 Bizerte                                2 0.000111      0.000173 \n14 Borgou                                 7 0.000389      0.000607 \n15 Bouaflé                                3 0.000167      0.000260 \n16 Bouna                                  1 0.0000556     0.0000867\n17 Budongo Forest                         1 0.0000556     0.0000867\n18 Bushenyi                              85 0.00473       0.00737  \n19 Cabo Delgado                           3 0.000167      0.000260 \n20 Cape Prov.                             2 0.000111      0.000173 \n# ℹ 179 more rows\n\n\nFrom the tabyl output, we can see there are few different variations of Province, Prov., Prov. As an example, we will correct these with the tidyverse packages stringr, dplyr, tidyr as well as glue.\n\nlibrary(glue)\n# Create a regular expression to match Prov. and Prov\npattern &lt;- regex(\"Prov(?![:lower:])\")\n# Use `str_subset` to pull out the cases that match our pattern\n# Confirm that these are the problematic ones\n# Assign these into an object\nstr_subset(african_ele$stateProvince, pattern = pattern)\n\n [1] \"Cape Prov.\"        \"Cape Prov.\"        \"West Nile Prov.\"  \n [4] \"Central Prov\"      \"Central Prov\"      \"Coastal Prov\"     \n [7] \"Northeastern Prov\" \"Central Prov\"      \"Eastern Prov\"     \n[10] \"Coastal Prov\"     \n\ntypos_provinces &lt;- str_subset(african_ele$stateProvince, pattern = pattern)\n\n# Create a new variable `stateProvince_clean`\n# `str_detect` for matches of pattern (returns TRUE for match)\n# `if_else`: if TRUE, the `glue` function will take the first part of the province name enclosed in and join it with word Province.\n# if FALSE , it will just take the corresponding value in stateProvince\n# Note that we are assigning these changes to a new object (`african_ele_2`)\nafrican_ele_2 &lt;- african_ele %&gt;%\n  mutate(stateProvince_clean = if_else(str_detect(stateProvince, pattern = pattern),\n    true = glue('{word(stateProvince, sep = \" P\")} Province'),\n    false = stateProvince\n  ))\n\n# Once we've made the correction we want to check we've done it correctly.\n# ALWAYS CHECK YOUR CORRECTIONS\n# Use the `select` function to isolate columns that `starts_with` \"stateProvince\"\n# Use the `filter` function to subset our the problematic provinces\nafrican_ele_2 %&gt;%\n  select(starts_with(\"stateProvince\")) %&gt;%\n  filter(stateProvince %in% typos_provinces)\n\n# A tibble: 10 × 2\n   stateProvince     stateProvince_clean  \n   &lt;chr&gt;             &lt;glue&gt;               \n 1 Cape Prov.        Cape Province        \n 2 Cape Prov.        Cape Province        \n 3 West Nile Prov.   West Nile Province   \n 4 Central Prov      Central Province     \n 5 Central Prov      Central Province     \n 6 Coastal Prov      Coastal Province     \n 7 Northeastern Prov Northeastern Province\n 8 Central Prov      Central Province     \n 9 Eastern Prov      Eastern Province     \n10 Coastal Prov      Coastal Province     \n\n# Its good practice to check the other values were not affected by your corrections\n# Here we are removing the NA with `drop_na` and subsetting unique rows with `distinct`\nafrican_ele_2 %&gt;%\n  select(starts_with(\"stateProvince\")) %&gt;%\n  tidyr::drop_na() %&gt;%\n  distinct()\n\n# A tibble: 198 × 2\n   stateProvince    stateProvince_clean\n   &lt;chr&gt;            &lt;glue&gt;             \n 1 Southern         Southern           \n 2 Taita Taveta     Taita Taveta       \n 3 Mara             Mara               \n 4 Arusha           Arusha             \n 5 Simiyu           Simiyu             \n 6 Morogoro         Morogoro           \n 7 Mashonaland West Mashonaland West   \n 8 Mpumalanga       Mpumalanga         \n 9 KwaZulu-Natal    KwaZulu-Natal      \n10 Manicaland       Manicaland         \n# ℹ 188 more rows\n\n# Final check\n# Check with the original code that detected the issue\nafrican_ele_2 %&gt;%\n  pull(stateProvince_clean) %&gt;%\n  tabyl() %&gt;%\n  tibble() %&gt;%\n  print(n = 20)\n\n# A tibble: 197 × 4\n   .                  n   percent valid_percent\n   &lt;glue&gt;         &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez             1 0.0000556     0.0000867\n 2 Al Qahirah         1 0.0000556     0.0000867\n 3 Alibori          601 0.0334        0.0521   \n 4 Arusha           333 0.0185        0.0289   \n 5 Arusha Region      1 0.0000556     0.0000867\n 6 Atacora          366 0.0204        0.0317   \n 7 Atakora          249 0.0139        0.0216   \n 8 Balaka             8 0.000445      0.000694 \n 9 Bassila            1 0.0000556     0.0000867\n10 Batha              1 0.0000556     0.0000867\n11 Bauchi             7 0.000389      0.000607 \n12 Bengo              3 0.000167      0.000260 \n13 Bizerte            2 0.000111      0.000173 \n14 Borgou             7 0.000389      0.000607 \n15 Bouaflé            3 0.000167      0.000260 \n16 Bouna              1 0.0000556     0.0000867\n17 Budongo Forest     1 0.0000556     0.0000867\n18 Bushenyi          85 0.00473       0.00737  \n19 Cabo Delgado       3 0.000167      0.000260 \n20 Cape Province      3 0.000167      0.000260 \n# ℹ 177 more rows\n\n\nThere are some other issues that can be corrected in a similar approach:\n\nNorth West, North West District and North-Western\nÀfrica Central, Central Province and Central\nAtacora and Atakora\nCoastal Province and Coastal\n\nWe recommend consulting reputable sources to delineate and consolidate similar values.\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067.",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/dates.html",
    "href": "3_cleaning_general/dates.html",
    "title": "11  Dates",
    "section": "",
    "text": "Some use cases may require dates beyond a simple year value. Standardising dates involves ensuring that the variables in a dataset have values that conform to a consistent and standard format. An example of unstandardised data is having varied date formats (e.g. DD/MM/YYYY for some entries and MM/DD/YYYY for others). This may be necessary when integrating data from multiple sources, but it is important to remember that there can be inconsistencies even within a single source dataset.",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Dates</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/column-names-and-classes.html#setup",
    "href": "3_cleaning_general/column-names-and-classes.html#setup",
    "title": "14  Column names & classes",
    "section": "14.1 Setup",
    "text": "14.1 Setup\n\nlibrary(galah)\ngalah_config(atlas = \"Australia\") # default\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"))\n\nresult &lt;- galah_call() |&gt;\n  galah_identify(\"Litoria\") |&gt;\n  galah_filter(year &gt;= 2020, cl22 == \"Tasmania\") |&gt;\n  atlas_occurrences()\nresult |&gt; head()\n\n# A tibble: 6 × 8\n  recordID        scientificName taxonConceptID decimalLatitude decimalLongitude\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 00168ca6-84d0-… Litoria        https://biodi…           -41.2             146.\n2 00250163-ec50-… Litoria        https://biodi…           -41.2             147.\n3 003e0f63-9f95-… Litoria ewing… https://biodi…           -42.9             148.\n4 00410554-5289-… Litoria ewing… https://biodi…           -41.7             147.\n5 0070521f-bb45-… Litoria ewing… https://biodi…           -43.1             147.\n6 0081e7ef-459b-… Litoria ewing… https://biodi…           -43.2             147.\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Column names & classes</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/column-names-and-classes.html#cleaning-column-names",
    "href": "3_cleaning_general/column-names-and-classes.html#cleaning-column-names",
    "title": "12  Column names & classes",
    "section": "12.2 Cleaning column names",
    "text": "12.2 Cleaning column names\n\nInfo about using {janitor} and clean_names()?\nInfo about renaming columns\nInfo about splitting and/or joining columns?",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Column names & classes</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/column-names-and-classes.html#column-classes",
    "href": "3_cleaning_general/column-names-and-classes.html#column-classes",
    "title": "12  Column names & classes",
    "section": "12.3 Column classes",
    "text": "12.3 Column classes\nWe can check for obvious inconsistencies using the classes of each column. We can do this with summary tables like a skimr report, or with base R. Below is a simple example where our decimalLatitude column is numeric, which is what we expect so in this case there is no problem. But as an example, if we change just one of the values to a degrees minutes seconds format, we can see that the class for the column changes to character.\n\nsapply(result, class)\n\n$recordID\n[1] \"character\"\n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$decimalLatitude\n[1] \"numeric\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$occurrenceStatus\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"\n\n# Change one of the values to a degrees minutes seconds format\nresult$decimalLatitude[5] &lt;- \"40° 51' 59 N\"\nsapply(result, class)\n\n$recordID\n[1] \"character\"\n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$decimalLatitude\n[1] \"character\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$occurrenceStatus\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Column names & classes</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/1_intro.html",
    "href": "4_cleaning_expert/1_intro.html",
    "title": "Cleaning data: Expert",
    "section": "",
    "text": "This section details data cleaning methods that rely on ecological/biological expert knowledge of your dataset. Not everything will apply to every dataset, and will depend on the species or clades that are in the data.",
    "crumbs": [
      "Cleaning data: Expert"
    ]
  },
  {
    "objectID": "4_cleaning_expert/taxonomic-synonyms.html#taxonomic-classification",
    "href": "4_cleaning_expert/taxonomic-synonyms.html#taxonomic-classification",
    "title": "13  Taxonomic validation",
    "section": "13.1 Taxonomic classification",
    "text": "13.1 Taxonomic classification\nTaxonomic classification is a complex issue when working with open source biodiversity data. Data infrastructures have their own taxonomic systems, which can lead to variations across platforms in hierarchical information. Furthermore, taxonomic classification is in a state of constant change, and views may differ within the literature or across authorities (refer back to Taxonomy and open source data). As a result, it is often the case that you will have synonyms, meaning, more than one name for the same species, in your dataset. Keep in mind that there is no universal solution to these issues. However you choose to resolve them, we recommend that you maintain a clear and explicit record of any decisions and changes made with respect to the data.\n\n13.1.1 Detecting synonyms\nThere are several packages available that can be used to query different taxonomic databases and check for synonyms.\n\n13.1.1.1 worrms\nThe {worrms} is the R interface to the World Register of Marine Species and has the ability to cross check synonyms with their database for taxa that has an AphiaID. The function will return synonymous record(s) associated with another different AphiaID.\n\nlibrary(worrms)\nlibrary(tidyverse)\n\nmarine_sp &lt;- read_csv(\"../data/worms/worms.csv\")\n\nmarine_sp |&gt;\n  slice(7) |&gt;\n  pull(AphiaID) |&gt;\n  wm_synonyms()\n\n# A tibble: 1 × 27\n  AphiaID url   scientificname authority status unacceptreason taxonRankID rank \n    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;                &lt;int&gt; &lt;chr&gt;\n1  453207 http… Goniosoma ina… Walker, … super… NA                     220 Spec…\n# ℹ 19 more variables: valid_AphiaID &lt;int&gt;, valid_name &lt;chr&gt;,\n#   valid_authority &lt;chr&gt;, parentNameUsageID &lt;int&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   citation &lt;chr&gt;, lsid &lt;chr&gt;, isMarine &lt;int&gt;, isBrackish &lt;int&gt;,\n#   isFreshwater &lt;int&gt;, isTerrestrial &lt;int&gt;, isExtinct &lt;int&gt;, match_type &lt;chr&gt;,\n#   modified &lt;chr&gt;\n\n\n\n\n13.1.1.2 taxize\n\n\nThe taxize package allows users to search over many taxonomic data sources for hierarchial taxonomic information, such as species names (scientific and common), to resolve synonymy. The gnr_resolve() function matches a supplied list with up to 118 data sources including GBIF, Catalogue of Life, World Register of Marine Species and many more. The function scores how well matched your name is to these sources.\n\nlibrary(taxize)\n\nWarning: package 'taxize' was built under R version 4.3.2\n\n# Read in a naming authority list\nafd &lt;- read_csv(\"../data/naming/afd.csv\")\n\nRows: 49 Columns: 32\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (28): GROUP_NAME, HIGHER_CLASSIFICATION, KINGDOM, PHYLUM, SUBPHYLUM, CLA...\ndbl  (1): YEAR\nlgl  (3): SUPERCLASS, SUPERTRIBE, SUBTRIBE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nunique(afd$VALID_NAME)\n\n [1] \"Prosphaerosyllis battiri\"         \"Clavellopsis parasargi\"          \n [3] \"Platypontonia hyotis\"             \"Palirhoeus eatoni\"               \n [5] \"Diastylis kapalae\"                \"Xenobates chinai\"                \n [7] \"Paratanais gaspodei\"              \"Paradexamine flindersi\"          \n [9] \"Prostebbingia brevicornis\"        \"Cythere lactea\"                  \n[11] \"Cythere melobesioides\"            \"Achelia transfugoides\"           \n[13] \"Halobates (Halobates) acherontis\" \"Quadraceps hopkinsi apophoretus\" \n[15] \"Anabarhynchus striatus\"           \"Australocytheridea vandenboldi\"  \n[17] \"Enigmaplax littoralis\"            \"Hyphalus insularis\"              \n[19] \"Plesiopenaeus armatus\"            \"Uroptychus brucei\"               \n[21] \"Caligus dasyaticus\"               \"Coralliophila tetragona\"         \n[23] \"Triphora alveolata\"               \"Clavus obliquatus\"               \n[25] \"Naria beckii\"                     \"Pharaonella rostrata\"            \n[27] \"Lasaea australis\"                 \"Cadulus rudmani\"                 \n[29] \"Bembicium flavescens\"             \"Mormula philippiana\"             \n[31] \"Turbonilla tiara\"                 \"Chlorodiloma crinita\"            \n[33] \"Mitrella merita\"                  \"Tritonoharpa antiquata\"          \n[35] \"Mauritia depressa dispersa\"       \"Laevidentalium zeidleri\"         \n[37] \"Conus (Harmoniconus) musicus\"     \"Marionia cyanobranchiata\"        \n[39] \"Tucetona flabellata\"              \"Neochromadora bilineata\"         \n[41] \"Desmoscolex membranosus\"          \"Echeneidocoelium indicum\"        \n[43] \"Indodidymozoon suttiei\"           \"Diploproctodaeum yosogi\"         \n[45] \"Pseudopecoelus japonicus\"         \"Pedibothrium lloydae\"            \n[47] \"Amphitethya stipitata\"            \"Pseudosuberites mollis\"          \n[49] \"Psammochela psammodes\"           \n\n# Resolve names\nresolved &lt;- gnr_resolve(unique(afd$VALID_NAME), best_match_only = TRUE)\nresolved |&gt; print(n = 50)\n\n# A tibble: 49 × 5\n   user_supplied_name        submitted_name matched_name data_source_title score\n * &lt;chr&gt;                     &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt;\n 1 Prosphaerosyllis battiri  Prosphaerosyl… Prosphaeros… National Center … 0.988\n 2 Clavellopsis parasargi    Clavellopsis … Clavellopsi… uBio NameBank     0.988\n 3 Platypontonia hyotis      Platypontonia… Platyponton… National Center … 0.988\n 4 Palirhoeus eatoni         Palirhoeus ea… Palirhoeus … Wikispecies       0.988\n 5 Diastylis kapalae         Diastylis kap… Diastylis k… Encyclopedia of … 0.988\n 6 Xenobates chinai          Xenobates chi… Xenobates c… Encyclopedia of … 0.988\n 7 Paratanais gaspodei       Paratanais ga… Paratanais … Wikispecies       0.988\n 8 Paradexamine flindersi    Paradexamine … Paradexamin… Encyclopedia of … 0.988\n 9 Prostebbingia brevicornis Prostebbingia… Prostebbing… Encyclopedia of … 0.988\n10 Cythere lactea            Cythere lactea Cythere lac… Encyclopedia of … 0.988\n11 Cythere melobesioides     Cythere melob… Cythere mel… Encyclopedia of … 0.988\n12 Achelia transfugoides     Achelia trans… Achelia tra… National Center … 0.988\n13 Halobates (Halobates) ac… Halobates (ha… Halobates (… CU*STAR           0.999\n14 Quadraceps hopkinsi apop… Quadraceps ho… Quadraceps … Catalogue of Lif… 0.999\n15 Anabarhynchus striatus    Anabarhynchus… Anabarhynch… Encyclopedia of … 0.988\n16 Australocytheridea vande… Australocythe… Australocyt… Encyclopedia of … 0.988\n17 Enigmaplax littoralis     Enigmaplax li… Enigmaplax … Encyclopedia of … 0.988\n18 Hyphalus insularis        Hyphalus insu… Hyphalus in… Wikispecies       0.988\n19 Plesiopenaeus armatus     Plesiopenaeus… Plesiopenae… Wikispecies       0.988\n20 Uroptychus brucei         Uroptychus br… Uroptychus … Wikispecies       0.988\n21 Caligus dasyaticus        Caligus dasya… Caligus das… Encyclopedia of … 0.988\n22 Coralliophila tetragona   Coralliophila… Coralliophi… Encyclopedia of … 0.988\n23 Triphora alveolata        Triphora alve… Triphora al… uBio NameBank     0.988\n24 Clavus obliquatus         Clavus obliqu… Clavus obli… Encyclopedia of … 0.988\n25 Naria beckii              Naria beckii   Naria beckii National Center … 0.988\n26 Pharaonella rostrata      Pharaonella r… Pharaonella… Arctos            0.988\n27 Lasaea australis          Lasaea austra… Lasaea aust… National Center … 0.988\n28 Cadulus rudmani           Cadulus rudma… Cadulus rud… Encyclopedia of … 0.988\n29 Bembicium flavescens      Bembicium fla… Bembicium f… National Center … 0.988\n30 Mormula philippiana       Mormula phili… Mormula phi… Encyclopedia of … 0.988\n31 Turbonilla tiara          Turbonilla ti… Turbonilla … Encyclopedia of … 0.988\n32 Chlorodiloma crinita      Chlorodiloma … Chlorodilom… National Center … 0.988\n33 Mitrella merita           Mitrella meri… Mitrella me… Encyclopedia of … 0.988\n34 Tritonoharpa antiquata    Tritonoharpa … Tritonoharp… National Center … 0.988\n35 Mauritia depressa disper… Mauritia depr… Mauritia de… National Center … 0.999\n36 Laevidentalium zeidleri   Laevidentaliu… Laevidental… Encyclopedia of … 0.988\n37 Conus (Harmoniconus) mus… Conus (harmon… Conus Linna… Catalogue of Lif… 0.75 \n38 Marionia cyanobranchiata  Marionia cyan… Marionia cy… National Center … 0.988\n39 Tucetona flabellata       Tucetona flab… Tucetona fl… Encyclopedia of … 0.988\n40 Neochromadora bilineata   Neochromadora… Neochromado… National Center … 0.988\n41 Desmoscolex membranosus   Desmoscolex m… Desmoscolex… Encyclopedia of … 0.988\n42 Echeneidocoelium indicum  Echeneidocoel… Echeneidoco… Integrated Taxon… 0.988\n43 Indodidymozoon suttiei    Indodidymozoo… Indodidymoz… National Center … 0.988\n44 Diploproctodaeum yosogi   Diploproctoda… Diploprocto… Encyclopedia of … 0.988\n45 Pseudopecoelus japonicus  Pseudopecoelu… Pseudopecoe… Integrated Taxon… 0.988\n46 Pedibothrium lloydae      Pedibothrium … Pedibothriu… Encyclopedia of … 0.988\n47 Amphitethya stipitata     Amphitethya s… Amphitethya… Wikispecies       0.988\n48 Pseudosuberites mollis    Pseudosuberit… Pseudosuber… Encyclopedia of … 0.988\n49 Psammochela psammodes     Psammochela p… Psammochela… Wikispecies       0.988\n\n# Retrieve synonyms\ntsn &lt;- get_tsn(unique(afd$VALID_NAME)[1:5])\n\n══  5 queries  ═══════════════\n\n\n\nRetrieving data for taxon 'Prosphaerosyllis battiri'\n\n\n✖  Not Found:  Prosphaerosyllis battiri\n\n\n\nRetrieving data for taxon 'Clavellopsis parasargi'\n\n\n✖  Not Found:  Clavellopsis parasargi\n\n\n\nRetrieving data for taxon 'Platypontonia hyotis'\n\n\n✔  Found:  Platypontonia hyotis\n\n\n\nRetrieving data for taxon 'Palirhoeus eatoni'\n\n\n✖  Not Found:  Palirhoeus eatoni\n\n\n\nRetrieving data for taxon 'Diastylis kapalae'\n\n\n✖  Not Found:  Diastylis kapalae\n══  Results  ═════════════════\n\n• Total: 5 \n• Found: 1 \n• Not Found: 4\n\nsynonyms(tsn)\n\n$&lt;NA&gt;\n[1] NA\n\n$&lt;NA&gt;\n[1] NA\n\n$`612530`\n  sub_tsn acc_tsn   syn_author                  syn_name syn_tsn\n1  612530  612530 Suzuki, 1971 Platypontonia pterostreae 1191962\n\n$&lt;NA&gt;\n[1] NA\n\n$&lt;NA&gt;\n[1] NA",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/taxonomic-synonyms.html#input-from-experts",
    "href": "4_cleaning_expert/taxonomic-synonyms.html#input-from-experts",
    "title": "13  Taxonomic validation",
    "section": "13.2 Input from experts",
    "text": "13.2 Input from experts\nProgrammatic solutions for resolving synonymy can only go so far. Seeking validation from experts is sensible if your goal is to obtain a high quality species list. Museums or taxonomic societies are extensive sources of knowledge. Below we have provided a list of some of Australian taxonomic society groups.\n\n13.2.1 Australian taxonomic society groups\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists\n\n\n\n13.2.2 Global taxonomy\n\nGBIF taxonomic backbone - Uses over 100 different sources\nIntegrated Taxonomic Information System, ITIS - Authoritative taxonomic information on plants, animals, fungi, and microbes\nCatalogue of Life - Global taxonomic catalogue",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/taxonomy.html#missing-data",
    "href": "4_cleaning_expert/taxonomy.html#missing-data",
    "title": "14  Taxonomy",
    "section": "14.1 Missing data",
    "text": "14.1 Missing data\nOne issue you might face is that higher taxonomy from different providers may not match. If this is the case, we suggest choosing the data provider with the higher taxonomy that is consistent with your naming authority and use it to back fill the higher taxonomy of the other data sources\n\n# higher_taxonomy &lt;- inverts %&gt;%\n#   select(scientificName) %&gt;%\n#   distinct() %&gt;%\n#   search_taxa()\n\n# higher_taxonomy",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/taxonomy.html#filtering-out-taxa",
    "href": "4_cleaning_expert/taxonomy.html#filtering-out-taxa",
    "title": "14  Taxonomy",
    "section": "14.2 Filtering out taxa",
    "text": "14.2 Filtering out taxa\nDepending on your project’s data scope, it may be necessary to remove certain groups of taxa. Here we present a few use cases, based on some commonly required criteria. This type of taxonomic filtering is particularly useful for large, multi-species datasets.\n\n14.2.1 Introduced or invasive species\nIf your project requires only native species, we can filter out those records using lists available online. Here we are using the list for Australia from the Global Register of Introduced and Invasive Species (GRIIS). After downloading this list, we read it into R, and exclude invasive species from our example dataset:\n\nlibrary(dplyr)\nplants &lt;- arrow::open_dataset(\"../data/dap/plants_subset\") |&gt; dplyr::collect()\ngriis_ls &lt;- read.csv(\"../data/lists/GRIIS_Australia_20230331-121730.csv\")\nglimpse(griis_ls)\n\nRows: 2,979\nColumns: 16\n$ scientific_name                  &lt;chr&gt; \"Oenothera longiflora L.\", \"Lampranth…\n$ scientific_name_type             &lt;chr&gt; \"species\", \"species\", \"species\", \"spe…\n$ kingdom                          &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ establishment_means              &lt;chr&gt; \"alien\", \"alien\", \"alien\", \"alien\", \"…\n$ is_invasive                      &lt;chr&gt; \"null\", \"null\", \"null\", \"null\", \"null…\n$ occurrence_status                &lt;chr&gt; \"present\", \"present\", \"present\", \"pre…\n$ checklist.name                   &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\"…\n$ checklist.iso_countrycode_alpha3 &lt;chr&gt; \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"A…\n$ accepted_name.species            &lt;chr&gt; \"Oenothera longiflora\", \"Lampranthus …\n$ accepted_name.kingdom            &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ accepted_name.phylum             &lt;chr&gt; \"Tracheophyta\", \"Tracheophyta\", \"Trac…\n$ accepted_name.class              &lt;chr&gt; \"Magnoliopsida\", \"Magnoliopsida\", \"Ma…\n$ accepted_name.order              &lt;chr&gt; \"Myrtales\", \"Caryophyllales\", \"Erical…\n$ accepted_name.family             &lt;chr&gt; \"Onagraceae\", \"Aizoaceae\", \"Ericaceae…\n$ accepted_name.habitat            &lt;chr&gt; \"[\\\"terrestrial\\\"]\", \"[\\\"terrestrial\\…\n$ accepted_name                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n# Check which species matched the GRIIS list\nmatches &lt;- filter(plants, scientific_name %in% griis_ls$accepted_name.species)\n\n# If you are happy with the matches, you can proceed to remove any records\n# that were matched\nplants_no_griis &lt;- filter(plants, !scientific_name %in% matches)\n\n\n\n\n\n\n\nTip\n\n\n\nYou can apply this concept of filtering to any list of species, or other fields, that you would like to exclude (or include, by removing the ! in the filter() step)\n\n\n\n\n14.2.2 Extinct species\nIn most cases, a year filter applied during your download query should remove most extinct species. Nevertheless, it is important to cross check for extinct species. We can do this using the Interim Register of Marine and Nonmarine Genera (IRMNG). The list is comprehensive and actively maintained. However, much of the data doesn’t go down to species level. As such, we recommend using the following approach to find potentially extinct taxa and further investigate the records that are flagged.\nThe required files are organised by year and can be downloaded from here, and unzipped to your project directory. Below we process the downloaded files and then check for matches in our dataset.\n\nirmng_taxa &lt;- arrow::open_dataset(\"../data/lists/IRMNG_genera_DwCA_2023-05-19/taxon_subset\") |&gt;\n  collect()\n\nirmng_sp &lt;- arrow::open_dataset(\"../data/lists/IRMNG_genera_DwCA_2023-05-19/speciesprofile\") |&gt;\n  collect()\n\n\n\nlibrary(\"stringr\")\ninverts &lt;- arrow::open_dataset(\"../data/galah/inverts\") |&gt; dplyr::collect()\n\nawc_pattern &lt;- \"(awaiting allocation)\"\ninsed_pattern &lt;- \"incertae sedis\"\n\ncleaned_irmng_taxa &lt;- irmng_taxa |&gt;\n  mutate(\n    class = ifelse(str_detect(class, pattern = paste0(awc_pattern, \"|\", insed_pattern)),\n      word(class), class\n    )\n  ) |&gt;\n  filter(taxonomicStatus == \"accepted\") |&gt; # Filter to accepted names\n  filter(\n    kingdom %in% c(\"Animalia\", \"Plantae\"),\n    !kingdom == \"Questionable / non-biota (fossil)\"\n  ) # Filter to Animal and plants - change if working with other kingdoms\n\n# Join with species profile, remove pesky values and filter to extinct taxa\nextinct_irmng &lt;- irmng_taxa |&gt;\n  left_join(irmng_sp, by = \"taxonID\") |&gt;\n  filter(!scientificName == \"Questionable / non-biota (fossil)\") |&gt;\n  filter(isExtinct == TRUE)\n\n# Summary of extinct species by taxonRank\nextinct_irmng$taxonRank |&gt; janitor::tabyl()\n\n extinct_irmng$taxonRank     n      percent\n                   Class    14 5.926177e-04\n                  Family  1675 7.090247e-02\n                   Genus 21718 9.193193e-01\n              Infraclass     1 4.232983e-05\n                   Order   210 8.889265e-03\n                  Phylum     4 1.693193e-04\n                Subclass     2 8.465967e-05\n\n# Create genus\ninverts_2 &lt;- inverts |&gt;\n  mutate(genus = word(scientificName, 1))\n\n# Extract unique extinct genus and remove genus that have punctuation in them\nextinct_genus &lt;- extinct_irmng |&gt;\n  tidyr::drop_na(genus) |&gt;\n  filter(!str_detect(genus, pattern = regex(\"[:punct:]\"))) |&gt;\n  pull(genus) |&gt;\n  unique()\n\n# Check if there are any matches at genus level\ncheck &lt;- inverts_2 |&gt;\n  filter(str_detect(genus, pattern = regex(paste0(extinct_genus, collapse = \"|\")))) |&gt;\n  pull(scientificName) |&gt;\n  unique()\n\nprint(check)\n\n[1] \"Halobates (Halobates) acherontis\"\n\n\nAlternatively, we can use the IUCN to retrieve a list of extinct species that are in their database. See the IUCN API for more information on queries based on species categories. Below we will the rredlist package to interface with the IUCN API. Note that you will need to register for an API token, which can take a day or two to be approved. Then we use the rl_sp_category(\"EX\") to return extinct species, to check against our dataset.\n\n\n# Create IUCN token\nrredlist::rl_use_iucn() # Application can take a day or two!\nusethis::edit_r_environ() # Place the approved token in your R environment\n\nextinct_iucn &lt;- rredlist::rl_sp_category(\"EX\")\nskimr::skim(extinct_iucn)\n\n# Note these are extinct species across the globe\nextinct_sp &lt;- tibble(extinct_iucn$result)\n\n# Find matches\nfilter(inverts, scientificName %in% extinct_sp$scientific_name) # No matches\n\n\n\n14.2.3 Biological attributes and life cycle stages\nIn some cases, you may want to filter out records based on attributes such as sex or life cycle stage, if this metadata is available for your records. In the example below, we download a dataset, including the extra metadata fields needed. We then examine the fields we want to filter by, to see what values are available and how many records are missing values.\n\nlibrary(galah)\n\ngalah_config(\n  email = Sys.getenv(\"ALA_EMAIL\"),\n  atlas = \"Australia\"\n)\n\nbilby &lt;- galah_call() |&gt;\n  galah_identify(\"Macrotis lagotis\") |&gt;\n  galah_filter(year == 2022) |&gt;\n  galah_select(group = \"basic\", sex, lifeStage, reproductiveCondition) |&gt;\n  atlas_occurrences()\n\n----\n\n# Quick way to check the unique values for each field\nlapply(bilby[c(\"sex\", \"lifeStage\", \"reproductiveCondition\")], unique)\n\n$sex\n[1] NA       \"FEMALE\" \"MALE\"  \n\n$lifeStage\n[1] NA\n\n$reproductiveCondition\n[1] NA                      \"- Not breeding\"        \"A Adult\"              \n[4] \"I Immature (subadult)\" \"J Juveniles\"          \n\n\nThe check above shows that the lifeStage field has only NA values, so we won’t be able to use it. The other two fields have values so it’s worth checking them out in more detail using skimr::skim() For this example we will focus on the sex field.\n\n# Skim without charts for a more compact output, making sure sex is treated as a factor\nbilby$sex &lt;- factor(bilby$sex)\nskimr::skim_without_charts(bilby, sex) |&gt;\n  skimr::yank(\"factor\")\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsex\n21375\n0.02\nFALSE\n2\nMAL: 361, FEM: 139\n\n\n\n\n\nThe dataset is mostly NA values for the sex field, but say that our project is focused only on female greater bilbies, now we can do our simple filter using == as shown below.\n\nhead(filter(bilby, sex == \"FEMALE\"), 3)\n\n# A tibble: 3 × 11\n  recordID        scientificName taxonConceptID decimalLatitude decimalLongitude\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 006e17c1-672c-… Macrotis lago… https://biodi…           -34.2             143.\n2 016d575f-39cd-… Macrotis lago… https://biodi…           -30.6             149.\n3 0374b34c-054c-… Macrotis lago… https://biodi…           -34.2             143.\n# ℹ 6 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, sex &lt;fct&gt;, lifeStage &lt;lgl&gt;,\n#   reproductiveCondition &lt;chr&gt;\n\n\nWe could also use != \"MALE to get the same result, since we only have two factor levels, and dplyr::filter() drops NA values. Be aware that if filtering with base R subsetting, the same approach would drop male rows but keep both female and NA rows.\n\nnrow(filter(bilby, sex != \"MALE\"))\n\n[1] 139\n\nnrow(filter(bilby[bilby$sex != \"MALE\", ]))\n\n[1] 21514\n\n\n\n\n14.2.4 Ecosystems\nFiltering by ecosystem, such as removing terrestrial records or aquatic records, can be necessary depending on the project. Below we demonstrate an example of filtering against the World Register of Marine Species (WoRMS), to remove marine invertebrates from our dataset. Note that you could apply this approach to any other ecosystem by using an appropriate list of species.\n\n\n\n\n# Obtain species list\nmy_species &lt;- inverts |&gt;\n  pull(scientificName) |&gt;\n  unique()\n\n# Query WoRMs\nmarine_check &lt;- purrr::map_dfr(\n  my_species,\n  purrr::possibly(~ worrms::wm_records_name(name = .x) |&gt;\n    mutate(search_term = .x))\n)\n# Filter species that are TRUE for isMarine\nmarine_inverts &lt;- marine_check |&gt;\n  filter(isMarine == TRUE)\n\n# Exclude marine invertebrates\nfilter(inverts, !scientificName %in% marine_inverts$search_term)\n\n# A tibble: 4 × 8\n  decimalLatitude decimalLongitude eventDate           scientificName           \n            &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;                    \n1           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n2           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n3           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n4           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n# ℹ 4 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;\n\n\nAfter filtering we are left with only four records of one species. It’s always worth double checking the results of your filtering, to make sure any species excluded or included are as expected.",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/geospatial.html#coordinate-precision-and-uncertainty",
    "href": "4_cleaning_expert/geospatial.html#coordinate-precision-and-uncertainty",
    "title": "17  Geospatial data",
    "section": "17.1 Coordinate precision and uncertainty",
    "text": "17.1 Coordinate precision and uncertainty\nCoordinate precision describes the consistency of values if one were to record the coordinates of the same location, multiple times. Coordinate precision can vary between data sources and recording equipment. For example, coordinates recorded with a GPS unit or a phone generally has higher precision compared to those manually determined from locality descriptions.\n\n\nDepending on the scope of your research question, you may need to limit your occurrence data to a certain level of coordinate.\nWe recommend first including coordinatePrecision in your download query and excluding???? its completeness and range before you exclude any data.\n\nlibrary(galah)\nlibrary(skimr)\n\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  galah_select(group = \"basic\", coordinatePrecision) |&gt; \n  atlas_occurrences()\n\n# banksia_serrata |&gt; \n#   select(coordinatePrecision) |&gt; \n#   skim()\n\n# Filter by number of decimal places\n# banksia_serrata |&gt; \n#   filter(coordinatePrecision &lt; XXX) \n\nhttps://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2664.2007.01408.x",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/geospatial.html#coordinate-uncertainty",
    "href": "4_cleaning_expert/geospatial.html#coordinate-uncertainty",
    "title": "17  Geospatial data",
    "section": "17.2 Coordinate Uncertainty",
    "text": "17.2 Coordinate Uncertainty\nAlternatively, you can refine your data using coordinate uncertainty which describes the possible circular area in meters where the true location is in.\n\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  galah_select(group = \"basic\", coordinatePrecision, coordinateUncertaintyInMeters) |&gt; \n  atlas_occurrences()\n\n# Filter by number of decimal places\n# banksia_serrata |&gt; \n#   filter(coordinateUncertaintyInMeters &lt; XXX) \n\n\n17.2.1 Missing coordinate data\nIf your research question requires spatial information, then it may be useful to exclude records that are missing coordinates data. Many spatial analytical tools are not compatible with missing coordinate data. We recommend tallying and identifying the rows that have missing data before excluding.\nYou can use drop_na() to remove missing values from your dataset.\n\nlibrary(dplyr)\n\n# Identify missing data in coordinates\nbanksia_serrata |&gt; \n  filter(is.na(decimalLatitude) | is.na (decimalLongitude))\n\n# Excluding them\nbanksia_serrata |&gt; \n  tidyr::drop_na(decimalLatitude, decimalLongitude)",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/geospatial.html#coordinate-correction",
    "href": "4_cleaning_expert/geospatial.html#coordinate-correction",
    "title": "17  Geospatial data",
    "section": "17.3 Coordinate correction",
    "text": "17.3 Coordinate correction\nSome of these steps may have been completed in a pre-cleaning step, however it’s now time to be more rigorous. As always we’ll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:\nFlipped coordinates: Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected. (Jin and Yang 2020)\n\n#example map of some flipped coordinates (what to look for) \n# https://www.gbif.org/occurrence/3013406216 this has flipped coordinates, which GBIF has corrected\n# https://www.gbif.org/occurrence/search?q=mammalia&continent=SOUTH_AMERICA&has_coordinate=true&has_geospatial_issue=false&issue=PRESUMED_SWAPPED_COORDINATE&advanced=1. ## the issue and flag is called 'presumed swapped coordinate' \n\nNumerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.\n\n#example map, like coordinates off the coast of japan\n\n# https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51360942&qualityProfile=CSDM&radius=50&lat=35.66845370835343&lon=138.9990234375#tab_recordsView\n\n# eucs &lt;- galah_call() %&gt;% \n#  galah_identify(\"Eucalyptus\") %&gt;%\n#  galah_filter( year == 2005, \n#             dataResourceName == \"The University of Melbourne Herbarium (MELU) AVH data\") %&gt;%\n#  atlas_occurrences()\n\nCountry field doesn’t match coordinates: The coordinates could be wrong or just the country listed.\n\n## this doesnt seem to be very common- atleast not in ALA data- because there is no neighboring country\n# https://biocache.ala.org.au/occurrences/a34fca43-9e7c-4b37-8fe4-07cc18369465 Australian coordinates, country listed as Trinidad and Tobago\n# https://www.gbif.org/occurrence/search?advanced=true&continent=SOUTH_AMERICA&geometry=POLYGON((-78.74961%20-8.25249,-76.29838%20-8.25249,-76.29838%20-4.74121,-78.74961%20-4.74121,-78.74961%20-8.25249))&has_coordinate=true&issue=COUNTRY_MISMATCH&locale=en&q=reptilia   # GBIF example- reptiles located in Peru, originally recorded as Ecuador\n\n\n17.3.1 Quick visualisation\nOne of the most straightforward ways to check for spatial errors is to plot your data onto a map. More obvious spatial errors are much easier to spot visually.\n\n\nlibrary(ggplot2)\nlibrary(ozmaps) \nlibrary(sf)\n\n# Retrieve map of Australia\naus &lt;- st_transform(ozmap_country, 4326)\n\n# Remove missing coordinates in Banksia data\n# Then transform into 'sf' object\nbanksia_sf &lt;- banksia_serrata |&gt; \n  tidyr::drop_na(starts_with(\"decimal\")) |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326)\n\n# A quick plot\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) + \n  geom_sf(data = banksia_sf)",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/geospatial.html#coordinate-cleaning",
    "href": "4_cleaning_expert/geospatial.html#coordinate-cleaning",
    "title": "17  Geospatial data",
    "section": "17.4 Coordinate cleaning",
    "text": "17.4 Coordinate cleaning\nOnce you have fixed everything you can, it’s time to remove records that still have errors. This doesn’t mean removing all outliers, you must have more than “it’s far away from the others” to justify a records removal.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, check first, however likely will need to remove\nRemove records with zero coordinates: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\n\n#zero coordinates acacia \n\n#https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51382879&disableAllQualityFilters=true&qualityProfile=ALA&fq=spatiallyValid%3A%22false%22&radius=25&lat=-0.024032592068740033&lon=-0.06591796875#tab_recordsView",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/geospatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "href": "4_cleaning_expert/geospatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "title": "17  Geospatial data",
    "section": "17.5 Remove records plotted away from the known area of distribution of the species.",
    "text": "17.5 Remove records plotted away from the known area of distribution of the species.\nIt is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it’s worth checking the literature before discarding records like these. These can also be mis-identified species, if you’re working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.\n\n\n\n\n17.5.1 Remove records with coordinates assigned to country and province centroids\nCentroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or grown in horticulture, which were not clearly labelled as such.\n\n\n17.5.2 Remove records from biological institutions\nsuch as botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and GBIF headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.\nIn a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\n\n\n17.5.3 CoordinateCleaner\nThis package probably worth looking at.\n\n\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "4_cleaning_expert/outliers.html#alternative-methods",
    "href": "4_cleaning_expert/outliers.html#alternative-methods",
    "title": "18  Outliers",
    "section": "18.1 Alternative methods",
    "text": "18.1 Alternative methods\nHere we document some other existing methods that can be used for outlier detection, and their limitations.\n\nSpecies Distribution Modelling for outlier detection:\n\nSimões and Peterson (2018)\nMaxiomum Entropy modelling (MaxEnt) was used to model habitat suitability for five species of leaf beetles in the genus Mesomphalia\nThe method relies on the assumption that an errornous point will have a lower habitat suitability value than a true point.\nFor their dataset, the method was useful for identifying geographical position errors, but not species level identification errors.\n\n\n\n\n\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and Limitations of Climate-Matching Approaches in Detecting Different Types of Spatial Errors in Biodiversity Data.” Insect Conservation and Diversity 11 (5): 407–14.",
    "crumbs": [
      "Cleaning data: Expert",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Outliers</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "19  References",
    "section": "",
    "text": "Garraffoni, A. R., Araújo, T. Q., Lourenço, A. P., Guidi, L., &\nBalsamo, M. (2019). Integrative taxonomy of a new redudasys species\n(gastrotricha: Macrodasyida) sheds light on the invasion of fresh water\nhabitats by macrodasyids. Scientific Reports, 9(1),\n2067.\n\n\nGodfree, R. C., Knerr, N., Encinas-Viso, F., Albrecht, D., Bush, D.,\nChristine Cargill, D., Clements, M., Gueidan, C., Guja, L. K., Harwood,\nT., Joseph, L., Lepschi, B., Nargar, K., Schmidt-Lebuhn, A., &\nBroadhurst, L. M. (2021). Implications of the 2019–2020 megafires for\nthe biogeography and conservation of Australian vegetation.\nNature Communications, 12(1), 1023. https://doi.org/10.1038/s41467-021-21266-5\n\n\nJin, J., & Yang, J. (2020). BDcleaner: A workflow for cleaning\ntaxonomic and geographic errors in occurrence data archived in\nbiodiversity databases. Global Ecology and Conservation,\n21, e00852. https://doi.org/10.1016/j.gecco.2019.e00852\n\n\nMarsh, J., Bal, P., Fraser, H., Umbers, K., Greenville, A., Rumpff, L.,\n& Woinarski, J. (2021). Assessment of the impacts of the 2019-20\nwildfires of southern and eastern australia on invertebrate species\nfinal report.\n\n\nRodrigues, A. V., Nakamura, G., Staggemeier, V. G., & Duarte, L.\n(2022). Species misidentification affects biodiversity metrics:\nDealing with this issue using the new R\npackage naturaList. Ecological\nInformatics, 69, 101625. https://doi.org/10.1016/j.ecoinf.2022.101625\n\n\nRowley, J. J., & Callaghan, C. T. (2020). The FrogID dataset:\nExpert-validated occurrence records of australia’s frogs collected by\ncitizen scientists. ZooKeys, 912, 139.\n\n\nSimões, M. V., & Peterson, A. T. (2018). Utility and limitations of\nclimate-matching approaches in detecting different types of spatial\nerrors in biodiversity data. Insect Conservation and Diversity,\n11(5), 407–414.",
    "crumbs": [
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "18  Packages",
    "section": "",
    "text": "19 rgbif\n{rgbif} is the Global Biodiversity Information Facility (GBIF)’s R package for downloading global biodiversity occurrence data and is the main node for all living atlases. Users can locate, restrict, and download occurrence records of interest across the globe as well associated multimedia. {rgbif} is one of four clients available to retrieve data. It is also available in Python, Ruby and PHP languages.\n{spocc} is an umbrella package that can retrieve data from multiple open-access biodiversity data repositories: GBIF, iNaturalist, VertNet, eBird, iDigBio, OBIS and the Atlas of Living Australia.\nA helpful tool to quickly summarise your data, particularly prior to data cleaning or whilst in the process of choosing an analysis. You can also use the skim function to calculate the number of columns or rows, view the number of empty or N/A data cells, and describe constituent data types. The summary function provides summary statistics of numerical data such as means, medians, minimum and maximums, as well as quartiles. skim allows the user to have a basic grasp of the spread of numercial data through averages, standard deviations and mini histograms.\n{tidyverse} is an umbrella package installing many packages into R that are useful for data wrangling, cleaning and analysis. Some notable packages within the tidyverse are {dplyr}, {ggplot2} and {stringr}. For example, you can use {dplyr} to add new columns to your data, filter your data for certain values and arrange rows in a preferred order; {ggplot2} can plot and visualise your data, and {stringr} can (though not limited to) help you locate and fix typos and extra spaces in your data.\n{janitor} is an effective R package to use for pre-cleaning data, especially when working with large data sets. It can help prepare data column names into a consistent format in order for combining data sets or simply the ease of processing of data later on (clean_names). For example, you might want to keep all column names lower case using underscores instead. You can quickly find any duplicate records (get_dupes()) using and produce counts of various combinations of data.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "packages.html#download-data",
    "href": "packages.html#download-data",
    "title": "18  Packages",
    "section": "18.1 Download data:",
    "text": "18.1 Download data:\n\n\n\n\n\n\n  \n\n\n\n18.1.1 galah\n{galah} is an R and Python interface to biodiversity data hosted by the Atlas of Living Australia (ALA). It enables users to locate and download species occurrence records (observations, specimens, eDNA records, etc.), taxonomic information, or associated media such as images or sounds, and to restrict their queries to particular taxa or locations. \n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n20 spocc",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "packages.html#visualise-your-data",
    "href": "packages.html#visualise-your-data",
    "title": "18  Packages",
    "section": "20.1 Visualise your data",
    "text": "20.1 Visualise your data\n\n\n\n\n\n\n \n\n\n21 skimr\n\n\n\n\n\n\n\n\n\n\n \n\n\n22 tidyverse",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "packages.html#general-cleaning",
    "href": "packages.html#general-cleaning",
    "title": "18  Packages",
    "section": "22.1 General cleaning",
    "text": "22.1 General cleaning\n\n\n\n\n\n\n \n\n\n23 janitor",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "appendix.html#data-scope",
    "href": "appendix.html#data-scope",
    "title": "21  Appendix",
    "section": "21.1 Data scope",
    "text": "21.1 Data scope\nData scope refers to the type and extent of data needed for your project. Defining your scope is an essential part of forming a research question, ultimately impacting what data you will use in your project. Availability of data may therefore influence your scope and research question.\nFor example, you might have a question about several species in the same area. However, data for one or more of those species could be limited because observations are rare, surveying the area where it lives is difficult, or only several historical records exist.\nWithout narrowing your data scope, you might find yourself downloading more data than you need, which can needlessly increase how much time is spent processing data prior to analyses. Alternatively, you might find there isn’t enough data to answer your question.\nWhile there are workable methods to analyse small sets of biodiversity data (e.g. hulls), it’s worth thinking critically about whether the amount of data available will allow you to sufficiently answer your research question.\nTo start, some initial questions you might ask are:\n\nWhat is the temporal unit relevant for your research question?\nAm I only interested in more recent data? Is there data that are too old to be relevant for my question?\nWhat is the taxonomic unit of your proposed research question?\nIs my question specific to one or more species in the same taxonomic group? Does it compare between higher taxonomic levels like genus, family or order?\nWhat is the spatial scale of your proposed research question?\nIs my question relevant at a global or national level, or is it specific to a region or ecosystem?\n\nQuestions like these will help you define what data is most relevant for your research question, and help you begin to think about how much evidence available, and the trade-offs you might make between the specificity of your question and the certainty of your answer.\n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville, Libby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts of the 2019-20 Wildfires of Southern and Eastern Australia on Invertebrate Species Final Report.”",
    "crumbs": [
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Appendix</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#setup",
    "href": "cleaning_standardisation.html#setup",
    "title": "22  General utility functions",
    "section": "22.1 Setup",
    "text": "22.1 Setup\n\nlibrary(\"galah\")\n\n\nAttaching package: 'galah'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\ngalah_config(atlas = \"Australia\") # default\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"))\n\n\nresult &lt;- galah_call() |&gt;\n  galah_identify(\"Litoria\") |&gt;\n  galah_filter(year &gt;= 2020, cl22 == \"Tasmania\") |&gt;\n  atlas_occurrences()\n\nRequest for 1690 occurrences placed in queue\nCurrent queue length: 1\n\n\n----\n\n\nDownloading\n\nresult |&gt; head()\n\n# A tibble: 6 × 8\n  recordID        scientificName taxonConceptID decimalLatitude decimalLongitude\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 00168ca6-84d0-… Litoria        https://biodi…           -41.2             146.\n2 00250163-ec50-… Litoria        https://biodi…           -41.2             147.\n3 003e0f63-9f95-… Litoria ewing… https://biodi…           -42.9             148.\n4 00410554-5289-… Litoria ewing… https://biodi…           -41.7             147.\n5 0070521f-bb45-… Litoria ewing… https://biodi…           -43.1             147.\n6 0081e7ef-459b-… Litoria ewing… https://biodi…           -43.2             147.\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#dates",
    "href": "cleaning_standardisation.html#dates",
    "title": "22  General utility functions",
    "section": "22.2 Dates",
    "text": "22.2 Dates\nSome use cases may require dates beyond a simple year value. Standardising dates involves ensuring that the variables in a dataset have values that conform to a consistent and standard format. An example of unstandardised data is having varied date formats (e.g. DD/MM/YYYY for some entries and MM/DD/YYYY for others). This may be necessary when integrating data from multiple sources, but it is important to remember that there can be inconsistencies even within a single source dataset.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#column-classes",
    "href": "cleaning_standardisation.html#column-classes",
    "title": "22  General utility functions",
    "section": "22.3 Column classes",
    "text": "22.3 Column classes\nWe can check for obvious inconsistencies using the classes of each column. We can do this with summary tables like a skimr report, or with base R. Below is a simple example where our decimalLatitude column is numeric, which is what we expect so in this case there is no problem. But as an example, if we change just one of the values to a degrees minutes seconds format, we can see that the class for the column changes to character.\n\nsapply(result, class)\n\n$recordID\n[1] \"character\"\n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$decimalLatitude\n[1] \"numeric\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$occurrenceStatus\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"\n\n# Change one of the values to a degrees minutes seconds format\nresult$decimalLatitude[5] &lt;- \"40° 51' 59 N\"\nsapply(result, class)\n\n$recordID\n[1] \"character\"\n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$decimalLatitude\n[1] \"character\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$occurrenceStatus\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#unexpected-values",
    "href": "cleaning_standardisation.html#unexpected-values",
    "title": "22  General utility functions",
    "section": "22.4 Unexpected values",
    "text": "22.4 Unexpected values\n\nChecking for unexpected values: this is a generic method but the resolution logic depends on the issue (taxonomic, categories, strings, etc.)\n\nContext: a merged dataset pertaining to a single species (using data frame from cleaning_integration.qmd). Species is L. chloris\n\nAssumption: species column contains only one species\n\nMethod: unique(merged_data$species)\nResult: two species names\nResolution: conform to one species name (assign)\n\nAssumption: country code contains only one country\n\nMethod: unique(merged_data$country_code)\nResult: AU, NA, JP\nResolution: Investigate NA and assign, investigate JP since chloris is an Australian species\n\n\n\n\n\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following object is masked from 'package:galah':\n\n    desc\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmerged_data &lt;- read.csv(\"data/galah/chloris.csv\")\n\nunique(merged_data$countryCode)\n\n[1] \"AU\" NA   \"JP\"\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]\n\n        X decimalLatitude decimalLongitude           eventDate\n3995 3995         24.4856         151.5842 2013-12-30 14:00:00\n6722 6722         24.4856         151.5842 2013-12-30 14:00:00\n                        scientificName\n3995                   Litoria chloris\n6722 Litoria chloris (Boulenger, 1892)\n                                                                taxonConceptID\n3995 https://biodiversity.org.au/afd/taxa/f532b88a-a6c0-4006-aa24-77e3d645530e\n6722                                                                      &lt;NA&gt;\n                                 recordID                  dataResourceName\n3995 c08e641e-cf01-4f0f-b5ad-c3b8fcff4da4 ALA species sightings and OzAtlas\n6722                                 &lt;NA&gt;                              &lt;NA&gt;\n     occurrenceStatus     basisOfRecord  kingdom taxonRank   phylum    class\n3995          PRESENT HUMAN_OBSERVATION Animalia   species Chordata Amphibia\n6722          PRESENT HUMAN_OBSERVATION Animalia   SPECIES Chordata Amphibia\n     order        family    genus         species countryCode locality\n3995 Anura       Hylidae  Litoria Litoria chloris          JP mt bucca\n6722 Anura Pelodryadidae Ranoidea Litoria chloris          JP mt bucca\n     stateProvince coordinateUncertaintyInMeters coordinatePrecision\n3995          &lt;NA&gt;                          5000                  NA\n6722          &lt;NA&gt;                          5000                  NA\n       dcterms.license                         occurrenceID source     gbifID\n3995 CC-BY-NC 3.0 (Au)             52c2c6973dff6b1593e42ef9    ALA         NA\n6722              &lt;NA&gt; c08e641e-cf01-4f0f-b5ad-c3b8fcff4da4   GBIF 1632945208\n                               datasetKey infraspecificEpithet\n3995                                 &lt;NA&gt;                   NA\n6722 84a649ce-ff81-420d-9c41-aa1de59e3766                   NA\n     verbatimScientificName verbatimScientificNameAuthorship individualCount\n3995                   &lt;NA&gt;                             &lt;NA&gt;              NA\n6722        Litoria chloris                (Boulenger, 1893)              NA\n                         publishingOrgKey elevation elevationAccuracy depth\n3995                                 &lt;NA&gt;        NA                NA    NA\n6722 adc174cd-c752-4eee-9630-7c1209eb1c4a        NA                NA    NA\n     depthAccuracy day month year taxonKey speciesKey institutionCode\n3995            NA  NA    NA   NA       NA         NA            &lt;NA&gt;\n6722            NA  30    12 2013  2427866   10759325            &lt;NA&gt;\n     collectionCode catalogNumber\n3995           &lt;NA&gt;          &lt;NA&gt;\n6722           &lt;NA&gt;          &lt;NA&gt;\n                                                                                       recordNumber\n3995                                                                                           &lt;NA&gt;\n6722 https://biocollect.ala.org.au/sightings/bioActivity/index/0d598d06-a077-48e1-b632-e856bc63f264\n     identifiedBy dateIdentified   license rightsHolder    recordedBy\n3995         &lt;NA&gt;           &lt;NA&gt;      &lt;NA&gt;         &lt;NA&gt;          &lt;NA&gt;\n6722         &lt;NA&gt;           &lt;NA&gt; CC_BY_4_0         &lt;NA&gt; Kylie, Carman\n     typeStatus establishmentMeans     lastInterpreted mediaType issue\n3995       &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;      &lt;NA&gt;  &lt;NA&gt;\n6722       &lt;NA&gt;               &lt;NA&gt; 2023-08-26 03:07:16      &lt;NA&gt;  &lt;NA&gt;\n\n# where should the point be? can check the `locality` column and coordinates\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$decimalLatitude\n\n[1] 24.4856 24.4856\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$decimalLongitude\n\n[1] 151.5842 151.5842\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$locality\n\n[1] \"mt bucca\" \"mt bucca\"\n\n# mt bucca is in australia but the coordinates are incorrect\n# the latitude is missing an \"-\"\n# we can fix this and check the result (#TODO map vis)\nfixed &lt;- merged_data %&gt;%\n  mutate(decimalLatitude = ifelse(countryCode == \"JP\", paste0(\n    \"-\",\n    decimalLatitude\n  ), decimalLatitude)) %&gt;%\n  mutate(countryCode = ifelse(countryCode == \"JP\", \"AU\", countryCode))",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#summary",
    "href": "cleaning_standardisation.html#summary",
    "title": "22  General utility functions",
    "section": "22.5 Summary",
    "text": "22.5 Summary\nIn this chapter, we learned a few basic checks for cleaning datasets, including methods to detect inconsistencies in date formats, coordinate systems, and units.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_duplicates.html#check-for-duplicate-records",
    "href": "cleaning_duplicates.html#check-for-duplicate-records",
    "title": "23  Duplicates and missing records",
    "section": "23.1 Check for duplicate records",
    "text": "23.1 Check for duplicate records\nDuplicates records can happen when using aggregated data sources. In this section we will cover detection and handling of duplicate records.\n\n# Check for duplicate records across the dataset\n# duplicated_records &lt;- merged_data[duplicated(merged_data), ]\n# Targeted checks\n# duplicated_records[which(duplicated(merged_data$occurrenceID)), ]",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Duplicates and missing records</span>"
    ]
  },
  {
    "objectID": "cleaning_duplicates.html#check-for-missing-records",
    "href": "cleaning_duplicates.html#check-for-missing-records",
    "title": "23  Duplicates and missing records",
    "section": "23.2 Check for missing records",
    "text": "23.2 Check for missing records\n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.2\n\niris %&gt;%\n  skim() %&gt;%\n  dplyr::filter(n_missing &gt; 0)\n\n# A tibble: 0 × 15\n# ℹ 15 variables: skim_type &lt;chr&gt;, skim_variable &lt;chr&gt;, n_missing &lt;int&gt;,\n#   complete_rate &lt;dbl&gt;, factor.ordered &lt;lgl&gt;, factor.n_unique &lt;int&gt;,\n#   factor.top_counts &lt;chr&gt;, numeric.mean &lt;dbl&gt;, numeric.sd &lt;dbl&gt;,\n#   numeric.p0 &lt;dbl&gt;, numeric.p25 &lt;dbl&gt;, numeric.p50 &lt;dbl&gt;, numeric.p75 &lt;dbl&gt;,\n#   numeric.p100 &lt;dbl&gt;, numeric.hist &lt;chr&gt;",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Duplicates and missing records</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#basic-string-manipulation",
    "href": "cleaning_manipulating_strings.html#basic-string-manipulation",
    "title": "24  Strings",
    "section": "24.1 Basic string manipulation",
    "text": "24.1 Basic string manipulation\nThe stringr package provides a number of useful functions for manipulating strings, many of which are useful when dealing with biodiversity data.\n\nlibrary(stringr)\nstr_trim(\"  Genus specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trim(\"  Genus specificus  \", side = \"left\")\n\n[1] \"Genus specificus  \"\n\nstr_squish(\"  Genus   specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trunc(\"Genus specificus\", width = 10, side = \"right\")\n\n[1] \"Genus s...\"\n\nstr_split(\"Genus specificus\", \" \")\n\n[[1]]\n[1] \"Genus\"      \"specificus\"\n\nstr_c(\"Genus\", \"specificus\", sep = \"_\")\n\n[1] \"Genus_specificus\"",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#matching",
    "href": "cleaning_manipulating_strings.html#matching",
    "title": "24  Strings",
    "section": "24.2 Matching",
    "text": "24.2 Matching\nMatching strings is a common task when working with biodiversity data. etc etc.\n\n24.2.1 Basic matching\nThe stringr package provides a number of functions for matching strings using patterns.\n\n# detect and remove\nstr_detect(\"Genus specificus\", \"Genus\")\n\n[1] TRUE\n\nstr_remove(\"Genus specificus\", pattern = \"Genus \")\n\n[1] \"specificus\"\n\n# locate and subset\nrecords &lt;- c(\"Genus\", \"species\", \"Genus species\", \"Difgenus difspecies\")\nstr_locate(records, \"Genus\")\n\n     start end\n[1,]     1   5\n[2,]    NA  NA\n[3,]     1   5\n[4,]    NA  NA\n\nstr_subset(records, \"Genus\")\n\n[1] \"Genus\"         \"Genus species\"\n\n\n\n\n24.2.2 Regex matching\nThe examples above demonstrate the use of basic patterns. But for cases that need more specific or advanced matching we can use regular expressions (regex). Regex is a powerful tool used to match patterns in strings, replace characters in strings, and extract substrings from strings. Regex can be complex and unintuitive, but there are websites available, such as Regex Generator, that are extremely helpful. Here we explore a few basic examples, and keep in mind that these methods can be applied to both column name strings and column values. In the case of column names, regex can be useful when conforming datasets (see Integration) or to meet a stylistic requirement. Applied to column values, there is a range of utility, such as unifying the formatting of taxonomic or location names.\nThe str_view() function is particularly useful for exploring regular expressions to see pattern matches. The results are shown in the console, and elements matched by the regex are surrounded with angle brackets &lt; &gt;.\n\n# Match the first word in the string (the genus)\nstr_view(tree_kangaroo$scientificName, \"^[A-Z][a-z]+\")\n\n [1] │ &lt;Dendrolagus&gt; lumholtzi\n [2] │ &lt;Dendrolagus&gt; lumholtzi\n [3] │ &lt;Dendrolagus&gt; lumholtzi\n [4] │ &lt;Dendrolagus&gt; lumholtzi\n [5] │ &lt;Dendrolagus&gt;\n [6] │ &lt;Dendrolagus&gt; bennettianus\n [7] │ &lt;Dendrolagus&gt; lumholtzi\n [8] │ &lt;Dendrolagus&gt; lumholtzi\n [9] │ &lt;Dendrolagus&gt;\n[10] │ &lt;Dendrolagus&gt; bennettianus\n[11] │ &lt;Dendrolagus&gt; lumholtzi\n[12] │ &lt;Dendrolagus&gt;\n[13] │ &lt;Dendrolagus&gt;\n[14] │ &lt;Dendrolagus&gt; lumholtzi\n[15] │ &lt;Dendrolagus&gt; bennettianus\n[16] │ &lt;Dendrolagus&gt; lumholtzi\n[17] │ &lt;Dendrolagus&gt;\n[18] │ &lt;Dendrolagus&gt; lumholtzi\n[19] │ &lt;Dendrolagus&gt; lumholtzi\n[20] │ &lt;Dendrolagus&gt; lumholtzi\n... and 1232 more\n\n# Match only the second word (species name)\nstr_view(tree_kangaroo$scientificName, \"(?&lt;=\\\\s)[a-z]+\")\n\n [1] │ Dendrolagus &lt;lumholtzi&gt;\n [2] │ Dendrolagus &lt;lumholtzi&gt;\n [3] │ Dendrolagus &lt;lumholtzi&gt;\n [4] │ Dendrolagus &lt;lumholtzi&gt;\n [6] │ Dendrolagus &lt;bennettianus&gt;\n [7] │ Dendrolagus &lt;lumholtzi&gt;\n [8] │ Dendrolagus &lt;lumholtzi&gt;\n[10] │ Dendrolagus &lt;bennettianus&gt;\n[11] │ Dendrolagus &lt;lumholtzi&gt;\n[14] │ Dendrolagus &lt;lumholtzi&gt;\n[15] │ Dendrolagus &lt;bennettianus&gt;\n[16] │ Dendrolagus &lt;lumholtzi&gt;\n[18] │ Dendrolagus &lt;lumholtzi&gt;\n[19] │ Dendrolagus &lt;lumholtzi&gt;\n[20] │ Dendrolagus &lt;lumholtzi&gt;\n[21] │ Dendrolagus &lt;lumholtzi&gt;\n[24] │ Dendrolagus &lt;lumholtzi&gt;\n[25] │ Dendrolagus &lt;bennettianus&gt;\n[27] │ Dendrolagus &lt;lumholtzi&gt;\n[28] │ Dendrolagus &lt;lumholtzi&gt;\n... and 849 more\n\n\n\n\n24.2.3 Replacements\nIn base R the gsub() function can be used for pattern replacement. In stringr, the str_replace() function can be used to replace the first match of a string. The str_replace_all() function can be used to replace all matches.\n\n# str_replace() example\n\nBase example:\n\ntree_kangaroo$scientificName &lt;- gsub(\n  pattern = \"Dendrolagus\",\n  replacement = \"Newname\",\n  x = tree_kangaroo$scientificName\n)",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#case-style",
    "href": "cleaning_manipulating_strings.html#case-style",
    "title": "24  Strings",
    "section": "24.3 Case style",
    "text": "24.3 Case style\nCase style can vary across data providers due to variable naming conventions. There are some basic functions available to change the case of strings in stringr:\n\nstr_to_lower(plants$scientific_name[1])\n\n[1] \"hakea eriantha\"\n\nstr_to_upper(plants$scientific_name[1])\n\n[1] \"HAKEA ERIANTHA\"\n\nstr_to_title(plants$scientific_name[1])\n\n[1] \"Hakea Eriantha\"\n\n\nIn some cases a more specific detection and replacement is required. For example, the World Register of Marine Species (WoRMS) uses a combination of lower case (scientific_name) and camel case (isExtinct). However, the Australian Fauna Directory (AFD) uses screaming snake case e.g. SCIENTIFIC_NAME. To work with both, case differences can be conformed to a single style, but the format you choose is a matter of personal preference.\n\n\nworms_small &lt;- head(worms)\n\n# gsub is a base R function for replacing strings\ncolnames(worms_small) &lt;- sapply(colnames(worms_small), function(name) {\n  name &lt;- tolower(gsub(\"([a-z])([A-Z])\", \"\\\\1_\\\\2\", name))\n  gsub(\"^_\", \"\", name)\n})\n\n# stringr version of above (with a slightly different regex approach)\ncolnames(worms_small) &lt;- sapply(colnames(worms_small), function(name) {\n  str_to_lower(str_replace_all(name, \"(?&lt;=\\\\p{Ll})(\\\\p{Lu})\", \"_\\\\1\"))\n})",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#simple-case-study",
    "href": "cleaning_manipulating_strings.html#simple-case-study",
    "title": "24  Strings",
    "section": "24.4 Simple case study",
    "text": "24.4 Simple case study\nWe will use the janitor R package to explore whether our elephant data has any string issues. The function tabyl will compute a counts and percent of total rows for each unique value.\n\nlibrary(dplyr)\nlibrary(janitor)\nafrican_ele &lt;- arrow::read_parquet(\"data/gbif/elephant\")\nafrican_ele |&gt;\n  pull(stateProvince) |&gt;\n  tabyl() |&gt;\n  tibble() |&gt;\n  print(n = 20)\n\n# A tibble: 197 × 4\n   `pull(african_ele, stateProvince)`     n   percent valid_percent\n   &lt;chr&gt;                              &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez                                 1 0.0000561     0.0000879\n 2 Al Qahirah                             1 0.0000561     0.0000879\n 3 Alibori                              601 0.0337        0.0528   \n 4 Arusha                               327 0.0183        0.0287   \n 5 Arusha Region                          1 0.0000561     0.0000879\n 6 Atacora                              366 0.0205        0.0322   \n 7 Atakora                              249 0.0140        0.0219   \n 8 Balaka                                 8 0.000449      0.000703 \n 9 Bassila                                1 0.0000561     0.0000879\n10 Batha                                  1 0.0000561     0.0000879\n11 Bauchi                                 7 0.000393      0.000615 \n12 Bengo                                  3 0.000168      0.000264 \n13 Bizerte                                2 0.000112      0.000176 \n14 Borgou                                 7 0.000393      0.000615 \n15 Bouaflé                                3 0.000168      0.000264 \n16 Bouna                                  1 0.0000561     0.0000879\n17 Budongo Forest                         1 0.0000561     0.0000879\n18 Bushenyi                              84 0.00471       0.00738  \n19 Cabo Delgado                           3 0.000168      0.000264 \n20 Cape Prov.                             2 0.000112      0.000176 \n# ℹ 177 more rows\n\n\nFrom the tabyl output, we can see there are few different variations of Province, Prov., Prov. As an example, we will correct these with the tidyverse packages stringr, dplyr, tidyr as well as glue.\n\nlibrary(glue)\n# Create a regular expression to match Prov. and Prov\npattern &lt;- regex(\"Prov(?![:lower:])\")\n# Use `str_subset` to pull out the cases that match our pattern\n# Confirm that these are the problematic ones\n# Assign these into an object\nstr_subset(african_ele$stateProvince, pattern = pattern)\n\n [1] \"Cape Prov.\"        \"Cape Prov.\"        \"West Nile Prov.\"  \n [4] \"Central Prov\"      \"Central Prov\"      \"Coastal Prov\"     \n [7] \"Northeastern Prov\" \"Central Prov\"      \"Eastern Prov\"     \n[10] \"Coastal Prov\"     \n\ntypos_provinces &lt;- str_subset(african_ele$stateProvince, pattern = pattern)\n\n# Create a new variable `stateProvince_clean`\n# `str_detect` for matches of pattern (returns TRUE for match)\n# `if_else`: if TRUE, the `glue` function will take the first part of the province name enclosed in and join it with word Province.\n# if FALSE , it will just take the corresponding value in stateProvince\n# Note that we are assigning these changes to a new object (`african_ele_2`)\nafrican_ele_2 &lt;- african_ele %&gt;%\n  mutate(stateProvince_clean = if_else(str_detect(stateProvince, pattern = pattern),\n    true = glue('{word(stateProvince, sep = \" P\")} Province'),\n    false = stateProvince\n  ))\n\n# Once we've made the correction we want to check we've done it correctly.\n# ALWAYS CHECK YOUR CORRECTIONS\n# Use the `select` function to isolate columns that `starts_with` \"stateProvince\"\n# Use the `filter` function to subset our the problematic provinces\nafrican_ele_2 %&gt;%\n  select(starts_with(\"stateProvince\")) %&gt;%\n  filter(stateProvince %in% typos_provinces)\n\n# A tibble: 10 × 2\n   stateProvince     stateProvince_clean  \n   &lt;chr&gt;             &lt;glue&gt;               \n 1 Cape Prov.        Cape Province        \n 2 Cape Prov.        Cape Province        \n 3 West Nile Prov.   West Nile Province   \n 4 Central Prov      Central Province     \n 5 Central Prov      Central Province     \n 6 Coastal Prov      Coastal Province     \n 7 Northeastern Prov Northeastern Province\n 8 Central Prov      Central Province     \n 9 Eastern Prov      Eastern Province     \n10 Coastal Prov      Coastal Province     \n\n# Its good practice to check the other values were not affected by your corrections\n# Here we are removing the NA with `drop_na` and subsetting unique rows with `distinct`\nafrican_ele_2 %&gt;%\n  select(starts_with(\"stateProvince\")) %&gt;%\n  tidyr::drop_na() %&gt;%\n  distinct()\n\n# A tibble: 196 × 2\n   stateProvince    stateProvince_clean\n   &lt;chr&gt;            &lt;glue&gt;             \n 1 Southern         Southern           \n 2 Taita Taveta     Taita Taveta       \n 3 Mara             Mara               \n 4 Arusha           Arusha             \n 5 Simiyu           Simiyu             \n 6 Morogoro         Morogoro           \n 7 Mashonaland West Mashonaland West   \n 8 Mpumalanga       Mpumalanga         \n 9 KwaZulu-Natal    KwaZulu-Natal      \n10 Manicaland       Manicaland         \n# ℹ 186 more rows\n\n# Final check\n# Check with the original code that detected the issue\nafrican_ele_2 %&gt;%\n  pull(stateProvince_clean) %&gt;%\n  tabyl() %&gt;%\n  tibble() %&gt;%\n  print(n = 20)\n\n# A tibble: 195 × 4\n   .                  n   percent valid_percent\n   &lt;glue&gt;         &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez             1 0.0000561     0.0000879\n 2 Al Qahirah         1 0.0000561     0.0000879\n 3 Alibori          601 0.0337        0.0528   \n 4 Arusha           327 0.0183        0.0287   \n 5 Arusha Region      1 0.0000561     0.0000879\n 6 Atacora          366 0.0205        0.0322   \n 7 Atakora          249 0.0140        0.0219   \n 8 Balaka             8 0.000449      0.000703 \n 9 Bassila            1 0.0000561     0.0000879\n10 Batha              1 0.0000561     0.0000879\n11 Bauchi             7 0.000393      0.000615 \n12 Bengo              3 0.000168      0.000264 \n13 Bizerte            2 0.000112      0.000176 \n14 Borgou             7 0.000393      0.000615 \n15 Bouaflé            3 0.000168      0.000264 \n16 Bouna              1 0.0000561     0.0000879\n17 Budongo Forest     1 0.0000561     0.0000879\n18 Bushenyi          84 0.00471       0.00738  \n19 Cabo Delgado       3 0.000168      0.000264 \n20 Cape Province      3 0.000168      0.000264 \n# ℹ 175 more rows\n\n\nThere are some other issues that can be corrected in a similar approach:\n\nNorth West, North West District and North-Western\nÀfrica Central, Central Province and Central\nAtacora and Atakora\nCoastal Province and Coastal\n\nWe recommend consulting reputable sources to delineate and consolidate similar values.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomy.html#missing-data",
    "href": "cleaning_taxonomy.html#missing-data",
    "title": "25  Taxonomy",
    "section": "25.1 Missing data",
    "text": "25.1 Missing data\nOne issue you might face is that higher taxonomy from different providers may not match. If this is the case, we suggest choosing the data provider with the higher taxonomy that is consistent with your naming authority and use it to back fill the higher taxonomy of the other data sources\n\n# higher_taxonomy &lt;- inverts %&gt;%\n#   select(scientificName) %&gt;%\n#   distinct() %&gt;%\n#   search_taxa()\n\n# higher_taxonomy",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomy.html#filtering-out-taxa",
    "href": "cleaning_taxonomy.html#filtering-out-taxa",
    "title": "25  Taxonomy",
    "section": "25.2 Filtering out taxa",
    "text": "25.2 Filtering out taxa\nDepending on your project’s data scope, it may be necessary to remove certain groups of taxa. Here we present a few use cases, based on some commonly required criteria. This type of taxonomic filtering is particularly useful for large, multi-species datasets.\n\n25.2.1 Introduced or invasive species\nIf your project requires only native species, we can filter out those records using lists available online. Here we are using the list for Australia from the Global Register of Introduced and Invasive Species (GRIIS). After downloading this list, we read it into R, and exclude invasive species from our example dataset:\n\nlibrary(dplyr)\nplants &lt;- arrow::open_dataset(\"data/dap/plants_subset\") |&gt; dplyr::collect()\ngriis_ls &lt;- read.csv(\"./data/lists/GRIIS_Australia_20230331-121730.csv\")\nglimpse(griis_ls)\n\nRows: 2,979\nColumns: 16\n$ scientific_name                  &lt;chr&gt; \"Oenothera longiflora L.\", \"Lampranth…\n$ scientific_name_type             &lt;chr&gt; \"species\", \"species\", \"species\", \"spe…\n$ kingdom                          &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ establishment_means              &lt;chr&gt; \"alien\", \"alien\", \"alien\", \"alien\", \"…\n$ is_invasive                      &lt;chr&gt; \"null\", \"null\", \"null\", \"null\", \"null…\n$ occurrence_status                &lt;chr&gt; \"present\", \"present\", \"present\", \"pre…\n$ checklist.name                   &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\"…\n$ checklist.iso_countrycode_alpha3 &lt;chr&gt; \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"A…\n$ accepted_name.species            &lt;chr&gt; \"Oenothera longiflora\", \"Lampranthus …\n$ accepted_name.kingdom            &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ accepted_name.phylum             &lt;chr&gt; \"Tracheophyta\", \"Tracheophyta\", \"Trac…\n$ accepted_name.class              &lt;chr&gt; \"Magnoliopsida\", \"Magnoliopsida\", \"Ma…\n$ accepted_name.order              &lt;chr&gt; \"Myrtales\", \"Caryophyllales\", \"Erical…\n$ accepted_name.family             &lt;chr&gt; \"Onagraceae\", \"Aizoaceae\", \"Ericaceae…\n$ accepted_name.habitat            &lt;chr&gt; \"[\\\"terrestrial\\\"]\", \"[\\\"terrestrial\\…\n$ accepted_name                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n# Check which species matched the GRIIS list\nmatches &lt;- filter(plants, scientific_name %in% griis_ls$accepted_name.species)\n\n# If you are happy with the matches, you can proceed to remove any records\n# that were matched\nplants_no_griis &lt;- filter(plants, !scientific_name %in% matches)\n\n\n\n\n\n\n\nTip\n\n\n\nYou can apply this concept of filtering to any list of species, or other fields, that you would like to exclude (or include, by removing the ! in the filter() step)\n\n\n\n\n25.2.2 Extinct species\nIn most cases, a year filter applied during your download query should remove most extinct species. Nevertheless, it is important to cross check for extinct species. We can do this using the Interim Register of Marine and Nonmarine Genera (IRMNG). The list is comprehensive and actively maintained. However, much of the data doesn’t go down to species level. As such, we recommend using the following approach to find potentially extinct taxa and further investigate the records that are flagged.\nThe required files are organised by year and can be downloaded from here, and unzipped to your project directory. Below we process the downloaded files and then check for matches in our dataset.\n\nirmng_taxa &lt;- arrow::open_dataset(\"data/lists/IRMNG_genera_DwCA_2023-05-19/taxon_subset\") |&gt;\n  collect()\n\nirmng_sp &lt;- arrow::open_dataset(\"data/lists/IRMNG_genera_DwCA_2023-05-19/speciesprofile\") |&gt;\n  collect()\n\n\n\nlibrary(\"stringr\")\ninverts &lt;- arrow::open_dataset(\"data/galah/inverts\") |&gt; dplyr::collect()\n\nawc_pattern &lt;- \"(awaiting allocation)\"\ninsed_pattern &lt;- \"incertae sedis\"\n\ncleaned_irmng_taxa &lt;- irmng_taxa |&gt;\n  mutate(\n    class = ifelse(str_detect(class, pattern = paste0(awc_pattern, \"|\", insed_pattern)),\n      word(class), class\n    )\n  ) |&gt;\n  filter(taxonomicStatus == \"accepted\") |&gt; # Filter to accepted names\n  filter(\n    kingdom %in% c(\"Animalia\", \"Plantae\"),\n    !kingdom == \"Questionable / non-biota (fossil)\"\n  ) # Filter to Animal and plants - change if working with other kingdoms\n\n# Join with species profile, remove pesky values and filter to extinct taxa\nextinct_irmng &lt;- irmng_taxa |&gt;\n  left_join(irmng_sp, by = \"taxonID\") |&gt;\n  filter(!scientificName == \"Questionable / non-biota (fossil)\") |&gt;\n  filter(isExtinct == TRUE)\n\n# Summary of extinct species by taxonRank\nextinct_irmng$taxonRank |&gt; janitor::tabyl()\n\n extinct_irmng$taxonRank     n      percent\n                   Class    14 5.926177e-04\n                  Family  1675 7.090247e-02\n                   Genus 21718 9.193193e-01\n              Infraclass     1 4.232983e-05\n                   Order   210 8.889265e-03\n                  Phylum     4 1.693193e-04\n                Subclass     2 8.465967e-05\n\n# Create genus\ninverts_2 &lt;- inverts |&gt;\n  mutate(genus = word(scientificName, 1))\n\n# Extract unique extinct genus and remove genus that have punctuation in them\nextinct_genus &lt;- extinct_irmng |&gt;\n  tidyr::drop_na(genus) |&gt;\n  filter(!str_detect(genus, pattern = regex(\"[:punct:]\"))) |&gt;\n  pull(genus) |&gt;\n  unique()\n\n# Check if there are any matches at genus level\ncheck &lt;- inverts_2 |&gt;\n  filter(str_detect(genus, pattern = regex(paste0(extinct_genus, collapse = \"|\")))) |&gt;\n  pull(scientificName) |&gt;\n  unique()\n\nprint(check)\n\n[1] \"Halobates (Halobates) acherontis\"\n\n\nAlternatively, we can use the IUCN to retrieve a list of extinct species that are in their database. See the IUCN API for more information on queries based on species categories. Below we will the rredlist package to interface with the IUCN API. Note that you will need to register for an API token, which can take a day or two to be approved. Then we use the rl_sp_category(\"EX\") to return extinct species, to check against our dataset.\n\n\n# Create IUCN token\nrredlist::rl_use_iucn() # Application can take a day or two!\nusethis::edit_r_environ() # Place the approved token in your R environment\n\nextinct_iucn &lt;- rredlist::rl_sp_category(\"EX\")\nskimr::skim(extinct_iucn)\n\n# Note these are extinct species across the globe\nextinct_sp &lt;- tibble(extinct_iucn$result)\n\n# Find matches\nfilter(inverts, scientificName %in% extinct_sp$scientific_name) # No matches\n\n\n\n25.2.3 Biological attributes and life cycle stages\nIn some cases, you may want to filter out records based on attributes such as sex or life cycle stage, if this metadata is available for your records. In the example below, we download a dataset, including the extra metadata fields needed. We then examine the fields we want to filter by, to see what values are available and how many records are missing values.\n\nlibrary(galah)\n\ngalah_config(\n  email = Sys.getenv(\"ALA_EMAIL\"),\n  atlas = \"Australia\"\n)\n\nbilby &lt;- galah_call() |&gt;\n  galah_identify(\"Macrotis lagotis\") |&gt;\n  galah_filter(year == 2022) |&gt;\n  galah_select(group = \"basic\", sex, lifeStage, reproductiveCondition) |&gt;\n  atlas_occurrences()\n\n----\n\n# Quick way to check the unique values for each field\nlapply(bilby[c(\"sex\", \"lifeStage\", \"reproductiveCondition\")], unique)\n\n$sex\n[1] NA       \"FEMALE\" \"MALE\"  \n\n$lifeStage\n[1] NA\n\n$reproductiveCondition\n[1] NA                      \"- Not breeding\"        \"A Adult\"              \n[4] \"I Immature (subadult)\" \"J Juveniles\"          \n\n\nThe check above shows that the lifeStage field has only NA values, so we won’t be able to use it. The other two fields have values so it’s worth checking them out in more detail using skimr::skim() For this example we will focus on the sex field.\n\n# Skim without charts for a more compact output, making sure sex is treated as a factor\nbilby$sex &lt;- factor(bilby$sex)\nskimr::skim_without_charts(bilby, sex) |&gt;\n  skimr::yank(\"factor\")\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsex\n21375\n0.02\nFALSE\n2\nMAL: 361, FEM: 139\n\n\n\n\n\nThe dataset is mostly NA values for the sex field, but say that our project is focused only on female greater bilbies, now we can do our simple filter using == as shown below.\n\nhead(filter(bilby, sex == \"FEMALE\"), 3)\n\n# A tibble: 3 × 11\n  recordID        scientificName taxonConceptID decimalLatitude decimalLongitude\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 006e17c1-672c-… Macrotis lago… https://biodi…           -34.2             143.\n2 016d575f-39cd-… Macrotis lago… https://biodi…           -30.6             149.\n3 0374b34c-054c-… Macrotis lago… https://biodi…           -34.2             143.\n# ℹ 6 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, sex &lt;fct&gt;, lifeStage &lt;lgl&gt;,\n#   reproductiveCondition &lt;chr&gt;\n\n\nWe could also use != \"MALE to get the same result, since we only have two factor levels, and dplyr::filter() drops NA values. Be aware that if filtering with base R subsetting, the same approach would drop male rows but keep both female and NA rows.\n\nnrow(filter(bilby, sex != \"MALE\"))\n\n[1] 139\n\nnrow(filter(bilby[bilby$sex != \"MALE\", ]))\n\n[1] 21514\n\n\n\n\n25.2.4 Ecosystems\nFiltering by ecosystem, such as removing terrestrial records or aquatic records, can be necessary depending on the project. Below we demonstrate an example of filtering against the World Register of Marine Species (WoRMS), to remove marine invertebrates from our dataset. Note that you could apply this approach to any other ecosystem by using an appropriate list of species.\n\n\n\n\n# Obtain species list\nmy_species &lt;- inverts |&gt;\n  pull(scientificName) |&gt;\n  unique()\n\n# Query WoRMs\nmarine_check &lt;- purrr::map_dfr(\n  my_species,\n  purrr::possibly(~ worrms::wm_records_name(name = .x) |&gt;\n    mutate(search_term = .x))\n)\n# Filter species that are TRUE for isMarine\nmarine_inverts &lt;- marine_check |&gt;\n  filter(isMarine == TRUE)\n\n# Exclude marine invertebrates\nfilter(inverts, !scientificName %in% marine_inverts$search_term)\n\n# A tibble: 1,801 × 8\n   decimalLatitude decimalLongitude eventDate           scientificName   \n             &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;            \n 1           -46.9             37.8 1983-04-01 00:00:00 Palirhoeus eatoni\n 2           -46.9             37.8 1984-09-01 00:00:00 Palirhoeus eatoni\n 3           -46.9             37.9 1986-04-01 00:00:00 Palirhoeus eatoni\n 4           -46.6             38.0 1985-04-01 00:00:00 Palirhoeus eatoni\n 5           -46.6             38.0 1983-05-01 00:00:00 Palirhoeus eatoni\n 6           -46.6             38.0 1984-09-01 00:00:00 Palirhoeus eatoni\n 7           -46.6             38.0 1984-04-01 00:00:00 Palirhoeus eatoni\n 8           -43.6            148.  NA                  Lasaea australis \n 9           -43.6            147.  2008-12-28 00:00:00 Lasaea australis \n10           -43.6            147.  2008-12-28 00:00:00 Lasaea australis \n# ℹ 1,791 more rows\n# ℹ 4 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;\n\n\nAfter filtering we are left with only four records of one species. It’s always worth double checking the results of your filtering, to make sure any species excluded or included are as expected.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomic_validation.html#taxonomic-classification",
    "href": "cleaning_taxonomic_validation.html#taxonomic-classification",
    "title": "26  Taxonomic validation",
    "section": "26.1 Taxonomic classification",
    "text": "26.1 Taxonomic classification\nTaxonomic classification is a complex issue when working with open source biodiversity data. Data infrastructures have their own taxonomic systems, which can lead to variations across platforms in hierarchical information. Furthermore, taxonomic classification is in a state of constant change, and views may differ within the literature or across authorities (refer back to Taxnomy and open source data). As a result, it is often the case that you will have synonyms, meaning, more than one name for the same species, in your dataset. Keep in mind that there is no universal solution to these issues. However you choose to resolve them, we recommend that you maintain a clear and explicit record of any decisions and changes made with respect to the data.\n\n26.1.1 Detecting synonyms\nThere are several packages available that can be used to query different taxonomic databases and check for synonyms.\n\n26.1.1.1 worrms\nThe {worrms} is the R interface to the World Register of Marine Species and has the ability to cross check synonyms with their database for taxa that has an AphiaID. The function will return synonymous record(s) associated with another different AphiaID.\n\nlibrary(worrms)\n\nmarine_sp &lt;- read_csv(\"data/worms/worms.csv\")\n\nmarine_sp |&gt;\n  slice(7) |&gt;\n  pull(AphiaID) |&gt;\n  wm_synonyms()\n\n# A tibble: 1 × 27\n  AphiaID url   scientificname authority status unacceptreason taxonRankID rank \n    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;                &lt;int&gt; &lt;chr&gt;\n1  453207 http… Goniosoma ina… Walker, … super… NA                     220 Spec…\n# ℹ 19 more variables: valid_AphiaID &lt;int&gt;, valid_name &lt;chr&gt;,\n#   valid_authority &lt;chr&gt;, parentNameUsageID &lt;int&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   citation &lt;chr&gt;, lsid &lt;chr&gt;, isMarine &lt;int&gt;, isBrackish &lt;int&gt;,\n#   isFreshwater &lt;int&gt;, isTerrestrial &lt;int&gt;, isExtinct &lt;int&gt;, match_type &lt;chr&gt;,\n#   modified &lt;chr&gt;\n\n\n\n\n26.1.1.2 taxize\n\n\nThe taxize package allows users to search over many taxonomic data sources for hierarchial taxonomic information, such as species names (scientific and common), to resolve synonymy. The gnr_resolve() function matches a supplied list with up to 118 data sources including GBIF, Catalogue of Life, World Register of Marine Species and many more. The function scores how well matched your name is to these sources.\n\nlibrary(taxize)\n\n# Read in a naming authority list\nafd &lt;- read_csv(\"data/naming/afd.csv\")\nunique(afd$VALID_NAME)\n\n [1] \"Prosphaerosyllis battiri\"         \"Clavellopsis parasargi\"          \n [3] \"Platypontonia hyotis\"             \"Palirhoeus eatoni\"               \n [5] \"Diastylis kapalae\"                \"Xenobates chinai\"                \n [7] \"Paratanais gaspodei\"              \"Paradexamine flindersi\"          \n [9] \"Prostebbingia brevicornis\"        \"Cythere lactea\"                  \n[11] \"Cythere melobesioides\"            \"Achelia transfugoides\"           \n[13] \"Halobates (Halobates) acherontis\" \"Quadraceps hopkinsi apophoretus\" \n[15] \"Anabarhynchus striatus\"           \"Australocytheridea vandenboldi\"  \n[17] \"Enigmaplax littoralis\"            \"Hyphalus insularis\"              \n[19] \"Plesiopenaeus armatus\"            \"Uroptychus brucei\"               \n[21] \"Caligus dasyaticus\"               \"Coralliophila tetragona\"         \n[23] \"Triphora alveolata\"               \"Clavus obliquatus\"               \n[25] \"Naria beckii\"                     \"Pharaonella rostrata\"            \n[27] \"Lasaea australis\"                 \"Cadulus rudmani\"                 \n[29] \"Bembicium flavescens\"             \"Mormula philippiana\"             \n[31] \"Turbonilla tiara\"                 \"Chlorodiloma crinita\"            \n[33] \"Mitrella merita\"                  \"Tritonoharpa antiquata\"          \n[35] \"Mauritia depressa dispersa\"       \"Laevidentalium zeidleri\"         \n[37] \"Conus (Harmoniconus) musicus\"     \"Marionia cyanobranchiata\"        \n[39] \"Tucetona flabellata\"              \"Neochromadora bilineata\"         \n[41] \"Desmoscolex membranosus\"          \"Echeneidocoelium indicum\"        \n[43] \"Indodidymozoon suttiei\"           \"Diploproctodaeum yosogi\"         \n[45] \"Pseudopecoelus japonicus\"         \"Pedibothrium lloydae\"            \n[47] \"Amphitethya stipitata\"            \"Pseudosuberites mollis\"          \n[49] \"Psammochela psammodes\"           \n\n# Resolve names\nresolved &lt;- gnr_resolve(unique(afd$VALID_NAME), best_match_only = TRUE)\nresolved |&gt; print(n = 50)\n\n# A tibble: 49 × 5\n   user_supplied_name        submitted_name matched_name data_source_title score\n * &lt;chr&gt;                     &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt;\n 1 Prosphaerosyllis battiri  Prosphaerosyl… Prosphaeros… National Center … 0.988\n 2 Clavellopsis parasargi    Clavellopsis … Clavellopsi… uBio NameBank     0.988\n 3 Platypontonia hyotis      Platypontonia… Platyponton… National Center … 0.988\n 4 Palirhoeus eatoni         Palirhoeus ea… Palirhoeus … Wikispecies       0.988\n 5 Diastylis kapalae         Diastylis kap… Diastylis k… Encyclopedia of … 0.988\n 6 Xenobates chinai          Xenobates chi… Xenobates c… Encyclopedia of … 0.988\n 7 Paratanais gaspodei       Paratanais ga… Paratanais … Wikispecies       0.988\n 8 Paradexamine flindersi    Paradexamine … Paradexamin… Encyclopedia of … 0.988\n 9 Prostebbingia brevicornis Prostebbingia… Prostebbing… Encyclopedia of … 0.988\n10 Cythere lactea            Cythere lactea Cythere lac… Encyclopedia of … 0.988\n11 Cythere melobesioides     Cythere melob… Cythere mel… Encyclopedia of … 0.988\n12 Achelia transfugoides     Achelia trans… Achelia tra… National Center … 0.988\n13 Halobates (Halobates) ac… Halobates (ha… Halobates (… CU*STAR           0.999\n14 Quadraceps hopkinsi apop… Quadraceps ho… Quadraceps … Catalogue of Lif… 0.999\n15 Anabarhynchus striatus    Anabarhynchus… Anabarhynch… Encyclopedia of … 0.988\n16 Australocytheridea vande… Australocythe… Australocyt… Encyclopedia of … 0.988\n17 Enigmaplax littoralis     Enigmaplax li… Enigmaplax … Encyclopedia of … 0.988\n18 Hyphalus insularis        Hyphalus insu… Hyphalus in… Wikispecies       0.988\n19 Plesiopenaeus armatus     Plesiopenaeus… Plesiopenae… Wikispecies       0.988\n20 Uroptychus brucei         Uroptychus br… Uroptychus … Wikispecies       0.988\n21 Caligus dasyaticus        Caligus dasya… Caligus das… Encyclopedia of … 0.988\n22 Coralliophila tetragona   Coralliophila… Coralliophi… Encyclopedia of … 0.988\n23 Triphora alveolata        Triphora alve… Triphora al… uBio NameBank     0.988\n24 Clavus obliquatus         Clavus obliqu… Clavus obli… Encyclopedia of … 0.988\n25 Naria beckii              Naria beckii   Naria beckii National Center … 0.988\n26 Pharaonella rostrata      Pharaonella r… Pharaonella… Arctos            0.988\n27 Lasaea australis          Lasaea austra… Lasaea aust… National Center … 0.988\n28 Cadulus rudmani           Cadulus rudma… Cadulus rud… Encyclopedia of … 0.988\n29 Bembicium flavescens      Bembicium fla… Bembicium f… National Center … 0.988\n30 Mormula philippiana       Mormula phili… Mormula phi… Encyclopedia of … 0.988\n31 Turbonilla tiara          Turbonilla ti… Turbonilla … Encyclopedia of … 0.988\n32 Chlorodiloma crinita      Chlorodiloma … Chlorodilom… National Center … 0.988\n33 Mitrella merita           Mitrella meri… Mitrella me… Encyclopedia of … 0.988\n34 Tritonoharpa antiquata    Tritonoharpa … Tritonoharp… National Center … 0.988\n35 Mauritia depressa disper… Mauritia depr… Mauritia de… National Center … 0.999\n36 Laevidentalium zeidleri   Laevidentaliu… Laevidental… Encyclopedia of … 0.988\n37 Conus (Harmoniconus) mus… Conus (harmon… Conus Linna… Catalogue of Lif… 0.75 \n38 Marionia cyanobranchiata  Marionia cyan… Marionia cy… National Center … 0.988\n39 Tucetona flabellata       Tucetona flab… Tucetona fl… Encyclopedia of … 0.988\n40 Neochromadora bilineata   Neochromadora… Neochromado… National Center … 0.988\n41 Desmoscolex membranosus   Desmoscolex m… Desmoscolex… Encyclopedia of … 0.988\n42 Echeneidocoelium indicum  Echeneidocoel… Echeneidoco… Integrated Taxon… 0.988\n43 Indodidymozoon suttiei    Indodidymozoo… Indodidymoz… National Center … 0.988\n44 Diploproctodaeum yosogi   Diploproctoda… Diploprocto… Encyclopedia of … 0.988\n45 Pseudopecoelus japonicus  Pseudopecoelu… Pseudopecoe… Integrated Taxon… 0.988\n46 Pedibothrium lloydae      Pedibothrium … Pedibothriu… Encyclopedia of … 0.988\n47 Amphitethya stipitata     Amphitethya s… Amphitethya… Wikispecies       0.988\n48 Pseudosuberites mollis    Pseudosuberit… Pseudosuber… Encyclopedia of … 0.988\n49 Psammochela psammodes     Psammochela p… Psammochela… Wikispecies       0.988\n\n# Retrieve synonyms\ntsn &lt;- get_tsn(unique(afd$VALID_NAME)[1:5])\n\n══  5 queries  ═══════════════\n✖  Not Found:  Prosphaerosyllis battiri\n✖  Not Found:  Clavellopsis parasargi\n✔  Found:  Platypontonia hyotis\n✖  Not Found:  Palirhoeus eatoni\n✖  Not Found:  Diastylis kapalae\n══  Results  ═════════════════\n\n• Total: 5 \n• Found: 1 \n• Not Found: 4\n\nsynonyms(tsn)\n\n$&lt;NA&gt;\n[1] NA\n\n$&lt;NA&gt;\n[1] NA\n\n$`612530`\n  sub_tsn acc_tsn   syn_author                  syn_name syn_tsn\n1  612530  612530 Suzuki, 1971 Platypontonia pterostreae 1191962\n\n$&lt;NA&gt;\n[1] NA\n\n$&lt;NA&gt;\n[1] NA",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomic_validation.html#input-from-experts",
    "href": "cleaning_taxonomic_validation.html#input-from-experts",
    "title": "26  Taxonomic validation",
    "section": "26.2 Input from experts",
    "text": "26.2 Input from experts\nProgrammatic solutions for resolving synonymy can only go so far. Seeking validation from experts is sensible if your goal is to obtain a high quality species list. Museums or taxonomic societies are extensive sources of knowledge. Below we have provided a list of some of Australian taxonomic society groups.\n\n26.2.1 Australian taxonomic society groups\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists\n\n\n\n26.2.2 Global taxonomy\n\nGBIF taxonomic backbone - Uses over 100 different sources\nIntegrated Taxonomic Information System, ITIS - Authoritative taxonomic information on plants, animals, fungi, and microbes\nCatalogue of Life - Global taxonomic catalogue\n\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-precision-and-uncertainty",
    "href": "cleaning_geospatial.html#coordinate-precision-and-uncertainty",
    "title": "27  Geospatial data",
    "section": "27.1 Coordinate precision and uncertainty",
    "text": "27.1 Coordinate precision and uncertainty\nCoordinate precision describes the consistency of values if one were to record the coordinates of the same location, multiple times. Coordinate precision can vary between data sources and recording equipment. For example, coordinates recorded with a GPS unit or a phone generally has higher precision compared to those manually determined from locality descriptions.\n\n\nDepending on the scope of your research question, you may need to limit your occurrence data to a certain level of coordinate.\nWe recommend first including coordinatePrecision in your download query and excluding???? its completeness and range before you exclude any data.\n\nlibrary(galah)\nlibrary(skimr)\n\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  galah_select(group = \"basic\", coordinatePrecision) |&gt; \n  atlas_occurrences()\n\n# banksia_serrata |&gt; \n#   select(coordinatePrecision) |&gt; \n#   skim()\n\n# Filter by number of decimal places\n# banksia_serrata |&gt; \n#   filter(coordinatePrecision &lt; XXX) \n\nhttps://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2664.2007.01408.x",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-uncertainty",
    "href": "cleaning_geospatial.html#coordinate-uncertainty",
    "title": "25  Geospatial data",
    "section": "25.2 Coordinate Uncertainty",
    "text": "25.2 Coordinate Uncertainty\nAlternatively, you can refine your data using coordinate uncertainty which describes the possible circular area in meters where the true location is in.\n\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  galah_select(group = \"basic\", coordinatePrecision, coordinateUncertaintyInMeters) |&gt; \n  atlas_occurrences()\n\n# Filter by number of decimal places\n# banksia_serrata |&gt; \n#   filter(coordinateUncertaintyInMeters &lt; XXX) \n\n\n25.2.1 Missing coordinate data\nIf your research question requires spatial information, then it may be useful to exclude records that are missing coordinates data. Many spatial analytical tools are not compatible with missing coordinate data. We recommend tallying and identifying the rows that have missing data before excluding.\nYou can use drop_na() to remove missing values from your dataset.\n\nlibrary(dplyr)\n\n# Identify missing data in coordinates\nbanksia_serrata |&gt; \n  filter(is.na(decimalLatitude) | is.na (decimalLongitude))\n\n# Excluding them\nbanksia_serrata |&gt; \n  tidyr::drop_na(decimalLatitude, decimalLongitude)",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-correction",
    "href": "cleaning_geospatial.html#coordinate-correction",
    "title": "25  Geospatial data",
    "section": "25.3 Coordinate correction",
    "text": "25.3 Coordinate correction\nSome of these steps may have been completed in a pre-cleaning step, however it’s now time to be more rigorous. As always we’ll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:\nFlipped coordinates: Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected. (Jin and Yang 2020)\n\n#example map of some flipped coordinates (what to look for) \n# https://www.gbif.org/occurrence/3013406216 this has flipped coordinates, which GBIF has corrected\n# https://www.gbif.org/occurrence/search?q=mammalia&continent=SOUTH_AMERICA&has_coordinate=true&has_geospatial_issue=false&issue=PRESUMED_SWAPPED_COORDINATE&advanced=1. ## the issue and flag is called 'presumed swapped coordinate' \n\nNumerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.\n\n#example map, like coordinates off the coast of japan\n\n# https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51360942&qualityProfile=CSDM&radius=50&lat=35.66845370835343&lon=138.9990234375#tab_recordsView\n\n# eucs &lt;- galah_call() %&gt;% \n#  galah_identify(\"Eucalyptus\") %&gt;%\n#  galah_filter( year == 2005, \n#             dataResourceName == \"The University of Melbourne Herbarium (MELU) AVH data\") %&gt;%\n#  atlas_occurrences()\n\nCountry field doesn’t match coordinates: The coordinates could be wrong or just the country listed.\n\n## this doesnt seem to be very common- atleast not in ALA data- because there is no neighboring country\n# https://biocache.ala.org.au/occurrences/a34fca43-9e7c-4b37-8fe4-07cc18369465 Australian coordinates, country listed as Trinidad and Tobago\n# https://www.gbif.org/occurrence/search?advanced=true&continent=SOUTH_AMERICA&geometry=POLYGON((-78.74961%20-8.25249,-76.29838%20-8.25249,-76.29838%20-4.74121,-78.74961%20-4.74121,-78.74961%20-8.25249))&has_coordinate=true&issue=COUNTRY_MISMATCH&locale=en&q=reptilia   # GBIF example- reptiles located in Peru, originally recorded as Ecuador\n\n\n25.3.1 Quick visualisation\nOne of the most straightforward ways to check for spatial errors is to plot your data onto a map. More obvious spatial errors are much easier to spot visually.\n\n\nlibrary(ggplot2)\nlibrary(ozmaps) \nlibrary(sf)\n\n# Retrieve map of Australia\naus &lt;- st_transform(ozmap_country, 4326)\n\n# Remove missing coordinates in Banksia data\n# Then transform into 'sf' object\nbanksia_sf &lt;- banksia_serrata |&gt; \n  tidyr::drop_na(starts_with(\"decimal\")) |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326)\n\n# A quick plot\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) + \n  geom_sf(data = banksia_sf)",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-cleaning",
    "href": "cleaning_geospatial.html#coordinate-cleaning",
    "title": "25  Geospatial data",
    "section": "25.4 Coordinate cleaning",
    "text": "25.4 Coordinate cleaning\nOnce you have fixed everything you can, it’s time to remove records that still have errors. This doesn’t mean removing all outliers, you must have more than “it’s far away from the others” to justify a records removal.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, check first, however likely will need to remove\nRemove records with zero coordinates: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\n\n#zero coordinates acacia \n\n#https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51382879&disableAllQualityFilters=true&qualityProfile=ALA&fq=spatiallyValid%3A%22false%22&radius=25&lat=-0.024032592068740033&lon=-0.06591796875#tab_recordsView",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "href": "cleaning_geospatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "title": "25  Geospatial data",
    "section": "25.5 Remove records plotted away from the known area of distribution of the species.",
    "text": "25.5 Remove records plotted away from the known area of distribution of the species.\nIt is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it’s worth checking the literature before discarding records like these. These can also be mis-identified species, if you’re working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.\n\n\n\n\n25.5.1 Remove records with coordinates assigned to country and province centroids\nCentroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or grown in horticulture, which were not clearly labelled as such.\n\n\n25.5.2 Remove records from biological institutions\nsuch as botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and GBIF headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.\nIn a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\n\n\n25.5.3 CoordinateCleaner\nThis package probably worth looking at.\n\n\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "outliers.html#alternative-methods",
    "href": "outliers.html#alternative-methods",
    "title": "26  Outliers",
    "section": "",
    "text": "Species Distribution Modelling for outlier detection:\n\nSimões and Peterson (2018)\nMaxiomum Entropy modelling (MaxEnt) was used to model habitat suitability for five species of leaf beetles in the genus Mesomphalia\nThe method relies on the assumption that an errornous point will have a lower habitat suitability value than a true point.\nFor their dataset, the method was useful for identifying geographical position errors, but not species level identification errors.\n\n\n\n\n\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and Limitations of Climate-Matching Approaches in Detecting Different Types of Spatial Errors in Biodiversity Data.” Insect Conservation and Diversity 11 (5): 407–14.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Outliers</span>"
    ]
  },
  {
    "objectID": "2_exploring/inspect.html#metadata-inspection",
    "href": "2_exploring/inspect.html#metadata-inspection",
    "title": "5  Inspect",
    "section": "5.1 Metadata inspection",
    "text": "5.1 Metadata inspection\nMetadata describes your data set: it defines each variable and its contents. For example, describing a variables unit of measurement, climatic conditions at the time of observation, or whether the occurrence is a marked outlier. Reviewing the metadata of your dataset is a useful first step, as it allows you to understand the kind of data you are working with and any potential limitations of the data that could affect your analysis.\nData infrastructures that use Darwin Core terms will have interoperable metadata. This makes it easier to consolidate across data sets. All Darwin Core term definitions can be found here. We suggest using Ctrl/CMD F and searching your variable name on the webpage. Don’t hesitate to Google variable names if you are unsure what they represent.\nIt is also worth checking the available metadata for your dataset, to determine if there is extra information that may be relevant. You could Google the dataset name, or search the dataset or institution on the ALA. The metadata on the ALA is submitted with the data, and because the ALA is not the data owner, this data is immutable.\nAn example of well formatted metadata is FrogID from the Australian Museum. From reading FrogID’s metadata (Rowley and Callaghan 2020), you’ll find:\n\nThe data is acoustic data, the majority of the species recorded are therefore male.\nBecause this is citizen science data, it is especially biased towards populated areas.\nAudio is recorded via a smartphone app, and so the authors recommend filtering data to geographic uncertainty of &lt;3000m if you require high coordinate precision.\nThe data is presence only data.\n\nMetadata can also be useful for understanding the license that the data falls under. This is mostly relevant for using or republishing multimedia associated with the data.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "2_exploring/inspect.html#data-inspection",
    "href": "2_exploring/inspect.html#data-inspection",
    "title": "5  Inspect",
    "section": "5.2 Data inspection",
    "text": "5.2 Data inspection\nA great way to get an initial overview of your data is to use the R package skimr, which provides tables of descriptive statistics, such as amount of missing data, for each variable. The output is also grouped by data type (numeric, character, date) so you can also check for any inconsistencies.\nAs you are looking through the output, ask yourself whether the data is in line with your expectations. If you requested data for a group of species, are they all represented? Are the values for a variable reasonable? Looking at the quartiles can help you get the sense of the distribution of data. These considerations will help you detect potential issues in the data. Make sure you take note of any issues you find, to investigate further and later address.\nHere we will continue using the African elephant dataset that we downloaded in the previous chapter on downloading. You can create a report using the skimr package by running the following code: \n\nlibrary(skimr)\n\nWarning: package 'skimr' was built under R version 4.3.2\n\nafrican_ele &lt;- arrow::read_parquet(\"../data/gbif/elephant\")\nskim(african_ele)\n\n\nData summary\n\n\nName\nafrican_ele\n\n\nNumber of rows\n17978\n\n\nNumber of columns\n50\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n31\n\n\nlogical\n1\n\n\nnumeric\n15\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndatasetKey\n0\n1.00\n36\n36\n0\n150\n0\n\n\noccurrenceID\n806\n0.96\n1\n81\n0\n16971\n0\n\n\nkingdom\n0\n1.00\n8\n8\n0\n1\n0\n\n\nphylum\n0\n1.00\n8\n8\n0\n1\n0\n\n\nclass\n0\n1.00\n8\n8\n0\n1\n0\n\n\norder\n0\n1.00\n11\n11\n0\n1\n0\n\n\nfamily\n0\n1.00\n12\n12\n0\n1\n0\n\n\ngenus\n0\n1.00\n9\n9\n0\n1\n0\n\n\nspecies\n0\n1.00\n18\n18\n0\n1\n0\n\n\ninfraspecificEpithet\n17851\n0.01\n8\n13\n0\n2\n0\n\n\ntaxonRank\n0\n1.00\n7\n10\n0\n3\n0\n\n\nscientificName\n0\n1.00\n12\n37\n0\n5\n0\n\n\nverbatimScientificName\n3\n1.00\n12\n53\n0\n31\n0\n\n\nverbatimScientificNameAuthorship\n16411\n0.09\n2\n31\n0\n256\n0\n\n\ncountryCode\n1718\n0.90\n2\n2\n0\n47\n0\n\n\nlocality\n14587\n0.19\n3\n254\n0\n725\n0\n\n\nstateProvince\n6447\n0.64\n3\n43\n0\n198\n0\n\n\noccurrenceStatus\n0\n1.00\n6\n7\n0\n2\n0\n\n\npublishingOrgKey\n0\n1.00\n36\n36\n0\n106\n0\n\n\nbasisOfRecord\n0\n1.00\n10\n19\n0\n9\n0\n\n\ninstitutionCode\n4075\n0.77\n2\n76\n0\n111\n0\n\n\ncollectionCode\n4091\n0.77\n1\n41\n0\n169\n0\n\n\ncatalogNumber\n4292\n0.76\n1\n36\n0\n13571\n0\n\n\nrecordNumber\n17815\n0.01\n1\n37\n0\n114\n0\n\n\nidentifiedBy\n7519\n0.58\n1\n81\n0\n1931\n0\n\n\nlicense\n0\n1.00\n7\n12\n0\n3\n0\n\n\nrightsHolder\n7128\n0.60\n1\n56\n0\n2175\n0\n\n\nrecordedBy\n4967\n0.72\n1\n160\n0\n2525\n0\n\n\nestablishmentMeans\n17691\n0.02\n6\n9\n0\n2\n0\n\n\nmediaType\n8141\n0.55\n5\n16\n0\n4\n0\n\n\nissue\n3189\n0.82\n15\n191\n0\n146\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntypeStatus\n17978\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ngbifID\n0\n1.00\n2667216870.07\n1.094792e+09\n49926810.00\n1677325129.75\n2465040820.00\n3821042610.75\n4.508041e+09\n▁▇▇▅▇\n\n\nindividualCount\n15703\n0.13\n4.90\n1.415000e+01\n0.00\n1.00\n1.00\n2.00\n2.920000e+02\n▇▁▁▁▁\n\n\ndecimalLatitude\n4174\n0.77\n-11.35\n1.427000e+01\n-34.58\n-24.29\n-15.91\n-0.15\n5.215000e+01\n▇▅▃▁▁\n\n\ndecimalLongitude\n4174\n0.77\n26.50\n1.133000e+01\n-111.97\n24.40\n31.30\n34.81\n4.053000e+01\n▁▁▁▁▇\n\n\ncoordinateUncertaintyInMeters\n6762\n0.62\n41697.58\n1.438321e+05\n1.00\n29981.00\n30598.00\n31425.00\n5.635548e+06\n▇▁▁▁▁\n\n\ncoordinatePrecision\n17939\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n▆▁▁▁▇\n\n\nelevation\n17942\n0.00\n154.42\n4.215900e+02\n0.00\n0.00\n0.00\n13.75\n2.134000e+03\n▇▁▁▁▁\n\n\nelevationAccuracy\n17948\n0.00\n0.83\n3.730000e+00\n0.00\n0.00\n0.00\n0.00\n2.000000e+01\n▇▁▁▁▁\n\n\ndepth\n17950\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n▁▁▇▁▁\n\n\ndepthAccuracy\n17950\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n▁▁▇▁▁\n\n\nday\n4092\n0.77\n16.10\n8.790000e+00\n1.00\n9.00\n17.00\n24.00\n3.100000e+01\n▇▆▇▇▇\n\n\nmonth\n4027\n0.78\n6.97\n3.280000e+00\n1.00\n4.00\n7.00\n10.00\n1.200000e+01\n▆▅▅▇▇\n\n\nyear\n1017\n0.94\n2011.69\n1.672000e+01\n1799.00\n2008.00\n2015.00\n2019.00\n2.024000e+03\n▁▁▁▁▇\n\n\ntaxonKey\n0\n1.00\n2492768.10\n6.281924e+05\n2435350.00\n2435350.00\n2435350.00\n2435350.00\n1.150335e+07\n▇▁▁▁▁\n\n\nspeciesKey\n0\n1.00\n2435350.00\n0.000000e+00\n2435350.00\n2435350.00\n2435350.00\n2435350.00\n2.435350e+06\n▁▁▇▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n1017\n0.94\n1799-01-01 00:00:00\n2024-01-02 18:51:11\n2015-05-23 00:00:00\n10862\n\n\ndateIdentified\n7025\n0.61\n1783-01-01 00:00:00\n2024-01-02 18:50:47\n2021-02-25 16:47:56\n9670\n\n\nlastInterpreted\n0\n1.00\n2023-08-25 11:37:02\n2024-01-09 20:05:47\n2024-01-09 13:04:58\n16960\n\n\n\n\n\n\n5.2.1 Evaluating the dataset\nHere are some starting points for evaluating a dataset. As you go through the skimr report and perform these checks, make detailed notes of your observations and any potential issues.\n\nConfirm the number of records:\n\nVerify if the number of records in the dataset matches your expectations. If the number is significantly higher or lower than anticipated, it may indicate an issue with the query or data source.\n\nChecking for the correct metadata columns:\n\nEnsure that all expected metadata columns are present. These might include species names, dates, locations, etc. The absence of key columns could suggest a problem with the data extraction process.\n\nAssessing missing data in critical fields:\n\nCheck the amount of missing data, especially in critical fields like latitude and longitude. A high number of missing values in these fields can significantly impact the usability of the dataset for geospatial analysis.\n\nReviewing geospatial data accuracy:\n\nLook for anomalies in geospatial data. Check if the coordinates are within plausible ranges and if they correspond to the geographic regions you expected.\n\nEvaluating data distribution and outliers:\n\nUse the quartiles and summary statistics provided by skimr to assess the distribution of key variables. Be on the lookout for outliers or unusual patterns that might need further investigation.\n\nConsistency and formatting of categorical data:\n\nCheck for consistency in categorical data, such as species names. Inconsistencies might arise from variations in spelling, capitalization, or use of synonyms.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "2_exploring/inspect.html#next-steps",
    "href": "2_exploring/inspect.html#next-steps",
    "title": "5  Inspect",
    "section": "5.3 Next steps",
    "text": "5.3 Next steps\nKeep in mind, we don’t expect a perfect dataset from a download. The goal of an initial inspection is to assess whether the download returned results in line with your expections based on your query. Some issues are expected, and may not signify an issue with the download itself but rather the actual data. The initial inspection is therefore a good opportunity to also start noting these issues, as they will be addressed during the cleaning phase.\nBased on your initial findings, consider whether you need to refine your download query. Perhaps you uncovered some additional metadata fields during your metadata inspection, and would like to adjust your query to include them. Or maybe you noticed missing data in specific time frames or locations that you expected from your query, or missing metadata fields. This could mean you need to adjust your download query parameters or investigate those issues further.\nWhen you are satisfied that the dataset is largely as expected, you are ready to move onto the data cleaning section. If you are working with multiple datasets from different sources, the next chapter will cover integration of datasets.\n\n\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset: Expert-Validated Occurrence Records of Australia’s Frogs Collected by Citizen Scientists.” ZooKeys 912: 139.",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "2_exploring/summarise.html",
    "href": "2_exploring/summarise.html",
    "title": "6  Summarise",
    "section": "",
    "text": "This chapter could ideally contain some common ways to explore data in the three domains that the “Data Scope” chapter was divided into: Taxonomic, Temporal, Spatial.\nI think examples of ways to check counts and visualise these 3 data types is plenty. It’s worth quickly mentioning, too, that galah and (i assume) other packages that use APIs can get count summaries prior to downloading data (which is good practice).",
    "crumbs": [
      "Exploring biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summarising your data</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "1  Data for this book",
    "section": "",
    "text": "This chapter will add some context/metadata of the datasets we use throughout the book.\nAt the moment, all data is either downloaded through galah or saved in the data folder. A more cohesive option might be to create an R package that contains data for this book, which is fairly common in other R resources.\nFor now, this chapter can act as a place to record any data downloads you use. For example, if you use galah to download data for a specific chapter, record the chapter and the data download here. We may be able to consolidate some datasets if we can keep track of what type of data each chapter requires.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Data for this book</span>"
    ]
  },
  {
    "objectID": "packages.html#galah",
    "href": "packages.html#galah",
    "title": "18  Packages",
    "section": "18.2 galah",
    "text": "18.2 galah\n{galah} is an R and Python interface to biodiversity data hosted by the Atlas of Living Australia (ALA). It enables users to locate and download species occurrence records (observations, specimens, eDNA records, etc.), taxonomic information, or associated media such as images or sounds, and to restrict their queries to particular taxa or locations.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Packages</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA’s Data Cleaning Booklet",
    "section": "",
    "text": "Welcome\nWelcome to the Atlas of Living Australia Data Cleaning book. This book is designed to be a practical guide on cleaning georeferenced biodiverdsity data using R. We focus on specific processes and challenges you’ll face with biodiversity data. As such, this book isn’t a guide to data cleaning in general, but a targeted resource for anyone working with or interested in georeferenced biodiversity data.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "ALA’s Data Cleaning Booklet",
    "section": "How to contribute",
    "text": "How to contribute\nContributions to this document are welcome. For questions or feedback, please open an issue on our GitHub repository. If you’d like to suggest content changes, feel free to submit a pull request. We recommend opening an issue first to discuss potential changes. Our contribution guidelines can be found here.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "ALA’s Data Cleaning Booklet",
    "section": "How to cite",
    "text": "How to cite\nYou can cite this book as: Kar, F., Schneider, M., Schwenke, A., Kellie, D., Balasubramaniam, S., Torresan, 0., Fenker, J., Westgate, M. (2023). ALA’s Data Cleaning Booklet. Retrieved Month dd, yyyy, from https://atlasoflivingaustralia.github.io/cleaning_data/\n\n\nThis book is available free to read, and is licenced under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ALA’s Data Cleaning Booklet",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA)\nAuthors:\n\nShandiya Balasubramaniam\nFonti Kar\nDax Kellie\nJessica Fenker\nMargot Schneider\nAndrew Schwenke\nOlivia Torresan\nMartin Westgate",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html",
    "href": "cleaning_geospatial.html",
    "title": "25  Geospatial data",
    "section": "",
    "text": "25.1 Coordinate precision and uncertainty\nCoordinate precision describes the consistency of values if one were to record the coordinates of the same location, multiple times. Coordinate precision can vary between data sources and recording equipment. For example, coordinates recorded with a GPS unit or a phone generally has higher precision compared to those manually determined from locality descriptions.\nDepending on the scope of your research question, you may need to limit your occurrence data to a certain level of coordinate.\nWe recommend first including coordinatePrecision in your download query and excluding???? its completeness and range before you exclude any data.\nlibrary(galah)\nlibrary(skimr)\n\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  galah_select(group = \"basic\", coordinatePrecision) |&gt; \n  atlas_occurrences()\n\n# banksia_serrata |&gt; \n#   select(coordinatePrecision) |&gt; \n#   skim()\n\n# Filter by number of decimal places\n# banksia_serrata |&gt; \n#   filter(coordinatePrecision &lt; XXX)\nhttps://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2664.2007.01408.x",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "outliers.html",
    "href": "outliers.html",
    "title": "26  Outliers",
    "section": "",
    "text": "26.1 Alternative methods\nHere we document some other existing methods that can be used for outlier detection, and their limitations.",
    "crumbs": [
      "Archived: Cleaning data",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Outliers</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/missing-values.html",
    "href": "3_cleaning_general/missing-values.html",
    "title": "8  Missing values",
    "section": "",
    "text": "8.1 Missing values\nlibrary(skimr)\niris %&gt;%\n  skim() %&gt;%\n  dplyr::filter(n_missing &gt; 0)\n\n# A tibble: 0 × 15\n# ℹ 15 variables: skim_type &lt;chr&gt;, skim_variable &lt;chr&gt;, n_missing &lt;int&gt;,\n#   complete_rate &lt;dbl&gt;, factor.ordered &lt;lgl&gt;, factor.n_unique &lt;int&gt;,\n#   factor.top_counts &lt;chr&gt;, numeric.mean &lt;dbl&gt;, numeric.sd &lt;dbl&gt;,\n#   numeric.p0 &lt;dbl&gt;, numeric.p25 &lt;dbl&gt;, numeric.p50 &lt;dbl&gt;, numeric.p75 &lt;dbl&gt;,\n#   numeric.p100 &lt;dbl&gt;, numeric.hist &lt;chr&gt;",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Missing values</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/unexpected-values.html",
    "href": "3_cleaning_general/unexpected-values.html",
    "title": "9  Unexpected values",
    "section": "",
    "text": "9.1 Unexpected values\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmerged_data &lt;- read.csv(\"../data/galah/chloris.csv\")\n\nunique(merged_data$countryCode)\n\n[1] \"AU\" NA   \"JP\"\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]\n\n        X decimalLatitude decimalLongitude           eventDate\n3995 3995         24.4856         151.5842 2013-12-30 14:00:00\n6722 6722         24.4856         151.5842 2013-12-30 14:00:00\n                        scientificName\n3995                   Litoria chloris\n6722 Litoria chloris (Boulenger, 1892)\n                                                                taxonConceptID\n3995 https://biodiversity.org.au/afd/taxa/f532b88a-a6c0-4006-aa24-77e3d645530e\n6722                                                                      &lt;NA&gt;\n                                 recordID                  dataResourceName\n3995 c08e641e-cf01-4f0f-b5ad-c3b8fcff4da4 ALA species sightings and OzAtlas\n6722                                 &lt;NA&gt;                              &lt;NA&gt;\n     occurrenceStatus     basisOfRecord  kingdom taxonRank   phylum    class\n3995          PRESENT HUMAN_OBSERVATION Animalia   species Chordata Amphibia\n6722          PRESENT HUMAN_OBSERVATION Animalia   SPECIES Chordata Amphibia\n     order        family    genus         species countryCode locality\n3995 Anura       Hylidae  Litoria Litoria chloris          JP mt bucca\n6722 Anura Pelodryadidae Ranoidea Litoria chloris          JP mt bucca\n     stateProvince coordinateUncertaintyInMeters coordinatePrecision\n3995          &lt;NA&gt;                          5000                  NA\n6722          &lt;NA&gt;                          5000                  NA\n       dcterms.license                         occurrenceID source     gbifID\n3995 CC-BY-NC 3.0 (Au)             52c2c6973dff6b1593e42ef9    ALA         NA\n6722              &lt;NA&gt; c08e641e-cf01-4f0f-b5ad-c3b8fcff4da4   GBIF 1632945208\n                               datasetKey infraspecificEpithet\n3995                                 &lt;NA&gt;                   NA\n6722 84a649ce-ff81-420d-9c41-aa1de59e3766                   NA\n     verbatimScientificName verbatimScientificNameAuthorship individualCount\n3995                   &lt;NA&gt;                             &lt;NA&gt;              NA\n6722        Litoria chloris                (Boulenger, 1893)              NA\n                         publishingOrgKey elevation elevationAccuracy depth\n3995                                 &lt;NA&gt;        NA                NA    NA\n6722 adc174cd-c752-4eee-9630-7c1209eb1c4a        NA                NA    NA\n     depthAccuracy day month year taxonKey speciesKey institutionCode\n3995            NA  NA    NA   NA       NA         NA            &lt;NA&gt;\n6722            NA  30    12 2013  2427866   10759325            &lt;NA&gt;\n     collectionCode catalogNumber\n3995           &lt;NA&gt;          &lt;NA&gt;\n6722           &lt;NA&gt;          &lt;NA&gt;\n                                                                                       recordNumber\n3995                                                                                           &lt;NA&gt;\n6722 https://biocollect.ala.org.au/sightings/bioActivity/index/0d598d06-a077-48e1-b632-e856bc63f264\n     identifiedBy dateIdentified   license rightsHolder    recordedBy\n3995         &lt;NA&gt;           &lt;NA&gt;      &lt;NA&gt;         &lt;NA&gt;          &lt;NA&gt;\n6722         &lt;NA&gt;           &lt;NA&gt; CC_BY_4_0         &lt;NA&gt; Kylie, Carman\n     typeStatus establishmentMeans     lastInterpreted mediaType issue\n3995       &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;      &lt;NA&gt;  &lt;NA&gt;\n6722       &lt;NA&gt;               &lt;NA&gt; 2023-08-26 03:07:16      &lt;NA&gt;  &lt;NA&gt;\n\n# where should the point be? can check the `locality` column and coordinates\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$decimalLatitude\n\n[1] 24.4856 24.4856\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$decimalLongitude\n\n[1] 151.5842 151.5842\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$locality\n\n[1] \"mt bucca\" \"mt bucca\"\n\n# mt bucca is in australia but the coordinates are incorrect\n# the latitude is missing an \"-\"\n# we can fix this and check the result (#TODO map vis)\nfixed &lt;- merged_data %&gt;%\n  mutate(decimalLatitude = ifelse(countryCode == \"JP\", paste0(\n    \"-\",\n    decimalLatitude\n  ), decimalLatitude)) %&gt;%\n  mutate(countryCode = ifelse(countryCode == \"JP\", \"AU\", countryCode))",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Unexpected values</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/strings.html",
    "href": "3_cleaning_general/strings.html",
    "title": "10  Strings",
    "section": "",
    "text": "10.1 Basic string manipulation\nThe stringr package provides a number of useful functions for manipulating strings, many of which are useful when dealing with biodiversity data.\nlibrary(stringr)\nstr_trim(\"  Genus specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trim(\"  Genus specificus  \", side = \"left\")\n\n[1] \"Genus specificus  \"\n\nstr_squish(\"  Genus   specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trunc(\"Genus specificus\", width = 10, side = \"right\")\n\n[1] \"Genus s...\"\n\nstr_split(\"Genus specificus\", \" \")\n\n[[1]]\n[1] \"Genus\"      \"specificus\"\n\nstr_c(\"Genus\", \"specificus\", sep = \"_\")\n\n[1] \"Genus_specificus\"",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "3_cleaning_general/column-names-and-classes.html",
    "href": "3_cleaning_general/column-names-and-classes.html",
    "title": "12  Column names & classes",
    "section": "",
    "text": "12.1 Setup\nlibrary(galah)\ngalah_config(atlas = \"Australia\") # default\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"))\n\nresult &lt;- galah_call() |&gt;\n  galah_identify(\"Litoria\") |&gt;\n  galah_filter(year &gt;= 2020, cl22 == \"Tasmania\") |&gt;\n  atlas_occurrences()\n\n----\n\nresult |&gt; head()\n\n# A tibble: 6 × 8\n  recordID        scientificName taxonConceptID decimalLatitude decimalLongitude\n  &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;                    &lt;dbl&gt;            &lt;dbl&gt;\n1 00168ca6-84d0-… Litoria        https://biodi…           -41.2             146.\n2 00250163-ec50-… Litoria        https://biodi…           -41.2             147.\n3 003e0f63-9f95-… Litoria ewing… https://biodi…           -42.9             148.\n4 00410554-5289-… Litoria ewing… https://biodi…           -41.7             147.\n5 0070521f-bb45-… Litoria ewing… https://biodi…           -43.1             147.\n6 0081e7ef-459b-… Litoria ewing… https://biodi…           -43.2             147.\n# ℹ 3 more variables: eventDate &lt;dttm&gt;, occurrenceStatus &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;",
    "crumbs": [
      "Cleaning data: General",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Column names & classes</span>"
    ]
  }
]