[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA Data Cleaning",
    "section": "",
    "text": "Welcome\nData cleaning is the exploration, detection and correction of erroneous data. The standard of what ‘clean’ data looks like varies considerably across projects and data sources. This means that there is no ‘one-size-fits-all’ approach.\nOur goal in creating this resource was to assist researchers and decision makers that may have limited experience with cleaning geo-referenced biodiversity data in R.\nIn this book, we provide an overview of a typical data cleaning workflow - from acquisition, to identifying potential errors to correction. Throughout each chapter, we include practical guidelines, R code blocks and additional resources that may aid with each data cleaning step.\nThe content of this book is guided by the current state of biodiversity literature on preparing data for species distribution modelling. For more details about how this was done, please refer to the Appendix. All resources that have been consulted for this book can be found in References."
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "ALA Data Cleaning",
    "section": "How to contribute",
    "text": "How to contribute\nWe would like to preface that we are not experts in data cleaning, but felt there was need for a consolidated resource to guide data cleaning decisions.\nWe welcome contributions to this document and suggest folks to submit pull requests at the GitHub repository of this document. Contributing guidelines can be found at XX (Maybe another section or just a MD in GitHub Repo)\nAlternatively, if you have questions please submit a GitHub issue."
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "ALA Data Cleaning",
    "section": "How to cite",
    "text": "How to cite\nTO COME BACK TO THIS LATER Refer to this when creating this section(https://ardc.edu.au/resource/citing-software/)\nYou can cite this document:"
  },
  {
    "objectID": "index.html#acknowlodgements",
    "href": "index.html#acknowlodgements",
    "title": "ALA Data Cleaning",
    "section": "Acknowlodgements",
    "text": "Acknowlodgements\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA)\nAuthors listed in alphabetic order:\n- Fonti Kar\n- Jessica Fenker\n- Margot Schneider\n- Martin Westgate"
  },
  {
    "objectID": "taxonomy.html#taxonomy-preclean",
    "href": "taxonomy.html#taxonomy-preclean",
    "title": "5  Taxonomy",
    "section": "5.1 Taxonomy preclean",
    "text": "5.1 Taxonomy preclean\nSimilar to what we did in the previous chapter, we will apply a broad sweep pre-clean to taxonomic data. This will make dealing with synonyms go as smoothly as possible.\nThe process is to first identify the issue, correct it, check it, and then document the changes. The goal is to standardise and correct as many errors issues before removing records.\n\n5.1.1 Capitalisation\nNormally higher taxonomy are capitalised e.g. Myrtaceae or Aves. Capitalisation errors are usually quick to spot when you print the data object. Alternatively you can try using str_subset on columns you expect to have capital letters.\nThe code below subsets out unique values for the variable class that have upper case letters. Notice that no matches are found\n\nlibrary(tidyverse)\n\nstr_subset(unique(bees$class), \"[:upper:]\")\n\ncharacter(0)\n\n\nWe can confirm that there are no upper case matches by subsetting unique values that have lower case letters to see what is going on. This shows us that Insecta is inputted entirely in lowercase.\n\nstr_subset(unique(bees$class), \"[:lower:]\") \n\n[1] \"insecta\"\n\n\nWe can correct the lower case formatting as below, remember to check the fix before overwriting/removing the erroneous column(s)\n\nbees |&gt; \n  mutate(class_corrected = str_to_sentence(class)) |&gt;\n  select(starts_with(\"class\"))\n\n# A tibble: 1,139 × 2\n   class   class_corrected\n   &lt;chr&gt;   &lt;chr&gt;          \n 1 insecta Insecta        \n 2 insecta Insecta        \n 3 insecta Insecta        \n 4 insecta Insecta        \n 5 insecta Insecta        \n 6 insecta Insecta        \n 7 insecta Insecta        \n 8 insecta Insecta        \n 9 insecta Insecta        \n10 insecta Insecta        \n# ℹ 1,129 more rows\n\nbees_corrected &lt;- bees |&gt; \n  mutate(class_corrected = str_to_sentence(class)) |&gt; \n  select(-class) |&gt; # Remove erroreous column \n  rename(class = class_corrected) # Rename corrected column as the new 'class'\n\n\n\n5.1.2 Seperators\nIn a taxonomic data, separators such as, spaces and underscore are found in scientific names and are used to delineate the genus and species name. While it is personal choice which separator you use, it is good practice to be consistent with your choice. Consistency ensures that unique values of scientific name truly reflects unique species and not due to inconsistencies.\nTry tabyl-ing your taxonomic columns to check if you have any inconsistencies first\n\nlibrary(janitor)\n\nplants |&gt; \n  pull(scientific_name) |&gt; \n  tabyl() |&gt; \n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants, scientific_name)`         n  percent\n   &lt;chr&gt;                               &lt;int&gt;    &lt;dbl&gt;\n 1 Acacia asparagoides                     2 0.000962\n 2 Acacia barakulensis                     1 0.000481\n 3 Acacia barringtonensis                  2 0.000962\n 4 Acacia beadleana                        1 0.000481\n 5 Acacia betchei                          6 0.00289 \n 6 Acacia blayana                          2 0.000962\n 7 Acacia brunioides                       1 0.000481\n 8 Acacia brunioides subsp. brunioides     6 0.00289 \n 9 Acacia brunioides subsp. granitica      1 0.000481\n10 Acacia bulgaensis                       3 0.00144 \n# ℹ 613 more rows\n\n\nConsistent taxonomic formatting may not be an issue if you are downloading data from one single source such as the ALA where scientific names are already formatted consistently e.g. “Moloch horridus”. This may not be the case when consolidating data from multiple sources.\nBelow is code to create an underscore scientific name from one that is separated with a space. Remember to check your changes\n\nplants_updated &lt;- plants |&gt; \n  mutate(scientific_name_undersc = str_replace_all(scientific_name, \" \", \"_\")) \n\nplants_updated |&gt; \n  pull(scientific_name_undersc) |&gt; \n  tabyl() |&gt; \n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants_updated, scientific_name_undersc)`     n  percent\n   &lt;chr&gt;                                           &lt;int&gt;    &lt;dbl&gt;\n 1 Acacia_asparagoides                                 2 0.000962\n 2 Acacia_barakulensis                                 1 0.000481\n 3 Acacia_barringtonensis                              2 0.000962\n 4 Acacia_beadleana                                    1 0.000481\n 5 Acacia_betchei                                      6 0.00289 \n 6 Acacia_blayana                                      2 0.000962\n 7 Acacia_brunioides                                   1 0.000481\n 8 Acacia_brunioides_subsp._brunioides                 6 0.00289 \n 9 Acacia_brunioides_subsp._granitica                  1 0.000481\n10 Acacia_bulgaensis                                   3 0.00144 \n# ℹ 613 more rows\n\n\n\n\n5.1.3 Higher taxonomy\nHigher taxonomy such as phylum and class may be used to group species for analysis or data visualisations. Its important to check the spelling and formatting of these columns. Its always good to start with some a useful table of counts for each taxonomic level. Keep an eye out for spelling errors, formatting issues and missing data. Note that NA in the output represents missing\nAs an example:\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nplants |&gt; \n  pull(class) |&gt; \n  tabyl()\n\n pull(plants, class)    n     percent valid_percent\n         Cycadopsida    4 0.001924002   0.001937046\n       Equisetopsida  202 0.097162097   0.097820823\n      Lycopodiopsida   10 0.004810005   0.004842615\n       Magnoliopsida 1822 0.876382876   0.882324455\n           Pinopsida    2 0.000962001   0.000968523\n      Polypodiopsida   25 0.012025012   0.012106538\n                &lt;NA&gt;   14 0.006734007            NA\n\nplants |&gt; \n  pull(order) |&gt; \n  tabyl() |&gt; \n  head()\n\n pull(plants, order)   n     percent valid_percent\n         Alismatales   6 0.002886003   0.002939735\n             Apiales  36 0.017316017   0.017638413\n         Asparagales  67 0.032227032   0.032827046\n           Asterales 158 0.075998076   0.077413033\n    Austrobaileyales   6 0.002886003   0.002939735\n          Canellales   5 0.002405002   0.002449780\n\nplants |&gt; \n  pull(genus) |&gt; \n  tabyl() |&gt; \n  tail()\n\n pull(plants, genus)  n     percent valid_percent\n               Viola  5 0.002405002   0.002501251\n          Westringia 12 0.005772006   0.006003002\n           Xanthosia  9 0.004329004   0.004502251\n               Xyris  4 0.001924002   0.002001001\n              Zieria 14 0.006734007   0.007003502\n                &lt;NA&gt; 80 0.038480038            NA\n\n\n\nMissing higher taxonomy\nIf you noticed you have missing data in these columns, you can usually back fill this information using your chosen naming authority or retrieving this information from a living atlas such as the ALA.\nThe code below demonstrates how you can isolate the scientific_names of taxa with missing data and searching for taxonomic information from ALA\n\n\n\nlibrary(galah)\n\n# Configure galah to point to Australia node\ngalah_config(atlas = \"Australia\",\n             email = Sys.getenv(\"ALA_EMAIL\"))\n\n# These are the taxa missing `class` information\nto_search &lt;- inverts |&gt; \n  filter(is.na(class)) |&gt; \n  select(scientific_name) |&gt; \n  distinct()\n\n# Reformat scientific_name to scientificName as the latter is the ALA format\nbackfilled_taxa &lt;- to_search|&gt;\n  rename(scientificName = scientific_name) |&gt; \n  search_taxa(to_search) |&gt; tibble()\n\nbackfilled_taxa\n\n# A tibble: 818 × 15\n   search_term     scientific_name scientific_name_auth…¹ taxon_concept_id rank \n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;\n 1 Idiosoma manst… Idiosoma manst… (Pocock, 1897)         https://biodive… spec…\n 2 Holonuncia rec… Holonuncia rec… Hunt, 1992             https://biodive… spec…\n 3 Trachycosmus s… Trachycosmus s… Simon, 1893            https://biodive… spec…\n 4 Pseudotyrannoc… Pseudotyrannoc… Beier, 1971            https://biodive… spec…\n 5 Phryganoporus … Phryganoporus … (L. Koch, 1872)        https://biodive… spec…\n 6 Latrodectus ha… Latrodectus ha… Thorell, 1870          https://biodive… spec…\n 7 Ascoschoengast… Ascoschoengast… (Hirst, 1915)          https://biodive… spec…\n 8 Chrestobunus f… Chrestobunus f… Hickman, 1958          https://biodive… spec…\n 9 Supunna picta   Nyssus colorip… Walckenaer, 1805       https://biodive… spec…\n10 Tasmanicosa le… Tasmanicosa le… (Thorell, 1870)        https://biodive… spec…\n# ℹ 808 more rows\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 10 more variables: match_type &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;,\n#   class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   issues &lt;chr&gt;, vernacular_name &lt;chr&gt;\n\n\n\n\nInsufficient taxonomic rank\nIf a record is not identified down to the taxonomic level that needed for the study e.g. species, then the record should be removed.\nDuring your data download, ensure you have requested for the column taxonRank, this variable tells us the lowest level of scientificName.\n\nlibrary(galah)\n\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"),\n             atlas = \"Australia\")\n\nhoneyeaters &lt;- galah_call() |&gt; \n  galah_identify(\"Meliphagidae\") |&gt; \n  galah_filter(year == 2012 & stateProvince == \"New South Wales\") |&gt; \n  galah_select(group = \"basic\", taxonRank) |&gt; \n  atlas_occurrences()\n\nhoneyeaters$taxonRank |&gt; unique()\n\nhoneyeaters |&gt; filter(taxonRank == \"species\")\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\n# honeyeaters &lt;- galah_call() |&gt;\n#   galah_identify(\"Meliphagidae\") |&gt;\n#   galah_filter(year == 2012 & stateProvince == \"New South Wales\") |&gt;\n#   galah_select(group = \"basic\", taxonRank) |&gt;\n#   atlas_occurrences()\n\n# write_parquet(honeyeaters, \"data/galah/honeyeater\")\n\nhoneyeaters &lt;- open_dataset(\"data/galah/honeyeater\") |&gt; collect()\n\nhoneyeaters$taxonRank |&gt; unique()\n\n[1] \"species\"    \"genus\"      \"subgenus\"   \"subspecies\" \"family\"    \n\nhoneyeaters |&gt; filter(taxonRank == \"species\")\n\n# A tibble: 43,684 × 9\n   decimalLatitude decimalLongitude eventDate           scientificName          \n             &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;                   \n 1           -37.4             150. 2012-09-26 14:00:00 Meliphaga (Meliphaga) l…\n 2           -37.4             150. 2012-09-26 14:00:00 Acanthorhynchus tenuiro…\n 3           -37.4             150. 2012-04-07 14:00:00 Acanthorhynchus tenuiro…\n 4           -37.4             150. 2012-04-07 14:00:00 Nesoptilotis leucotis   \n 5           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Meliornis…\n 6           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Phylidony…\n 7           -37.4             150. 2012-04-07 14:00:00 Nesoptilotis leucotis   \n 8           -37.4             150. 2012-04-07 14:00:00 Phylidonyris (Meliornis…\n 9           -37.4             150. 2012-04-07 14:00:00 Melithreptus (Melithrep…\n10           -37.4             150. 2012-04-07 14:00:00 Acanthorhynchus tenuiro…\n# ℹ 43,674 more rows\n# ℹ 5 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, taxonRank &lt;chr&gt;\n\n\n\n\nInconsistent higher taxonomy\nA great approach to detect inconsistencies in your taxonomic data is to compute counts for each level of taxonomic rank. These counts act as a check for you to verify that the data is in line with your expectation. This is particularly important when combining data from different sources where their taxonomy might vary. If you have detected inconsistencies as we have done below, you will have to correct accordingly, either by consulting a taxonomic expert or a naming authority and ensure this is reported in your methods.\n\n# Get counts for every species where they have more than 1 class\nplants |&gt; \n  select(phylum:species, scientific_name) |&gt; \n  distinct() |&gt; \n  group_by(species) |&gt; \n  summarise(n_class = length(unique(class))) |&gt; \n  filter(n_class &gt; 1) \n\n# A tibble: 1 × 2\n  species               n_class\n  &lt;chr&gt;                   &lt;int&gt;\n1 Allocasuarina distyla       2\n\n# Get the species that have more than 1 class\ninconsistent_taxa &lt;- plants |&gt; \n  select(phylum:species, scientific_name) |&gt; \n  distinct() |&gt; \n  group_by(species) |&gt; \n  summarise(n_class = length(unique(class))) |&gt; \n  filter(n_class &gt; 1) |&gt; \n  pull(species) \n\n# Filter species that have more than 1 class\nplants |&gt; filter(species %in% inconsistent_taxa) |&gt; \n  select(phylum:species, scientific_name) |&gt; \n  arrange(species) |&gt; \n  distinct() \n\n# A tibble: 2 × 7\n  phylum       class         order   family        genus species scientific_name\n  &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;          \n1 Tracheophyta Magnoliopsida Fagales Casuarinaceae Allo… Alloca… Allocasuarina …\n2 Tracheophyta Equisetopsida Fagales Casuarinaceae Allo… Alloca… Allocasuarina …"
  },
  {
    "objectID": "taxonomy.html#synonyms",
    "href": "taxonomy.html#synonyms",
    "title": "5  Taxonomy",
    "section": "5.2 Synonyms",
    "text": "5.2 Synonyms\nSynonyms is a complex issue when working with open source biodiversity data. Data infrastructures have their own taxonomic systems which may not align with researchers’ view or consistent with your chosen naming authority.\nKeeping in mind that there is no universal solution to synonymy. Best practice is to flag and correct synonyms in a clear and consistent manner. We recommend being explicit with your decisions about which names are retained and keeping a good record of the changes to aid transparency and reproducibility.\n\n{worrms}\nThe {worrms} is the R interface to the World Register of Marine Species and has a ability to cross check synonyms with their database for taxa that has an AphiaID. The function will return synonymous record(s) that have a different AphiaID.\n\nlibrary(worrms)\n\nmarine_sp &lt;- read_csv(\"data/worms/worms.csv\")\n\nmarine_sp |&gt; \n  slice(7) |&gt;\n  pull(AphiaID) |&gt; \n  wm_synonyms()\n\n# A tibble: 1 × 27\n  AphiaID url   scientificname authority status unacceptreason taxonRankID rank \n    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;                &lt;int&gt; &lt;chr&gt;\n1  453207 http… Goniosoma ina… Walker, … super… NA                     220 Spec…\n# ℹ 19 more variables: valid_AphiaID &lt;int&gt;, valid_name &lt;chr&gt;,\n#   valid_authority &lt;chr&gt;, parentNameUsageID &lt;int&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   citation &lt;chr&gt;, lsid &lt;chr&gt;, isMarine &lt;int&gt;, isBrackish &lt;int&gt;,\n#   isFreshwater &lt;int&gt;, isTerrestrial &lt;int&gt;, isExtinct &lt;int&gt;, match_type &lt;chr&gt;,\n#   modified &lt;chr&gt;\n\n\n\n\n{taxize}\n\nlibrary(taxize)"
  },
  {
    "objectID": "taxonomy.html#input-from-experts",
    "href": "taxonomy.html#input-from-experts",
    "title": "5  Taxonomy",
    "section": "5.3 Input from experts",
    "text": "5.3 Input from experts\n\n5.3.1 Australian taxonomic society groups\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists\n\n\n\n5.3.2 Global taxonomy\n\nGBIF uses 100 different sources to assemble - their global taxonomic backbone\nAuthoritative taxonomic information on plants, animals, fungi, and microbes - Integrated Taxonomic Information System, ITIS\nGlobal taxonomic catalogue\nCatalogue of Life\n\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067."
  },
  {
    "objectID": "taxonomy.html#notes",
    "href": "taxonomy.html#notes",
    "title": "5  Taxonomy",
    "section": "5.4 Notes",
    "text": "5.4 Notes\n##fiddling with fake data\n\nplants &lt;- read_csv(\"/Users/sch609/Documents/Github/cleaning_data/ignore/Curated_Plant_and_Invertebrate_Data_for_Bushfire_Modelling/vascularplant.data.csv\")\n\n\nplants |&gt;\n  select(record_id:longitude_used) |&gt;\n  rename(latitude = latitude_used,\n         longitude = longitude_used) |&gt;\n  sample_frac(0.05) |&gt;\n  write_csv_arrow(sink = \"/Users/sch609/Documents/Github/cleaning_data/ignore/dap/plant_subset.csv\")\n\nplants &lt;- read_csv(\"/Users/sch609/Documents/Github/cleaning_data/ignore/dap/plant_subset.csv\")\n\n### Making some fake missing data\nset.seed(5)\ntobemissing &lt;- plants |&gt;\n  filter(order == \"Fabales\") |&gt;\n  sample_frac(0.15) |&gt;\n  pull(scientific_name) |&gt;\n  unique()\n\nplants &lt;- plants |&gt;\n  mutate(order = ifelse(scientific_name %in% tobemissing, NA, order)) # 40 species\n\n#try inverts \ninverts&lt;-read_csv(\"/Users/sch609/Documents/Github/cleaning_data/ignore/Curated_Plant_and_Invertebrate_Data_for_Bushfire_Modelling/invertebrate.data.csv\")\n\n\ninverts |&gt;\n  select(record_id:longitude) |&gt;\n  sample_frac(0.01) |&gt;\n  write_csv_arrow(sink = \"/Users/sch609/Documents/Github/cleaning_data/ignore/dap/invert_subset.csv\")\n\ninverts &lt;- read_csv(\"/Users/sch609/Documents/Github/cleaning_data/ignore/dap/invert_subset.csv\")\n\n### Making some fake missing data\nset.seed(5)\n\ntobemissing &lt;- inverts |&gt;\n  filter(class == \"Arachnida\") |&gt;\n  sample_frac(0.3) |&gt;\n  pull(scientific_name) |&gt;\n  unique()\n\ninverts &lt;- inverts |&gt;\n  mutate(class = ifelse(scientific_name %in% tobemissing, NA, class))\n\n#try and backfill\nto_search &lt;- inverts |&gt; \n  filter(is.na(class)) |&gt; \n  select(scientific_name) |&gt; \n  distinct()\n\nto_search&lt;- to_search|&gt;\n  rename(scientificName = scientific_name)\n\nback_filled_arachnida&lt;-galah::search_taxa(to_search) |&gt; tibble()\n\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067."
  },
  {
    "objectID": "intro.html#what-you-will-learn-outline-of-the-book",
    "href": "intro.html#what-you-will-learn-outline-of-the-book",
    "title": "1  Introduction",
    "section": "1.1 What you will learn / Outline of the book",
    "text": "1.1 What you will learn / Outline of the book\n\n# new diagram here\nlibrary(DiagrammeR)\n\nTo begin working with open access data we’ll teach you how to:\n\nnarrowing your data scope\nImport data\npre-cleaning steps, such as tidying and familiarise with meta-data\n\nOnce data has been imported and formatted correctly we’ll dive into the major cleaning steps. We will focus on how to deal with taxonomic and spatial issues with biodiversity data.\n\nWe will start with taxonomic issues\n\nTaxonomic issues\n\nnaming authorities\nsynonyms\nDuplicates\n\nSpatial data\n\nOutliers\nDuplicates"
  },
  {
    "objectID": "intro.html#what-you-wont-learn",
    "href": "intro.html#what-you-wont-learn",
    "title": "1  Introduction",
    "section": "1.2 What you won’t learn",
    "text": "1.2 What you won’t learn\nThere are many important subject areas which this book will not cover. We won’t be teaching you:\n\nHow to clean other data types e.g. environmental or trait data\nHow to run a species distribution model\nHypothesis testing"
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "1  Introduction",
    "section": "1.3 Prerequisites",
    "text": "1.3 Prerequisites\n\n1.3.1 User accounts\nTo get data out of data infrastructures such as the Atlas of living Australia (ALA) or the Global Biodiversity Information (GBIF) you’ll need to first create an account. You’ll want to sign up for an account with the relevant data infrastructre, this book will use ALA and GBIF data as examples.\nAtlas of Living Australia = create an account Global Biodiversity Information Facility = create an account\n\n\n1.3.2 R\nDownload R from CRAN (the comprehensive R archive network), for your operating system, and install it on your device. Major updates for R come out yearly with a few minor releases throughout the year, so make sure to update semi regularly.\n\nWindows\n\n\nMac\n\n\n\n1.3.3 RStudio\nRstudio is an integrated development environment (IDE) for R programming. Download and install Rstudio for your operating system https://posit.co/download/rstudio-desktop/\n\nWindows\n\n\nMac"
  },
  {
    "objectID": "intro.html#how-to-use-this-book",
    "href": "intro.html#how-to-use-this-book",
    "title": "1  Introduction",
    "section": "1.4 How to use this book",
    "text": "1.4 How to use this book\nThere is no one size fits all workflow, not all steps are relevant and/or possible. Through examining the literature we found steps were frequently done in completely different orders depending on the nature of the study and the area of expertise possessed. Because of this, we don’t recommend you use this book in a linear fashion. However some steps logically come first, you might need to go back to them after completely another (fig x) \n\n\n\n\nRodrigues, A. V., Nakamura, G., Staggemeier, V. G., & Duarte, L. (2022). Species misidentification affects biodiversity metrics: Dealing with this issue using the new R package naturaList. Ecological Informatics, 69, 101625. https://doi.org/10.1016/j.ecoinf.2022.101625"
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "11  Appendix",
    "section": "",
    "text": "We don’t claim to be experts in data cleaning, therefore in order to ensure content for this book was current and relevant we undertook an informal literature review of both peer reviewed and grey literature. Key themes searched were:\n\nCleaning data for species distribution models\nCleaning open biodiversity data\nAustralian and global naming authorities\nR packages for biodiversity data cleaning\n\nAs this was not a comprehensive literature review recent papers were selected first as the R environment is a rapidly evolving space. Methods sections outlining data cleaning protocols were read and collated into a database. Papers which were frequently referenced were also chosen for review in order to not miss older seminal papers. Additionally our project partners outputs (Marsh et al. 2021; Godfree et al. 2021) have been investigated in detail to understand and streamline their data cleaning processes. This has included detailed review of their code base as well as meetings with the authors of the papers to understand their processes, issues and needs.\nAll steps for acquiring and cleaning data were then looked at together in order to understand what were essential steps, versus what was done in certain use cases. We also investigated the order in which steps were undertaken with the idea of developing a streamlined workflow. However the diagrams below show the complexity of this, with data cleaning being extremely iterative.\n \n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville, Libby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts of the 2019-20 Wildfires of Southern and Eastern Australia on Invertebrate Species Final Report.”"
  },
  {
    "objectID": "preclean.html#metadata",
    "href": "preclean.html#metadata",
    "title": "4  Precleaning",
    "section": "4.1 Metadata",
    "text": "4.1 Metadata\nMetadata describes your dataset. It defines each variable and describes its contents such as what units a variable is measured in. Data infrastructures that uses Darwin Core terms will have interoperable metadata. All Darwin Core term definitions can be found here, we suggest using Ctrl/CMD F and searching your variable name on the webpage. Don’t hesitate to Google variable names if you are unsure what they represent.\nIf you’re using data from particular institutions it’s worth checking the metadata for the entire dataset to delineate if there is extra information about the data which might limit what you can do with the data. You could google the dataset name, or search the dataset/institution on the ALA. The metadata on the ALA is submitted with the data, it’s not always of high standard which is why it’s worth investigating externally, an example of some good metadata is FrogID from the Australian Museum. A benefit to reading metadata is understanding the limitations of your dataset. From reading FrogID’s metadata (Rowley and Callaghan 2020), you’ll find:\n\nThe data is acoustic data, the majority of the species recorded are therefore male\nBecause this is citizen science data, it is especially biased towards populated areas\nAudio is recorded via a smartphone app, the authors recommend if you require high coordinate precision to filter data to geographic uncertainty of &lt;3000m\nThe data is presence only data\n\nMetadata can also be useful for understanding the license that the data falls under, this is mostly relevant for using multimedia associated with the data."
  },
  {
    "objectID": "preclean.html#initial-inspection",
    "href": "preclean.html#initial-inspection",
    "title": "4  Precleaning",
    "section": "4.2 Initial inspection",
    "text": "4.2 Initial inspection\nA great way to get an initial overview of your data is to use the R package skimr. Importantly skimr produces tables of descriptive statistics, such as amount of missing data, for every variable\nThe output is also grouped by data type (numeric, character, date) so you can also check for any inconsistencies. As you are looking through the output, ask yourself whether the data is in line with your expectation. If you requested data for a group of species, are they all represented? Are the values for a variable reasonable? Looking at the quartiles will help you get the sense of the distribution of data. These considerations will help you detect potential issues in the data.\n\nlibrary(skimr)\n\nskim(african_ele)\n\nHere is the skimr report for our African elephant dataset we downloaded earlier\n\n\n\nData summary\n\n\nName\nafrican_ele\n\n\nNumber of rows\n12537\n\n\nNumber of columns\n50\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n31\n\n\nlogical\n1\n\n\nnumeric\n15\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndatasetKey\n0\n1.00\n36\n36\n0\n132\n0\n\n\noccurrenceID\n708\n0.94\n1\n81\n0\n11787\n0\n\n\nkingdom\n0\n1.00\n8\n8\n0\n1\n0\n\n\nphylum\n0\n1.00\n8\n8\n0\n1\n0\n\n\nclass\n0\n1.00\n8\n8\n0\n1\n0\n\n\norder\n0\n1.00\n11\n11\n0\n1\n0\n\n\nfamily\n0\n1.00\n12\n12\n0\n1\n0\n\n\ngenus\n0\n1.00\n9\n9\n0\n1\n0\n\n\nspecies\n0\n1.00\n18\n18\n0\n1\n0\n\n\ninfraspecificEpithet\n12410\n0.01\n8\n13\n0\n2\n0\n\n\ntaxonRank\n0\n1.00\n7\n10\n0\n3\n0\n\n\nscientificName\n0\n1.00\n12\n37\n0\n5\n0\n\n\nverbatimScientificName\n3\n1.00\n12\n53\n0\n32\n0\n\n\nverbatimScientificNameAuthorship\n10964\n0.13\n2\n31\n0\n255\n0\n\n\ncountryCode\n1461\n0.88\n2\n2\n0\n44\n0\n\n\nlocality\n9211\n0.27\n3\n254\n0\n686\n0\n\n\nstateProvince\n3573\n0.72\n3\n43\n0\n182\n0\n\n\noccurrenceStatus\n0\n1.00\n6\n7\n0\n2\n0\n\n\npublishingOrgKey\n0\n1.00\n36\n36\n0\n102\n0\n\n\nbasisOfRecord\n0\n1.00\n10\n19\n0\n9\n0\n\n\ninstitutionCode\n1325\n0.89\n2\n76\n0\n103\n0\n\n\ncollectionCode\n1353\n0.89\n1\n41\n0\n164\n0\n\n\ncatalogNumber\n1553\n0.88\n1\n36\n0\n10866\n0\n\n\nrecordNumber\n12420\n0.01\n1\n37\n0\n77\n0\n\n\nidentifiedBy\n4646\n0.63\n2\n81\n0\n1464\n0\n\n\nlicense\n0\n1.00\n7\n12\n0\n3\n0\n\n\nrightsHolder\n4240\n0.66\n2\n56\n0\n1634\n0\n\n\nrecordedBy\n2138\n0.83\n1\n160\n0\n1972\n0\n\n\nestablishmentMeans\n12249\n0.02\n6\n6\n0\n1\n0\n\n\nmediaType\n5021\n0.60\n5\n16\n0\n4\n0\n\n\nissue\n397\n0.97\n15\n191\n0\n130\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntypeStatus\n12537\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ngbifID\n0\n1.00\n2535815516.94\n960444243.67\n49926810.00\n1802649142.00\n2465251941.00\n3.351048e+09\n4.029318e+09\n▁▅▇▅▇\n\n\nindividualCount\n10226\n0.18\n4.81\n14.03\n0.00\n1.00\n1.00\n2.000000e+00\n2.920000e+02\n▇▁▁▁▁\n\n\ndecimalLatitude\n1350\n0.89\n-10.01\n14.67\n-34.58\n-24.06\n-6.25\n4.800000e-01\n5.215000e+01\n▇▅▅▁▁\n\n\ndecimalLongitude\n1350\n0.89\n25.56\n12.35\n-122.33\n22.97\n31.08\n3.480000e+01\n4.053000e+01\n▁▁▁▂▇\n\n\ncoordinateUncertaintyInMeters\n3966\n0.68\n41636.59\n158053.45\n1.00\n29775.00\n30580.00\n3.142200e+04\n5.635548e+06\n▇▁▁▁▁\n\n\ncoordinatePrecision\n12512\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▁▁▇\n\n\nelevation\n12501\n0.00\n154.42\n421.59\n0.00\n0.00\n0.00\n1.375000e+01\n2.134000e+03\n▇▁▁▁▁\n\n\nelevationAccuracy\n12507\n0.00\n0.83\n3.73\n0.00\n0.00\n0.00\n0.000000e+00\n2.000000e+01\n▇▁▁▁▁\n\n\ndepth\n12509\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▇▁▁\n\n\ndepthAccuracy\n12509\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▇▁▁\n\n\nday\n1254\n0.90\n16.27\n8.74\n1.00\n9.00\n17.00\n2.400000e+01\n3.100000e+01\n▇▆▇▇▇\n\n\nmonth\n1191\n0.91\n6.92\n3.33\n1.00\n4.00\n7.00\n1.000000e+01\n1.200000e+01\n▆▅▅▇▇\n\n\nyear\n997\n0.92\n2011.05\n19.34\n1799.00\n2011.00\n2016.00\n2.019000e+03\n2.023000e+03\n▁▁▁▁▇\n\n\ntaxonKey\n0\n1.00\n2517047.48\n747546.46\n2435350.00\n2435350.00\n2435350.00\n2.435350e+06\n1.150335e+07\n▇▁▁▁▁\n\n\nspeciesKey\n0\n1.00\n2435350.00\n0.00\n2435350.00\n2435350.00\n2435350.00\n2.435350e+06\n2.435350e+06\n▁▁▇▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n997\n0.92\n1799-01-01 00:00:00\n2023-02-07 09:17:14\n2016-02-07 12:00:00\n8324\n\n\ndateIdentified\n4150\n0.67\n1783-01-01 00:00:00\n2023-02-07 21:51:36\n2020-04-16 19:35:25\n7242\n\n\nlastInterpreted\n0\n1.00\n2023-01-24 14:57:46\n2023-02-14 01:52:09\n2023-02-13 16:01:27\n10885"
  },
  {
    "objectID": "preclean.html#structural-inconsistencies",
    "href": "preclean.html#structural-inconsistencies",
    "title": "4  Precleaning",
    "section": "4.3 Structural inconsistencies",
    "text": "4.3 Structural inconsistencies\n\n4.3.1 String inconsistencies\nString inconsistencies include mispellings, capitalisation errors, misplaced punctuations or trailing white spaces. We will use the janitor R package to explore whether our data has any of these issues. The function tabyl will compute a counts and percent of total rows for each unique value.\nWe recommend tabyl-ing any character strings that are relevant to your project. For example, here is the stateProvince in alphabetical order.\n\nlibrary(janitor)\n\nafrican_ele %&gt;%\n  pull(stateProvince) %&gt;% \n  tabyl() %&gt;% \n  tibble() %&gt;% \n  print(n = 20)\n\n\n\n# A tibble: 183 × 4\n   .                     n   percent valid_percent\n   &lt;chr&gt;             &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez                1 0.0000798      0.000112\n 2 Al Qahirah            1 0.0000798      0.000112\n 3 Alibori             601 0.0479         0.0670  \n 4 Arusha              231 0.0184         0.0258  \n 5 Arusha Region         1 0.0000798      0.000112\n 6 Atacora             366 0.0292         0.0408  \n 7 Atakora             239 0.0191         0.0267  \n 8 Balaka                7 0.000558       0.000781\n 9 Bassila               1 0.0000798      0.000112\n10 Batha                 1 0.0000798      0.000112\n11 Bauchi                3 0.000239       0.000335\n12 Bengo                 3 0.000239       0.000335\n13 Borgou                7 0.000558       0.000781\n14 Budongo Forest        1 0.0000798      0.000112\n15 Bushenyi             61 0.00487        0.00680 \n16 Cabo Delgado          2 0.000160       0.000223\n17 Cape Prov.            2 0.000160       0.000223\n18 Cape Province         1 0.0000798      0.000112\n19 Central             113 0.00901        0.0126  \n20 Central Equatoria     2 0.000160       0.000223\n# ℹ 163 more rows\n\n\nFrom the tabyl output, we can see there are few different variations of Province, Prov., Prov. As an example, we will correct these with the tidyverse packages stringr, dplyr, tidyr as well as glue. If you are not very familiar with regular expressions, we highly recommend this cheatsheet\n\nlibrary(tidyverse)\nlibrary(glue)\n\n# Create a regular expression to match Prov. and Prov\n# The pattern below means Prov that is NOT followed by any lowercase letters\npattern = regex(\"Prov(?![:lower:])\")\n\n# Use `str_subset` to pull out the cases that match our pattern\n# Confirm that these are the problematic ones\n# Assign these into an object\nstr_subset(african_ele$stateProvince, pattern = pattern)\n\n [1] \"Cape Prov.\"        \"Cape Prov.\"        \"West Nile Prov.\"  \n [4] \"Central Prov\"      \"Central Prov\"      \"Coastal Prov\"     \n [7] \"Northeastern Prov\" \"Central Prov\"      \"Eastern Prov\"     \n[10] \"Coastal Prov\"     \n\ntypos_provinces &lt;- str_subset(african_ele$stateProvince, pattern = pattern)\n\n# Create a new variable `stateProvince_clean` using `mutate`, `if_else`, `str_detect` and `glue`\n# `str_detect` will evaluate values of `stateProvince` that matches our pattern we defined earlier.\n# Matches will return TRUE, non-matches will return FALSE. \n# The `if_else` will then evaluate these logicals (TRUE/FALSE/NA) \n# for TRUE values, the `glue` function will take the first part of the province name enclosed in and join it with word Province.\n# for FALSE values , it will just take the corresponding value in stateProvince\n# Note that we are assigning these changes to a new object (`african_ele_2`)\nafrican_ele_2 &lt;- african_ele %&gt;% \n  mutate(stateProvince_clean = if_else(str_detect(stateProvince, pattern = pattern),\n                                      true = glue('{word(stateProvince, sep = \" P\")} Province'),\n                                      false = stateProvince)\n         ) \n\n# Once we've made the correction we want to check we've done it correctly.\n# ALWAYS CHECK YOUR CORRECTIONS\n# Use the `select` function to isolate columns that `starts_with` \"stateProvince\"\n# Use the `filter` function to subset our the problematic provinces \nafrican_ele_2 %&gt;% \n  select(starts_with(\"stateProvince\")) %&gt;% \n  filter(stateProvince %in% typos_provinces)\n\n# A tibble: 10 × 2\n   stateProvince     stateProvince_clean  \n   &lt;chr&gt;             &lt;glue&gt;               \n 1 Cape Prov.        Cape Province        \n 2 Cape Prov.        Cape Province        \n 3 West Nile Prov.   West Nile Province   \n 4 Central Prov      Central Province     \n 5 Central Prov      Central Province     \n 6 Coastal Prov      Coastal Province     \n 7 Northeastern Prov Northeastern Province\n 8 Central Prov      Central Province     \n 9 Eastern Prov      Eastern Province     \n10 Coastal Prov      Coastal Province     \n\n# Its good practice to check the other values were not affected by your corrections\n# Here we are removing the NA with `drop_na` and subsetting unique rows with `distinct`\nafrican_ele_2 %&gt;% \n  select(starts_with(\"stateProvince\")) %&gt;% \n  drop_na() %&gt;% \n  distinct() \n\n# A tibble: 182 × 2\n   stateProvince    stateProvince_clean\n   &lt;chr&gt;            &lt;glue&gt;             \n 1 Southern         Southern           \n 2 Taita Taveta     Taita Taveta       \n 3 Mara             Mara               \n 4 Arusha           Arusha             \n 5 Simiyu           Simiyu             \n 6 Morogoro         Morogoro           \n 7 Mashonaland West Mashonaland West   \n 8 Mpumalanga       Mpumalanga         \n 9 KwaZulu-Natal    KwaZulu-Natal      \n10 Manicaland       Manicaland         \n# ℹ 172 more rows\n\n# Final check\n# Check with the original code that detected the issue\nafrican_ele_2 %&gt;%\n  pull(stateProvince_clean) %&gt;% \n  tabyl() %&gt;% \n  tibble() %&gt;% \n  print(n = 20)\n\n# A tibble: 181 × 4\n   .                     n   percent valid_percent\n   &lt;glue&gt;            &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez                1 0.0000798      0.000112\n 2 Al Qahirah            1 0.0000798      0.000112\n 3 Alibori             601 0.0479         0.0670  \n 4 Arusha              231 0.0184         0.0258  \n 5 Arusha Region         1 0.0000798      0.000112\n 6 Atacora             366 0.0292         0.0408  \n 7 Atakora             239 0.0191         0.0267  \n 8 Balaka                7 0.000558       0.000781\n 9 Bassila               1 0.0000798      0.000112\n10 Batha                 1 0.0000798      0.000112\n11 Bauchi                3 0.000239       0.000335\n12 Bengo                 3 0.000239       0.000335\n13 Borgou                7 0.000558       0.000781\n14 Budongo Forest        1 0.0000798      0.000112\n15 Bushenyi             61 0.00487        0.00680 \n16 Cabo Delgado          2 0.000160       0.000223\n17 Cape Province         3 0.000239       0.000335\n18 Central             113 0.00901        0.0126  \n19 Central Equatoria     2 0.000160       0.000223\n20 Central Province      4 0.000319       0.000446\n# ℹ 161 more rows\n\n\nThere are some other issues that can be corrected in a similar approach:\n\nNorth West, North West District and North-Western\nÀfrica Central, Central Province and Central\nAtacora and Atakora\nCoastal Province and Coastal\n\nWe recommend consulting reputable sources that can help delineate or consolidate similar values. Googling and looking at Wikipedia’s sources are good places to find resources that you can verify accepted state and province names.\n\n\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset: Expert-Validated Occurrence Records of Australia’s Frogs Collected by Citizen Scientists.” ZooKeys 912: 139.\n\n\nstreamdna. 2020. “Sharing Is Caring: Working with Other People’s Data.” https://methodsblog.com/2020/09/04/sharing-is-caring-working-with-other-peoples-data/."
  },
  {
    "objectID": "scope.html#taxonomic-scope",
    "href": "scope.html#taxonomic-scope",
    "title": "2  Data scope",
    "section": "2.1 Taxonomic scope",
    "text": "2.1 Taxonomic scope\nWhere the aim of the study is to gather data on a specific taxonomic unit. This could be a threatened species or a broad taxonomic group. The download query is performed using the scientific name or name of the taxonomic group.\n\n\n\n\n\n\nCurious what Lampromicra senator looks like?\n\n\n\nLampromicra senator perched on a leaf by Dexmond Wells CC-BY-NC 4.0"
  },
  {
    "objectID": "scope.html#spatial-scope",
    "href": "scope.html#spatial-scope",
    "title": "2  Data scope",
    "section": "2.2 Spatial scope",
    "text": "2.2 Spatial scope\nWhere the aim is to obtain data for targeted taxa in a given location. In this case, the region name or area boundaries can be used to delimit the area of interest. The example below shows all Insecta orders in the state of Tasmania in Australia"
  },
  {
    "objectID": "scope.html#naming-authorities",
    "href": "scope.html#naming-authorities",
    "title": "2  Data scope",
    "section": "2.3 Naming authorities",
    "text": "2.3 Naming authorities\n\n\n\n\n\n2.3.1 Choosing your own naming authority\nUsing a naming authority is a great way to make decisions surrounding taxonomic categorizations of open source biodiversity data. However, deciding what naming authority to use can be challenging and time consuming.\nWhat naming authority you choose will most certainly depend on your data scope. Spatial focus, will have many species and may need multiple naming authorities.\nA knowledge of taxonomy assist your ability to verify the data you are working with. For this, different organizations provide updated lists of species or even details of the taxonomic history of a species.\nChecking changes in taxonomy can be helpful when interpreting old data which may have species names you don’t recognize.\nChanges in taxonomy, such as species split, new higher level classification (as genera), or species descriptions, highlight the importance of keeping up-to-date with taxonomic literature. This can be achieved by consulting the literature. Most taxonomic society groups release annual updates on taxonomy.\nIn Australia, the Australian Plant Name Index (APNI) is the primary naming authority for plants. With the Australian Faunal Directory (AFD) the main taxonomic catalog for animal species. These authorities provide a list of accepted and authoritative names as a template. If you’re unsure what naming authority to use and you’re looking at Australian species, the APNI and the AFD are a good place to start, especially if the data you’re investigating covers a wide range of taxa. If you’re investigating specific taxa it’s worth checking when the taxonomy was last updated in the APNI or AFD, especially if you know there has been recent changes. If you want to investigate closer, we’ve provided some links to society groups, in some cases these can be more up to date that the APNI or AFD."
  },
  {
    "objectID": "scope.html#naming-authorities-1",
    "href": "scope.html#naming-authorities-1",
    "title": "2  Data scope",
    "section": "2.4 Naming authorities",
    "text": "2.4 Naming authorities\nAccurate species delimitation is crucial for adequate conservation management and understanding evolutionary processes (Mace 2004). Species-level lists are the foundation of conservation decisions, such as is the IUCN Red List (melville21?).\nThe difference in scope might influence if you choose to use a naming authority from a taxonomic society group or multiple broad sources."
  },
  {
    "objectID": "scope.html#naming-authorities-and-taxonomy-in-biodiversity-databases",
    "href": "scope.html#naming-authorities-and-taxonomy-in-biodiversity-databases",
    "title": "2  Data scope",
    "section": "2.5 Naming authorities and taxonomy in biodiversity databases",
    "text": "2.5 Naming authorities and taxonomy in biodiversity databases\nWhen you download data from different databases you might be faced with inconsistencies between the datasets. This is a challenge that data aggregators face when ingesting and aggregating data. This is a large task with lots of heterogeneity and can lead to errors along the way. To help deal with naming inconsistencies, naming authorities are used by online biodiversity databases in order to classify species [REF]. Different databases might use different naming authorities, and you might not agree with their classifications. There may be other issues you are not aware of: For example, the ALA uses multiple naming authorities in a hierarchical format:\n(note image is from a helpfile I wrote- we can re-do it so it’s consistent with the style of this document)\n\nWith all that, open source data has many pros, so how does one deal with taxonomic inconsistencies to get the most accurate data in the end?\nWhile this is in theory how the ALAs backbone is built, issues can occur with aggregation leading to potentially serious problems with the taxonomic structure. In addition data can be parsed incorrectly, and the process isn’t transparent. Meaning that when the taxonomic backbone is updated, the elements that have changed are untraceable. These issues are not specific to ALA taxonomy, but occur in varying forms among data aggregators.\n\n\n\n\nMace, Georgina M. 2004. “The Role of Taxonomy in Species Conservation.” Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences 359 (1444): 711–19."
  },
  {
    "objectID": "taxonomy-2.html#joining-datasets-from-different-infrastructures",
    "href": "taxonomy-2.html#joining-datasets-from-different-infrastructures",
    "title": "6  Taxonomy II",
    "section": "6.1 Joining datasets from different infrastructures",
    "text": "6.1 Joining datasets from different infrastructures\nIf you have downloaded data from different sources, you likely will need to collate your data into a singular database. It is important to make sure fields that have the same, are indeed the same variable, so prior to merging - take the time cross check the meta-data from different data providers (Ribeiro et al. 2022).\n\n6.1.1 Variable names and case format\nData providers will have their own naming conventions for variables. For example, World Register of Marine Species uses a combination of lower case e.g scientific_name and camel case e.g isExtinct. While the naming authority - Australian Fauna Directory (AFD) uses upper, snake case e.g. SCIENTIFIC_NAME. What format you choose is a matter of personal preference, the key is to be consistent.\nHere we will subset the variables we want, reformat them to the lower snake case names and then join by VALID_NAME\n\nlibrary(stringr)\n\nhabitat_data &lt;- worms %&gt;% \n  select(valid_name, starts_with(\"is\")) \n\nnames(habitat_data)[-1] \n\n[1] \"isMarine\"      \"isBrackish\"    \"isFreshwater\"  \"isTerrestrial\"\n[5] \"isExtinct\"    \n\nnew_names &lt;- str_split(names(habitat_data)[-1], pattern =  \"(?&lt;=[a-z])(?=[A-Z])\", n = 2) %&gt;%  # Seperate where case cases from lower to upper i.e. camel case\n  map(.x = ., \n      .f = ~tolower(.x)) %&gt;% # Convert to all lower case\n    map(.x = ., \n      .f = ~str_flatten(.x, \"_\")) %&gt;%  # Bind the two seperated elements\n  unlist()\n  \nnew_names\n\n[1] \"is_marine\"      \"is_brackish\"    \"is_freshwater\"  \"is_terrestrial\"\n[5] \"is_extinct\"    \n\n# Replace old with new\nnames(habitat_data)[-1] &lt;- new_names\n\n# Join habitat data by VALID_NAME\nafd %&gt;% left_join(habitat_data, by = join_by(VALID_NAME == valid_name))\n\n# A tibble: 49 × 37\n   GROUP_NAME HIGHER_CLASSIFICATION    KINGDOM PHYLUM SUBPHYLUM SUPERCLASS CLASS\n   &lt;chr&gt;      &lt;chr&gt;                    &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;     &lt;lgl&gt;      &lt;chr&gt;\n 1 ANNELIDA   Phylum ANNELIDA, Class … ANIMAL… ANNEL… &lt;NA&gt;      NA         POLY…\n 2 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MAXI…\n 3 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 4 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… HEXAPODA  NA         INSE…\n 5 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 6 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… HEXAPODA  NA         INSE…\n 7 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 8 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n 9 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         MALA…\n10 ARTHROPODA Phylum ARTHROPODA, Subp… ANIMAL… ARTHR… CRUSTACEA NA         OSTR…\n# ℹ 39 more rows\n# ℹ 30 more variables: SUBCLASS &lt;chr&gt;, SUPERORDER &lt;chr&gt;, ORDER &lt;chr&gt;,\n#   SUBORDER &lt;chr&gt;, SUPERFAMILY &lt;chr&gt;, FAMILY &lt;chr&gt;, SUBFAMILY &lt;chr&gt;,\n#   SUPERTRIBE &lt;lgl&gt;, TRIBE &lt;chr&gt;, SUBTRIBE &lt;lgl&gt;, GENUS &lt;chr&gt;,\n#   SUB_GENUS &lt;chr&gt;, SPECIES &lt;chr&gt;, SUB_SPECIES &lt;chr&gt;, AUTHOR &lt;chr&gt;,\n#   YEAR &lt;dbl&gt;, CHANGED_COMBINATION &lt;chr&gt;, VALID_NAME &lt;chr&gt;,\n#   COMPLETE_NAME &lt;chr&gt;, SYNONYMS &lt;chr&gt;, CHANGED_COMB_NAMES &lt;chr&gt;, …\n\n\nOne issue you might face is that higher taxonomy from different providers may not match. If this is the case, we suggest choosing the data provider with the higher taxonomy that is consistent with your naming authority and use it to back fill the higher taxonomy of the other data sources\n\nhigher_taxonomy &lt;- inverts %&gt;%\n  select(scientificName) %&gt;% \n  distinct() %&gt;% \n  search_taxa()\n\nhigher_taxonomy\n\n# A tibble: 36 × 15\n   search_term     scientific_name scientific_name_auth…¹ taxon_concept_id rank \n   &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;\n 1 Palirhoeus eat… Palirhoeus eat… (C.O. Waterhouse, 187… https://biodive… spec…\n 2 Lasaea austral… Lasaea austral… (Lamarck, 1818)        https://biodive… spec…\n 3 Turbonilla tia… Turbonilla tia… May, 1911              https://biodive… spec…\n 4 Tucetona flabe… Tucetona flabe… (Tenison-Woods, 1878)  https://biodive… spec…\n 5 Achelia transf… Achelia transf… Stock, 1973            https://biodive… spec…\n 6 Coralliophila … Coralliophila … Kosuge, 1986           https://biodive… spec…\n 7 Amphitethya st… Amphitethya st… (Carter, 1886)         https://biodive… spec…\n 8 Australocyther… Australocyther… McKenzie, 1967         https://biodive… spec…\n 9 Plesiopenaeus … Plesiopenaeus … (Spence Bate, 1881)    https://biodive… spec…\n10 Chlorodiloma c… Chlorodiloma c… (Philippi, 1849)       https://biodive… spec…\n# ℹ 26 more rows\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 10 more variables: match_type &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;,\n#   class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   issues &lt;chr&gt;, vernacular_name &lt;chr&gt;\n\n\nRemember to always check your changes after!"
  },
  {
    "objectID": "taxonomy-2.html#extended-taxonomic-cleaning",
    "href": "taxonomy-2.html#extended-taxonomic-cleaning",
    "title": "6  Taxonomy II",
    "section": "6.2 Extended taxonomic cleaning",
    "text": "6.2 Extended taxonomic cleaning\nDepending on your project’s data scope, it may be necessary to remove certain groups of taxa. Below, we have provided a few examples. We will also briefly showcase CoordinateCleaner a useful R package for removing XX records.\n\n6.2.1 Introduced or Invasive species\nRemove non-native species: This step is a common requirement. A list can be obtained from the Global Register of Introduced and Invasive Species (GRIIS). The downloads are sorted my country. Once this list is read into R, you can proceed to exclude invasive species from your data as below:\n\nlibrary(tidyverse)\nlibrary(here)\n\ngriis_ls &lt;- read_csv(here(\"data/lists/GRIIS_Australia_20230331-121730.csv\"))\n\nglimpse(griis_ls)\n\nRows: 2,979\nColumns: 16\n$ scientific_name                  &lt;chr&gt; \"Oenothera longiflora L.\", \"Lampranth…\n$ scientific_name_type             &lt;chr&gt; \"species\", \"species\", \"species\", \"spe…\n$ kingdom                          &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ establishment_means              &lt;chr&gt; \"alien\", \"alien\", \"alien\", \"alien\", \"…\n$ is_invasive                      &lt;chr&gt; \"null\", \"null\", \"null\", \"null\", \"null…\n$ occurrence_status                &lt;chr&gt; \"present\", \"present\", \"present\", \"pre…\n$ checklist.name                   &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\"…\n$ checklist.iso_countrycode_alpha3 &lt;chr&gt; \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"A…\n$ accepted_name.species            &lt;chr&gt; \"Oenothera longiflora\", \"Lampranthus …\n$ accepted_name.kingdom            &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ accepted_name.phylum             &lt;chr&gt; \"Tracheophyta\", \"Tracheophyta\", \"Trac…\n$ accepted_name.class              &lt;chr&gt; \"Magnoliopsida\", \"Magnoliopsida\", \"Ma…\n$ accepted_name.order              &lt;chr&gt; \"Myrtales\", \"Caryophyllales\", \"Erical…\n$ accepted_name.family             &lt;chr&gt; \"Onagraceae\", \"Aizoaceae\", \"Ericaceae…\n$ accepted_name.habitat            &lt;chr&gt; \"[\\\"terrestrial\\\"]\", \"[\\\"terrestrial\\…\n$ accepted_name                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n# Note which species matched with GRIIS list\nmatches &lt;- plants |&gt; filter(scientific_name %in% griis_ls$accepted_name.species)\nmatches\n\n# A tibble: 2 × 13\n  record_id    scientific_name vernacular_name kingdom phylum class order family\n  &lt;chr&gt;        &lt;chr&gt;           &lt;chr&gt;           &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; \n1 94df1223-4c… Lysimachia jap… Creeping Loose… Plantae Trach… Magn… Eric… Primu…\n2 8055e15e-36… Lysimachia jap… Creeping Loose… Plantae Trach… Magn… Eric… Primu…\n# ℹ 5 more variables: genus &lt;chr&gt;, species &lt;chr&gt;, subspecies &lt;chr&gt;,\n#   latitude &lt;dbl&gt;, longitude &lt;dbl&gt;\n\n# Exclude GRIIS matches\nplants_no_griis &lt;- plants |&gt; filter(! scientific_name %in% matches)\n\n\n\n6.2.2 Extinct species\nIn most cases, a year filter during in your download query should remove most extinct species.\nYou want to cross check for extinct species using the Interim Register of Marine and Nonmarine Genera (IRMNG). The list is comprehensive and actively maintained, the only caveat is that a lot of its data doesn’t go down to species level. As such, we recommend using the following approach to find potentially extinct taxa and further investigate the records that we are flagged.\nThe required files are organised by year and can be downloaded from here. Once you have unzipped the file in your projected directory, we need to process the list a littlerbefore we use it to exclude extinct species.\n\nlibrary(data.table)\nlibrary(janitor)\n\n# Taxonomic info\nirmng_taxa &lt;- fread(\"data/lists/IRMNG_genera_DwCA_2023-05-19/taxon.txt\", na.strings = c(\"\"), quote=\"\")\n\n# Species profile\nirmng_sp &lt;- fread(\"data/lists/IRMNG_genera_DwCA_2023-05-19/speciesprofile.txt\", na.strings = c(\"\"), quote=\"\")\n\n\n# Precleaning \nawc_pattern &lt;- \"(awaiting allocation)\"\ninsed_pattern &lt;- \"incertae sedis\"\n\ncleaned_irmng_taxa &lt;- irmng_taxa |&gt; \n  mutate(class = ifelse(str_detect(class, pattern = paste0(awc_pattern,\"|\", insed_pattern)),\n                        word(class), class) # Remove pesky values\n         ) |&gt; \n  filter(taxonomicStatus == \"accepted\") |&gt; # Filter to accepted names \n  filter(kingdom %in% c(\"Animalia\", \"Plantae\"),\n         ! kingdom == \"Questionable / non-biota (fossil)\") # Filter to Animal and plants - change if working with other kingdoms\n\n# Join with species profile, remove pesky values and filter to extinct taxa \nextinct_irmng &lt;- irmng_taxa |&gt; \n  left_join(irmng_sp, by = \"taxonID\") |&gt; \n  filter(! scientificName == \"Questionable / non-biota (fossil)\") |&gt; \n  filter(isExtinct == TRUE) \n\n# Summary of extinct species by taxonRank\nextinct_irmng$taxonRank |&gt; tabyl()\n\n extinct_irmng$taxonRank     n      percent\n                   Class    14 5.926177e-04\n                  Family  1675 7.090247e-02\n                   Genus 21718 9.193193e-01\n              Infraclass     1 4.232983e-05\n                   Order   210 8.889265e-03\n                  Phylum     4 1.693193e-04\n                Subclass     2 8.465967e-05\n\n# Create genus \ninverts &lt;- inverts |&gt; \n  mutate(genus = word(scientificName, 1)) \n\n# Extract unique extinct genus and remove genus that have punctuation in them\nextinct_genus &lt;- extinct_irmng |&gt; \n  drop_na(genus) |&gt; \n  filter(!str_detect(genus, pattern = regex(\"[:punct:]\"))) |&gt; \n  pull(genus) |&gt; \n  unique() \n \n# Check if there are any matches at genus level\ncheck &lt;- inverts |&gt; \nfilter(str_detect(genus, pattern = regex(paste0(extinct_genus, collapse=\"|\")))) |&gt; \n  pull(scientificName) |&gt; \n  unique() \n\ncheck\n\n[1] \"Halobates (Halobates) acherontis\"\n\n\nAlternatively, you can use the IUCN to retrieve a list of extinct species that are in their database\nhttps://apiv3.iucnredlist.org/api/v3/docs#species-category https://docs.ropensci.org/crul/articles/crul.html\n\nlibrary(rredlist)\nlibrary(skimr)\n\n# Create IUCN token\nrredlist::rl_use_iucn() # Application can take a day or two!\nusethis::edit_r_environ() # Place the approved token in your R environment\n\nextinct_iucn &lt;- rl_sp_category('EX')\nskim(extinct_iucn)\n\nextinct_sp &lt;- extinct_iucn$result |&gt; tibble() # Note these are extinct species across the globe\n\n# Find matches\ninverts |&gt; filter(scientificName %in% extinct_sp$scientific_name) # No matches\n\n\n\n6.2.3 Certain lifestges\n\nlibrary(galah)\nlibrary(skimr)\n\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"),\n             atlas = \"Australia\")\n\nbilby &lt;- galah_call() |&gt; \n  galah_identify(\"Macrotis lagotis\") |&gt; \n  galah_filter(year == 2022) |&gt; \n  galah_select(group = \"basic\", sex, lifeStage, reproductiveCondition) |&gt; \n  atlas_occurrences()\n\nbilby |&gt; filter(!sex == \"MALE\")\n\n\n\n# A tibble: 35 × 11\n   decimalLatitude decimalLongitude eventDate           scientificName  \n             &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;           \n 1           -34.2             143. 2022-06-16 14:00:00 Macrotis lagotis\n 2           -34.2             143. 2022-06-14 14:00:00 Macrotis lagotis\n 3           -34.2             143. 2022-03-22 13:00:00 Macrotis lagotis\n 4           -34.2             143. 2022-03-22 13:00:00 Macrotis lagotis\n 5           -34.2             143. 2022-03-22 13:00:00 Macrotis lagotis\n 6           -34.2             143. 2022-03-23 13:00:00 Macrotis lagotis\n 7           -34.2             143. 2022-03-21 13:00:00 Macrotis lagotis\n 8           -34.2             143. 2022-06-12 14:00:00 Macrotis lagotis\n 9           -34.2             143. 2022-03-23 13:00:00 Macrotis lagotis\n10           -34.2             143. 2022-06-12 14:00:00 Macrotis lagotis\n# ℹ 25 more rows\n# ℹ 7 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, sex &lt;chr&gt;, lifeStage &lt;lgl&gt;,\n#   reproductiveCondition &lt;chr&gt;\n\n\n\n\n6.2.4 Marine species\nRemove specific taxa/ depending on the study: For example, if working with terrestrial data, it is necessary to remove marine taxa.\n\nlibrary(worrms)\n\n# Obtain species list\nmy_species &lt;- inverts |&gt; \n  pull(scientificName) |&gt;\n  unique()\n\n# Query WoRMs\nmarine_check &lt;- map_dfr(my_species,\n       possibly(~worrms::wm_records_name(name = .x) |&gt; mutate(search_term = .x))\n)\n\n# Filter species that are TRUE for isMarine\nmarine_inverts &lt;- marine_check |&gt; \n  filter(isMarine == TRUE) |&gt; \n  select(search_term)\n\n# Exclude marine invertebrates\ninverts |&gt; filter(!scientificName %in% marine_inverts)\n\n# A tibble: 2,637 × 9\n   decimalLatitude decimalLongitude eventDate           scientificName   \n             &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;            \n 1           -46.9             37.8 1983-04-01 00:00:00 Palirhoeus eatoni\n 2           -46.9             37.8 1984-09-01 00:00:00 Palirhoeus eatoni\n 3           -46.9             37.9 1986-04-01 00:00:00 Palirhoeus eatoni\n 4           -46.6             38.0 1985-04-01 00:00:00 Palirhoeus eatoni\n 5           -46.6             38.0 1983-05-01 00:00:00 Palirhoeus eatoni\n 6           -46.6             38.0 1984-09-01 00:00:00 Palirhoeus eatoni\n 7           -46.6             38.0 1984-04-01 00:00:00 Palirhoeus eatoni\n 8           -43.6            148.  NA                  Lasaea australis \n 9           -43.6            147.  2008-12-28 00:00:00 Lasaea australis \n10           -43.6            147.  2008-12-28 00:00:00 Lasaea australis \n# ℹ 2,627 more rows\n# ℹ 5 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, genus &lt;chr&gt;\n\n\n\n\n\n\nRibeiro, Bruno R., Santiago José Elías Velazco, Karlo Guidoni-Martins, Geiziane Tessarolo, Lucas Jardim, Steven P. Bachman, and Rafael Loyola. 2022. “Bdc: A Toolkit for Standardizing, Integrating and Cleaning Biodiversity Data.” Methods in Ecology and Evolution 13 (7): 1421–28. https://doi.org/10.1111/2041-210X.13868."
  },
  {
    "objectID": "outliers.html",
    "href": "outliers.html",
    "title": "9  Outliers",
    "section": "",
    "text": "#note from meeting with Martin this section might include some alpha hull examples for how to detect outliers, or how they can skew your data, in addition to maybe an SDM for outlier detection (Simões and Peterson 2018) even if we won’t be teaching people how to run an SDM\nOutliers can be true outliers or data errors, true outliers are not necessarily to be removed. This could represent mis-identified specimens, etc\n(#note to double check what i wrote for support article around inconsistent sampling and open source data)\n\nAlpha hull (some example species - check cailtin chat history)\nSDM Shandiya?\nRemove records with miss-identified taxonomy: Incorrectly identified species, or unrecognized species names compared to a naming authority, should be removed.\n\nIncorrectly identified specimens can be difficult to identify with open source biodiversity data. Often these will be picked up by 1) an image of the species in question which does not match 2) If you notice a species outside of its geographic range, this could be a true outlier, it could be a spatial error, or it could be a different species. (see — for more info)\n\n\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and Limitations of Climate-Matching Approaches in Detecting Different Types of Spatial Errors in Biodiversity Data.” Insect Conservation and Diversity 11 (5): 407–14."
  },
  {
    "objectID": "duplicates.html",
    "href": "duplicates.html",
    "title": "8  Duplicates",
    "section": "",
    "text": "Duplicates add computational burden to your analyses. Some spatial analyses won’t run if duplicates are present as it breaks mathematical constraints. There are a few different categories of duplicates which you might encounter when working with open source biodiversity data, with some being more difficult to work with than others.\n\nTrue duplicates = Unique identifier (UID) is the same\nTrue duplicates can occur for many reasons, often data is sent to the state authority it was collected in as well as the authority responsible for collecting the data, which is not always the same. When this data is aggregated by the ALA for example, they end up with multiple copies. These are true duplicates- as in they have the same UID, same coordinates, same species. They don’t always impact modelling. Although they can impact sampling bias and increase computational burden for no added benefit so it’s best to remove them (Jin and Yang 2020; Marsh et al. 2022).\nRemoving true duplicates where the UID is the same is quite straightforward and is a common step before mapping biodiversity data.\n\n\n#assertions: duplicateType \"DIFFERENT_DATASET\"\n\n\nDifferent UID Same species, same coordinates, yet different year.\nIf the UID is different, but the species name is the same and the coordinates are the same this could be a couple of different things:\na) If the year is different, it’s likely a true record, indicating it’s continued presence- this is most likely for plants…there are cases where you’ll still want to remove the\n\n#assertions: duplicate_status \"ASSOCIATED\"\n\nb) Herbarium duplicates: same year, same collector, however different UID and minor differences in locality, coordinate precision. These can be more difficult to decipher, and we’ve called them Herbarium duplicates as this is when they most commonly occur. The same specimen will sometimes be sent to multiple herbariums, this results in different UIDs. Additionally because the data is potentially being inputted by different people the discrepancies this causes can make them difficult to spot [REF bob pers com].\n\n\n#assertions: duplicateType \"DIFFERENT_DATASET\"\n#assertions: isDuplicateOf \"DIFFERENT_DATASET\"\n\n\nSpatial thinning = records located close to each other\nThese records are not duplicates, not the same individual, not in exactly the same spot, yet close together. Think about patch of grass, this isn’t one plant but many all packed tightly together. This adds computational burden, especially for large scale biodiversity analyses and distribution modelling for many species (Zizka et al. 2020; Kuralt, n.d.). This can also be done to reduce bias associated with oversampling at a small number of sites within larger species ranges (Godfree et al. 2021).\n\n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nKuralt, Zan. n.d. “GBIF Data for Species Distribution Modelling: A Case Study of Lithobius Erythrocephalus (Chilopoda: Lithobiidae).” http://rstudio-pubs-static.s3.amazonaws.com/415459_61fae98ff3984241bd5f7f31da425c98.html.\n\n\nMarsh, Jessica R., Payal Bal, Hannah Fraser, Kate Umbers, Tanya Latty, Aaron Greenville, Libby Rumpff, and John C. Z. Woinarski. 2022. “Accounting for the Neglected: Invertebrate Species and the 2019–2020 Australian Megafires.” Global Ecology and Biogeography n/a (n/a). https://doi.org/10.1111/geb.13550.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio Baez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus Colli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais Ferreira-Araújo. 2020. “No One-Size-Fits-All Solution to Clean GBIF.” PeerJ 8: e9916."
  },
  {
    "objectID": "spatial.html",
    "href": "spatial.html",
    "title": "7  Spatial data",
    "section": "",
    "text": "8 Notes"
  },
  {
    "objectID": "spatial.html#quick-visualisation",
    "href": "spatial.html#quick-visualisation",
    "title": "7  Spatial data",
    "section": "7.1 Quick visualisation",
    "text": "7.1 Quick visualisation\nNow is a great time to plot your data onto a map again. Spatial errors are much easier to spot from a visual perspective."
  },
  {
    "objectID": "spatial.html#coordinate-precision",
    "href": "spatial.html#coordinate-precision",
    "title": "7  Spatial data",
    "section": "7.2 Coordinate precision",
    "text": "7.2 Coordinate precision\nOpen access data will be collected from many people using different tools with varying expertise, some record coordinates may have been recorded with a phone, some with a GPS, or a place name and coordinates added after the fact. Depending on the level of precision you need, you might consider discarding data of lower precision, or removing decimal places for data you know could not be that precise. At the ALA there is a “cooridnateprecision”/ “coordinateUncertainityIn Meters” assertion (see assertion section to download these with the data)\n\nhttps://xkcd.wtf/2170/\nCoordinate precision below 100km represents the grain size of many macroecological analyses (Zizka et al. 2020). Some studies have used a cut-off of spatial resolution &gt;25,000m or precision with less than three decimal places (add a reference here). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision. Understanding the level of quality you need is important before removing/keeping large volumes of data.\n\n#How to filter by number of decimal places"
  },
  {
    "objectID": "spatial.html#coordinate-correction",
    "href": "spatial.html#coordinate-correction",
    "title": "7  Spatial data",
    "section": "7.3 Coordinate correction",
    "text": "7.3 Coordinate correction\nSome of these steps may have been completed in a pre-cleaning step, however it’s now time to be more rigorous. As always we’ll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:\nFlipped coordinates: Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected. (Jin and Yang 2020)\n\n#example map of some flipped coordinates (what to look for) \n# https://www.gbif.org/occurrence/3013406216 this has flipped coordinates, which GBIF has corrected\n# https://www.gbif.org/occurrence/search?q=mammalia&continent=SOUTH_AMERICA&has_coordinate=true&has_geospatial_issue=false&issue=PRESUMED_SWAPPED_COORDINATE&advanced=1. ## the issue and flag is called 'presumed swapped coordinate' \n\nNumerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.\n\n#example map, like coordinates off the coast of japan\n\n# https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51360942&qualityProfile=CSDM&radius=50&lat=35.66845370835343&lon=138.9990234375#tab_recordsView\n\n# eucs &lt;- galah_call() %&gt;% \n#  galah_identify(\"Eucalyptus\") %&gt;%\n#  galah_filter( year == 2005, \n#             dataResourceName == \"The University of Melbourne Herbarium (MELU) AVH data\") %&gt;%\n#  atlas_occurrences()\n\nCountry field doesn’t match coordinates: The coordinates could be wrong or just the country listed.\n\n## this doesnt seem to be very common- atleast not in ALA data- because there is no neighboring country\n# https://biocache.ala.org.au/occurrences/a34fca43-9e7c-4b37-8fe4-07cc18369465 Australian coordinates, country listed as Trinidad and Tobago\n# https://www.gbif.org/occurrence/search?advanced=true&continent=SOUTH_AMERICA&geometry=POLYGON((-78.74961%20-8.25249,-76.29838%20-8.25249,-76.29838%20-4.74121,-78.74961%20-4.74121,-78.74961%20-8.25249))&has_coordinate=true&issue=COUNTRY_MISMATCH&locale=en&q=reptilia   # GBIF example- reptiles located in Peru, originally recorded as Ecuador"
  },
  {
    "objectID": "spatial.html#coordinate-cleaning",
    "href": "spatial.html#coordinate-cleaning",
    "title": "7  Spatial data",
    "section": "7.4 Coordinate cleaning",
    "text": "7.4 Coordinate cleaning\nOnce you have fixed everything you can, it’s time to remove records that still have errors. This doesn’t mean removing all outliers, you must have more than “it’s far away from the others” to justify a records removal.\nRemove records with null or missing coordinates: This will be records missing partial or complete information. Missing values can cause errors, many analytical tools do not respond well to missing values. If you can’t find the information elsewhere, it’s best to remove it.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, check first, however likely will need to remove\nRemove records with zero coordinates: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\n\n#zero coordinates acacia \n\n#https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51382879&disableAllQualityFilters=true&qualityProfile=ALA&fq=spatiallyValid%3A%22false%22&radius=25&lat=-0.024032592068740033&lon=-0.06591796875#tab_recordsView \n\nRemove records plotted away from the known area of distribution of the species. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it’s worth checking the literature before discarding records like these. These can also be mis-identified species, if you’re working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area. –&gt; unsure about this bit"
  },
  {
    "objectID": "spatial.html#optional-record-removal",
    "href": "spatial.html#optional-record-removal",
    "title": "7  Spatial data",
    "section": "7.5 Optional record removal",
    "text": "7.5 Optional record removal\nRemove records with coordinates assigned to country and province centroids: such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.\nCentroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such.\nIn a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary."
  },
  {
    "objectID": "spatial.html#checklist-of-data-standardization",
    "href": "spatial.html#checklist-of-data-standardization",
    "title": "7  Spatial data",
    "section": "7.6 Checklist of data standardization",
    "text": "7.6 Checklist of data standardization"
  },
  {
    "objectID": "spatial.html#missing-data",
    "href": "spatial.html#missing-data",
    "title": "7  Spatial data",
    "section": "8.1 Missing data",
    "text": "8.1 Missing data\n(I wonder if this is really the place for this or better to just do this in the Spatial chapter)\n\nRemove records with no coordinates"
  },
  {
    "objectID": "spatial.html#quick-visualiations",
    "href": "spatial.html#quick-visualiations",
    "title": "7  Spatial data",
    "section": "8.2 Quick visualiations",
    "text": "8.2 Quick visualiations\nA graphic plot of your data can be very telling and can help you spot potential errors that may be due to formatting.\n\n8.2.1 GGally\nA visual inspection of your entire dataset can save time and solve easy-to-spot errors.\n\n\n8.2.2 Quick map\n(I wonder if this is really the place for this or better to just do this in the Spatial chapter)\nA simple way to visualize your data is to plot it on a map.\n\nFix minor coordinates errors, such as inverted or badly formatted\n\n\n\n8.2.3 \n\n\n8.2.4 CoordinateCleaner\n\n\n\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio Baez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus Colli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais Ferreira-Araújo. 2020. “No One-Size-Fits-All Solution to Clean GBIF.” PeerJ 8: e9916."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "10  References",
    "section": "",
    "text": "Führding-Potschkat, Petra, Holger Kreft, and Stefanie M. Ickert-Bond.\n2022. “Influence of Different Data Cleaning Solutions of\nPoint-Occurrence Records on Downstream Macroecological Diversity\nModels.” Ecology and Evolution 12 (8): e9168. https://doi.org/10.1002/ece3.9168.\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi,\nand Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys\nSpecies (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of\nFresh Water Habitats by Macrodasyids.” Scientific\nReports 9 (1): 2067.\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David\nAlbrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021.\n“Implications of the 2019–2020 Megafires for the Biogeography and\nConservation of Australian Vegetation.” Nature\nCommunications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nGueta, Tomer, and Yohay Carmel. 2016. “Quantifying the Value of\nUser-Level Data Cleaning for Big Data: A Case Study Using\nMammal Distribution Models.” Ecological Informatics 34\n(July): 139–45. https://doi.org/10.1016/j.ecoinf.2016.06.001.\n\n\nJin, Jing, and Jun Yang. 2020a. “BDcleaner:\nA Workflow for Cleaning Taxonomic and Geographic Errors in\nOccurrence Data Archived in Biodiversity Databases.” Global\nEcology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\n———. 2020b. “BDcleaner: A Workflow for Cleaning Taxonomic and\nGeographic Errors in Occurrence Data Archived in Biodiversity\nDatabases.” Global Ecology and Conservation 21 (March):\ne00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nKuralt, Zan. n.d. “GBIF Data for Species Distribution Modelling: A\nCase Study of Lithobius Erythrocephalus (Chilopoda:\nLithobiidae).” http://rstudio-pubs-static.s3.amazonaws.com/415459_61fae98ff3984241bd5f7f31da425c98.html.\n\n\nMace, Georgina M. 2004. “The Role of Taxonomy in Species\nConservation.” Philosophical Transactions of the Royal\nSociety of London. Series B: Biological Sciences 359 (1444):\n711–19.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville,\nLibby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts\nof the 2019-20 Wildfires of Southern and Eastern Australia on\nInvertebrate Species Final Report.”\n\n\nMarsh, Jessica R., Payal Bal, Hannah Fraser, Kate Umbers, Tanya Latty,\nAaron Greenville, Libby Rumpff, and John C. Z. Woinarski. 2022.\n“Accounting for the Neglected: Invertebrate Species\nand the 2019–2020 Australian Megafires.” Global\nEcology and Biogeography n/a (n/a). https://doi.org/10.1111/geb.13550.\n\n\nRibeiro, Bruno R., Santiago José Elías Velazco, Karlo Guidoni-Martins,\nGeiziane Tessarolo, Lucas Jardim, Steven P. Bachman, and Rafael Loyola.\n2022. “Bdc: A Toolkit for Standardizing, Integrating\nand Cleaning Biodiversity Data.” Methods in Ecology and\nEvolution 13 (7): 1421–28. https://doi.org/10.1111/2041-210X.13868.\n\n\nRodrigues, Arthur Vinicius, Gabriel Nakamura, Vanessa Graziele\nStaggemeier, and Leandro Duarte. 2022. “Species Misidentification\nAffects Biodiversity Metrics: Dealing with This Issue Using\nthe New R Package naturaList.” Ecological\nInformatics 69 (July): 101625. https://doi.org/10.1016/j.ecoinf.2022.101625.\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset:\nExpert-Validated Occurrence Records of Australia’s Frogs Collected by\nCitizen Scientists.” ZooKeys 912: 139.\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and\nLimitations of Climate-Matching Approaches in Detecting Different Types\nof Spatial Errors in Biodiversity Data.” Insect Conservation\nand Diversity 11 (5): 407–14.\n\n\nstreamdna. 2020. “Sharing Is Caring:\nWorking with Other People’s\nData.” https://methodsblog.com/2020/09/04/sharing-is-caring-working-with-other-peoples-data/.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio\nBaez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus\nColli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais\nFerreira-Araújo. 2020b. “No One-Size-Fits-All Solution to Clean\nGBIF.” PeerJ 8: e9916.\n\n\n———. 2020a. “No One-Size-Fits-All Solution to Clean GBIF.”\nPeerJ 8: e9916."
  },
  {
    "objectID": "download-data.html#where-to-get-data-from",
    "href": "download-data.html#where-to-get-data-from",
    "title": "3  Download occurrence data",
    "section": "3.1 Where to get data from",
    "text": "3.1 Where to get data from\nThe Global Biodiversity Information Facility (GBIF) network consists of a series of ‘node’ organisations who collate biodiversity data from their own countries, with GBIF acting as an overarching organisation to store data from all nodes. Users that are interested in obtaining data that has global coverage may want to download directly from GBIF.\nAlternatively, using a regional node may be more relevant if your project is at a smaller scale. For example, the Atlas of Living Australia (ALA) is the Australian node to GBIF and aggregates data from a broad range of providers such as government initiatives, museums, and universities. Importantly, the ALA uses their own taxonomic system and may vary with other data infrastructures. To find other nodes, check out this page\nIf your project relates to citizen science then iNaturalist may be a good option for accessing crowd-sourced data of species observations."
  },
  {
    "objectID": "download-data.html#downloading-data",
    "href": "download-data.html#downloading-data",
    "title": "3  Download occurrence data",
    "section": "3.2 Downloading data",
    "text": "3.2 Downloading data\n\n3.2.1 Taxonomic focus"
  },
  {
    "objectID": "download-data.html#query-with-choosen-naming-authority",
    "href": "download-data.html#query-with-choosen-naming-authority",
    "title": "3  Download occurrence data",
    "section": "3.3 Query with choosen naming authority",
    "text": "3.3 Query with choosen naming authority\n(May go before download data or used after download to refine, improve download)\nNow that you’ve chosen a naming authority you can use it to ensure consistency across your data set, but also check you haven’t missed any species data from your download.\n\n3.3.1 Getting higher taxonomy\nDownloading higher taxon data (kingdom:class) and then filtering for what you need, as disparities are less common at higher levels (???? Check with Martin)\n\n\n3.3.2 Getting all taxonomy relevant columns\nInclude the original name that was recorded by the data provider in your download. This is often referred to as verbatimScientificName. or vernacularname\n\nInclude synonyms of the species names you’re interested in your download\n\nMany developers have created R packages to interact with each data infrastructures’s API to aid access to biodiversity data. Here are a few examples, we recommend taking a look at each package’s documentation to choose one that suits your project.\n\nrgbif an interface to GBIF\ngalah an interface to a number living Atlases, as well as GBIF\nrinat an interface to iNaturalist observations\nrebird an interface with the eBird webservices.\nspocc a R package to query and collect species occurrence data from various sources including VertNet, iDigBio and others.\n\nOne benefit of using galah is that enables users to acquire not only species occurrence records but also taxonomic information, or associated media such as images or sounds. Below we have included some code blocks for downloading occurrence data with galah from GBIF and a Spain node.\n\n3.3.2.1 GBIF data via galah\nFirst, we have to configure galah. This is where you supply your account credentials and set the atlas to a particular region. See ?galah_config for more configuration options. You can save these credentials in your .Renviron so you don’t have to enter it explicitly in code.\nWe will be downloading all occurrences for the African Elephant from GBIF. This may take a while as it is around 12,000 records. Once downloaded, you can save the records locally in your desired format. For larger downloads, we recommend saving the data as parquets using arrow::write_parquet\n\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"),\n             username = Sys.getenv(\"GBIF_USER\"),\n             password = Sys.getenv(\"GBIF_PWD\"),\n             atlas = \"Global\")\n\nafrican_ele &lt;- galah_call() %&gt;% \n  galah_identify(\"Loxodonta africana\") %&gt;% \n  atlas_occurrences()\n\narrow::write_parquet(african_ele, \"data/gbif/elephant\")\n\n\n\n# A tibble: 12,537 × 50\n      gbifID datasetKey     occurrenceID kingdom phylum class order family genus\n *     &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;\n 1 924537719 95f132fe-f762… 73e088f2-f8… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 2 924537718 95f132fe-f762… 73e0ad3c-f8… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 3 924537717 95f132fe-f762… 73f0f6ec-f8… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 4 923926679 50c9509d-22c7… http://www.… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 5 923924124 50c9509d-22c7… http://www.… Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 6 922237429 6ac3f774-d9fb… &lt;NA&gt;         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 7 922237412 6ac3f774-d9fb… &lt;NA&gt;         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 8 922237188 6ac3f774-d9fb… &lt;NA&gt;         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n 9 922237135 6ac3f774-d9fb… &lt;NA&gt;         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n10 922237121 6ac3f774-d9fb… &lt;NA&gt;         Animal… Chord… Mamm… Prob… Eleph… Loxo…\n# ℹ 12,527 more rows\n# ℹ 41 more variables: species &lt;chr&gt;, infraspecificEpithet &lt;chr&gt;,\n#   taxonRank &lt;chr&gt;, scientificName &lt;chr&gt;, verbatimScientificName &lt;chr&gt;,\n#   verbatimScientificNameAuthorship &lt;chr&gt;, countryCode &lt;chr&gt;, locality &lt;chr&gt;,\n#   stateProvince &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, individualCount &lt;dbl&gt;,\n#   publishingOrgKey &lt;chr&gt;, decimalLatitude &lt;dbl&gt;, decimalLongitude &lt;dbl&gt;,\n#   coordinateUncertaintyInMeters &lt;dbl&gt;, coordinatePrecision &lt;dbl&gt;, …\n\n\n\n\n3.3.2.2 Regional node via galah\nIn order to access data from the Australia node, we will need to reconfigure galah so that our query points to Australia. After that, we will download all records for the Pink Robin.\n\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"), \n             atlas = \"Australia\")\n\npink_robin &lt;- galah_call() %&gt;% \n  galah_identify(\"Petroica rodinogaster\") %&gt;% \n  atlas_occurrences\n\n\n\n# A tibble: 11,992 × 8\n   decimalLatitude decimalLongitude eventDate           scientificName          \n *           &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;                   \n 1           -43.7             146. NA                  Petroica (Erythrodryas)…\n 2           -43.7             146. NA                  Petroica (Erythrodryas)…\n 3           -43.7             146. 1971-02-03 14:00:00 Petroica (Erythrodryas)…\n 4           -43.7             146. 2020-10-07 02:39:00 Petroica (Erythrodryas)…\n 5           -43.7             146. 2015-09-22 14:00:00 Petroica (Erythrodryas)…\n 6           -43.6             146. 2002-01-03 13:00:00 Petroica (Erythrodryas)…\n 7           -43.6             146. NA                  Petroica (Erythrodryas)…\n 8           -43.6             146. 2020-12-27 13:00:00 Petroica (Erythrodryas)…\n 9           -43.6             146. 2021-03-07 13:00:00 Petroica (Erythrodryas)…\n10           -43.6             146. 2020-12-26 13:00:00 Petroica (Erythrodryas)…\n# ℹ 11,982 more rows\n# ℹ 4 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;\n\n\n\n\n\n3.3.3 Spatial focus"
  },
  {
    "objectID": "download-data.html#choosing-specific-data-columns",
    "href": "download-data.html#choosing-specific-data-columns",
    "title": "3  Download occurrence data",
    "section": "3.4 Choosing specific data columns",
    "text": "3.4 Choosing specific data columns\nBy default, atlas_occurrences will return a tibble with a selection of columns containing taxonomic and spatial data as well as other metadata. Alternatively, you can use galah_select to subset the columns that are relevant for your work. To see all available fields you can choose from:\n\nshow_all(fields) \n\n# A tibble: 611 × 4\n   id                    description                                 type  link \n   &lt;chr&gt;                 &lt;chr&gt;                                       &lt;chr&gt; &lt;chr&gt;\n 1 abcdTypeStatus        ABCD field in use by herbaria               fiel… &lt;NA&gt; \n 2 acceptedNameUsage     http://rs.tdwg.org/dwc/terms/acceptedNameU… fiel… &lt;NA&gt; \n 3 acceptedNameUsageID   http://rs.tdwg.org/dwc/terms/acceptedNameU… fiel… &lt;NA&gt; \n 4 accessRights          &lt;NA&gt;                                        fiel… &lt;NA&gt; \n 5 assertionUserId       User ID of the person who has made an asse… fiel… &lt;NA&gt; \n 6 assertions            A list of all assertions (user and system … fiel… &lt;NA&gt; \n 7 associatedMedia       http://rs.tdwg.org/dwc/terms/associatedMed… fiel… &lt;NA&gt; \n 8 associatedOccurrences http://rs.tdwg.org/dwc/terms/associatedOcc… fiel… &lt;NA&gt; \n 9 associatedOrganisms   http://rs.tdwg.org/dwc/terms/associatedOrg… fiel… &lt;NA&gt; \n10 associatedReferences  http://rs.tdwg.org/dwc/terms/associatedRef… fiel… &lt;NA&gt; \n# ℹ 601 more rows\n\n\nHere, we will choose a smaller subsets of 8 columns to download for the Pink Robin\n\nproject_fields &lt;- c(\"recordID\",\n                    \"eventDate\",\n                    \"year\", \n                    \"basisOfRecord\", \n                    \"occurrenceStatus\",\n                    \"scientificName\",\n                    \"decimalLatitude\",\n                    \"decimalLongitude\")\n\npink_robin_projfields &lt;- galah_call() %&gt;% \n  galah_identify(\"Petroica rodinogaster\") %&gt;% \n  galah_select(project_fields) %&gt;% \n  atlas_occurrences()\n\n\n\n# A tibble: 11,992 × 8\n   recordID             eventDate            year basisOfRecord occurrenceStatus\n * &lt;chr&gt;                &lt;dttm&gt;              &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt;           \n 1 000fc2ef-b696-4576-… 1976-12-18 13:00:00  1976 HUMAN_OBSERV… PRESENT         \n 2 001410fd-3a01-43aa-… 1978-05-23 14:00:00  1978 HUMAN_OBSERV… PRESENT         \n 3 00164a76-0b3a-4b44-… 1977-12-15 13:00:00  1977 HUMAN_OBSERV… PRESENT         \n 4 001bfca5-4197-40a6-… 1940-12-31 14:00:00  1941 OBSERVATION   PRESENT         \n 5 001e33bd-bb15-4384-… 2002-10-17 14:00:00  2002 HUMAN_OBSERV… PRESENT         \n 6 0021cc7c-a371-4af6-… 2016-04-09 14:00:00  2016 OCCURRENCE    PRESENT         \n 7 00287e24-87b8-429a-… 2021-01-14 13:00:00  2021 HUMAN_OBSERV… PRESENT         \n 8 002e05a7-b1bf-4eba-… 2000-07-24 14:00:00  2000 OBSERVATION   PRESENT         \n 9 00327fc2-ae67-467b-… 1983-11-23 13:00:00  1983 PRESERVED_SP… PRESENT         \n10 0035016f-ae80-494a-… NA                     NA HUMAN_OBSERV… PRESENT         \n# ℹ 11,982 more rows\n# ℹ 3 more variables: scientificName &lt;chr&gt;, decimalLatitude &lt;dbl&gt;,\n#   decimalLongitude &lt;dbl&gt;"
  },
  {
    "objectID": "download-data.html#refining-your-data-download",
    "href": "download-data.html#refining-your-data-download",
    "title": "3  Download occurrence data",
    "section": "3.5 Refining your data download",
    "text": "3.5 Refining your data download\nOpen access biodiversity data comes from many different providers such as universities, research institutes (museums and herbariums), government and the general public. As such, data type and quality can vary considerably. For example, museums harbour older records that are associated with a preserved specimen, whereas citizen sourced data are often images captured from a smart phone.\nRefining your download query ensures higher quality data and also reduces the download size as many data infrastructures impose constraints to download size. Below we have illustrated how you can refine your query a few quality measures using galah_filter.\n\n3.5.0.1 By Year\nGenerally, old data records tend to be insufficient or less reliable as taxonomic knowledge and GPS tools were not readily available. For this reason, many users consider removing all occurrence records before a certain year to increase data precision (Gueta and Carmel 2016; Marsh et al. 2022) .\nChoosing the year ‘cut-off’ is relatively arbitary, but the most commonly used year is 1945 (Zizka et al. 2020; Führding-Potschkat, Kreft, and Ickert-Bond 2022), although some studies discard all data collected before 1990 (Gueta and Carmel 2016; Marsh et al. 2022).\nHere we will narrow the Pink Robin query from above to records after 1945 using galah_filter:\n\npink_robin_post1945 &lt;- galah_call() %&gt;% \n  galah_identify(\"Petroica rodinogaster\") %&gt;% \n  galah_filter(year &gt; 1945) %&gt;% \n  atlas_occurrences()\n\n\n\n3.5.0.2 Basis of record\nBasis of record is a Darwin Core term that refers to the specific nature of the occurrence record. It can be used to refine your data download and ensure consistency when consolidating data from multiple organisations (Führding-Potschkat, Kreft, and Ickert-Bond 2022).\nThere are 6 different classes for basis of record:\n\nLiving Specimen - a specimen that is alive, e.g. a living plant in a national park\nPreserved Specimen - a specimen that has been preserved, for example, a dried plant on an herbarium sheet\nFossil Specimen - a preserved specimen that is a fossil\nMaterial Sample - a genetic or environmental sample\nMaterial Citation - A reference to, or citation of, a specimen in scholarly publications, e.g a citation of a physical specimen in a scientific journal\nHuman Observation - an output of human observation process e.g. evidence of an occurrence taken from field notes or an occurrence without any physical evidence\nMachine Observation - An output of a machine observation process e.g. a photograph, a video, an audio recording, a remote sensing image or an occurrence record based on telemetry.\n\nDepending on your data scope, it may be practical to limit data that can be traced to a physical specimen or observation (Godfree et al. 2021), which we do for the Pink Robin below\n\ntractable_records &lt;- c(\"LIVING_SPECIMEN\", \n                       \"PRESERVED_SPECIMEN\", \n                       \"MATERIAL_SAMPLE\", \n                       \"MACHINE_OBSERVATION\")\n\npink_robin_tractable &lt;- galah_call() %&gt;% \n  galah_identify(\"Petroica rodinogaster\") %&gt;% \n  galah_filter(basisOfRecord == tractable_records) %&gt;% \n  atlas_occurrences()\n\n\n\n3.5.0.3 Assertions\nData infrastructures use assertions to internally grade the quality, completeness and consistency of each occurrence record. Assertions take values of either 1 or 0, indicating the presence or absence of the data quality issue. Note that assertions may vary depending what atlas you have configured to. You can see the available assertions and their descriptions using:\n\nshow_all(\"assertions\") \n\n# A tibble: 117 × 4\n   id                                 description                 category type \n   &lt;chr&gt;                              &lt;chr&gt;                       &lt;chr&gt;    &lt;chr&gt;\n 1 AMBIGUOUS_COLLECTION               Ambiguous collection        Warning  asse…\n 2 AMBIGUOUS_INSTITUTION              Ambiguous institution       Warning  asse…\n 3 BASIS_OF_RECORD_INVALID            Basis of record badly form… Warning  asse…\n 4 biosecurityIssue                   Biosecurity issue           Error    asse…\n 5 COLLECTION_MATCH_FUZZY             Collection match fuzzy      Warning  asse…\n 6 COLLECTION_MATCH_NONE              Collection not matched      Warning  asse…\n 7 CONTINENT_COUNTRY_MISMATCH         Continent country mismatch  Warning  asse…\n 8 CONTINENT_DERIVED_FROM_COORDINATES Continent derived from coo… Warning  asse…\n 9 CONTINENT_INVALID                  Continent invalid           Warning  asse…\n10 COORDINATE_ACCURACY_INVALID        Coordinate accuracy invalid Warning  asse…\n# ℹ 107 more rows\n\n\nOnce you have decided which assertions are important for your project you can further refine your download. To retrieve all the assertions for your query use galah_select(group = \"assertions\")\n\n\n\n\n\n\n\n\nFührding-Potschkat, Petra, Holger Kreft, and Stefanie M. Ickert-Bond. 2022. “Influence of Different Data Cleaning Solutions of Point-Occurrence Records on Downstream Macroecological Diversity Models.” Ecology and Evolution 12 (8): e9168. https://doi.org/10.1002/ece3.9168.\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nGueta, Tomer, and Yohay Carmel. 2016. “Quantifying the Value of User-Level Data Cleaning for Big Data: A Case Study Using Mammal Distribution Models.” Ecological Informatics 34 (July): 139–45. https://doi.org/10.1016/j.ecoinf.2016.06.001.\n\n\nMarsh, Jessica R., Payal Bal, Hannah Fraser, Kate Umbers, Tanya Latty, Aaron Greenville, Libby Rumpff, and John C. Z. Woinarski. 2022. “Accounting for the Neglected: Invertebrate Species and the 2019–2020 Australian Megafires.” Global Ecology and Biogeography n/a (n/a). https://doi.org/10.1111/geb.13550.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio Baez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus Colli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais Ferreira-Araújo. 2020. “No One-Size-Fits-All Solution to Clean GBIF.” PeerJ 8: e9916."
  }
]