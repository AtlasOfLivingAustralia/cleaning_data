[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA Data Cleaning",
    "section": "",
    "text": "Welcome\nData cleaning is the exploration, detection and correction of erroneous or unsuitably formatted data. The standard of what ‘clean’ data looks like varies considerably across projects and data sources. This means that there is no ‘one-size-fits-all’ approach.\nOur goal in creating this resource is to assist researchers and decision makers that may have limited experience with cleaning geo-referenced biodiversity data in R.\nIn this book, we provide an overview of a typical data cleaning workflow - from acquisition, to identifying potential errors, and, to correction. In each chapter we include practical guidelines, R code blocks and additional resources that may aid with each data cleaning step.\nThe content of this book is guided by the current state of biodiversity literature on preparing data for species distribution modelling. For more details about how this was done, please refer to the Appendix. All resources that have been consulted for this book can be found in References."
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "ALA Data Cleaning",
    "section": "How to contribute",
    "text": "How to contribute\nWe would like to preface that we are not experts in data cleaning, but felt there was need for a consolidated resource to guide data cleaning decisions.\nWe welcome contributions to this document and suggest anyone to submit pull requests at the GitHub repository of this document. Contributing guidelines can be found at XX (Maybe another section or just a MD in GitHub Repo)\nAlternatively, if you have questions please submit a GitHub issue."
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "ALA Data Cleaning",
    "section": "How to cite",
    "text": "How to cite\nTO COME BACK TO THIS LATER Refer to this when creating this section(https://ardc.edu.au/resource/citing-software/)\nYou can cite this document:"
  },
  {
    "objectID": "index.html#acknowlodgements",
    "href": "index.html#acknowlodgements",
    "title": "ALA Data Cleaning",
    "section": "Acknowlodgements",
    "text": "Acknowlodgements\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA)\nAuthors listed in alphabetic order:\n- Fonti Kar\n- Jessica Fenker\n- Margot Schneider\n- Martin Westgate"
  },
  {
    "objectID": "intro.html#what-you-will-learn-outline-of-the-book",
    "href": "intro.html#what-you-will-learn-outline-of-the-book",
    "title": "1  Introduction",
    "section": "1.1 What you will learn / Outline of the book",
    "text": "1.1 What you will learn / Outline of the book\n\n\n# new diagram here\nlibrary(DiagrammeR)\n\nTo begin working with open access data we’ll teach you how to:\n\nNarrow your data scope\nImport data\nTidy and familiarise yourself with metadata\n\nOnce data have been imported and formatted correctly we’ll dive into the major cleaning steps. We will focus on how to deal with taxonomic and spatial issues with biodiversity or species occurrence data.\n\nWe will start with taxonomic issues\n\nTaxonomic issues\n\nnaming authorities\nsynonyms\nDuplicates\n\nSpatial data\n\nOutliers\nDuplicates"
  },
  {
    "objectID": "intro.html#what-you-wont-learn",
    "href": "intro.html#what-you-wont-learn",
    "title": "1  Introduction",
    "section": "1.2 What you won’t learn",
    "text": "1.2 What you won’t learn\nThere are many important subject areas that this book will not cover. We won’t be teaching you:\n\nHow to clean other data types e.g. environmental or trait data\nHow to run a species distribution model\nHypothesis testing or experimental design"
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "1  Introduction",
    "section": "1.3 Prerequisites",
    "text": "1.3 Prerequisites\n\n1.3.1 User accounts\nTo get data out of data infrastructures such as the Atlas of living Australia (ALA) or the Global Biodiversity Information (GBIF) you’ll need to first create an account. You’ll want to sign up for an account with the relevant data infrastructure. This book will use ALA and GBIF data as examples.\nAtlas of Living Australia = create an account Global Biodiversity Information Facility = create an account\n\n\n1.3.2 R\nDownload R from CRAN (the comprehensive R archive network), for your operating system, and install it on your device. Major updates for R come out yearly with a few minor releases throughout the year, so make sure to update semi regularly.\n\nWindows\n\n\nMac\n\n\n\n1.3.3 RStudio\nRstudio is an integrated development environment (IDE) for R programming. Download and install Rstudio for your operating system https://posit.co/download/rstudio-desktop/\n\nWindows\n\n\nMac"
  },
  {
    "objectID": "intro.html#how-to-use-this-book",
    "href": "intro.html#how-to-use-this-book",
    "title": "1  Introduction",
    "section": "1.4 How to use this book",
    "text": "1.4 How to use this book\nThere is no one size fits all workflow and not all steps are relevant and/or possible. Through examining the literature we found steps were frequently done in completely different orders depending on the nature of the study and the area of expertise possessed. Because of this, we don’t recommend you use this book in a linear fashion. However some steps logically come first, you might need to go back to them after completely another (fig x) \n\n\n\n\nRodrigues, A. V., Nakamura, G., Staggemeier, V. G., & Duarte, L. (2022). Species misidentification affects biodiversity metrics: Dealing with this issue using the new R package naturaList. Ecological Informatics, 69, 101625. https://doi.org/10.1016/j.ecoinf.2022.101625"
  },
  {
    "objectID": "taxonomy.html#taxonomy-preclean",
    "href": "taxonomy.html#taxonomy-preclean",
    "title": "5  Taxonomy",
    "section": "5.1 Taxonomy preclean",
    "text": "5.1 Taxonomy preclean\nSimilar to what we did in the previous chapter, we will apply a broad sweep pre-clean to taxonomic data. This will make dealing with synonyms go as smoothly as possible.\nThe process is to first identify the issue, correct it, check it, and then document the changes. The goal is to standardise and correct as many errors issues before removing records.\n\n5.1.1 Capitalisation\nNormally higher taxonomy are capitalised e.g. Myrtaceae or Aves. Capitalisation errors are usually quick to spot when you print the data object. Alternatively you can try using str_subset on columns you expect to have capital letters.\nThe code below subsets out unique values for the variable class that have upper case letters. Notice that no matches are found\n\nlibrary(tidyverse)\n\nstr_subset(unique(bees$class), \"[:upper:]\")\n\ncharacter(0)\n\n\nWe can confirm that there are no upper case matches by subsetting unique values that have lower case letters to see what is going on. This shows us that Insecta is inputted entirely in lowercase.\n\nstr_subset(unique(bees$class), \"[:lower:]\") \n\n[1] \"insecta\"\n\n\nWe can correct the lower case formatting as below, remember to check the fix before overwriting/removing the erroneous column(s)\n\nbees |> \n  mutate(class_corrected = str_to_sentence(class)) |>\n  select(starts_with(\"class\"))\n\n# A tibble: 1,139 × 2\n   class   class_corrected\n   <chr>   <chr>          \n 1 insecta Insecta        \n 2 insecta Insecta        \n 3 insecta Insecta        \n 4 insecta Insecta        \n 5 insecta Insecta        \n 6 insecta Insecta        \n 7 insecta Insecta        \n 8 insecta Insecta        \n 9 insecta Insecta        \n10 insecta Insecta        \n# … with 1,129 more rows\n\nbees_corrected <- bees |> \n  mutate(class_corrected = str_to_sentence(class)) |> \n  select(-class) |> # Remove erroreous column \n  rename(class = class_corrected) # Rename corrected column as the new 'class'\n\n\n\n5.1.2 Seperators\nIn a taxonomic data, separators such as, spaces and underscore are found in scientific names and are used to delineate the genus and species name. While it is personal choice which separator you use, it is good practice to be consistent with your choice. Consistency ensures that unique values of scientific name truly reflects unique species and not due to inconsistencies.\nTry tabyl-ing your taxonomic columns to check if you have any inconsistencies first\n\nlibrary(janitor)\n\nplants |> \n  pull(scientific_name) |> \n  tabyl() |> \n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants, scientific_name)`         n  percent\n   <chr>                               <int>    <dbl>\n 1 Acacia asparagoides                     2 0.000962\n 2 Acacia barakulensis                     1 0.000481\n 3 Acacia barringtonensis                  2 0.000962\n 4 Acacia beadleana                        1 0.000481\n 5 Acacia betchei                          6 0.00289 \n 6 Acacia blayana                          2 0.000962\n 7 Acacia brunioides                       1 0.000481\n 8 Acacia brunioides subsp. brunioides     6 0.00289 \n 9 Acacia brunioides subsp. granitica      1 0.000481\n10 Acacia bulgaensis                       3 0.00144 \n# … with 613 more rows\n\n\nConsistent taxonomic formatting may not be an issue if you are downloading data from one single source such as the ALA where scientific names are already formatted consistently e.g. “Moloch horridus”. This may not be the case when consolidating data from multiple sources.\nBelow is code to create an underscore scientific name from one that is separated with a space. Remember to check your changes\n\nplants_updated <- plants |> \n  mutate(scientific_name_undersc = str_replace_all(scientific_name, \" \", \"_\")) \n\nplants_updated |> \n  pull(scientific_name_undersc) |> \n  tabyl() |> \n  tibble()\n\n# A tibble: 623 × 3\n   `pull(plants_updated, scientific_name_undersc)`     n  percent\n   <chr>                                           <int>    <dbl>\n 1 Acacia_asparagoides                                 2 0.000962\n 2 Acacia_barakulensis                                 1 0.000481\n 3 Acacia_barringtonensis                              2 0.000962\n 4 Acacia_beadleana                                    1 0.000481\n 5 Acacia_betchei                                      6 0.00289 \n 6 Acacia_blayana                                      2 0.000962\n 7 Acacia_brunioides                                   1 0.000481\n 8 Acacia_brunioides_subsp._brunioides                 6 0.00289 \n 9 Acacia_brunioides_subsp._granitica                  1 0.000481\n10 Acacia_bulgaensis                                   3 0.00144 \n# … with 613 more rows\n\n\n\n\n5.1.3 Higher taxonomy\nHigher taxonomy such as phylum and class may be used to group species for analysis or data visualisations. Its important to check the spelling and formatting of these columns. Its always good to start with some a useful table of counts for each taxonomic level. Keep an eye out for spelling errors, formatting issues and missing data. Note that NA in the output represents missing\nAs an example:\n\nlibrary(tidyverse)\nlibrary(janitor)\n\nplants |> \n  pull(class) |> \n  tabyl()\n\n pull(plants, class)    n     percent valid_percent\n         Cycadopsida    4 0.001924002   0.001937046\n       Equisetopsida  202 0.097162097   0.097820823\n      Lycopodiopsida   10 0.004810005   0.004842615\n       Magnoliopsida 1822 0.876382876   0.882324455\n           Pinopsida    2 0.000962001   0.000968523\n      Polypodiopsida   25 0.012025012   0.012106538\n                <NA>   14 0.006734007            NA\n\nplants |> \n  pull(order) |> \n  tabyl() |> \n  head()\n\n pull(plants, order)   n     percent valid_percent\n         Alismatales   6 0.002886003   0.002939735\n             Apiales  36 0.017316017   0.017638413\n         Asparagales  67 0.032227032   0.032827046\n           Asterales 158 0.075998076   0.077413033\n    Austrobaileyales   6 0.002886003   0.002939735\n          Canellales   5 0.002405002   0.002449780\n\nplants |> \n  pull(genus) |> \n  tabyl() |> \n  tail()\n\n pull(plants, genus)  n     percent valid_percent\n               Viola  5 0.002405002   0.002501251\n          Westringia 12 0.005772006   0.006003002\n           Xanthosia  9 0.004329004   0.004502251\n               Xyris  4 0.001924002   0.002001001\n              Zieria 14 0.006734007   0.007003502\n                <NA> 80 0.038480038            NA\n\n\n\nMissing higher taxonomy\nIf you noticed you have missing data in these columns, you can usually back fill this information using your chosen naming authority or retrieving this information from a living atlas such as the ALA.\nThe code below demonstrates how you can isolate the scientific_names of taxa with missing data and searching for taxonomic information from ALA\n\n\n\nlibrary(galah)\n\n# Configure galah to point to Australia node\ngalah_config(atlas = \"Australia\",\n             email = Sys.getenv(\"ALA_EMAIL\"))\n\n# These are the taxa missing `class` information\nto_search <- inverts |> \n  filter(is.na(class)) |> \n  select(scientific_name) |> \n  distinct()\n\n# Reformat scientific_name to scientificName as the latter is the ALA format\nbackfilled_taxa <- to_search|>\n  rename(scientificName = scientific_name) |> \n  search_taxa(to_search) |> tibble()\n\nbackfilled_taxa\n\n# A tibble: 818 × 15\n   search_term  scien…¹ scien…² taxon…³ rank  match…⁴ kingdom phylum class order\n   <chr>        <chr>   <chr>   <chr>   <chr> <chr>   <chr>   <chr>  <chr> <chr>\n 1 Idiosoma ma… Idioso… (Pococ… https:… spec… exactM… Animal… Arthr… Arac… Aran…\n 2 Holonuncia … Holonu… Hunt, … https:… spec… exactM… Animal… Arthr… Arac… Opil…\n 3 Trachycosmu… Trachy… Simon,… https:… spec… exactM… Animal… Arthr… Arac… Aran…\n 4 Pseudotyran… Pseudo… Beier,… https:… spec… exactM… Animal… Arthr… Arac… Pseu…\n 5 Phryganopor… Phryga… (L. Ko… https:… spec… exactM… Animal… Arthr… Arac… Aran…\n 6 Latrodectus… Latrod… Thorel… https:… spec… exactM… Animal… Arthr… Arac… Aran…\n 7 Ascoschoeng… Ascosc… (Hirst… https:… spec… exactM… Animal… Arthr… Arac… Trom…\n 8 Chrestobunu… Chrest… Hickma… https:… spec… exactM… Animal… Arthr… Arac… Opil…\n 9 Supunna pic… Nyssus… Walcke… https:… spec… exactM… Animal… Arthr… Arac… Aran…\n10 Tasmanicosa… Tasman… (Thore… https:… spec… exactM… Animal… Arthr… Arac… Aran…\n# … with 808 more rows, 5 more variables: family <chr>, genus <chr>,\n#   species <chr>, issues <chr>, vernacular_name <chr>, and abbreviated\n#   variable names ¹​scientific_name, ²​scientific_name_authorship,\n#   ³​taxon_concept_id, ⁴​match_type\n\n\n\n\nInsufficient taxonomic rank\nIf a record is not identified down to the taxonomic level that needed for the study e.g. species, then the record should be removed.\nDuring your data download, ensure you have requested for the column taxonRank, this variable tells us the lowest level of scientificName.\n\nlibrary(galah)\n\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"),\n             atlas = \"Australia\")\n\nhoneyeaters <- galah_call() |> \n  galah_identify(\"Meliphagidae\") |> \n  galah_filter(year == 2012 & stateProvince == \"New South Wales\") |> \n  galah_select(group = \"basic\", taxonRank) |> \n  atlas_occurrences()\n\nhoneyeaters$taxonRank |> unique()\n\nhoneyeaters |> filter(taxonRank == \"species\")\n\n\nlibrary(arrow)\nlibrary(dplyr)\n\n# honeyeaters <- galah_call() |>\n#   galah_identify(\"Meliphagidae\") |>\n#   galah_filter(year == 2012 & stateProvince == \"New South Wales\") |>\n#   galah_select(group = \"basic\", taxonRank) |>\n#   atlas_occurrences()\n\n# write_parquet(honeyeaters, \"data/galah/honeyeater\")\n\nhoneyeaters <- open_dataset(\"data/galah/honeyeater\") |> collect()\n\nhoneyeaters$taxonRank |> unique()\n\n[1] \"species\"    \"genus\"      \"subgenus\"   \"subspecies\" \"family\"    \n\nhoneyeaters |> filter(taxonRank == \"species\")\n\n# A tibble: 43,684 × 9\n   decimal…¹ decim…² eventDate           scien…³ taxon…⁴ recor…⁵ dataR…⁶ occur…⁷\n       <dbl>   <dbl> <dttm>              <chr>   <chr>   <chr>   <chr>   <chr>  \n 1     -37.4    150. 2012-09-26 14:00:00 Meliph… https:… a03712… NSW Bi… PRESENT\n 2     -37.4    150. 2012-09-26 14:00:00 Acanth… https:… d0a6d4… NSW Bi… PRESENT\n 3     -37.4    150. 2012-04-07 14:00:00 Acanth… https:… b86299… eBird … PRESENT\n 4     -37.4    150. 2012-04-07 14:00:00 Nesopt… https:… 3dc377… eBird … PRESENT\n 5     -37.4    150. 2012-04-07 14:00:00 Phylid… https:… a011da… eBird … PRESENT\n 6     -37.4    150. 2012-04-07 14:00:00 Phylid… https:… a6d1a8… eBird … PRESENT\n 7     -37.4    150. 2012-04-07 14:00:00 Nesopt… https:… 8ca89a… eBird … PRESENT\n 8     -37.4    150. 2012-04-07 14:00:00 Phylid… https:… a47dac… eBird … PRESENT\n 9     -37.4    150. 2012-04-07 14:00:00 Melith… https:… 609ff3… eBird … PRESENT\n10     -37.4    150. 2012-04-07 14:00:00 Acanth… https:… 3309e8… eBird … PRESENT\n# … with 43,674 more rows, 1 more variable: taxonRank <chr>, and abbreviated\n#   variable names ¹​decimalLatitude, ²​decimalLongitude, ³​scientificName,\n#   ⁴​taxonConceptID, ⁵​recordID, ⁶​dataResourceName, ⁷​occurrenceStatus\n\n\n\n\nInconsistent higher taxonomy\nA great approach to detect inconsistencies in your taxonomic data is to compute counts for each level of taxonomic rank. These counts act as a check for you to verify that the data is in line with your expectation. This is particularly important when combining data from different sources where their taxonomy might vary. If you have detected inconsistencies as we have done below, you will have to correct accordingly, either by consulting a taxonomic expert or a naming authority and ensure this is reported in your methods.\n\n# Get counts for every species where they have more than 1 class\nplants |> \n  select(phylum:species, scientific_name) |> \n  distinct() |> \n  group_by(species) |> \n  summarise(n_class = length(unique(class))) |> \n  filter(n_class > 1) \n\n# A tibble: 1 × 2\n  species               n_class\n  <chr>                   <int>\n1 Allocasuarina distyla       2\n\n# Get the species that have more than 1 class\ninconsistent_taxa <- plants |> \n  select(phylum:species, scientific_name) |> \n  distinct() |> \n  group_by(species) |> \n  summarise(n_class = length(unique(class))) |> \n  filter(n_class > 1) |> \n  pull(species) \n\n# Filter species that have more than 1 class\nplants |> filter(species %in% inconsistent_taxa) |> \n  select(phylum:species, scientific_name) |> \n  arrange(species) |> \n  distinct() \n\n# A tibble: 2 × 7\n  phylum       class         order   family        genus         species scien…¹\n  <chr>        <chr>         <chr>   <chr>         <chr>         <chr>   <chr>  \n1 Tracheophyta Magnoliopsida Fagales Casuarinaceae Allocasuarina Alloca… Alloca…\n2 Tracheophyta Equisetopsida Fagales Casuarinaceae Allocasuarina Alloca… Alloca…\n# … with abbreviated variable name ¹​scientific_name"
  },
  {
    "objectID": "taxonomy.html#synonyms",
    "href": "taxonomy.html#synonyms",
    "title": "5  Taxonomy",
    "section": "5.2 Synonyms",
    "text": "5.2 Synonyms\nSynonyms is a complex issue when working with open source biodiversity data. Data infrastructures have their own taxonomic systems which may not align with researchers’ view or consistent with your chosen naming authority.\nKeeping in mind that there is no universal solution to synonymy. Best practice is to flag and correct synonyms in a clear and consistent manner. We recommend being explicit with your decisions about which names are retained and keeping a good record of the changes to aid transparency and reproducibility.\n\n{worrms}\nThe {worrms} is the R interface to the World Register of Marine Species and has a ability to cross check synonyms with their database for taxa that has an AphiaID. The function will return synonymous record(s) associated with another different AphiaID.\n\nlibrary(worrms)\n\nmarine_sp <- read_csv(\"data/worms/worms.csv\")\n\nmarine_sp |> \n  slice(7) |>\n  pull(AphiaID) |> \n  wm_synonyms()\n\n# A tibble: 1 × 27\n  AphiaID url       scien…¹ autho…² status unacc…³ taxon…⁴ rank  valid…⁵ valid…⁶\n    <int> <chr>     <chr>   <chr>   <chr>  <lgl>     <int> <chr>   <int> <chr>  \n1  453207 https://… Gonios… Walker… super… NA          220 Spec…  208785 Lupocy…\n# … with 17 more variables: valid_authority <chr>, parentNameUsageID <int>,\n#   kingdom <chr>, phylum <chr>, class <chr>, order <chr>, family <chr>,\n#   genus <chr>, citation <chr>, lsid <chr>, isMarine <int>, isBrackish <int>,\n#   isFreshwater <int>, isTerrestrial <int>, isExtinct <int>, match_type <chr>,\n#   modified <chr>, and abbreviated variable names ¹​scientificname, ²​authority,\n#   ³​unacceptreason, ⁴​taxonRankID, ⁵​valid_AphiaID, ⁶​valid_name\n\n\n\n\n{taxize}\n{taxize} allows users to search over many taxonomic data sources for species names (scientific and common) to resolve synonymy. The gnr_resolve() function matches your supplied list with up to 118 data sources including GBIF, Catalogue of Life, World Register of Marine Species and many more. The function scores how well matched your name is to these sources.\n\nlibrary(taxize)\n\n# Read in a naming authority list\nafd <- read_csv(\"data/naming/afd.csv\")\nunique(afd$VALID_NAME)\n\n [1] \"Prosphaerosyllis battiri\"         \"Clavellopsis parasargi\"          \n [3] \"Platypontonia hyotis\"             \"Palirhoeus eatoni\"               \n [5] \"Diastylis kapalae\"                \"Xenobates chinai\"                \n [7] \"Paratanais gaspodei\"              \"Paradexamine flindersi\"          \n [9] \"Prostebbingia brevicornis\"        \"Cythere lactea\"                  \n[11] \"Cythere melobesioides\"            \"Achelia transfugoides\"           \n[13] \"Halobates (Halobates) acherontis\" \"Quadraceps hopkinsi apophoretus\" \n[15] \"Anabarhynchus striatus\"           \"Australocytheridea vandenboldi\"  \n[17] \"Enigmaplax littoralis\"            \"Hyphalus insularis\"              \n[19] \"Plesiopenaeus armatus\"            \"Uroptychus brucei\"               \n[21] \"Caligus dasyaticus\"               \"Coralliophila tetragona\"         \n[23] \"Triphora alveolata\"               \"Clavus obliquatus\"               \n[25] \"Naria beckii\"                     \"Pharaonella rostrata\"            \n[27] \"Lasaea australis\"                 \"Cadulus rudmani\"                 \n[29] \"Bembicium flavescens\"             \"Mormula philippiana\"             \n[31] \"Turbonilla tiara\"                 \"Chlorodiloma crinita\"            \n[33] \"Mitrella merita\"                  \"Tritonoharpa antiquata\"          \n[35] \"Mauritia depressa dispersa\"       \"Laevidentalium zeidleri\"         \n[37] \"Conus (Harmoniconus) musicus\"     \"Marionia cyanobranchiata\"        \n[39] \"Tucetona flabellata\"              \"Neochromadora bilineata\"         \n[41] \"Desmoscolex membranosus\"          \"Echeneidocoelium indicum\"        \n[43] \"Indodidymozoon suttiei\"           \"Diploproctodaeum yosogi\"         \n[45] \"Pseudopecoelus japonicus\"         \"Pedibothrium lloydae\"            \n[47] \"Amphitethya stipitata\"            \"Pseudosuberites mollis\"          \n[49] \"Psammochela psammodes\"           \n\n# Resolve names\nresolved <- gnr_resolve(unique(afd$VALID_NAME), best_match_only = TRUE) \nresolved |> print(n = 50)\n\n# A tibble: 49 × 5\n   user_supplied_name               submitted_name         match…¹ data_…² score\n * <chr>                            <chr>                  <chr>   <chr>   <dbl>\n 1 Prosphaerosyllis battiri         Prosphaerosyllis batt… Prosph… Nation… 0.988\n 2 Clavellopsis parasargi           Clavellopsis parasargi Clavel… uBio N… 0.988\n 3 Platypontonia hyotis             Platypontonia hyotis   Platyp… Nation… 0.988\n 4 Palirhoeus eatoni                Palirhoeus eatoni      Palirh… Wikisp… 0.988\n 5 Diastylis kapalae                Diastylis kapalae      Diasty… Encycl… 0.988\n 6 Xenobates chinai                 Xenobates chinai       Xenoba… Encycl… 0.988\n 7 Paratanais gaspodei              Paratanais gaspodei    Parata… Wikisp… 0.988\n 8 Paradexamine flindersi           Paradexamine flindersi Parade… Encycl… 0.988\n 9 Prostebbingia brevicornis        Prostebbingia brevico… Proste… Encycl… 0.988\n10 Cythere lactea                   Cythere lactea         Cyther… Encycl… 0.988\n11 Cythere melobesioides            Cythere melobesioides  Cyther… Encycl… 0.988\n12 Achelia transfugoides            Achelia transfugoides  Acheli… Nation… 0.988\n13 Halobates (Halobates) acherontis Halobates (halobates)… Haloba… CU*STAR 0.999\n14 Quadraceps hopkinsi apophoretus  Quadraceps hopkinsi a… Quadra… Catalo… 0.999\n15 Anabarhynchus striatus           Anabarhynchus striatus Anabar… Encycl… 0.988\n16 Australocytheridea vandenboldi   Australocytheridea va… Austra… Encycl… 0.988\n17 Enigmaplax littoralis            Enigmaplax littoralis  Enigma… Encycl… 0.988\n18 Hyphalus insularis               Hyphalus insularis     Hyphal… Wikisp… 0.988\n19 Plesiopenaeus armatus            Plesiopenaeus armatus  Plesio… Wikisp… 0.988\n20 Uroptychus brucei                Uroptychus brucei      Uropty… Wikisp… 0.988\n21 Caligus dasyaticus               Caligus dasyaticus     Caligu… Encycl… 0.988\n22 Coralliophila tetragona          Coralliophila tetrago… Corall… Encycl… 0.988\n23 Triphora alveolata               Triphora alveolata     Tripho… uBio N… 0.988\n24 Clavus obliquatus                Clavus obliquatus      Clavus… Encycl… 0.988\n25 Naria beckii                     Naria beckii           Naria … Nation… 0.988\n26 Pharaonella rostrata             Pharaonella rostrata   Pharao… Arctos  0.988\n27 Lasaea australis                 Lasaea australis       Lasaea… Nation… 0.988\n28 Cadulus rudmani                  Cadulus rudmani        Cadulu… Encycl… 0.988\n29 Bembicium flavescens             Bembicium flavescens   Bembic… Nation… 0.988\n30 Mormula philippiana              Mormula philippiana    Mormul… Encycl… 0.988\n31 Turbonilla tiara                 Turbonilla tiara       Turbon… Encycl… 0.988\n32 Chlorodiloma crinita             Chlorodiloma crinita   Chloro… Nation… 0.988\n33 Mitrella merita                  Mitrella merita        Mitrel… Encycl… 0.988\n34 Tritonoharpa antiquata           Tritonoharpa antiquata Triton… Nation… 0.988\n35 Mauritia depressa dispersa       Mauritia depressa dis… Maurit… Nation… 0.999\n36 Laevidentalium zeidleri          Laevidentalium zeidle… Laevid… Encycl… 0.988\n37 Conus (Harmoniconus) musicus     Conus (harmoniconus) … Conus … Catalo… 0.75 \n38 Marionia cyanobranchiata         Marionia cyanobranchi… Marion… Nation… 0.988\n39 Tucetona flabellata              Tucetona flabellata    Tuceto… Encycl… 0.988\n40 Neochromadora bilineata          Neochromadora bilinea… Neochr… Nation… 0.988\n41 Desmoscolex membranosus          Desmoscolex membranos… Desmos… Encycl… 0.988\n42 Echeneidocoelium indicum         Echeneidocoelium indi… Echene… Integr… 0.988\n43 Indodidymozoon suttiei           Indodidymozoon suttiei Indodi… Nation… 0.988\n44 Diploproctodaeum yosogi          Diploproctodaeum yoso… Diplop… Encycl… 0.988\n45 Pseudopecoelus japonicus         Pseudopecoelus japoni… Pseudo… Integr… 0.988\n46 Pedibothrium lloydae             Pedibothrium lloydae   Pedibo… Encycl… 0.988\n47 Amphitethya stipitata            Amphitethya stipitata  Amphit… Wikisp… 0.988\n48 Pseudosuberites mollis           Pseudosuberites mollis Pseudo… Encycl… 0.988\n49 Psammochela psammodes            Psammochela psammodes  Psammo… Wikisp… 0.988\n# … with abbreviated variable names ¹​matched_name, ²​data_source_title\n\n# Retrieve synonyms\ntsn <- get_tsn(unique(afd$VALID_NAME)[1:5])\n\n══  5 queries  ═══════════════\n✖  Not Found:  Prosphaerosyllis battiri\n✖  Not Found:  Clavellopsis parasargi\n✔  Found:  Platypontonia hyotis\n✖  Not Found:  Palirhoeus eatoni\n✖  Not Found:  Diastylis kapalae\n══  Results  ═════════════════\n\n• Total: 5 \n• Found: 1 \n• Not Found: 4\n\nsynonyms(tsn)\n\n$<NA>\n[1] NA\n\n$<NA>\n[1] NA\n\n$`612530`\n  sub_tsn acc_tsn   syn_author                  syn_name syn_tsn\n1  612530  612530 Suzuki, 1971 Platypontonia pterostreae 1191962\n\n$<NA>\n[1] NA\n\n$<NA>\n[1] NA"
  },
  {
    "objectID": "taxonomy.html#input-from-experts",
    "href": "taxonomy.html#input-from-experts",
    "title": "5  Taxonomy",
    "section": "5.3 Input from experts",
    "text": "5.3 Input from experts\nProgrammatic solutions for resolving synonymy can only go so far. Seeking validation from experts is sensible if your goal is to obtain a high quality species list. Museums or taxonomic societies are extensive sources of knowledge. Below we have provided a list of some of Australian taxonomic society groups.\n\n5.3.1 Australian taxonomic society groups\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists\n\n\n\n5.3.2 Global taxonomy\n\nGBIF uses 100 different sources to assemble - their global taxonomic backbone\nAuthoritative taxonomic information on plants, animals, fungi, and microbes - Integrated Taxonomic Information System, ITIS\nGlobal taxonomic catalogue\nCatalogue of Life\n\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067."
  },
  {
    "objectID": "spatial.html",
    "href": "spatial.html",
    "title": "7  Spatial data",
    "section": "",
    "text": "8 Notes"
  },
  {
    "objectID": "spatial.html#quick-visualisation",
    "href": "spatial.html#quick-visualisation",
    "title": "7  Spatial data",
    "section": "7.1 Quick visualisation",
    "text": "7.1 Quick visualisation\nOne of the most straightforward ways to check for spatial errors is to plot your data onto a map. More obvious spatial errors are much easier to spot visually."
  },
  {
    "objectID": "spatial.html#coordinate-precision",
    "href": "spatial.html#coordinate-precision",
    "title": "7  Spatial data",
    "section": "7.2 Coordinate precision",
    "text": "7.2 Coordinate precision\nData from different sources are collected by different people often using differing tools. For example, some might record coordinates with a tool with high precision like a phone or a GPS, whereas others might record coordinates with low precision by manually recording a place name or writing coordinates after the fact.\nDepending on the level of precision to answer your research question,  you might consider discarding data of lower precision, or removing decimal places for data you know could not be that precise. At the ALA there is a “cooridnateprecision”/ “coordinateUncertainityIn Meters” assertion (see assertion section to download these with the data)\n\nhttps://xkcd.wtf/2170/\nCoordinate precision below 100km represents the grain size of many macroecological analyses (Zizka et al. 2020). Some studies have used a cut-off of spatial resolution >25,000m or precision with less than three decimal places (Godfree et al. 2021). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision. Understanding the level of quality you need is important before removing/keeping large volumes of data.\n\n# How to filter by number of decimal places"
  },
  {
    "objectID": "spatial.html#coordinate-correction",
    "href": "spatial.html#coordinate-correction",
    "title": "7  Spatial data",
    "section": "7.3 Coordinate correction",
    "text": "7.3 Coordinate correction\nSome of these steps may have been completed in a pre-cleaning step, however it’s now time to be more rigorous. As always we’ll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:\nFlipped coordinates: Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected. (Jin and Yang 2020)\n\n#example map of some flipped coordinates (what to look for) \n# https://www.gbif.org/occurrence/3013406216 this has flipped coordinates, which GBIF has corrected\n# https://www.gbif.org/occurrence/search?q=mammalia&continent=SOUTH_AMERICA&has_coordinate=true&has_geospatial_issue=false&issue=PRESUMED_SWAPPED_COORDINATE&advanced=1. ## the issue and flag is called 'presumed swapped coordinate' \n\nNumerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.\n\n#example map, like coordinates off the coast of japan\n\n# https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51360942&qualityProfile=CSDM&radius=50&lat=35.66845370835343&lon=138.9990234375#tab_recordsView\n\n# eucs <- galah_call() %>% \n#  galah_identify(\"Eucalyptus\") %>%\n#  galah_filter( year == 2005, \n#             dataResourceName == \"The University of Melbourne Herbarium (MELU) AVH data\") %>%\n#  atlas_occurrences()\n\nCountry field doesn’t match coordinates: The coordinates could be wrong or just the country listed.\n\n## this doesnt seem to be very common- atleast not in ALA data- because there is no neighboring country\n# https://biocache.ala.org.au/occurrences/a34fca43-9e7c-4b37-8fe4-07cc18369465 Australian coordinates, country listed as Trinidad and Tobago\n# https://www.gbif.org/occurrence/search?advanced=true&continent=SOUTH_AMERICA&geometry=POLYGON((-78.74961%20-8.25249,-76.29838%20-8.25249,-76.29838%20-4.74121,-78.74961%20-4.74121,-78.74961%20-8.25249))&has_coordinate=true&issue=COUNTRY_MISMATCH&locale=en&q=reptilia   # GBIF example- reptiles located in Peru, originally recorded as Ecuador"
  },
  {
    "objectID": "spatial.html#coordinate-cleaning",
    "href": "spatial.html#coordinate-cleaning",
    "title": "7  Spatial data",
    "section": "7.4 Coordinate cleaning",
    "text": "7.4 Coordinate cleaning\nOnce you have fixed everything you can, it’s time to remove records that still have errors. This doesn’t mean removing all outliers, you must have more than “it’s far away from the others” to justify a records removal.\nRemove records with null or missing coordinates: This will be records missing partial or complete information. Missing values can cause errors, many analytical tools do not respond well to missing values. If you can’t find the information elsewhere, it’s best to remove it.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, check first, however likely will need to remove\nRemove records with zero coordinates: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\n\n#zero coordinates acacia \n\n#https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51382879&disableAllQualityFilters=true&qualityProfile=ALA&fq=spatiallyValid%3A%22false%22&radius=25&lat=-0.024032592068740033&lon=-0.06591796875#tab_recordsView \n\n\n\n\nRemove records plotted away from the known area of distribution of the species. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it’s worth checking the literature before discarding records like these. These can also be mis-identified species, if you’re working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area. –> unsure about this bit\nI’m not sure I understand what the above means. But I think in general for less obvious errors, it’s best to suggest that before data analysis (and honestly, before seeing the data at all), people should determine whether there is an upper bound to remove coordinates (like a 95% confidence interval, or within xx km of an accepted expert distribution). Then run whatever model or test with the complete data and with the reduced data. If it makes a difference, probably make an informed decision based on literature of which results to use as the “main” findings.\nHaving written this out, a brief discussion about this rather than any suggestions is probably all that’s in scope for this book\nThe final decisions depend on the species, research question, model parameters etc"
  },
  {
    "objectID": "spatial.html#optional-record-removal",
    "href": "spatial.html#optional-record-removal",
    "title": "7  Spatial data",
    "section": "7.5 Optional record removal",
    "text": "7.5 Optional record removal\nNot sure why the below is optional? I think a lot of national or global analyses would require some kind of data cleaning for this\nRemove records with coordinates assigned to country and province centroids: such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.\nCentroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such.\nIn a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary."
  },
  {
    "objectID": "spatial.html#checklist-of-data-standardization",
    "href": "spatial.html#checklist-of-data-standardization",
    "title": "7  Spatial data",
    "section": "7.6 Checklist of data standardization",
    "text": "7.6 Checklist of data standardization"
  },
  {
    "objectID": "spatial.html#missing-data",
    "href": "spatial.html#missing-data",
    "title": "7  Spatial data",
    "section": "8.1 Missing data",
    "text": "8.1 Missing data\n(I wonder if this is really the place for this or better to just do this in the Spatial chapter)\n\nRemove records with no coordinates"
  },
  {
    "objectID": "spatial.html#quick-visualiations",
    "href": "spatial.html#quick-visualiations",
    "title": "7  Spatial data",
    "section": "8.2 Quick visualiations",
    "text": "8.2 Quick visualiations\nA graphic plot of your data can be very telling and can help you spot potential errors that may be due to formatting.\n\n8.2.1 GGally\nA visual inspection of your entire dataset can save time and solve easy-to-spot errors.\n\n\n8.2.2 Quick map\n(I wonder if this is really the place for this or better to just do this in the Spatial chapter)\nA simple way to visualize your data is to plot it on a map.\n\nFix minor coordinates errors, such as inverted or badly formatted\n\n\n\n\n\n\n8.2.3 \n\n\n8.2.4 CoordinateCleaner\n\n\n\n\n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 20192020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio Baez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus Colli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais Ferreira-Araújo. 2020. “No One-Size-Fits-All Solution to Clean GBIF.” PeerJ 8: e9916."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ALA Data Cleaning",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA)\nAuthors listed in alphabetic order:\n- Fonti Kar\n- Jessica Fenker\n- Margot Schneider\n- Martin Westgate"
  },
  {
    "objectID": "intro.html#what-you-will-learn-book-outline",
    "href": "intro.html#what-you-will-learn-book-outline",
    "title": "1  Introduction",
    "section": "1.1 What you will learn: Book outline",
    "text": "1.1 What you will learn: Book outline\n\n\n# new diagram here\nlibrary(DiagrammeR)\n\nTo begin working with open access data we’ll teach you how to:\n\nNarrow your data scope\nImport data\nTidy and familiarise yourself with metadata\n\nOnce data have been imported and formatted correctly we’ll dive into the major cleaning steps. We will focus on how to deal with taxonomic and spatial issues with biodiversity or species occurrence data.\n\nWe will start with taxonomic issues\n\nTaxonomic issues\n\nnaming authorities\nsynonyms\nDuplicates\n\nSpatial data\n\nOutliers\nDuplicates"
  },
  {
    "objectID": "intro.html#what-you-will-learn",
    "href": "intro.html#what-you-will-learn",
    "title": "1  Introduction",
    "section": "1.1 What you will learn",
    "text": "1.1 What you will learn\n\n\n# new diagram here\nlibrary(DiagrammeR)\n\nTo begin working with open access data we’ll teach you how to:\n\nNarrow your data scope\nImport data\nTidy and familiarise yourself with metadata\n\nOnce data have been imported and formatted correctly we’ll dive into the major cleaning steps. We will focus on how to deal with taxonomic and spatial issues with biodiversity or species occurrence data.\n\nWe will start with taxonomic issues\n\nTaxonomic issues\n\nnaming authorities\nsynonyms\nDuplicates\n\nSpatial data\n\nOutliers\nDuplicates"
  },
  {
    "objectID": "intro.html#what-you-will-learn-outline",
    "href": "intro.html#what-you-will-learn-outline",
    "title": "1  Introduction",
    "section": "1.1 What you will learn (Outline)",
    "text": "1.1 What you will learn (Outline)\n\n\n# new diagram here\nlibrary(DiagrammeR)\n\nTo begin working with open access data we’ll teach you how to:\n\nNarrow your data scope\nImport data\nTidy and familiarise yourself with metadata\n\nOnce data have been imported and formatted correctly we’ll dive into the major cleaning steps. We will focus on how to deal with taxonomic and spatial issues with biodiversity or species occurrence data.\n\nWe will start with taxonomic issues\n\nTaxonomic issues\n\nnaming authorities\nsynonyms\nDuplicates\n\nSpatial data\n\nOutliers\nDuplicates"
  },
  {
    "objectID": "scope.html#taxonomic-scope",
    "href": "scope.html#taxonomic-scope",
    "title": "2  Data scope",
    "section": "2.1 Taxonomic scope",
    "text": "2.1 Taxonomic scope\nWhere the aim of the study is to gather data on a specific taxonomic unit. This could be a threatened species or a broad taxonomic group. The download query is performed using the scientific name, or, name of the taxonomic group.\n\n\n\n\n\n\nCurious what Lampromicra senator looks like?\n\n\n\nLampromicra senator perched on a leaf by Dexmond Wells CC-BY-NC 4.0"
  },
  {
    "objectID": "scope.html#spatial-scope",
    "href": "scope.html#spatial-scope",
    "title": "2  Data scope",
    "section": "2.2 Spatial scope",
    "text": "2.2 Spatial scope\nWhere the aim is to obtain data for targeted taxa in a given location. In this case, the region name or area boundaries can be used to delimit the area of interest. The example below shows all Insecta orders in the state of Tasmania in Australia"
  },
  {
    "objectID": "scope.html#naming-authorities",
    "href": "scope.html#naming-authorities",
    "title": "2  Data scope",
    "section": "2.3 Naming authorities",
    "text": "2.3 Naming authorities\n\n\n\n\n\n2.3.1 Choosing your taxonomic naming authority\nNaming authorities are the different organisations that provide updated or revised lists of species taxonomic splits or taxonomic history following new research. Species names in these lists vary as there may be disagreements as to what distinguishes a new genus, species, subspecies etc. Open source repositories are often provided with conflicting taxonomies that leaving them open to a degree of error.\nChoosing a naming authority is, then, one one way to make decisions surrounding taxonomic categorisations of open source biodiversity data. However, deciding what naming authority to use can be both challenging and time consuming. What you choose will depend on your own taxonomic research and evaluation, but, also, your scope. A spatial scope will have many species and may need multiple naming authorities. On the other hand, choosing a naming authority can impact your scope by shrinking or enlarging datasets.\n\nChecking changes in the taxonomy of your focus species can be helpful when interpreting old data which may have species names you don’t recognize, or, when using data citing a different naming authority to another data set you wish to consolidate it with. This can be achieved by consulting the literature.\nMost taxonomic society groups also release annual updates on taxonomy.\n\nIn Australia, the Australian Plant Name Index (APNI) is the primary naming authority for plants. With the Australian Faunal Directory (AFD) the main taxonomic catalog for animal species. These authorities provide a list of accepted and authoritative names as a template. If you’re unsure what naming authority to use and you’re looking at Australian species, the APNI and the AFD are a good place to start, especially if the data you’re investigating covers a wide range of taxa. If you’re investigating specific taxa it’s worth checking when the taxonomy was last updated in the APNI or AFD, especially if you know there has been recent changes. If you want to investigate closer, we’ve provided some links to society groups, in some cases these can be more up to date that the APNI or AFD."
  },
  {
    "objectID": "scope.html#naming-authorities-1",
    "href": "scope.html#naming-authorities-1",
    "title": "2  Data scope",
    "section": "2.4 Naming authorities",
    "text": "2.4 Naming authorities\nAccurate species delimitation is crucial for adequate conservation management and understanding evolutionary processes (Mace 2004). Species-level lists are also the foundation of conservation decisions, such as is the IUCN Red List (melville21?).\nThe difference in scope might influence if you choose to use a naming authority from a taxonomic society group or multiple broad sources."
  },
  {
    "objectID": "scope.html#naming-authorities-and-taxonomy-in-biodiversity-databases",
    "href": "scope.html#naming-authorities-and-taxonomy-in-biodiversity-databases",
    "title": "2  Data scope",
    "section": "2.5 Naming authorities and taxonomy in biodiversity databases",
    "text": "2.5 Naming authorities and taxonomy in biodiversity databases\nWhen you download data from different databases you might be faced with inconsistencies between the datasets. This is a challenge that data aggregators face when ingesting and aggregating data. This is a large task with lots of heterogeneity and can lead to errors along the way. To help deal with naming inconsistencies, naming authorities are used by online biodiversity databases in order to classify species [REF]. Different databases might use different naming authorities, and you might not agree with their classifications. There may be other issues you are not aware of: For example, the ALA uses multiple naming authorities in a hierarchical format:\n(note image is from a helpfile I wrote- we can re-do it so it’s consistent with the style of this document)\n\nWith all that, open source data has many pros, so how does one deal with taxonomic inconsistencies to get the most accurate data in the end?\nWhile this is in theory how the ALAs backbone is built, issues can occur with aggregation leading to potentially serious problems with the taxonomic structure. In addition data can be parsed incorrectly, and the process isn’t transparent. Meaning that when the taxonomic backbone is updated, the elements that have changed are untraceable. These issues are not specific to ALA taxonomy, but occur in varying forms among data aggregators.\n\n\n\n\nMace, Georgina M. 2004. “The Role of Taxonomy in Species Conservation.” Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences 359 (1444): 711–19."
  },
  {
    "objectID": "preclean.html#metadata",
    "href": "preclean.html#metadata",
    "title": "4  Pre-cleaning",
    "section": "4.1 Metadata",
    "text": "4.1 Metadata\nMetadata describes your data set: it defines each variable and its contents. This might be as simple as describing what units a variable has been measured in, but can also be the climate the occurrence was collected in and whether it is a marked outlier. Starting the process of pre-cleaning by briefing your metadata allows you to understand the kind of data you are working with and any potential biases that may limit what you can do with it. Similarly, these biases may need to be of consideration when creating models or when used in your work more broadly.\nData infrastructures that use Darwin Core terms will have interoperable metadata. This makes it easier to consolidate across data sets. All Darwin Core term definitions can be found here, we suggest using Ctrl/CMD F and searching your variable name on the webpage. Don’t hesitate to Google variable names if you are unsure what they represent.\nIt is also worth checking the metadata for the entire dataset to delineate if there is extra information about the data which may be relevant. You could Google the dataset name, or search the dataset or institution on the ALA. The metadata on the ALA is submitted with the data, of which the ALA as a repository and not an owner cannot change. This means low-quality metadata cannot necessarily be vetoed.\nAn example of some good metadata is FrogID from the Australian Museum. From reading FrogID’s metadata (Rowley and Callaghan 2020), you’ll find:\n\nThe data is acoustic data, the majority of the species recorded are therefore male\nBecause this is citizen science data, it is especially biased towards populated areas\nAudio is recorded via a smartphone app, the authors recommend if you require high coordinate precision to filter data to geographic uncertainty of &lt;3000m\nThe data is presence only data\n\nMetadata can also be useful for understanding the license that the data falls under. This is mostly relevant for using or republishing multimedia associated with the data."
  },
  {
    "objectID": "preclean.html#initial-inspection",
    "href": "preclean.html#initial-inspection",
    "title": "4  Pre-cleaning",
    "section": "4.2 Initial inspection",
    "text": "4.2 Initial inspection\nA great way to get an initial overview of your data is to use the R package skimr. Importantly skimr produces tables of descriptive statistics, such as amount of missing data, for every variable\nThe output is also grouped by data type (numeric, character, date) so you can also check for any inconsistencies. As you are looking through the output, ask yourself whether the data is in line with your expectations. For example:\nIf you requested data for a group of species, are they all represented?\nAre the values for a variable reasonable? Looking at the quartiles will help you get the sense of the distribution of data.\nThese considerations will help you detect potential issues in the data.\n\nlibrary(skimr)\n\nskim(african_ele)\n\nHere is the skimr report for our African elephant dataset we downloaded earlier\n\n\n\nData summary\n\n\nName\nafrican_ele\n\n\nNumber of rows\n12537\n\n\nNumber of columns\n50\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n31\n\n\nlogical\n1\n\n\nnumeric\n15\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndatasetKey\n0\n1.00\n36\n36\n0\n132\n0\n\n\noccurrenceID\n708\n0.94\n1\n81\n0\n11787\n0\n\n\nkingdom\n0\n1.00\n8\n8\n0\n1\n0\n\n\nphylum\n0\n1.00\n8\n8\n0\n1\n0\n\n\nclass\n0\n1.00\n8\n8\n0\n1\n0\n\n\norder\n0\n1.00\n11\n11\n0\n1\n0\n\n\nfamily\n0\n1.00\n12\n12\n0\n1\n0\n\n\ngenus\n0\n1.00\n9\n9\n0\n1\n0\n\n\nspecies\n0\n1.00\n18\n18\n0\n1\n0\n\n\ninfraspecificEpithet\n12410\n0.01\n8\n13\n0\n2\n0\n\n\ntaxonRank\n0\n1.00\n7\n10\n0\n3\n0\n\n\nscientificName\n0\n1.00\n12\n37\n0\n5\n0\n\n\nverbatimScientificName\n3\n1.00\n12\n53\n0\n32\n0\n\n\nverbatimScientificNameAuthorship\n10964\n0.13\n2\n31\n0\n255\n0\n\n\ncountryCode\n1461\n0.88\n2\n2\n0\n44\n0\n\n\nlocality\n9211\n0.27\n3\n254\n0\n686\n0\n\n\nstateProvince\n3573\n0.72\n3\n43\n0\n182\n0\n\n\noccurrenceStatus\n0\n1.00\n6\n7\n0\n2\n0\n\n\npublishingOrgKey\n0\n1.00\n36\n36\n0\n102\n0\n\n\nbasisOfRecord\n0\n1.00\n10\n19\n0\n9\n0\n\n\ninstitutionCode\n1325\n0.89\n2\n76\n0\n103\n0\n\n\ncollectionCode\n1353\n0.89\n1\n41\n0\n164\n0\n\n\ncatalogNumber\n1553\n0.88\n1\n36\n0\n10866\n0\n\n\nrecordNumber\n12420\n0.01\n1\n37\n0\n77\n0\n\n\nidentifiedBy\n4646\n0.63\n2\n81\n0\n1464\n0\n\n\nlicense\n0\n1.00\n7\n12\n0\n3\n0\n\n\nrightsHolder\n4240\n0.66\n2\n56\n0\n1634\n0\n\n\nrecordedBy\n2138\n0.83\n1\n160\n0\n1972\n0\n\n\nestablishmentMeans\n12249\n0.02\n6\n6\n0\n1\n0\n\n\nmediaType\n5021\n0.60\n5\n16\n0\n4\n0\n\n\nissue\n397\n0.97\n15\n191\n0\n130\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntypeStatus\n12537\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ngbifID\n0\n1.00\n2535815516.94\n960444243.67\n49926810.00\n1802649142.00\n2465251941.00\n3.351048e+09\n4.029318e+09\n▁▅▇▅▇\n\n\nindividualCount\n10226\n0.18\n4.81\n14.03\n0.00\n1.00\n1.00\n2.000000e+00\n2.920000e+02\n▇▁▁▁▁\n\n\ndecimalLatitude\n1350\n0.89\n-10.01\n14.67\n-34.58\n-24.06\n-6.25\n4.800000e-01\n5.215000e+01\n▇▅▅▁▁\n\n\ndecimalLongitude\n1350\n0.89\n25.56\n12.35\n-122.33\n22.97\n31.08\n3.480000e+01\n4.053000e+01\n▁▁▁▂▇\n\n\ncoordinateUncertaintyInMeters\n3966\n0.68\n41636.59\n158053.45\n1.00\n29775.00\n30580.00\n3.142200e+04\n5.635548e+06\n▇▁▁▁▁\n\n\ncoordinatePrecision\n12512\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▁▁▇\n\n\nelevation\n12501\n0.00\n154.42\n421.59\n0.00\n0.00\n0.00\n1.375000e+01\n2.134000e+03\n▇▁▁▁▁\n\n\nelevationAccuracy\n12507\n0.00\n0.83\n3.73\n0.00\n0.00\n0.00\n0.000000e+00\n2.000000e+01\n▇▁▁▁▁\n\n\ndepth\n12509\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▇▁▁\n\n\ndepthAccuracy\n12509\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.000000e+00\n0.000000e+00\n▁▁▇▁▁\n\n\nday\n1254\n0.90\n16.27\n8.74\n1.00\n9.00\n17.00\n2.400000e+01\n3.100000e+01\n▇▆▇▇▇\n\n\nmonth\n1191\n0.91\n6.92\n3.33\n1.00\n4.00\n7.00\n1.000000e+01\n1.200000e+01\n▆▅▅▇▇\n\n\nyear\n997\n0.92\n2011.05\n19.34\n1799.00\n2011.00\n2016.00\n2.019000e+03\n2.023000e+03\n▁▁▁▁▇\n\n\ntaxonKey\n0\n1.00\n2517047.48\n747546.46\n2435350.00\n2435350.00\n2435350.00\n2.435350e+06\n1.150335e+07\n▇▁▁▁▁\n\n\nspeciesKey\n0\n1.00\n2435350.00\n0.00\n2435350.00\n2435350.00\n2435350.00\n2.435350e+06\n2.435350e+06\n▁▁▇▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n997\n0.92\n1799-01-01 00:00:00\n2023-02-07 09:17:14\n2016-02-07 12:00:00\n8324\n\n\ndateIdentified\n4150\n0.67\n1783-01-01 00:00:00\n2023-02-07 21:51:36\n2020-04-16 19:35:25\n7242\n\n\nlastInterpreted\n0\n1.00\n2023-01-24 14:57:46\n2023-02-14 01:52:09\n2023-02-13 16:01:27\n10885"
  },
  {
    "objectID": "preclean.html#structural-inconsistencies",
    "href": "preclean.html#structural-inconsistencies",
    "title": "4  Pre-cleaning",
    "section": "4.3 Structural inconsistencies",
    "text": "4.3 Structural inconsistencies\n\n4.3.1 String inconsistencies and typographical errors\nString inconsistencies include misspellings, capitalisation errors, misplaced punctuation or trailing white spaces. We will use the janitor R package to explore whether our data has any of these issues. The function tabyl will compute a counts and percent of total rows for each unique value.\nWe recommend tabyl-ing any character strings that are relevant to your project. For example, here is the stateProvince in alphabetical order.\n\nlibrary(janitor)\n\nafrican_ele %&gt;%\n  pull(stateProvince) %&gt;% \n  tabyl() %&gt;% \n  tibble() %&gt;% \n  print(n = 20)\n\n\n\n# A tibble: 183 × 4\n   .                     n   percent valid_percent\n   &lt;chr&gt;             &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez                1 0.0000798      0.000112\n 2 Al Qahirah            1 0.0000798      0.000112\n 3 Alibori             601 0.0479         0.0670  \n 4 Arusha              231 0.0184         0.0258  \n 5 Arusha Region         1 0.0000798      0.000112\n 6 Atacora             366 0.0292         0.0408  \n 7 Atakora             239 0.0191         0.0267  \n 8 Balaka                7 0.000558       0.000781\n 9 Bassila               1 0.0000798      0.000112\n10 Batha                 1 0.0000798      0.000112\n11 Bauchi                3 0.000239       0.000335\n12 Bengo                 3 0.000239       0.000335\n13 Borgou                7 0.000558       0.000781\n14 Budongo Forest        1 0.0000798      0.000112\n15 Bushenyi             61 0.00487        0.00680 \n16 Cabo Delgado          2 0.000160       0.000223\n17 Cape Prov.            2 0.000160       0.000223\n18 Cape Province         1 0.0000798      0.000112\n19 Central             113 0.00901        0.0126  \n20 Central Equatoria     2 0.000160       0.000223\n# ℹ 163 more rows\n\n\nFrom the tabyl output, we can see there are few different variations of Province, Prov., Prov. As an example, we will correct these with the tidyverse packages stringr, dplyr, tidyr as well as glue. If you are not very familiar with regular expressions, we highly recommend this cheatsheet\n\nlibrary(tidyverse)\nlibrary(glue)\n\n# Create a regular expression to match Prov. and Prov\n# The pattern below means Prov that is NOT followed by any lowercase letters\npattern = regex(\"Prov(?![:lower:])\")\n\n# Use `str_subset` to pull out the cases that match our pattern\n# Confirm that these are the problematic ones\n# Assign these into an object\nstr_subset(african_ele$stateProvince, pattern = pattern)\n\n [1] \"Cape Prov.\"        \"Cape Prov.\"        \"West Nile Prov.\"  \n [4] \"Central Prov\"      \"Central Prov\"      \"Coastal Prov\"     \n [7] \"Northeastern Prov\" \"Central Prov\"      \"Eastern Prov\"     \n[10] \"Coastal Prov\"     \n\ntypos_provinces &lt;- str_subset(african_ele$stateProvince, pattern = pattern)\n\n# Create a new variable `stateProvince_clean` using `mutate`, `if_else`, `str_detect` and `glue`\n# `str_detect` will evaluate values of `stateProvince` that matches our pattern we defined earlier.\n# Matches will return TRUE, non-matches will return FALSE. \n# The `if_else` will then evaluate these logicals (TRUE/FALSE/NA) \n# for TRUE values, the `glue` function will take the first part of the province name enclosed in and join it with word Province.\n# for FALSE values , it will just take the corresponding value in stateProvince\n# Note that we are assigning these changes to a new object (`african_ele_2`)\nafrican_ele_2 &lt;- african_ele %&gt;% \n  mutate(stateProvince_clean = if_else(str_detect(stateProvince, pattern = pattern),\n                                      true = glue('{word(stateProvince, sep = \" P\")} Province'),\n                                      false = stateProvince)\n         ) \n\n# Once we've made the correction we want to check we've done it correctly.\n# ALWAYS CHECK YOUR CORRECTIONS\n# Use the `select` function to isolate columns that `starts_with` \"stateProvince\"\n# Use the `filter` function to subset our the problematic provinces \nafrican_ele_2 %&gt;% \n  select(starts_with(\"stateProvince\")) %&gt;% \n  filter(stateProvince %in% typos_provinces)\n\n# A tibble: 10 × 2\n   stateProvince     stateProvince_clean  \n   &lt;chr&gt;             &lt;glue&gt;               \n 1 Cape Prov.        Cape Province        \n 2 Cape Prov.        Cape Province        \n 3 West Nile Prov.   West Nile Province   \n 4 Central Prov      Central Province     \n 5 Central Prov      Central Province     \n 6 Coastal Prov      Coastal Province     \n 7 Northeastern Prov Northeastern Province\n 8 Central Prov      Central Province     \n 9 Eastern Prov      Eastern Province     \n10 Coastal Prov      Coastal Province     \n\n# Its good practice to check the other values were not affected by your corrections\n# Here we are removing the NA with `drop_na` and subsetting unique rows with `distinct`\nafrican_ele_2 %&gt;% \n  select(starts_with(\"stateProvince\")) %&gt;% \n  drop_na() %&gt;% \n  distinct() \n\n# A tibble: 182 × 2\n   stateProvince    stateProvince_clean\n   &lt;chr&gt;            &lt;glue&gt;             \n 1 Southern         Southern           \n 2 Taita Taveta     Taita Taveta       \n 3 Mara             Mara               \n 4 Arusha           Arusha             \n 5 Simiyu           Simiyu             \n 6 Morogoro         Morogoro           \n 7 Mashonaland West Mashonaland West   \n 8 Mpumalanga       Mpumalanga         \n 9 KwaZulu-Natal    KwaZulu-Natal      \n10 Manicaland       Manicaland         \n# ℹ 172 more rows\n\n# Final check\n# Check with the original code that detected the issue\nafrican_ele_2 %&gt;%\n  pull(stateProvince_clean) %&gt;% \n  tabyl() %&gt;% \n  tibble() %&gt;% \n  print(n = 20)\n\n# A tibble: 181 × 4\n   .                     n   percent valid_percent\n   &lt;glue&gt;            &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez                1 0.0000798      0.000112\n 2 Al Qahirah            1 0.0000798      0.000112\n 3 Alibori             601 0.0479         0.0670  \n 4 Arusha              231 0.0184         0.0258  \n 5 Arusha Region         1 0.0000798      0.000112\n 6 Atacora             366 0.0292         0.0408  \n 7 Atakora             239 0.0191         0.0267  \n 8 Balaka                7 0.000558       0.000781\n 9 Bassila               1 0.0000798      0.000112\n10 Batha                 1 0.0000798      0.000112\n11 Bauchi                3 0.000239       0.000335\n12 Bengo                 3 0.000239       0.000335\n13 Borgou                7 0.000558       0.000781\n14 Budongo Forest        1 0.0000798      0.000112\n15 Bushenyi             61 0.00487        0.00680 \n16 Cabo Delgado          2 0.000160       0.000223\n17 Cape Province         3 0.000239       0.000335\n18 Central             113 0.00901        0.0126  \n19 Central Equatoria     2 0.000160       0.000223\n20 Central Province      4 0.000319       0.000446\n# ℹ 161 more rows\n\n\nThere are some other issues that can be corrected in a similar approach:\n\nNorth West, North West District and North-Western\nÀfrica Central, Central Province and Central\nAtacora and Atakora\nCoastal Province and Coastal\n\nWe recommend consulting reputable sources that can help delineate or consolidate similar values. Googling and looking at Wikipedia’s sources are good places to find resources that you can verify accepted state and province names.\n\n\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset: Expert-Validated Occurrence Records of Australia’s Frogs Collected by Citizen Scientists.” ZooKeys 912: 139.\n\n\nstreamdna. 2020. “Sharing Is Caring: Working with Other People’s Data.” https://methodsblog.com/2020/09/04/sharing-is-caring-working-with-other-peoples-data/."
  }
]