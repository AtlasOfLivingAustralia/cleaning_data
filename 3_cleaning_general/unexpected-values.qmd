---
editor: 
  markdown: 
    wrap: 72
code-annotations: hover
---

# Unexpected values

```{=html}

<!--
*Dax's note*:

I think this section could show some ways to summarise data to find when there is a value that has been mis-entered in the raw data. Andrew's example is a coordinate that is missing a "-". I'm sure there are a few ways to search for problem-values like this.

Eventually this section could end up being dispersed into other sections. For now, I'm happy to try this out as a quick-reference section about finding quirky values in datasets.
-->

```

Most data sets have unexpected values in them somewhere. Usually, these are from a mistake in data entry or a mismatch between merged data sets. A typo, a missing symbol or a missing space can turn a good data point sour. In this chapter we learn how to find and clean some kinds of unexpected values in ecological data sets.

Unexpected values are tricky because we can't fix all of them with one single, unanimous method. In this chapter we show ways to use additional information to understand the nature of an unexpected value. This can help us determine how to clean each data point.

---

### Prerequisites {#sec-prereq}

In this chapter, we will use Red-eye tree frog occurrence data in 2013, and Kingfisher data from 2022. 

```{r prereq}
#| message: false
#| warning: false
#| echo: false
library(galah)
library(dplyr)
library(sf)
library(ggplot2)
galah_config(email = Sys.getenv("ALA_EMAIL"),
             verbose = FALSE)
frogs <- galah_call() |>
  identify("Litoria chloris") |>
  filter(year == 2013) |>
  select(group = "basic",
         countryCode, locality,
         family, genus, species, 
         cl22, eventDate) |>
  atlas_occurrences()

birds <- galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  select(group = "basic", 
         family, genus, species, 
         cl22, eventDate, year) |>
  atlas_occurrences()
```

```{r}
#| eval: false
# packages
library(galah)
library(dplyr)

# data: Frog records in 2013
galah_config(email = "your-email-here") # ALA Registered email

frogs <- galah_call() |>
  identify("Litoria chloris") |>
  filter(year == 2013) |>
  select(group = "basic",
         countryCode, locality,
         family, genus, species, 
         cl22, eventDate) |>
  atlas_occurrences()

birds <- galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  select(group = "basic", 
         family, genus, species, cl22, eventDate) |>
  atlas_occurrences()
```

:::{.aside}

<img class = "rounded" src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/3/1/a/b/987382fa-8168-4249-870b-4e043824ba13/original"></img>

::: {.figure-caption}
[*Litoria chloris* standing on leaves.<br>Photo by Reiner Richter CC-BY](https://biocache.ala.org.au/occurrences/e0d5d604-e148-408e-8dbf-984f42701b4c)
:::

:::{.aside}

<img class = "rounded" src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/2/5/1/d/9525c6da-fd47-41fa-8eff-55c6747ed152/original"></img>

::: {.figure-caption}
[*Todiramphus (Todiramphus) sanctus* perched on a branch. Photo by Kerri-Lee Harris CC-BY-NC 4.0
(Int)](https://biocache.ala.org.au/occurrences/77b8aac0-18af-4ec6-a03c-ff825859a6f3)
:::
:::
:::

## Unexpected name

<!-- Might need to find an example after the names index updates --> 

```{r}
birds |>
  distinct(scientificName) |>
  print(n = 25)
```

```{r}
galah_call() |>
  identify("Thalassarche") |>
  group_by(scientificName) |>
  atlas_counts()
```



## Unexpected location

Spatial outliers aren't always due to a misidentified species. Sometimes, they can be true observations with mistakes in their coordinates. It's good practice to use several sources of spatial information to decide whether an unexpected data point is due to a small but fixable error in coordinates.

Let's try an example. When we plot the coordinates of our red-eyed tree frog occurrences, there is an unexpected observation near Japan. This is quite surprising - red-eyed tree frogs are not native to Japan!

```{r}
# Get a map of aus, transform projection
aus <- ozmaps::ozmap_country |>
  st_transform(crs = st_crs(4326))

# Map
ggplot() +
  geom_sf(data = aus,
          fill = NA,
          colour = "grey60") +
  geom_point(data = frogs,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             colour = "#557755") +
  theme_void()

```

Let's check the `countryCode` column to see whether this might be an Australian record with a mistake in the coordinates. 

Using `distinct()`, we can see that there are 2 country codes...

```{r}
frogs |>
  distinct(countryCode)
```

...and filtering to Japan (`"JP"`) identifies our stray data point.

```{r}
frogs |>
  filter(countryCode == "JP")
```

So far this observation does seem to be in Japan. To be extra certain, we can also use the column `locality`, which provides additional information from the data collector about the record's location.

```{r}
frogs |>
  filter(countryCode == "JP") |>
  select(countryCode, locality, scientificName, decimalLatitude, decimalLongitude)
```

The `locality` column reveals the observation was made in "mt bucca". This is surprising to see because Mt Bucca is a mountain in Queensland! 

When we look at our Japan data point's `decimalLongitude` and `decimalLatitude` alongside other values in our data, it becomes clear that the Japan data point seems to sit within the same numerical range as other points, but is positive rather than negative.

```{r}
frogs |>
  arrange(desc(countryCode)) |>
  select(countryCode, decimalLongitude, decimalLatitude) |>
  print(n = 5)
```

All of this evidence suggests that our Japan "outlier" might instead be an occurrence point with a mis-entered latitude coordinate. 

Let's fix this by adding a negative symbol (`-`) to the record's latitude coordinate number. We'll use `case_when()` from dplyr, which works the same as an `ifelse` statement (but can handle many of them) to specify that if the `countryCode == "JP"`, then we'll "stick" a negative in front of `decimalLatitude` (using `glue()` from [the glue package](https://glue.tidyverse.org/)).

```{r}
library(glue)

frogs_fixed <- frogs |>
  mutate(
    decimalLatitude = case_when(
      countryCode == "JP" ~ glue("-{decimalLatitude}"),
      .default = as.character(decimalLatitude) # <1>
    ) |> 
      as.integer() # <2>
  )

frogs_fixed |>
  filter(countryCode == "JP") |> 
  select(decimalLatitude, decimalLongitude, countryCode)
```
1. This is like a catch-all `else` statement. To make it work, we have to convert our `decimalLatitude` to a `character` because the result of using `glue` or `paste` in R is a `character` class (we are pasting `characters` together to make something new, so to be safe R assumes the class isn't `numeric` anymore).
2. The result of our `case_when()` is a column of class `character`. So, we have to convert it back to a number so we can use it as a coordinate again, rather than as text.

Mapping our data again shows our outlier is an outlier no longer!

```{r}
#| code-fold: true
ggplot() +
  geom_sf(data = aus,
          fill = NA,
          colour = "grey60") +
  geom_point(data = frogs_fixed,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             colour = "#557755") +
  theme_void()

```


## Unexpected time

Sometimes, although the correct filters were used to download a data set, some unexpected values can sneak through and require cleaning. These unexpected values can happen when processes used to clean or categorise data by a data provider or data infrastructure miss a few values. Missed values might have been mis-entered originally, fixed incorrectly or undetected.

For example, recall that we filtered our data download query to `year == 2022` using galah ([@sec-prereq]). If we look at the `year` field returned by galah, it looks like our data is only from 2022.

```{r}
birds |>
  distinct(year)
```

However, we can use the `eventDate` field to double check this is true. Let's extract year from `eventDate` by using the `year()` function from the lubridate package.

```{r}
#| warning: false
#| message: false
library(lubridate)

birds_dates <- birds |>
  mutate(date = date(eventDate), # <1>
         year_extracted = year(eventDate))

birds_dates |>
  select(date, year_extracted)
```
1. We first convert values in the `eventDate` column to a `date` class. The lubridate package is very good at reading dates in *many* different formats and standardising them into a "yyyy-mm-dd" format. After this conversion, dates can be handled correctly (and more easily) by the lubridate package.

Despite specifying the year in our galah query, when we summarise our new `year_extracted` column, we find that there are other unexpected records from 2021, too!

```{r}
birds_dates |>
  group_by(year_extracted) |>
  count()
```

Viewing these records' `eventDate` shows that each of them occurred on New Year's Eve in 2021---on the cusp of 2022. For some unknown reason they still slipped through into our galah data query.

```{r}
birds_dates |>
  filter(year_extracted == 2021) |>
  select(eventDate, date, year, year_extracted)
```

As we are only interested in records from 2022, we can filter these unexpected 2021 records out of our data set.

```{r}
birds_filtered <- birds_dates |>
  filter(year_extracted == 2022)
```


## Summary

In this chapter, we learned a few basic checks for cleaning datasets, including
methods to detect inconsistencies in date formats, coordinate systems, and
units.