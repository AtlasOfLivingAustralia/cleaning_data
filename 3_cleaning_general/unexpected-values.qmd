---
editor: 
  markdown: 
    wrap: 72
code-annotations: hover
---

# Unexpected values

```{=html}
#| echo: false
<!--
*Dax's note*:

I think this section could show some ways to summarise data to find when there is a value that has been mis-entered in the raw data. Andrew's example is a coordinate that is missing a "-". I'm sure there are a few ways to search for problem-values like this.

Eventually this section could end up being dispersed into other sections. For now, I'm happy to try this out as a quick-reference section about finding quirky values in datasets.
-->
```

Most data sets have unexpected values in them somewhere. Usually, these are from a mistake in data entry or a mismatch between merged data sets. A typo, a missing symbol or a missing space can turn a good data point sour. In this chapter we learn how to find and clean some kinds of unexpected values in ecological data sets.

Unexpected values are tricky because we fix all of them with the same method. In this chapter we show ways to use additional information to understand the nature of an unexpected value. This can help us determine how to clean each data point.

---

### Prerequisites

In this chapter, we will use Red-eye tree frog occurrence data in 2013 from the ALA. 

```{r prereq}
#| message: false
#| warning: false
#| echo: false
library(galah)
library(dplyr)
library(sf)
library(ggplot2)
galah_config(email = Sys.getenv("ALA_EMAIL"),
             verbose = FALSE)
frogs <- galah_call() |>
  identify("Litoria chloris") |>
  filter(year == 2013) |>
  select(group = "basic",
         countryCode, locality,
         family, genus, species, 
         cl22, eventDate) |>
  atlas_occurrences()
```

```{r}
#| eval: false
# packages
library(galah)
library(dplyr)

# data: Frog records in 2013
galah_config(email = "your-email-here") # ALA Registered email

frogs <- galah_call() |>
  identify("Litoria chloris") |>
  filter(year == 2013) |>
  select(group = "basic",
         countryCode, locality,
         family, genus, species, 
         cl22, eventDate) |>
  atlas_occurrences()
```

:::{.aside}

<img class = "rounded" src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/3/1/a/b/987382fa-8168-4249-870b-4e043824ba13/original"></img>

::: {.figure-caption}
[*Litoria chloris* standing on leaves.<br>Photo by Reiner Richter CC-BY](https://biocache.ala.org.au/occurrences/e0d5d604-e148-408e-8dbf-984f42701b4c)
:::
:::

## Unexpected name

## Unexpected location

Spatial outliers aren't always due to a misidentified species. Sometimes, they can be true observations with mistakes in their coordinates. It's good practice to use several sources of spatial information to decide whether an unexpected data point is due to a small but fixable error in coordinates.

Let's try an example. When we plot the coordinates of our red-eyed tree frog occurrences, there is an unexpected observation near Japan. This is quite surprising - red-eyed tree frogs are not native to Japan!

```{r}
# Get a map of aus, transform projection
aus <- ozmaps::ozmap_country |>
  st_transform(crs = st_crs(4326))

# Map
ggplot() +
  geom_sf(data = aus,
          fill = NA,
          colour = "grey60") +
  geom_point(data = frogs,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             colour = "#557755") +
  theme_void()

```

Let's check the `countryCode` column to see whether this might be an Australian record with a mistake in the coordinates. 

Using `distinct()`, we can see that there are 2 country codes...

```{r}
frogs |>
  distinct(countryCode)
```

...and filtering to Japan (`"JP"`) identifies our stray data point.

```{r}
frogs |>
  filter(countryCode == "JP")
```

So far this observation does seem to be in Japan. To be extra certain, we can also use the column `locality`, which provides additional information from the data collector about the record's location.

```{r}
frogs |>
  filter(countryCode == "JP") |>
  select(countryCode, locality, scientificName, decimalLatitude, decimalLongitude)
```

The `locality` column reveals the observation was made in "mt bucca". This is surprising to see because Mt Bucca is a mountain in Queensland! 

When we look at our Japan data point's `decimalLongitude` and `decimalLatitude` alongside other values in our data, it becomes clear that the Japan data point seems to sit within the same numerical range as other points, but is positive rather than negative.

```{r}
frogs |>
  arrange(desc(countryCode)) |>
  select(countryCode, decimalLongitude, decimalLatitude) |>
  print(n = 5)
```

All of this evidence suggests that our Japan "outlier" might instead be an occurrence point with a mis-entered latitude coordinate. 

Let's fix this by adding a negative symbol (`-`) to the record's latitude coordinate number. We'll use `case_when()` from dplyr, which works the same as an `ifelse` statement (but can handle many of them) to specify that if the `countryCode == "JP"`, then we'll "stick" a negative in front of `decimalLatitude` (using `glue()` from [the glue package](https://glue.tidyverse.org/)).

```{r}
library(glue)

frogs_fixed <- frogs |>
  mutate(
    decimalLatitude = case_when(
      countryCode == "JP" ~ glue("-{decimalLatitude}"),
      .default = as.character(decimalLatitude) # <1>
    ) |> 
      as.integer() # <2>
  )

frogs_fixed |>
  filter(countryCode == "JP") |> 
  select(decimalLatitude, decimalLongitude, countryCode)
```
1. This is like a catch-all `else` statement. To make it work, we have to convert our `decimalLatitude` to a `character` because the result of using `glue` or `paste` in R is a `character` class (we are pasting `characters` together to make something new, so to be safe R assumes the class isn't `numeric` anymore).
2. The result of our `case_when()` is a column of class `character`. So, we have to convert it back to a number so we can use it as a coordinate again, rather than as text.

Mapping our data again shows our outlier is an outlier no longer!

```{r}
#| code-fold: true
ggplot() +
  geom_sf(data = aus,
          fill = NA,
          colour = "grey60") +
  geom_point(data = frogs_fixed,
             aes(x = decimalLongitude,
                 y = decimalLatitude),
             colour = "#557755") +
  theme_void()

```


* Checking for unexpected values: this is a generic method but the resolution
logic depends on the issue (taxonomic, categories, strings, etc.)
  * Context: a merged dataset pertaining to a single species (using data frame
  from cleaning_integration.qmd). Species is L. chloris
    * Assumption: species column contains only one species
      * Method: `unique(merged_data$species)`
      * Result: two species names
      * Resolution: conform to one species name (assign)
    * Assumption: country code contains only one country
      * Method: `unique(merged_data$country_code)`
      * Result: AU, NA, JP
      * Resolution: Investigate NA and assign, investigate JP since chloris is
      an Australian species

## Unexpected time

## Summary

In this chapter, we learned a few basic checks for cleaning datasets, including
methods to detect inconsistencies in date formats, coordinate systems, and
units.