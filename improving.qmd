# Data Enrichment

Now that the data is cleaned and standardized, extra work can be done to guarantee the data quality. These steps will depend on the kind of study being conducted. 

- Remove duplicates: Data duplication is common when combining data from multiple sources. In most part of the cases, you will want to remove duplicate data, as it just increase you data size without bringing in any relevant information. It can also make analysis faster and more efficient. 

- Bias correction: Account for sampling bias.

- Scrutinise outliers: Outliers can be true outliers or data errors. True outliers are not necessarily to be removed. This could represent misidentified specimens, etc.

- Format data: Subset, specify data source as ALA, indicate sensitive species, assign habitat column, rearrange and name columns.

- Study region: Important if you need to crop data to the region or to work out the current range, background region, and projection region.

- Assign quality levels to data: If you need help with specific data, assigning quality level metrics for taxonomy and geographical dimensions can be good.

- Manually identify and remove false positives: False positives that may have been overlooked by automated error removal, based on the knowledge that they are in the records.

- Remove records with an individual count of less than 1 or more than 99: Records may be unsuitable if the number of recorded individuals is 0 or the count is too high (data entry or data-basing problems), indicate records from dna barcoding and in some cases indicate records of absence.

- Consider species with fewer records: Depending of the the type of analysis to be conducted, as in the case of Species Distribution Modelling, the number of distribution points available can influence the quality of the results.

- Reach out and ask questions:	When preparing occurrence data for modeling it can be helpful to speak to experts in the field.
