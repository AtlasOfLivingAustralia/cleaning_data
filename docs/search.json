[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ALA Data Cleaning",
    "section": "",
    "text": "Welcome\nWelcome to the Atlas of Living Australia Data Cleaning book. This book is designed to be a practical guide on cleaning georeferenced biodiverdsity data using R. We focus on specific processes and challenges you’ll face with biodiversity data. As such, this book isn’t a guide to data cleaning in general, but a targeted resource for anyone working with or interested in georeferenced biodiversity data.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "ALA Data Cleaning",
    "section": "How to contribute",
    "text": "How to contribute\nContributions to this document are welcome. For questions or feedback, please open an issue on our GitHub repository. If you’d like to suggest content changes, feel free to submit a pull request. We recommend opening an issue first to discuss potential changes. Our contribution guidelines can be found here.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "ALA Data Cleaning",
    "section": "How to cite",
    "text": "How to cite\nYou can cite this book as: Kar, F., Fenker, J., Schneider, M., Westgate, M. [Andrew-somewhere] (2023). Cleaning biodiversity data in R. Retrieved Month dd, yyyy, from https://atlasoflivingaustralia.github.io/cleaning_data/\n\n\nThis book is available free to read, and is licenced under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ALA Data Cleaning",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis book was inspired by an Australian Research Data Commons project where our team worked closely with research partners to streamline their data cleaning workflows. This book is a collaborative effort from the Science and Decision Support team at the Atlas of Living Australia (ALA)\nAuthors listed in alphabetic order: - Fonti Kar - Dax Kellie - Jessica Fenker - Margot Schneider - Andrew Schwenke - Olivia Torresan - Martin Westgate",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "intro.html#who-is-this-book-for",
    "href": "intro.html#who-is-this-book-for",
    "title": "Introduction",
    "section": "Who is this book for?",
    "text": "Who is this book for?\nIf you are new to working with biodiversity data in R, or hoping to add some tips and code examples to your toolbox, then this book is for you. By learning how to download and apply common data cleaning steps, you will also develop a better understanding of biodiversity data itself, and the common issues to be aware of.\nWe use R as it is commonly used across ecological projects, and has a rich ecosystem of packages for data cleaning and visualisation. A basic familiarity with the language is recommended.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#what-this-book-covers",
    "href": "intro.html#what-this-book-covers",
    "title": "Introduction",
    "section": "What this book covers",
    "text": "What this book covers\nIn this book, we provide an overview of a typical data cleaning workflow for cleaning open-access georeferenced biodiversity data - from acquisition, identifying potential errors, to correction. These processes are broken down into three sections. The chapters whithin each section include practical guidelines, example R code, and additional resources that may aid with each data cleaning step. An overview of the three sections and what they cover:\n\nData scope\n\nWhat is data scope?\nHow to determine the termporal, taxonomic, and spatial scope of available data for your study\n\nAccessing data\n\nWhere to get data from?\nHow to download data using R\nHow to refine download queries\nFirst steps in data inspection\n\nData cleaning\n\nString manipulation\nTaxonomic standardisation (synonyms, naming authorities, duplicates)\nSpatial data cleaning\nOutlier detection\n\n\n\n\n\n\n\n\nThere is no one size fits all workflow.\nData cleaning steps are frequently completed in entirely different orders. As such, this book should be regarded as just one example of a data cleaning workflow, rather than a strict framework. It does not need to be used in a linear fashion, although some steps may logically preceed others, or may need to be revisited after completing another. Nevertheless, if you are just stating out in this domain, working through the book sequentially is a great way to get started.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#what-we-dont-cover",
    "href": "intro.html#what-we-dont-cover",
    "title": "Introduction",
    "section": "What we don’t cover",
    "text": "What we don’t cover\nThe areas of research and uses of biodiversity data are many and varied. Here we have focused on just one facet - downloading and cleaning georeferenced occurrence / biodiversity data. As such, this book will not cover:\n\nHypothesis testing or experimental design\nHow to clean environmental data that is not occurrence / biodiversity data (e.g. trait data)\nHow to perform analyses (e.g. species distribution modelling)",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#requirements",
    "href": "intro.html#requirements",
    "title": "Introduction",
    "section": "Requirements",
    "text": "Requirements\n\nUser accounts\nWe will be working with point-based species occurrence data retrieved from online infrastructures such as Global Biodiversity Information Facility (GBIF) and the Atlas of Living Australia (ALA). To retrieve data from these services, you will need to create a user account, if you do not already have one.\n\nAtlas of Living Australia account creation\nGlobal Biodiversity Information Facility account creation\n\n\n\nR\nTo get the most out of this book, a basic knowledge of using R and RStudio is recommended. If you are new to R or need a refresher, there are many high quality and freely available resources available online. Data Analysis and Visualisation in R for Ecologists, and R for Data Science are both excellent starting points.\nDownload R from CRAN, selecting the version that matches your operating system, and install it on your device.\n\n\nRStudio\nRStudio is an integrated development environment (IDE) for R programming. R studio provides a range of tools to make working with R easier, and you can download and install RStudio for your operating system here.\n\n\nPackages\nWe use a range of R packages throughout the book, primarily for data cleaning and visualisations. These packages will be noted at the beginning of a code block, typically at the start of a chapter. To access biodiversity data we will be working with the galah package. If you have collected your own occurrence data, you should still find this book useful.\n\nTODO link to the packages page",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "intro.html#conventions",
    "href": "intro.html#conventions",
    "title": "Introduction",
    "section": "Conventions",
    "text": "Conventions\nDemonstrations and instructions throughout this book are accompanied by code blocks. These blocks show how a particular task was executed in R:\n# This is a code block with a comment\nlibrary(package)\nplot(data)\n\n\n\n\n\n\nYou can copy code by clicking the button in the top right corner of a code block.\n\n\n\nWhen performing a sequence of related actions, we use the native R pipe operator |&gt;. This allows multiple operations to be performed, without needing to save the intermediate results to a variable. You can learn more about the pipe in the R for Data Science book. Some code blocks may also be annotated, to help explain the sequence of steps. See the annotated example below:\n\n# This is a code block with annotation\n1mtcars |&gt;\n2   dplyr::group_by(cyl) |&gt;\n3   dplyr::summarise(mpg = mean(mpg))\n\n\n1\n\nUsing the pipe operator to pass the mtcars data frame to the group_by() function\n\n2\n\nGrouping the data frame by the cyl variable\n\n3\n\nPrint a summary of the filtered data frame using the summarise() function\n\n\n\n\n\n\n\n\ncyl\nmpg\n\n\n\n\n4\n26.66364\n\n\n6\n19.74286\n\n\n8\n15.10000\n\n\n\n\n\n\n\n\n\n\nRodrigues, A. V., Nakamura, G., Staggemeier, V. G., & Duarte, L. (2022). Species misidentification affects biodiversity metrics: Dealing with this issue using the new R package naturaList. Ecological Informatics, 69, 101625. https://doi.org/10.1016/j.ecoinf.2022.101625",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "scope.html#demonstration",
    "href": "scope.html#demonstration",
    "title": "Data scope",
    "section": "Demonstration",
    "text": "Demonstration\nAs an example, let’s imagine we were interested in understanding more about the distribution of several Jewel beetles in the genus Lampromicra. Let’s see some ways we might investigate what data are available about them in Australia.\n\n\n\n\n\n\n \n\n\n\n\n\n \n\n\n\n\nCurious what a Jewel beetle looks like? Here is a Lampromicra senator perched on a leaf by Matthew Connors CC-BY-NC 4.0 (Int)",
    "crumbs": [
      "Data scope"
    ]
  },
  {
    "objectID": "scope_temporal.html",
    "href": "scope_temporal.html",
    "title": "1  Temporal scope",
    "section": "",
    "text": "A good first step to understanding what data are available is to check the number of observations across different time periods. To do this, we are using the galah package to query the Atlas of Living Australia (ALA), which is the largest biodiversity data aggregator in Australia.\nFirst we load the galah package, and provide our registered ALA email address to the galah_config() function.\n\n\nLoad required packages\nlibrary(galah)\nlibrary(tidyverse) # group of packages\n\n\nWarning: package 'stringr' was built under R version 4.2.3\n\n\n\n# Provide your registered ALA email address\ngalah_config(email = \"youremail@here.com\")\n\nThe atlas_counts() function returns a count of records. By itself, it returns a count of all records in the Atlas of Living Australia, but we can narrow this query using galah helper functions. In this case, we narrow the search to only include insects.\n\n# Query all records\natlas_counts()\n\n# Query only insects\n1galah_call() |&gt;\n2  galah_identify(\"insecta\") |&gt;\n3  atlas_counts()\n\n\n1\n\nStart building a data query\n\n2\n\nNarrow the query with taxonomic identifiers\n\n3\n\nReturn the count of records\n\n\n\n\n# A tibble: 1 × 1\n      count\n      &lt;int&gt;\n1 132402767\n# A tibble: 1 × 1\n    count\n    &lt;int&gt;\n1 5903072\n\n\nNow let’s see how many insects have been observed each year over the last 10 years. We’ll order this by descending year using dplyr::arrange() and dplyr::desc().\n\ngalah_call() |&gt;\n  galah_identify(\"insecta\") |&gt;\n  galah_filter(year &gt;= 2013) |&gt;\n  galah_group_by(year) |&gt;\n  atlas_counts() |&gt;\n  dplyr::arrange(dplyr::desc(year))\n\n# A tibble: 11 × 2\n   year   count\n   &lt;chr&gt;  &lt;int&gt;\n 1 2023  467273\n 2 2022  449885\n 3 2021  357182\n 4 2020  265912\n 5 2019  186230\n 6 2018  229175\n 7 2017  195283\n 8 2016  170392\n 9 2015  125436\n10 2014  127019\n11 2013  116672\n\n\nNow that we have an idea of the total amount of data in the Atlas of Living Australia, let’s try checking how many observations exist of the genus Lampromicra. We’ll first make sure the scientific name Lampromicra returns the taxon information we expect with search_taxa().\njbf search_taxa(\"Lampromicra\")\nThis looks correct! Next let’s see how many total observations there are of Lampromicra and how many observations there were in each of the last 10 years.\n\ngalah_call() |&gt; \n  galah_identify(\"Lampromicra\") |&gt; \n  atlas_counts()\n\n# A tibble: 1 × 1\n  count\n  &lt;int&gt;\n1  1408\n\ngalah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  galah_filter(year &gt;= 2013) |&gt;\n  galah_group_by(year) |&gt;\n  atlas_counts() |&gt;\n  dplyr::arrange(dplyr::desc(year))\n\n# A tibble: 11 × 2\n   year  count\n   &lt;chr&gt; &lt;int&gt;\n 1 2023    174\n 2 2022    230\n 3 2021    221\n 4 2020    152\n 5 2019     75\n 6 2018     53\n 7 2017     44\n 8 2016     42\n 9 2015     14\n10 2014     14\n11 2013      6\n\n\nThere are a growing number of observations from 2012 to 2023 of Jewel beetles in the Atlas of Living Australia, with fewer than 100 observations each year prior to 2020.\nWith this information, we might choose to combine data from all years in our analysis (rather than separating them by year). Alternatively, we might decide to only include data since 2020, which might be sufficient to represent where Lampromicra are found and be more relevant because they are more recent observations. These are decisions that might affect the granularity of the research question we ask.",
    "crumbs": [
      "Data scope",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Temporal scope</span>"
    ]
  },
  {
    "objectID": "scope_taxonomic.html",
    "href": "scope_taxonomic.html",
    "title": "2  Taxonomic scope",
    "section": "",
    "text": "Taxonomy refers to ways by which we classify an organism and its relationship to all other organisms. Typically, your research question will be concerned with one or more taxonomic groups, ranging from a single species to an entire kingdom (e.g. Plantae).\nFollowing on with our example, we are interested in understanding more about Jewel beetles in the genus Lampromicra.\nWe first might want to know what species there are in the genus Lampromicra and view some additional taxonomic information about them. We can do this by adding atlas_species() to the end of a query in {galah}.\n\n\n\n\n\n\nNote\n\n\n\nYou will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information.\n\n\n\nlibrary(galah)\n\n\nAttaching package: 'galah'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\n\n# Provide your registered ALA email address\ngalah_config(email = \"youremail@here.com\")\n\n\ngalah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  atlas_species() |&gt;\n  select(family:species_guid)\n\n# A tibble: 3 × 5\n  family        genus       species             author            species_guid  \n  &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;               &lt;chr&gt;             &lt;chr&gt;         \n1 Scutelleridae Lampromicra Lampromicra senator (Fabricius, 1803) https://biodi…\n2 Scutelleridae Lampromicra Lampromicra aerea   (Distant, 1892)   https://biodi…\n3 Scutelleridae Lampromicra Lampromicra regia   Bergroth, 1895    https://biodi…\n\n\nOur query returned three species in the genus Lampromicra. The URLs returned under species_guid can be entered in a web browser to see more information.\nWe might also wish to check the total number of observations of each of these species. We can check this by grouping our counts by species using galah_group_by(species)\n\ngalah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  galah_group_by(species) |&gt;\n  atlas_counts()\n\n# A tibble: 3 × 2\n  species             count\n  &lt;chr&gt;               &lt;int&gt;\n1 Lampromicra senator  1140\n2 Lampromicra aerea     185\n3 Lampromicra regia      14\n\n\nOur result shows that the majority of observations of Lampromicra are of the species Lampromicra senator.\nGiven this information, we might consider whether our question needs to be made at the species level, or whether we might increase the taxonomic scope to the genus or family level to use more data. Ultimately, the taxonomic scope of your data will depend on how important it is to your question to compare specific taxonomic groups.",
    "crumbs": [
      "Data scope",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taxonomic scope</span>"
    ]
  },
  {
    "objectID": "scope_spatial.html",
    "href": "scope_spatial.html",
    "title": "3  Spatial scope",
    "section": "",
    "text": "It’s useful to investigate the spatial range of available data for your taxonomic group(s) of interest. How specific your question can be may change depending on whether the majority of data is in only a few locations or evenly spread over the entire distribution of a species or taxonomic group.\nFor our example question about Lampromicra, we may wish to map where observations in Australia have been made. We can do this by using the {ozmaps} package to download a nice map of Australia, plot it with sf::geom_sf(), and add our observation points on top with geom_point(). We can separate the colours of our points by setting colour = scientificName within the aes() of geom_point().\n\n\n\n\n\n\nNote\n\n\n\nYou will need to add an email address registered with the Atlas of Living Australia in galah_config() to download species information.\n\n\n\n\nLoad required packages\nlibrary(galah)\nlibrary(tidyr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(paletteer) # colour palettes\nlibrary(ozmaps)\nlibrary(viridis)\nlibrary(gt)\nlibrary(here)\nlibrary(rmapshaper)\n\n\n\n# Provide your registered ALA email address\ngalah_config(email = \"youremail@here.com\")\n\n\nbeetles &lt;- galah_call() |&gt;\n  galah_identify(\"lampromicra\") |&gt;\n  atlas_occurrences() |&gt;\n  tidyr::drop_na() # remove any NA values\n\n# Get map of australia, and transform to WGS84\naus &lt;- st_transform(ozmaps::ozmap_country, 4326)\n\n# Plot the observations on our map of Australia\nggplot() +\n  geom_sf(data = aus, colour = \"grey60\", fill = \"white\", alpha = 0.2) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude, y = decimalLatitude, colour =\n        scientificName\n    ),\n    size = 1.8, alpha = 0.6\n  ) +\n  scale_color_paletteer_d(\"feathers::eastern_rosella\") +\n  coord_sf(xlim = c(110, 155), ylim = c(-45, -10)) +\n  theme_void()\n\n\n\n\n\n\n\n\nPlotting our points shows us that observations are spread along the northern and eastern coasts of Australia. We can also see that some observations are only identified to the genus level (e.g. Lampromicra), rather than to a specific species (e.g. Lampromicra aerea).\nThere are several places on the east coast of Australia where there are clumps of overlapping points. It’s difficult to tell how many observations there really are in those areas. To investigate, we can recreate this into a point density plot using the {ggpointdensity package}.\n\n\nCode\nlibrary(ggpointdensity)\n\nggplot() +\n  geom_sf(data = aus, colour = \"grey60\", fill = \"white\", alpha = 0.2) +\n  geom_pointdensity(\n    data = beetles,\n    mapping = aes(x = decimalLongitude, y = decimalLatitude)\n  ) +\n  scale_color_paletteer_c(\"viridis::plasma\") +\n  coord_sf(xlim = c(110, 155), ylim = c(-45, -10)) +\n  theme_void()\n\n\n\n\n\n\n\n\n\nAdding the density of overlapping points to our map allows us to see that there is one area with many more observations—more than 400 observations are found in the light yellow area!\nUsing this information, we might decide to make our research question more specific to the region where there are the most records of Lampromicra.\nLet’s have a look at these records in the context of their IBRA bioregions (distinct areas defined on a common climate, geology, landform, native vegetation and species information).\nTo find out what region(s) the genus Lampromicra is most common, you can group_by the IBRA region field code in {galah} (use search_fields to see others).\n\nibra_counts &lt;- galah_call() |&gt;\n  galah_identify(\"Lampromicra\") |&gt;\n  galah_group_by(\"cl1048\") |&gt; # IBRA regions\n  atlas_counts()\ngt(head(ibra_counts))\n\n\n\n\n\n\n\ncl1048\ncount\n\n\n\n\nSouth Eastern Queensland\n523\n\n\nSydney Basin\n198\n\n\nVictoria Bonaparte\n82\n\n\nBrigalow Belt North\n77\n\n\nWet Tropics\n72\n\n\nEinasleigh Uplands\n65\n\n\n\n\n\n\n\n\nSouth Eastern Queensland (red), Sydney Basin (green)\n\n\n\n\n\n\n\n\n\n\nWe can see that South East Queensland has the most records followed by Sydney Basin. At this point, it would be useful to know if this is because of a sampling bias towards these large metropolitan areas, or if Lampromicra is actually more common in these areas. We will not cover the process here, but see this article on quantifying geographic sampling bias with {sampbias} to learn more.\n\nCode\nshapefile &lt;- st_read(\n  here(\n    \"data\",\n    \"shapefiles\",\n    \"IBRA7_regions\",\n    \"ibra7_regions.shp\"\n  ),\n  quiet = TRUE\n) |&gt;\n  ms_simplify(keep = 0.1)\n\n\n# South Eastern Queensland\nggplot() +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 == \"South Eastern Queensland\"),\n    aes(fill = \"red\"),\n    colour = \"grey60\",\n    alpha = 0.7\n  ) +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 != \"South Eastern Queensland\"),\n    aes(fill = \"white\"),\n    colour = \"grey60\",\n    alpha = 0.2\n  ) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude\n    ),\n    size = 0.5\n  ) +\n  coord_sf(\n    xlim = c(140, 155),\n    ylim = c(-30, -10)\n  ) +\n  scale_fill_identity() +\n  theme_void()\n# Sydney Basin\nggplot() +\n  geom_sf(\n    data = aus,\n    colour = \"grey60\",\n    fill = \"white\",\n    alpha = 0.2\n  ) +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 == \"Sydney Basin\"),\n    aes(fill = \"green\"),\n    colour = \"grey60\",\n    alpha = 0.7\n  ) +\n  geom_sf(\n    data = shapefile %&gt;% filter(REG_NAME_7 != \"Sydney Basin\"),\n    aes(fill = \"white\"),\n    colour = \"grey60\",\n    alpha = 0.2\n  ) +\n  geom_point(\n    data = beetles,\n    mapping = aes(\n      x = decimalLongitude,\n      y = decimalLatitude\n    ),\n    size = 0.5\n  ) +\n  coord_sf(\n    xlim = c(145, 155),\n    ylim = c(-37, -30)\n  ) +\n  scale_fill_identity() +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, we might decide that there isn’t enough data (or data of a good enough quality) to make accurate estimates about Lampromicra.\nDepending on the spatial specificity of your question, you might have to adjust your data scope or your question accordingly.",
    "crumbs": [
      "Data scope",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Spatial scope</span>"
    ]
  },
  {
    "objectID": "scope_summary.html",
    "href": "scope_summary.html",
    "title": "4  Data scope summary",
    "section": "",
    "text": "This section has demonstrated a few ways to perform an initial investigation of the data available to answer a research question using the {galah} package. This is a critical part of the research process, and should be conducted in the early stages of your project. Keep in mind that this was just a small example of examining available data, and our aim is to encourage readers to think critically about their own data scope, building on the steps have presented here. In the next section, we will explain how to download and save this data.",
    "crumbs": [
      "Data scope",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data scope summary</span>"
    ]
  },
  {
    "objectID": "access_intro.html",
    "href": "access_intro.html",
    "title": "Accessing biodiversity data",
    "section": "",
    "text": "The aim of this section is to demonstrate the process of going from a planned data scope, to a complete, ready for cleaning dataset. We will demonstrate an example workflow for accessing biodiversity data, from downloading data, to integrating data from multiple sources. Along the way we will also highlight some of the important concepts and challenges to be aware of, such as taxonomic name variation across data aggregators, and working with disparate data sources.\nOutline of chapters:\n\nDownload data:\n\nIntroduce some common open access biodiversity data infrastructures\nHow to access this data, including download queries and filtering techniques\n\nInitial inspection:\n\nHow to assess a downloaded dataset as to whether it matches your expectations\n\nDataset integration:\n\nHow to integrate data from multiple sources into a single dataset",
    "crumbs": [
      "Accessing biodiversity data"
    ]
  },
  {
    "objectID": "access_taxonomy.html",
    "href": "access_taxonomy.html",
    "title": "5  Taxnomy and open source data",
    "section": "",
    "text": "6 Appendix: Naming Authorities\nAccurate species delimitation is also crucial for adequate conservation management and understanding evolutionary processes (Mace 2004). Species level lists are the foundation of many conservation decisions: such as the IUCN conservation status classification system. Taxonomic scope therefore has an effect on research application impacts.\nDeciding what naming authority to use can be challenging. What you choose will depend on your own taxonomic research and evaluation, but also your research scope.\nThese authorities provide a list of accepted and authoritative names as a template. If you’re unsure what naming authority to use and you’re looking at Australian species, the APNI and the AFD are a good place to start, especially if the data you’re investigating covers a wide range of taxa. If you’re investigating specific taxa it’s worth checking when the taxonomy was last updated in the APNI or AFD, especially if you know there has been recent changes. If you want to investigate closer, we’ve provided some links to society groups, in some cases these can be more up to date that the APNI or AFD.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Taxnomy and open source data</span>"
    ]
  },
  {
    "objectID": "access_taxonomy.html#taxonomic-authorities",
    "href": "access_taxonomy.html#taxonomic-authorities",
    "title": "5  Taxnomy and open source data",
    "section": "5.1 Taxonomic authorities",
    "text": "5.1 Taxonomic authorities\nTaxonomic classifications and groupings can vary over time, and between data data sources and aggregators. To ensure consistency in the classifications of biodiversity data, data aggregators use something called a ‘taxonomic backbone’, which is essentially a reference framework that dictates which taxonomic names are used for organisms in their system. GBIF uses a taxonomic backbone that is based on a wide variety of authority sources. Other data aggregators (such as the ALA), use their own taxonomic backbone of authority sources for classification. As a result, taxonomic classifications can vary across data aggregators and sources.\nThese sources that make up taxonomic backbones are typically authoritative databases or naming authorities. These authorities are usually an organisation or institution that has the responsibility and expertise to formally name and classify living organisms, and this process is governed by various international codes of nomenclature. As an example, the ALA uses the Australian Plant Name Index (APNI) as the primary naming authority for plants, and the Australian Faunal Directory (AFD) as the main taxonomic catalog for animal species (for a full list, see the appendix).\nWith this in mind, it is important to first familiarise yourself with the taxonomic classification of your study organism(s), and any variations across different sources and naming authorities. Following this, you should ensure that you adhere to a single taxonomic classification system for your organism. Later in this book, we demonstrate techniques for cleaning and standardising taxonomic names, which is particularly important when working with an organism that has classification differences across sources.\n\n\n\n\n\n\nCaution\n\n\n\nData that doesn’t match your preferred naming authority or contains data from multiple naming authorities may need to be conformed to a single taxonomic backbone. See the placeholder section (or appendix) for more information on how to do this.\n\n\n\n\n.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Taxnomy and open source data</span>"
    ]
  },
  {
    "objectID": "access_download.html#where-to-get-data-from",
    "href": "access_download.html#where-to-get-data-from",
    "title": "6  Download data",
    "section": "6.1 Where to get data from",
    "text": "6.1 Where to get data from\nThere are a wide variety of data aggregators available online, ranging from more regional or localised records, to those with a global scope. We will introduce a few of the most common ones.\nOne of the largest biodiversity aggregators is the Global Biodiversity Information Facility (GBIF), an international network and data infrastructure that provides open access biodiversity data from many sources around the world. Presently, GBIF manages and serves over 1.5 billion occurrence data points. These data points are aggregated from a number of particpant organisations, each of which collate biodiversity data from their own regions and sources, to be distributed through a designated ‘node’, with GBIF acting as the overarching organisation to store and provide this data using a unified data standard.\nIn addition to GBIF, there are a variety of other well known aggregators that index a large amount of records, such as Integrated Digitzed Biocollections and VertNet.\nBesides these large scale aggregators, we can also download data dierectly from more localised aggregators, such as the regional nodes of GBIF. For example, the Atlas of Living Australia (ALA) is the Australian node, Sistema de Informação sobre a Biodiversidade Brasileira (SiBBr) is the Brazilian node, and GBIF Sweden is the Swedish node. Living Atlases like the ALA ingest and aggregate data from a broad range of providers such as government monitoring programs, museums and herbaria, research projects and citizen science initiatives. If your project is focused on a specific region, downloading data directly from a regional node may be more appropriate.\n\n\n\n\n\n\nNote\n\n\n\nTo see what national and regional nodes exist, check out The GBIF Network.\n\n\nIf your project relates to data from a specific data provider, it also might be best to download data directly from the source. For example, a common citizen science tool to collect species observations is iNaturalist. Downloading directly from the original data source can help to ensure you don’t have any stray data from other sources.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Download data</span>"
    ]
  },
  {
    "objectID": "access_download.html#packages-for-downloading-data",
    "href": "access_download.html#packages-for-downloading-data",
    "title": "6  Download data",
    "section": "6.2 Packages for downloading data",
    "text": "6.2 Packages for downloading data\nThere are a range of R packages available for accessing biodiversity data. These packages serve as convenient interfaces to various data providers. By wrapping the respective APIs of data providers, they streamline the process of accessing and downloading datasets, directly within R. The functionality offered by these packages typically ranges from querying species occurrence records, to more comprehensive taxonomic and spatial download queries. Below, we highlight some commonly used packages. We encourage users to explore the documentation of each package to understand their capabilities, which will help you select one (or more!) that align with your specific needs.\n\nrgbif - Search and retrieve data from the Global Biodiversity Information Facility (GBIF)\ngalah - An interface for accessing GBIF and GBIF network nodes that maintain their own APIs (i.e. the ‘living atlases’)\nrinat - An R wrapper for accessing iNaturalist observations\nrebird - Provides access to the eBird webservices.\nspocc - Query and collect species occurrence data from a variety of sources, including GBIF, ALA, VertNet, iDigBio and others.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Download data</span>"
    ]
  },
  {
    "objectID": "access_download.html#basic-downloads-via-galah",
    "href": "access_download.html#basic-downloads-via-galah",
    "title": "6  Download data",
    "section": "6.3 Basic downloads via galah",
    "text": "6.3 Basic downloads via galah\nIn the majority of examples we will be using the galah package for download queries. One benefit of using galah is that in addition to species occurrence records, we can specify what metadata to return, from all available fields. It also allows access to any media, such as images or sounds, associated with the occurrence records.\n\n6.3.1 Setting an atlas\nWith galah, records are downloaded from the configured atlas. You can set the atlas using galah_config(). For example, to set the atlas to the Global Biodiversity Information Facility (GBIF), enter your GBIF account credentials and set the atlas to “Global”. See ?galah_config for more configuration options. You can enter your details directly, or else save them in your .Renviron, so you don’t have to enter them explicitly.\n\nlibrary(galah)\ngalah_config(\n  atlas    = \"Global\",\n  email    = Sys.getenv(\"GBIF_EMAIL\"),\n  username = Sys.getenv(\"GBIF_USER\"),\n  password = Sys.getenv(\"GBIF_PWD\")\n)\n\n\n\n6.3.2 Download from GBIF\nFor a basic download query, we simply pass a taxonomic identifier to the galah_identify() function, and end our query with atlas_occurrences() to return a data frame from the query. This is similar to the queries we made in Chapter 1, except there we used atlas_counts() to return counts of records rather than the observation data itself. Below is an example using the species name of the African Elephant, Loxodonta africana.\n\n\n\n\n\n\nNote\n\n\n\nDepending on your connection speed, downloads such as this (&gt; 1700 records) may take some time to complete\n\n\n\nafrican_ele &lt;- galah_call() |&gt;\n  galah_identify(\"Loxodonta africana\") |&gt;\n  atlas_occurrences()\n\nChecking queue\n succeeded \n\n\nDownloaded records can be saved locally using write.csv() or readr::write_csv as with any other dataframe. For larger downloads, we recommend saving the data as a Parquet file, as the compression and read/write speeds are typically better for this type of data structure. We can do this using the arrow::write_parquet() function, and arrow::read_parquet() can be used to read in a parquet file.\n\narrow::write_parquet(african_ele, \"data/gbif/elephant\")\nelephant &lt;- arrow::read_parquet(\"data/gbif/elephant\")\n\n\n\n6.3.3 Download from a regional node\nAbove, we downloaded records from GBIF. To access data from the Australian node, we change the galah configuration so that our query points to Australia. After that, we will download all records for the Pink Robin.\n\ngalah_config(\n  email = Sys.getenv(\"ALA_EMAIL\"),\n  atlas = \"Australia\"\n)\n\npink_robin &lt;- galah_call() |&gt;\n  galah_identify(\"Petroica rodinogaster\") |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue  running .\n\n\n\n\n6.3.4 Return specific data fields\nWhen downloading data using atlas_occurrences, a default selection of data fields (columns) are returned, which includes some of the key taxonomic and spatial fields. There are fields for a wide array of metadata that may accompany an observation. To choose what fields are included in a download query, the galah_select function can be used. This function takes a vector of field names as an argument, and when used within a query, a tibble with only those fields will be returned. To see the fields available for selection use show_all(fields).\nBelow is an example of using galah_select() to download only the requested data fields, for records of the species Petroica rodinogaster.\n\nlibrary(galah)\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"))\nproject_fields &lt;- c(\n  \"recordID\",\n  \"eventDate\",\n  \"year\",\n  \"basisOfRecord\",\n  \"occurrenceStatus\",\n  \"scientificName\",\n  \"genus\",\n  \"decimalLatitude\",\n  \"decimalLongitude\"\n)\npink_robin_projfields &lt;- galah_call() |&gt;\n  galah_identify(\"Petroica rodinogaster\") |&gt;\n  galah_select(all_of(project_fields)) |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue  running .",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Download data</span>"
    ]
  },
  {
    "objectID": "access_download.html#taxonomic-queries",
    "href": "access_download.html#taxonomic-queries",
    "title": "6  Download data",
    "section": "6.4 Taxonomic queries",
    "text": "6.4 Taxonomic queries\nTechniques specific to taxonomic queries and related knowledge.\n\n6.4.1 Name discrepancies\n\nTo search by a taxonomic classification, include the original name that was recorded by the data provider in your download.\n\n# Orchid as an example\n# Read in problem child data and show\n# Group by species and count unique values for higher taxonomy\n\nOrchids (family Orchidaceae) are one taxonomic clade that naming authorities have (famously) differing opinions about taxonomic classification. Comparing the scientific name originally provided with the observation by the data provider (i.e. raw_scientificName) compared to the name held within the Atlas of Living Australia (i.e. `scientificName) we are likely to notice some differences.\nFor example, say we were interested in downloading observations of Dendrobium, one of the largest genera of Orchids. Let’s download occurrence data of this genus using galah, and add raw_scientificName & taxonomicStatus information columns to our download.\n\ngalah_config(\n  atlas   = \"Australia\",\n  email   = Sys.getenv(\"ALA_EMAIL\")\n)\n\n# Download Dendrobium occurrences\norchids &lt;- galah_call() |&gt;\n  galah_identify(\"Dendrobium\") |&gt;\n  galah_select(group = \"basic\", raw_scientificName, taxonomicStatus) |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue . running .\n\n\nIf we filter our data to data without an “accepted” taxonomic status and compare a random group of names (rows 30 to 50), we’ll see a few names with differing names between the raw_scientificName and scientificName\n\n\nlibrary(dplyr)\norchids |&gt;\n  filter(\n    is.na(taxonomicStatus), # return names that aren't flagged as \"accepted\"\n    !scientificName...4 %in% scientificName...9\n  ) |&gt;\n  select(scientificName...4, scientificName...9) |&gt;\n  slice(30:50)\n\n# A tibble: 21 × 2\n   scientificName...4              scientificName...9                           \n   &lt;chr&gt;                           &lt;chr&gt;                                        \n 1 Dendrobium concavissimum        Dendrobium concavissimum J.J.Sm.             \n 2 Dendrobium concavissimum        Dendrobium concavissimum J.J.Sm.             \n 3 Dendrobium concavissimum        Dendrobium concavissimum J.J.Sm.             \n 4 Dendrobium concavissimum        Dendrobium concavissimum J.J.Sm.             \n 5 Dendrobium sect. Calyptrochilus Dendrobium sect. Calyptrochilus Schltr.      \n 6 Dendrobium sect. Calyptrochilus Dendrobium sect. Calyptrochilus Schltr.      \n 7 Dendrobium sect. Monophyllaea   Monophyllaea                                 \n 8 Dendrobium protractum           Dendrobium protractum Dauncey                \n 9 Dendrobium protractum           Dendrobium protractum Dauncey                \n10 Dendrobium sect. Calyptrochilus Pedilonum sect. Calyptrochilus (Schltr.) Bri…\n# ℹ 11 more rows\n\n\nLucky for us, the Atlas of Living Austrlaia accounts for some of these differences when storing their data to help standardise these data taxonomically. However, this isn’t always the case for every taxonomic clade. Searching by classification is a good first step when you expect to find certain taxonomic classifications within your data set.\nIt’s useful to include synonyms of the species names you’re interested in your download to ensure you return the data you are interested in.\n\nsearch_taxa(\"Dendrobium keffordii\")\n\n# A tibble: 1 × 14\n  search_term      scientific_name scientific_name_auth…¹ taxon_concept_id rank \n  &lt;chr&gt;            &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;\n1 Dendrobium keff… Grastidium bai… (F.Muell.) Rauschert   https://id.biod… spec…\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 9 more variables: match_type &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;,\n#   class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   issues &lt;chr&gt;\n\nsearch_taxa(\"Grastidium baileyi\")\n\n# A tibble: 1 × 14\n  search_term      scientific_name scientific_name_auth…¹ taxon_concept_id rank \n  &lt;chr&gt;            &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;            &lt;chr&gt;\n1 Grastidium bail… Grastidium bai… (F.Muell.) Rauschert   https://id.biod… spec…\n# ℹ abbreviated name: ¹​scientific_name_authorship\n# ℹ 9 more variables: match_type &lt;chr&gt;, kingdom &lt;chr&gt;, phylum &lt;chr&gt;,\n#   class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, species &lt;chr&gt;,\n#   issues &lt;chr&gt;\n\n## Not sure what was meant to happen here\nlibrary(galah)\n\ngalah_call() |&gt;\n  galah_filter(year &gt; 2019) |&gt;\n  atlas_counts()\n\n# A tibble: 1 × 1\n     count\n     &lt;int&gt;\n1 27282361",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Download data</span>"
    ]
  },
  {
    "objectID": "access_download.html#spatial-filtering",
    "href": "access_download.html#spatial-filtering",
    "title": "6  Download data",
    "section": "6.5 Spatial filtering",
    "text": "6.5 Spatial filtering\n\n\n\n\nWe can add spatial filters to download queries, to return only records within a specified area. Spatial filtering , and are useful for long-term analyses of observations in specific regions or areas.\n\n6.5.1 Filter by region\nOne way to download data is by filtering to an area of interest using fields already in the ALA and {galah}.\n\nsearch_fields(\"wetlands\")\n\n# A tibble: 1 × 4\n  id    description                                                  type  link \n  &lt;chr&gt; &lt;chr&gt;                                                        &lt;chr&gt; &lt;chr&gt;\n1 cl901 Directory of Important Wetlands Directory of Important Wetl… laye… http…\n\nsearch_fields(\"cl901\") |&gt;\n  search_values(\"kakadu\")\n\n# A tibble: 1 × 2\n  field category            \n  &lt;chr&gt; &lt;chr&gt;               \n1 cl901 Kakadu National Park\n\n# Northern Snake-necked Turtle\ngalah_call() |&gt;\n  galah_identify(\"Chelodina oblonga\") |&gt;\n  galah_filter(cl901 == \"Kakadu National Park\") |&gt;\n  atlas_occurrences() |&gt;\n  head(5) |&gt;\n  gt::gt()\n\n\nChecking queue\nCurrent queue size: 1 inqueue \n\n\n\n\n\n\n\n\ndecimalLatitude\ndecimalLongitude\neventDate\nscientificName\ntaxonConceptID\nrecordID\ndataResourceName\noccurrenceStatus\n\n\n\n\n-12.71089\n132.5883\n2018-03-28 05:47:34\nChelodina (Macrochelodina) oblonga\nhttps://biodiversity.org.au/afd/taxa/967549e7-7fa9-4770-b86e-5e3520d3c43d\n71f1273d-f425-4d49-8ea7-86bee30bb018\niNaturalist Australia\nPRESENT\n\n\n-12.66610\n132.4898\n1998-10-23 00:00:00\nChelodina (Macrochelodina) oblonga\nhttps://biodiversity.org.au/afd/taxa/967549e7-7fa9-4770-b86e-5e3520d3c43d\na60cb14f-a2b0-48d2-8990-f088d7f07f5d\nFauna Atlas N.T.\nPRESENT\n\n\n-12.60000\n132.8800\n1982-09-02 00:00:00\nChelodina (Macrochelodina) oblonga\nhttps://biodiversity.org.au/afd/taxa/967549e7-7fa9-4770-b86e-5e3520d3c43d\n3a3825db-9ca9-4226-b513-25fc1d5564ad\nNorthern Territory Museum and Art Gallery provider for OZCAM\nPRESENT\n\n\n-12.53258\n132.3971\n1981-04-30 00:00:00\nChelodina (Macrochelodina) oblonga\nhttps://biodiversity.org.au/afd/taxa/967549e7-7fa9-4770-b86e-5e3520d3c43d\n3bd79448-e5bd-44c6-a819-18535fdc7985\nFauna Atlas N.T.\nPRESENT\n\n\n-12.46670\n132.5000\nNA\nChelodina (Macrochelodina) oblonga\nhttps://biodiversity.org.au/afd/taxa/967549e7-7fa9-4770-b86e-5e3520d3c43d\nf1a8f89a-1d56-4b45-89b8-4709c2adbf49\nFauna Atlas N.T.\nPRESENT\n\n\n\n\n\n\n\n\n# Show how to download data in galah with a bounding box\n\n\n\n6.5.2 Filter by vector geometry\nVector geometry can also be used to filter observations. The advantage of this method is that you can return data for very specific shapes or areas. The galah_geolocate() function accepts vector geometries in the form of simple feature objects, shapefiles or Well-Known Text (WKT) strings.\nIn this example, we first construct a simple polygon for a theoretical “site A”, using a WKT string. You could also import an existing geometry such as a shapefile. To work with spatial vector data we use the sf package. The function st_as_sf() is used to create a simple feature with type polygon, from our WKT string. The coordinate reference system (CRS) of our WKT is 4326, so we need to use st_set_crs() to set this value for our simple feature object. Now we can use this object in a download query using galah_geolocate() to filter the records.\n\nmy_polygon &lt;- dplyr::tibble(\n  site = \"A\",\n  geometry = \"POLYGON((149.96704 -32.08651, 150.64294 -32.2957, 151.18152 -32.58776, 150.98376 -33.10617, 149.86316 -32.83581, 149.59900 -31.90793, 149.96704 -32.08651))\"\n)\n\nmy_polygon_sf &lt;- sf::st_as_sf(my_polygon, wkt = \"geometry\") |&gt;\n  sf::st_set_crs(4326)\n\n# Satin Bowerbird (*Ptilonorhynchus violaceus*\nsatin_bb &lt;- galah_call() |&gt;\n  galah_identify(\"Ptilonorhynchus violaceus\") |&gt;\n  galah_geolocate(my_polygon_sf) |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue  running \n\n\nOur download query returns only the records from within our polygon. We can visualise the result using ggplot2:\n\nlibrary(ggplot2)\n\naus &lt;- sf::st_transform(ozmaps::ozmap_country, 4326)\n\nggplot() +\n  geom_sf(data = aus) +\n  geom_sf(data = my_polygon_sf, fill = \"springgreen\", alpha = 0.2) +\n  geom_point(data = satin_bb, color = \"orchid1\", aes(\n    x = decimalLongitude,\n    y = decimalLatitude\n  )) +\n  coord_sf(xlim = c(148, 153), ylim = c(-34, -31)) +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\n6.5.3 Filter by bounding box\nAnother way to filter a query is by using a bounding box. This is similar to the polygon method shown above. We again use galah_geolocate(), but set the type arguement, which is polygon by default to “bbox”. As a result, the provided POLYGON or MULTIPOLYGON will be converted into the smallest bounding box (rectangle) that contains the POLYGON. In this case, records will be included that may not exactly lie inside the provided shape.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Download data</span>"
    ]
  },
  {
    "objectID": "access_download.html#refining-your-download-query",
    "href": "access_download.html#refining-your-download-query",
    "title": "6  Download data",
    "section": "6.6 Refining your download query",
    "text": "6.6 Refining your download query\nOpen access biodiversity data comes from many different data sources such as government monitoring programs, museums, herbaria, research projects, and citizen science apps. As such, data type and quality can vary considerably. For example, museums harbour older records that are associated with a preserved specimens. These data often contain lots of extra information (metadata) about a specific specimen and its location. On the other hand, data sourced from citizen science apps like iNaturalist or eBird may have less extensive metadata in comparison, but can include associated images or sounds.\nRefining your download query is useful for downloading only records that meet your project requirements, or filting records that may be of a lower quality. In any case, refining a dowload query where possible has the benifit of reducing filtering you would otherwise need to perform locally, and also reducing download size. Below we have illustrate a few ways of refining your download query using galah_filter.\n\n6.6.1 By Year\nGenerally, old data records tend to be insufficient or less reliable as taxonomic knowledge and GPS tools were not readily available. For this reason, many users consider removing all occurrence records before a certain year to increase data precision (Gueta and Carmel 2016; Marsh et al. 2022).\nChoosing the year ‘cut-off’ is relatively arbitary, but the most commonly used year is 1945 (Zizka et al. 2020; Führding-Potschkat, Kreft, and Ickert-Bond 2022), although some studies discard all data collected before 1990 (Gueta and Carmel 2016; Marsh et al. 2022).\nHere we will narrow the Pink Robin query from above to records after 1945 using galah_filter:\n\npink_robin_post1945 &lt;- galah_call() |&gt;\n  galah_identify(\"Petroica rodinogaster\") |&gt;\n  galah_filter(year &gt; 1945) |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue  running .\n\n\n\n\n6.6.2 Basis of record\nBasis of record is a Darwin Core term that refers to the specific nature of the occurrence record. It can be used to refine your data download and ensure consistency when consolidating data from multiple organisations (Führding-Potschkat, Kreft, and Ickert-Bond 2022).\nThere are 6 different classes for basis of record:\n\nLiving Specimen - a specimen that is alive, e.g. a living plant in a national park\nPreserved Specimen - a specimen that has been preserved, for example, a dried plant on an herbarium sheet\nFossil Specimen - a preserved specimen that is a fossil\nMaterial Sample - a genetic or environmental sample\nMaterial Citation - A reference to, or citation of, a specimen in scholarly publications, e.g a citation of a physical specimen in a scientific journal\nHuman Observation - an output of human observation process e.g. evidence of an occurrence taken from field notes or an occurrence without any physical evidence\nMachine Observation - An output of a machine observation process e.g. a photograph, a video, an audio recording, a remote sensing image or an occurrence record based on telemetry.\n\nDepending on your data scope, it may be practical to limit data that can be traced to a physical specimen or observation (Godfree et al. 2021), which we do for the Pink Robin below\n\ntractable_records &lt;- c(\n  \"LIVING_SPECIMEN\",\n  \"PRESERVED_SPECIMEN\",\n  \"MATERIAL_SAMPLE\",\n  \"MACHINE_OBSERVATION\"\n)\n\npink_robin_tractable &lt;- galah_call() |&gt;\n  galah_identify(\"Petroica rodinogaster\") |&gt;\n  galah_filter(basisOfRecord == tractable_records) |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue  running \n\n\n\n\n6.6.3 Assertions\nData infrastructures use assertions to internally grade the quality, completeness and consistency of each occurrence record. Assertions take values of either 1 or 0, indicating the presence or absence of the data quality issue. Note that assertions may vary depending what atlas you have configured to. You can see the available assertions and their descriptions using:\n\nshow_all(\"assertions\")\n\n# A tibble: 114 × 4\n   id                                 description                 category type \n   &lt;chr&gt;                              &lt;chr&gt;                       &lt;chr&gt;    &lt;chr&gt;\n 1 AMBIGUOUS_COLLECTION               Ambiguous collection        Warning  asse…\n 2 AMBIGUOUS_INSTITUTION              Ambiguous institution       Warning  asse…\n 3 BASIS_OF_RECORD_INVALID            Basis of record badly form… Warning  asse…\n 4 biosecurityIssue                   Biosecurity issue           Error    asse…\n 5 COLLECTION_MATCH_FUZZY             Collection match fuzzy      Warning  asse…\n 6 COLLECTION_MATCH_NONE              Collection not matched      Warning  asse…\n 7 CONTINENT_COUNTRY_MISMATCH         Continent country mismatch  Warning  asse…\n 8 CONTINENT_DERIVED_FROM_COORDINATES Continent derived from coo… Warning  asse…\n 9 CONTINENT_INVALID                  Continent invalid           Warning  asse…\n10 COORDINATE_INVALID                 Coordinate invalid          Warning  asse…\n# ℹ 104 more rows\n\n\nOnce you have decided which assertions are important for your project you can further refine your download. To retrieve all the assertions for your query use galah_select(group = \"assertions\")\n\n\n\n\n\nprobin_assertions &lt;- galah_call() |&gt;\n  galah_identify(\"Petroica rodinogaster\") |&gt;\n  galah_filter(basisOfRecord == tractable_records) |&gt;\n  galah_select(group = \"assertions\") |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue  running \n\n# Preview all the assertions\nhead(colnames(probin_assertions), 10)\n\n [1] \"recordID\"                           \"AMBIGUOUS_COLLECTION\"              \n [3] \"AMBIGUOUS_INSTITUTION\"              \"BASIS_OF_RECORD_INVALID\"           \n [5] \"biosecurityIssue\"                   \"COLLECTION_MATCH_FUZZY\"            \n [7] \"COLLECTION_MATCH_NONE\"              \"CONTINENT_COUNTRY_MISMATCH\"        \n [9] \"CONTINENT_DERIVED_FROM_COORDINATES\" \"CONTINENT_INVALID\"                 \n\n# A quick way to check which assertions contain TRUEs\nprobin_assertions |&gt;\n  select(-recordID) |&gt;\n  colSums()\n\n                             AMBIGUOUS_COLLECTION \n                                                0 \n                            AMBIGUOUS_INSTITUTION \n                                                0 \n                          BASIS_OF_RECORD_INVALID \n                                                0 \n                                 biosecurityIssue \n                                                0 \n                           COLLECTION_MATCH_FUZZY \n                                                0 \n                            COLLECTION_MATCH_NONE \n                                                0 \n                       CONTINENT_COUNTRY_MISMATCH \n                                                0 \n               CONTINENT_DERIVED_FROM_COORDINATES \n                                                0 \n                                CONTINENT_INVALID \n                                                0 \n                               COORDINATE_INVALID \n                                                0 \n                          COORDINATE_OUT_OF_RANGE \n                                                0 \n                     COORDINATE_PRECISION_INVALID \n                                                2 \n                           COORDINATE_REPROJECTED \n                                                6 \n                   COORDINATE_REPROJECTION_FAILED \n                                                0 \n               COORDINATE_REPROJECTION_SUSPICIOUS \n                                                0 \n                               COORDINATE_ROUNDED \n                                                0 \n            COORDINATE_UNCERTAINTY_METERS_INVALID \n                                              143 \n                    COORDINATES_CENTRE_OF_COUNTRY \n                                                0 \n              COORDINATES_CENTRE_OF_STATEPROVINCE \n                                                0 \n                      COUNTRY_COORDINATE_MISMATCH \n                                                0 \n                 COUNTRY_DERIVED_FROM_COORDINATES \n                                                0 \n                                  COUNTRY_INVALID \n                                                0 \n                                 COUNTRY_MISMATCH \n                                                0 \n                            DEPTH_MIN_MAX_SWAPPED \n                                                0 \n                                DEPTH_NON_NUMERIC \n                                                0 \n                                 DEPTH_NOT_METRIC \n                                                0 \n                                   DEPTH_UNLIKELY \n                                                0 \n                                  detectedOutlier \n                                                0 \n                      DIFFERENT_OWNER_INSTITUTION \n                                                0 \n                        ELEVATION_MIN_MAX_SWAPPED \n                                                0 \n                            ELEVATION_NON_NUMERIC \n                                                0 \n                             ELEVATION_NOT_METRIC \n                                                0 \n                               ELEVATION_UNLIKELY \n                                                0 \n                                 FIRST_OF_CENTURY \n                                                0 \n                                   FIRST_OF_MONTH \n                                               14 \n                                    FIRST_OF_YEAR \n                                               26 \n                            FOOTPRINT_SRS_INVALID \n                                                0 \n                            FOOTPRINT_WKT_INVALID \n                                                0 \n                           FOOTPRINT_WKT_MISMATCH \n                                                0 \n                     GEODETIC_DATUM_ASSUMED_WGS84 \n                                              234 \n                           GEODETIC_DATUM_INVALID \n                                                0 \n                     GEOREFERENCE_POST_OCCURRENCE \n                                                2 \n                       GEOREFERENCED_DATE_INVALID \n                                                0 \n                      GEOREFERENCED_DATE_UNLIKELY \n                                                0 \n                                  geospatialIssue \n                                                0 \n                                  habitatMismatch \n                                                0 \n                                ID_PRE_OCCURRENCE \n                                                0 \n                          identificationIncorrect \n                                                0 \n                          IDENTIFIED_DATE_INVALID \n                                                0 \n                         IDENTIFIED_DATE_UNLIKELY \n                                                0 \nINDIVIDUAL_COUNT_CONFLICTS_WITH_OCCURRENCE_STATUS \n                                                0 \n                         INDIVIDUAL_COUNT_INVALID \n                                                2 \n                  INSTITUTION_COLLECTION_MISMATCH \n                                                0 \n                          INSTITUTION_MATCH_FUZZY \n                                                0 \n                           INSTITUTION_MATCH_NONE \n                                                0 \n                             INTERPRETATION_ERROR \n                                                0 \n                          INVALID_SCIENTIFIC_NAME \n                                                0 \n                            LOCATION_NOT_SUPPLIED \n                                               21 \n                          MISSING_COLLECTION_DATE \n                                               43 \n                            MISSING_GEODETICDATUM \n                                              234 \n                        MISSING_GEOREFERENCE_DATE \n                                              336 \n                          MISSING_GEOREFERENCEDBY \n                                              336 \n                     MISSING_GEOREFERENCEPROTOCOL \n                                              281 \n                      MISSING_GEOREFERENCESOURCES \n                                              331 \n           MISSING_GEOREFERENCEVERIFICATIONSTATUS \n                                              338 \n                                MISSING_TAXONRANK \n                                              196 \n                            MODIFIED_DATE_INVALID \n                                                0 \n                           MODIFIED_DATE_UNLIKELY \n                                                0 \n                          MULTIMEDIA_DATE_INVALID \n                                                0 \n                           MULTIMEDIA_URI_INVALID \n                                                3 \n                                NAME_NOT_SUPPLIED \n                                                4 \n  OCCURRENCE_STATUS_INFERRED_FROM_BASIS_OF_RECORD \n                                                0 \n OCCURRENCE_STATUS_INFERRED_FROM_INDIVIDUAL_COUNT \n                                                1 \n                     OCCURRENCE_STATUS_UNPARSABLE \n                                                0 \n                        PRESUMED_NEGATED_LATITUDE \n                                                0 \n                       PRESUMED_NEGATED_LONGITUDE \n                                                0 \n                      PRESUMED_SWAPPED_COORDINATE \n                                                0 \n                            RECORDED_DATE_INVALID \n                                               59 \n                           RECORDED_DATE_MISMATCH \n                                                0 \n                           RECORDED_DATE_UNLIKELY \n                                                0 \n                           REFERENCES_URI_INVALID \n                                                0 \n                       SENSITIVITY_REPORT_INVALID \n                                                0 \n                  SENSITIVITY_REPORT_NOT_LOADABLE \n                                                0 \n                        STATE_COORDINATE_MISMATCH \n                                                0 \n                           TAXON_AFFINITY_SPECIES \n                                                0 \n                             TAXON_CONFER_SPECIES \n                                                0 \n                              TAXON_DEFAULT_MATCH \n                                                0 \n                                      TAXON_ERROR \n                                                0 \n                                   TAXON_EXCLUDED \n                                                0 \n                        TAXON_EXCLUDED_ASSOCIATED \n                                                0 \n                                    TAXON_HOMONYM \n                                                0 \n                      TAXON_INDETERMINATE_SPECIES \n                                                0 \n                            TAXON_MATCH_AGGREGATE \n                                                0 \n                                TAXON_MATCH_FUZZY \n                                                0 \n                           TAXON_MATCH_HIGHERRANK \n                                                0 \n                                 TAXON_MATCH_NONE \n                                                0 \n                                 TAXON_MISAPPLIED \n                                                0 \n                         TAXON_MISAPPLIED_MATCHED \n                                                0 \n                       TAXON_PARENT_CHILD_SYNONYM \n                                                0 \n                           TAXON_QUESTION_SPECIES \n                                                0 \n                             TAXON_SCOPE_MISMATCH \n                                                0 \n                             TAXON_SPECIES_PLURAL \n                                                0 \n                                   taxonomicIssue \n                                                0 \n                                    temporalIssue \n                                                0 \n                              TYPE_STATUS_INVALID \n                                                0 \n                         UNCERTAINTY_IN_PRECISION \n                                                0 \n                        UNCERTAINTY_NOT_SPECIFIED \n                                                0 \n                             UNKNOWN_COUNTRY_NAME \n                                                0 \n                                  UNKNOWN_KINGDOM \n                                                0 \n                     UNRECOGNISED_COLLECTION_CODE \n                                                0 \n                    UNRECOGNISED_INSTITUTION_CODE \n                                                0 \n                               userAssertionOther \n                                                0 \n                              userDuplicateRecord \n                                                0 \n                                  ZERO_COORDINATE \n                                                0 \n\n# Requery for single assertion\nprobin_subset &lt;- galah_call() |&gt;\n  galah_identify(\"Petroica rodinogaster\") |&gt;\n  galah_filter(\n    basisOfRecord == tractable_records,\n    identificationIncorrect == FALSE\n  ) |&gt;\n  galah_select(group = \"basic\") |&gt;\n  atlas_counts()\n\n\n# For exclusions using multiple assertions [Currently throws errors, need to think carefully about != means for logical assertions...]\n# assertions &lt;- c(\"UNKNOWN_KINGDOM\", \"identificationIncorrect\",\n#                    \"COORDINATE_PRECISION_MISMATCH\", \"MISSING_GEODETICDATUM\")\n#\n# galah_call() |&gt;\n#   galah_identify(\"Petroica rodinogaster\") |&gt;\n#   galah_filter(basisOfRecord == tractable_records,\n#                assertions != IA_assertions) |&gt;\n#   atlas_counts()\n\n\n\n\n\nFührding-Potschkat, Petra, Holger Kreft, and Stefanie M. Ickert-Bond. 2022. “Influence of Different Data Cleaning Solutions of Point-Occurrence Records on Downstream Macroecological Diversity Models.” Ecology and Evolution 12 (8): e9168. https://doi.org/10.1002/ece3.9168.\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nGueta, Tomer, and Yohay Carmel. 2016. “Quantifying the Value of User-Level Data Cleaning for Big Data: A Case Study Using Mammal Distribution Models.” Ecological Informatics 34 (July): 139–45. https://doi.org/10.1016/j.ecoinf.2016.06.001.\n\n\nMarsh, Jessica R., Payal Bal, Hannah Fraser, Kate Umbers, Tanya Latty, Aaron Greenville, Libby Rumpff, and John C. Z. Woinarski. 2022. “Accounting for the Neglected: Invertebrate Species and the 2019–2020 Australian Megafires.” Global Ecology and Biogeography n/a (n/a). https://doi.org/10.1111/geb.13550.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio Baez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus Colli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais Ferreira-Araújo. 2020. “No One-Size-Fits-All Solution to Clean GBIF.” PeerJ 8: e9916.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Download data</span>"
    ]
  },
  {
    "objectID": "access_inspect.html#metadata-inspection",
    "href": "access_inspect.html#metadata-inspection",
    "title": "7  Initial inspection",
    "section": "7.1 Metadata inspection",
    "text": "7.1 Metadata inspection\nMetadata describes your data set: it defines each variable and its contents. For example, describing a variables unit of measurement, climatic conditions at the time of observation, or whether the occurrence is a marked outlier. Reviewing the metadata of your dataset is a useful first step, as it allows you to understand the kind of data you are working with and any potential limitations of the data that could affect your analysis.\nData infrastructures that use Darwin Core terms will have interoperable metadata. This makes it easier to consolidate across data sets. All Darwin Core term definitions can be found here. We suggest using Ctrl/CMD F and searching your variable name on the webpage. Don’t hesitate to Google variable names if you are unsure what they represent.\nIt is also worth checking the available metadata for your dataset, to determine if there is extra information that may be relevant. You could Google the dataset name, or search the dataset or institution on the ALA. The metadata on the ALA is submitted with the data, and because the ALA is not the data owner, this data is immutable.\nAn example of well formatted metadata is FrogID from the Australian Museum. From reading FrogID’s metadata (Rowley and Callaghan 2020), you’ll find:\n\nThe data is acoustic data, the majority of the species recorded are therefore male.\nBecause this is citizen science data, it is especially biased towards populated areas.\nAudio is recorded via a smartphone app, and so the authors recommend filtering data to geographic uncertainty of &lt;3000m if you require high coordinate precision.\nThe data is presence only data.\n\nMetadata can also be useful for understanding the license that the data falls under. This is mostly relevant for using or republishing multimedia associated with the data.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "access_inspect.html#data-inspection",
    "href": "access_inspect.html#data-inspection",
    "title": "7  Initial inspection",
    "section": "7.2 Data inspection",
    "text": "7.2 Data inspection\nA great way to get an initial overview of your data is to use the R package skimr, which provides tables of descriptive statistics, such as amount of missing data, for each variable. The output is also grouped by data type (numeric, character, date) so you can also check for any inconsistencies.\nAs you are looking through the output, ask yourself whether the data is in line with your expectations. If you requested data for a group of species, are they all represented? Are the values for a variable reasonable? Looking at the quartiles can help you get the sense of the distribution of data. These considerations will help you detect potential issues in the data. Make sure you take note of any issues you find, to investigate further and later address.\nHere we will continue using the African elephant dataset that we downloaded in the previous chapter on downloading. You can create a report using the skimr package by running the following code: \n\nlibrary(skimr)\nafrican_ele &lt;- arrow::read_parquet(\"data/gbif/elephant\")\nskim(african_ele)\n\n\nData summary\n\n\nName\nafrican_ele\n\n\nNumber of rows\n17825\n\n\nNumber of columns\n50\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n31\n\n\nlogical\n1\n\n\nnumeric\n15\n\n\nPOSIXct\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ndatasetKey\n0\n1.00\n36\n36\n0\n150\n0\n\n\noccurrenceID\n806\n0.95\n1\n81\n0\n16818\n0\n\n\nkingdom\n0\n1.00\n8\n8\n0\n1\n0\n\n\nphylum\n0\n1.00\n8\n8\n0\n1\n0\n\n\nclass\n0\n1.00\n8\n8\n0\n1\n0\n\n\norder\n0\n1.00\n11\n11\n0\n1\n0\n\n\nfamily\n0\n1.00\n12\n12\n0\n1\n0\n\n\ngenus\n0\n1.00\n9\n9\n0\n1\n0\n\n\nspecies\n0\n1.00\n18\n18\n0\n1\n0\n\n\ninfraspecificEpithet\n17698\n0.01\n8\n13\n0\n2\n0\n\n\ntaxonRank\n0\n1.00\n7\n10\n0\n3\n0\n\n\nscientificName\n0\n1.00\n12\n37\n0\n5\n0\n\n\nverbatimScientificName\n3\n1.00\n12\n53\n0\n31\n0\n\n\nverbatimScientificNameAuthorship\n16258\n0.09\n2\n31\n0\n256\n0\n\n\ncountryCode\n1701\n0.90\n2\n2\n0\n46\n0\n\n\nlocality\n14434\n0.19\n3\n254\n0\n725\n0\n\n\nstateProvince\n6447\n0.64\n3\n43\n0\n196\n0\n\n\noccurrenceStatus\n0\n1.00\n6\n7\n0\n2\n0\n\n\npublishingOrgKey\n0\n1.00\n36\n36\n0\n106\n0\n\n\nbasisOfRecord\n0\n1.00\n10\n19\n0\n9\n0\n\n\ninstitutionCode\n4075\n0.77\n2\n76\n0\n111\n0\n\n\ncollectionCode\n4091\n0.77\n1\n41\n0\n169\n0\n\n\ncatalogNumber\n4292\n0.76\n1\n36\n0\n13418\n0\n\n\nrecordNumber\n17662\n0.01\n1\n37\n0\n114\n0\n\n\nidentifiedBy\n7519\n0.58\n1\n81\n0\n1899\n0\n\n\nlicense\n0\n1.00\n7\n12\n0\n3\n0\n\n\nrightsHolder\n7128\n0.60\n1\n56\n0\n2135\n0\n\n\nrecordedBy\n4967\n0.72\n1\n160\n0\n2485\n0\n\n\nestablishmentMeans\n17538\n0.02\n6\n9\n0\n2\n0\n\n\nmediaType\n8137\n0.54\n5\n16\n0\n4\n0\n\n\nissue\n3189\n0.82\n15\n191\n0\n148\n0\n\n\n\nVariable type: logical\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\ncount\n\n\n\n\ntypeStatus\n17825\n0\nNaN\n:\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ngbifID\n0\n1.00\n2651173026.73\n1.085849e+09\n49926810.00\n1677294509.00\n2.45486e+09\n3817646721.00\n4.499724e+09\n▁▇▇▅▇\n\n\nindividualCount\n15550\n0.13\n4.90\n1.415000e+01\n0.00\n1.00\n1.00000e+00\n2.00\n2.920000e+02\n▇▁▁▁▁\n\n\ndecimalLatitude\n4174\n0.77\n-11.29\n1.430000e+01\n-34.58\n-24.28\n-1.58400e+01\n-0.13\n5.215000e+01\n▇▅▃▁▁\n\n\ndecimalLongitude\n4174\n0.77\n26.47\n1.137000e+01\n-111.97\n24.34\n3.13000e+01\n34.82\n4.053000e+01\n▁▁▁▁▇\n\n\ncoordinateUncertaintyInMeters\n6763\n0.62\n41707.41\n1.445170e+05\n1.00\n29981.00\n3.05980e+04\n31425.00\n5.635548e+06\n▇▁▁▁▁\n\n\ncoordinatePrecision\n17786\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n0.000000e+00\n▆▁▁▁▇\n\n\nelevation\n17789\n0.00\n154.42\n4.215900e+02\n0.00\n0.00\n0.00000e+00\n13.75\n2.134000e+03\n▇▁▁▁▁\n\n\nelevationAccuracy\n17795\n0.00\n0.83\n3.730000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n2.000000e+01\n▇▁▁▁▁\n\n\ndepth\n17797\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n0.000000e+00\n▁▁▇▁▁\n\n\ndepthAccuracy\n17797\n0.00\n0.00\n0.000000e+00\n0.00\n0.00\n0.00000e+00\n0.00\n0.000000e+00\n▁▁▇▁▁\n\n\nday\n4092\n0.77\n16.10\n8.790000e+00\n1.00\n9.00\n1.70000e+01\n24.00\n3.100000e+01\n▇▆▇▇▇\n\n\nmonth\n4027\n0.77\n6.94\n3.270000e+00\n1.00\n4.00\n7.00000e+00\n10.00\n1.200000e+01\n▆▅▅▇▇\n\n\nyear\n1017\n0.94\n2011.59\n1.677000e+01\n1799.00\n2008.00\n2.01500e+03\n2019.00\n2.023000e+03\n▁▁▁▁▇\n\n\ntaxonKey\n0\n1.00\n2493260.94\n6.308602e+05\n2435350.00\n2435350.00\n2.43535e+06\n2435350.00\n1.150335e+07\n▇▁▁▁▁\n\n\nspeciesKey\n0\n1.00\n2435350.00\n0.000000e+00\n2435350.00\n2435350.00\n2.43535e+06\n2435350.00\n2.435350e+06\n▁▁▇▁▁\n\n\n\nVariable type: POSIXct\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\neventDate\n1017\n0.94\n1799-01-01 00:00:00\n2023-12-12 14:22:24\n2015-05-22 00:00:00\n10716\n\n\ndateIdentified\n7025\n0.61\n1783-01-01 00:00:00\n2023-12-12 20:59:49\n2021-02-03 20:16:20\n9526\n\n\nlastInterpreted\n0\n1.00\n2023-08-25 11:37:02\n2023-12-24 01:51:40\n2023-12-19 07:41:11\n16810\n\n\n\n\n\n\n7.2.1 Evaluating the dataset\nHere are some starting points for evaluating a dataset. As you go through the skimr report and perform these checks, make detailed notes of your observations and any potential issues.\n\nConfirm the number of records:\n\nVerify if the number of records in the dataset matches your expectations. If the number is significantly higher or lower than anticipated, it may indicate an issue with the query or data source.\n\nChecking for the correct metadata columns:\n\nEnsure that all expected metadata columns are present. These might include species names, dates, locations, etc. The absence of key columns could suggest a problem with the data extraction process.\n\nAssessing missing data in critical fields:\n\nCheck the amount of missing data, especially in critical fields like latitude and longitude. A high number of missing values in these fields can significantly impact the usability of the dataset for geospatial analysis.\n\nReviewing geospatial data accuracy:\n\nLook for anomalies in geospatial data. Check if the coordinates are within plausible ranges and if they correspond to the geographic regions you expected.\n\nEvaluating data distribution and outliers:\n\nUse the quartiles and summary statistics provided by skimr to assess the distribution of key variables. Be on the lookout for outliers or unusual patterns that might need further investigation.\n\nConsistency and formatting of categorical data:\n\nCheck for consistency in categorical data, such as species names. Inconsistencies might arise from variations in spelling, capitalization, or use of synonyms.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "access_inspect.html#next-steps",
    "href": "access_inspect.html#next-steps",
    "title": "7  Initial inspection",
    "section": "7.3 Next steps",
    "text": "7.3 Next steps\nKeep in mind, we don’t expect a perfect dataset from a download. The goal of an initial inspection is to assess whether the download returned results in line with your expections based on your query. Some issues are expected, and may not signify an issue with the download itself but rather the actual data. The initial inspection is therefore a good opportunity to also start noting these issues, as they will be addressed during the cleaning phase.\nBased on your initial findings, consider whether you need to refine your download query. Perhaps you uncovered some additional metadata fields during your metadata inspection, and would like to adjust your query to include them. Or maybe you noticed missing data in specific time frames or locations that you expected from your query, or missing metadata fields. This could mean you need to adjust your download query parameters or investigate those issues further.\nWhen you are satisfied that the dataset is largely as expected, you are ready to move onto the data cleaning section. If you are working with multiple datasets from different sources, the next chapter will cover integration of datasets.\n\n\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset: Expert-Validated Occurrence Records of Australia’s Frogs Collected by Citizen Scientists.” ZooKeys 912: 139.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Initial inspection</span>"
    ]
  },
  {
    "objectID": "access_integration.html#setup",
    "href": "access_integration.html#setup",
    "title": "8  Dataset integration",
    "section": "8.1 Setup",
    "text": "8.1 Setup\n\n\nTo see the download process for example data expand here.\n\nWe will download data for the species Litoria chloris from the ALA and GBIF using the galah package. For the download request to ALA the galah_select() is used to return specific fields (see: Specify fields for occurrence download — galah_select). This is a project specific decision and these fields are used as an example.\n\n\nDefine a character vector of fields to return…\nala_fields &lt;- c(\n  \"kingdom\",\n  \"taxonRank\",\n  \"phylum\",\n  \"class\",\n  \"order\",\n  \"family\",\n  \"genus\",\n  \"species\",\n  \"taxonRank\",\n  \"countryCode\",\n  \"locality\",\n  \"stateProvince\",\n  \"coordinateUncertaintyInMeters\",\n  \"coordinatePrecision\",\n  \"license\",\n  \"occurrenceID\"\n)\n\n\n\n\nSet galah_config() options and download data from ALA…\nlibrary(\"galah\")\ngalah_config(atlas = \"Australia\") # default\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"))\nala_data &lt;- galah_call() |&gt;\n  galah_identify(\"Litoria chloris\") |&gt;\n  galah_select(basisOfRecord, all_of(ala_fields), group = \"basic\") |&gt;\n  atlas_occurrences()\n\n\n\n\nSet galah_config() options and download data from GBIF…\n# For GBIF, a username and password are required\ngalah_config(\n  atlas = \"Global\",\n  username = Sys.getenv(\"GBIF_USER\"),\n  email = Sys.getenv(\"GBIF_EMAIL\"),\n  password = Sys.getenv(\"GBIF_PWD\")\n)\n## Atlas selected: Global Biodiversity Information Facility (GBIF) [Global]\n\n# Search the species name to get the GBIF taxon key\nknitr::kable(search_taxa(\"Litoria chloris\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsearch_term\ntaxon_concept_id\nscientific_name\ncanonical_name\nrank\nstatus\nmatch_type\nkingdom\nphylum\norder\nfamily\ngenus\nspecies\nclass\n\n\n\n\nLitoria chloris\n2427866\nLitoria chloris (Boulenger, 1892)\nLitoria chloris\nSPECIES\nSYNONYM\nEXACT\nAnimalia\nChordata\nAnura\nPelodryadidae\nRanoidea\nRanoidea chloris\nAmphibia\n\n\n\n\n\nSet galah_config() options and download data from GBIF…\n\n# Download data\ngbif_data &lt;- galah_call() |&gt;\n  galah_identify(\"2427866\", search = FALSE) |&gt;\n  atlas_occurrences()\n## This query will return 3,733 records\n## Checking queue\n##  succeeded",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dataset integration</span>"
    ]
  },
  {
    "objectID": "access_integration.html#inspecting-our-datasets",
    "href": "access_integration.html#inspecting-our-datasets",
    "title": "8  Dataset integration",
    "section": "8.2 Inspecting our datasets",
    "text": "8.2 Inspecting our datasets\nThe example data we are using (see setup) was downloaded from GBIF and from Atlas of Living Australia (ALA). Each dataset contains records of a single species, Litoria chloris.\nFirst, we add a new column to each dataset called source, which acts as an identifier. This isn’t required but its a simple way to keep track of where each record came from after the data has been merged.\n\n# add identifier column to each dataset\nala_data$source &lt;- \"ALA\"\ngbif_data$source &lt;- \"GBIF\"\n\nTo merge datasets, we need to understand what variables are in each dataset, and how they are formatted.\n\nHow many columns does each dataset have?\nWhat are the column names?\nDo the column names match between the two datasets?\nWhat are the data types of each column?\n\n\n\nTake a glimpse at the data\ndplyr::glimpse(ala_data)\n## Rows: 3,995\n## Columns: 25\n## $ decimalLatitude               &lt;dbl&gt; -34.91394, -34.91394, -34.87318, -34.873…\n## $ decimalLongitude              &lt;dbl&gt; 150.5402, 150.5402, 150.4640, 150.4640, …\n## $ eventDate                     &lt;dttm&gt; 2020-02-13, 2020-02-13, 2021-10-22, 202…\n## $ scientificName                &lt;chr&gt; \"Litoria chloris\", \"Litoria chloris\", \"L…\n## $ taxonConceptID                &lt;chr&gt; \"https://biodiversity.org.au/afd/taxa/f5…\n## $ recordID                      &lt;chr&gt; \"ca28eeb2-5416-4049-a354-1d1dfb194be3\", …\n## $ dataResourceName              &lt;chr&gt; \"NSW BioNet Atlas\", \"FrogID\", \"FrogID\", …\n## $ occurrenceStatus              &lt;chr&gt; \"PRESENT\", \"PRESENT\", \"PRESENT\", \"PRESEN…\n## $ basisOfRecord                 &lt;chr&gt; \"HUMAN_OBSERVATION\", \"OCCURRENCE\", \"OCCU…\n## $ kingdom                       &lt;chr&gt; \"Animalia\", \"Animalia\", \"Animalia\", \"Ani…\n## $ taxonRank                     &lt;chr&gt; \"species\", \"species\", \"species\", \"specie…\n## $ phylum                        &lt;chr&gt; \"Chordata\", \"Chordata\", \"Chordata\", \"Cho…\n## $ class                         &lt;chr&gt; \"Amphibia\", \"Amphibia\", \"Amphibia\", \"Amp…\n## $ order                         &lt;chr&gt; \"Anura\", \"Anura\", \"Anura\", \"Anura\", \"Anu…\n## $ family                        &lt;chr&gt; \"Hylidae\", \"Hylidae\", \"Hylidae\", \"Hylida…\n## $ genus                         &lt;chr&gt; \"Litoria\", \"Litoria\", \"Litoria\", \"Litori…\n## $ species                       &lt;chr&gt; \"Litoria chloris\", \"Litoria chloris\", \"L…\n## $ countryCode                   &lt;chr&gt; \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\"…\n## $ locality                      &lt;chr&gt; \"locality withheld\", NA, NA, \"locality w…\n## $ stateProvince                 &lt;chr&gt; \"New South Wales\", \"New South Wales\", \"N…\n## $ coordinateUncertaintyInMeters &lt;dbl&gt; 34.28, 34.28, 10.00, 10.00, 48.00, 48.00…\n## $ coordinatePrecision           &lt;dbl&gt; 1e-09, NA, NA, 1e-09, NA, 1e-09, 1e-09, …\n## $ `dcterms:license`             &lt;chr&gt; \"CC-BY 4.0 (Int)\", \"CC-BY-NC 4.0 (Int)\",…\n## $ occurrenceID                  &lt;chr&gt; \"urn:catalog:NSW Dept of Planning, Indus…\n## $ source                        &lt;chr&gt; \"ALA\", \"ALA\", \"ALA\", \"ALA\", \"ALA\", \"ALA\"…\ndplyr::glimpse(gbif_data)\n## Rows: 3,733\n## Columns: 51\n## $ gbifID                           &lt;dbl&gt; 864931363, 864930363, 692133811, 6920…\n## $ datasetKey                       &lt;chr&gt; \"0debafd0-6c8a-11de-8225-b8a03c50a862…\n## $ occurrenceID                     &lt;chr&gt; \"e710bb1f-21dc-4330-a9e2-da7362d32b88…\n## $ kingdom                          &lt;chr&gt; \"Animalia\", \"Animalia\", \"Animalia\", \"…\n## $ phylum                           &lt;chr&gt; \"Chordata\", \"Chordata\", \"Chordata\", \"…\n## $ class                            &lt;chr&gt; \"Amphibia\", \"Amphibia\", \"Amphibia\", \"…\n## $ order                            &lt;chr&gt; \"Anura\", \"Anura\", \"Anura\", \"Anura\", \"…\n## $ family                           &lt;chr&gt; \"Pelodryadidae\", \"Pelodryadidae\", \"Pe…\n## $ genus                            &lt;chr&gt; \"Ranoidea\", \"Ranoidea\", \"Ranoidea\", \"…\n## $ species                          &lt;chr&gt; \"Litoria chloris\", \"Litoria chloris\",…\n## $ infraspecificEpithet             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ taxonRank                        &lt;chr&gt; \"SPECIES\", \"SPECIES\", \"SPECIES\", \"SPE…\n## $ scientificName                   &lt;chr&gt; \"Litoria chloris (Boulenger, 1892)\", …\n## $ verbatimScientificName           &lt;chr&gt; \"Litoria chloris\", \"Litoria chloris\",…\n## $ verbatimScientificNameAuthorship &lt;chr&gt; \"(Boulenger, 1893)\", \"(Boulenger, 189…\n## $ countryCode                      &lt;chr&gt; \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"AU\", \"…\n## $ locality                         &lt;chr&gt; \"Nemarotu, Wilsons Creek via Mullumbi…\n## $ stateProvince                    &lt;chr&gt; \"New South Wales\", \"New South Wales\",…\n## $ occurrenceStatus                 &lt;chr&gt; \"PRESENT\", \"PRESENT\", \"PRESENT\", \"PRE…\n## $ individualCount                  &lt;dbl&gt; NA, NA, 1, 1, NA, NA, NA, NA, NA, NA,…\n## $ publishingOrgKey                 &lt;chr&gt; \"64bd66c1-e7d3-48d0-9462-488729aed122…\n## $ decimalLatitude                  &lt;dbl&gt; -28.56670, -28.56670, -32.30000, -26.…\n## $ decimalLongitude                 &lt;dbl&gt; 153.4000, 153.4000, 152.4333, 151.633…\n## $ coordinateUncertaintyInMeters    &lt;dbl&gt; 5000, 5000, 50000, 50000, NA, NA, NA,…\n## $ coordinatePrecision              &lt;dbl&gt; 0.01667, 0.01667, NA, NA, NA, NA, NA,…\n## $ elevation                        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ elevationAccuracy                &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ depth                            &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ depthAccuracy                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ eventDate                        &lt;dttm&gt; 1987-03-05, 1983-11-30, NA, NA, NA, …\n## $ day                              &lt;dbl&gt; 5, 30, NA, NA, NA, NA, NA, NA, NA, 23…\n## $ month                            &lt;dbl&gt; 3, 11, NA, NA, NA, NA, NA, NA, NA, 2,…\n## $ year                             &lt;dbl&gt; 1987, 1983, NA, NA, NA, NA, NA, NA, N…\n## $ taxonKey                         &lt;dbl&gt; 2427866, 2427866, 2427866, 2427866, 2…\n## $ speciesKey                       &lt;dbl&gt; 10759325, 10759325, 10759325, 1075932…\n## $ basisOfRecord                    &lt;chr&gt; \"MACHINE_OBSERVATION\", \"MACHINE_OBSER…\n## $ institutionCode                  &lt;chr&gt; \"ANWC\", \"ANWC\", \"WAM\", \"WAM\", \"SAMA\",…\n## $ collectionCode                   &lt;chr&gt; \"Sounds\", \"Sounds\", \"REPT\", \"REPT\", \"…\n## $ catalogNumber                    &lt;chr&gt; \"X06195\", \"X04978\", \"R68284\", \"R42442…\n## $ recordNumber                     &lt;chr&gt; \"CDMNo A20 ProgNo 04\", \"CDMNo A8 Prog…\n## $ identifiedBy                     &lt;chr&gt; NA, NA, \"MAHONEY, M.\", \"LIEM, D.S.\", …\n## $ dateIdentified                   &lt;dttm&gt; NA, NA, 1980-01-01, 1973-01-01, NA, …\n## $ license                          &lt;chr&gt; \"CC_BY_4_0\", \"CC_BY_4_0\", \"CC_BY_4_0\"…\n## $ rightsHolder                     &lt;chr&gt; \"CSIRO\", \"CSIRO\", NA, NA, NA, NA, NA,…\n## $ recordedBy                       &lt;chr&gt; \"Stewart, D.\", \"Stewart, D.\", \"Mahone…\n## $ typeStatus                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ establishmentMeans               &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ lastInterpreted                  &lt;dttm&gt; 2023-11-29 14:54:09, 2023-11-29 14:5…\n## $ mediaType                        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, \"…\n## $ issue                            &lt;chr&gt; \"CONTINENT_DERIVED_FROM_COORDINATES;T…\n## $ source                           &lt;chr&gt; \"GBIF\", \"GBIF\", \"GBIF\", \"GBIF\", \"GBIF…\n\n\n\nlength(colnames(ala_data))\n\n[1] 25\n\nlength(colnames(gbif_data))\n\n[1] 51\n\n\nComparing the column names is important because the function we will use merges data based on shared column names. Therefore, we want any shared variables across datasets, such as scentific name or decimal coordinates, to also have the same column name in both dataframes. If a column containing latitude values is named Latitude in one dataset and latitude in the other, the final dataset will have two columns, instead of one single latitude column.\nHere we will show how to do a quick inspection using the base intersect() and setdiff() functions, but there are some great packages available to conduct a more complete comparison, such as the waldo package, or the Arsenal package’s comparedf() function.\n\n# waldo::compare(ala_data, gbif_data, max_diffs = 100)\n\n# Quick comparison\ncommon_cols &lt;- intersect(names(ala_data), names(gbif_data))\n\n# Find columns unique to each dataset\nunique_ala_data &lt;- setdiff(names(ala_data), names(gbif_data))\nunique_gbif_data &lt;- setdiff(names(gbif_data), names(ala_data))\n\n# Summary\nsprintf(\"Number of common columns: %i\", length(common_cols))\n\n[1] \"Number of common columns: 21\"\n\nsprintf(\"Common column names: %s\", paste(common_cols, collapse = \", \"))\n\n[1] \"Common column names: decimalLatitude, decimalLongitude, eventDate, scientificName, occurrenceStatus, basisOfRecord, kingdom, taxonRank, phylum, class, order, family, genus, species, countryCode, locality, stateProvince, coordinateUncertaintyInMeters, coordinatePrecision, occurrenceID, source\"\n\nsprintf(\"Columns unique to ala_data: %s\", unique_ala_data)\n\n[1] \"Columns unique to ala_data: taxonConceptID\"  \n[2] \"Columns unique to ala_data: recordID\"        \n[3] \"Columns unique to ala_data: dataResourceName\"\n[4] \"Columns unique to ala_data: dcterms:license\"",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dataset integration</span>"
    ]
  },
  {
    "objectID": "access_integration.html#selecting-and-renaming-columns",
    "href": "access_integration.html#selecting-and-renaming-columns",
    "title": "8  Dataset integration",
    "section": "8.3 Selecting and renaming columns",
    "text": "8.3 Selecting and renaming columns\nSubset each dataset, selecting only the columns or variables that you want to have in the final dataset. Merging a subset of only the needed columns can reduce clutter in the merged dataset.\nThis is just an example of selecting columns; the columns you select will depend on your requirements:\n\ncolumns_keep_data_A &lt;- c(\"column1\", \"column2\", \"column3\", \"column4\", \"column5\")\ndata_A_subset &lt;- dplyr::select(data_A, all_of(columns_keep_data_A))\n\nRepeat for the other dataset. Remember, your column names may differ between datasets, so you should refer to your comparisons to determine which name to use when selecting for each dataset, and then rename those columns to match the first dataset. The order of operations here is subset -&gt; conform names -&gt; merge.\n\ncolumns_keep_data_B &lt;- c(\n  \"column_a\", \"column_s\", \"column_d\", \"column_f\", \"column_g\"\n)\ndata_B_subset &lt;- dplyr::select(data_B, all_of(columns_keep_data_B))\ndata_B_subset_renamed &lt;- dyplr::rename(data_B_subset,\n  column1 = column_a,\n  column2 = column_s,\n  column3 = column_d,\n  column4 = column_f,\n  column5 = column_g\n)\n\n\n\n\n\n\n\nNote\n\n\n\nNote, instead of renaming columns to match a particular dataset, you can of course pick your own column naming scheme, and rename the other datasets to match.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dataset integration</span>"
    ]
  },
  {
    "objectID": "access_integration.html#merging-datasets",
    "href": "access_integration.html#merging-datasets",
    "title": "8  Dataset integration",
    "section": "8.4 Merging datasets",
    "text": "8.4 Merging datasets\nWe can merge the datasets using dplyr::bind_rows(). This function binds data frames on top of each other, by matching columns by name. Dataframes that were missing columns present in another dataframe will have NA values for that column.\n\nmerged_data &lt;- dplyr::bind_rows(ala_data, gbif_data)\nwrite.csv(merged_data, \"data/galah/chloris.csv\")\n\n\n\n\n\n\n\nCaution\n\n\n\nThe bind_rows() function requires columns of the same name to have the same data type. If you get an error, check the data types of the flagged columns in each of your datasets and conform them to the same data type.\n\n\nAfter mering datasets, you may see many rows of NA values, depending on whether those columns were shared or not. This is a good time to look through the merged dataset and check if the merge went as expected. You can start by using the inspection code or packages mentioned above. Note that some of these steps are also cleaning steps that will be repeated later in detail. The focus here is primarily to identify any obvious merge issues that can be resolved before moving on.\nSome things to check are: - Are there any columns missing that should be present? - Are there any columns that should be present but are missing? - Are there any unexpected columns that you didn’t intend to include? - Are there any unexpected values, such as NA values in columns that you expected to be shared and have values for all records?\n\n# Check for missing values\nlibrary(\"dplyr\")\n\nmerged_data %&gt;%\n  dplyr::group_by(source) %&gt;%\n  dplyr::summarise(across(everything(), ~ sum(is.na(.)),\n    .names =\n      \"na_in_{.col}\"\n  )) %&gt;%\n  # reshape for easier comparison\n  tidyr::pivot_longer(\n    cols = -source, names_to = \"column\", names_prefix =\n      \"source_\"\n  ) %&gt;%\n  tidyr::pivot_wider(names_from = source, values_from = value) %&gt;%\n  # add percentage #TODO\n  dplyr::mutate(percentage = round(100 * (GBIF + ALA) / nrow(merged_data), 2)) %&gt;%\n  dplyr::arrange(desc(percentage)) %&gt;%\n  dplyr::filter(percentage &lt; 55 & percentage &gt; 45) %&gt;%\n  head(10)\n\n# A tibble: 10 × 4\n   column                                   ALA  GBIF percentage\n   &lt;chr&gt;                                  &lt;int&gt; &lt;int&gt;      &lt;dbl&gt;\n 1 na_in_day                               3995   228       54.6\n 2 na_in_month                             3995   225       54.6\n 3 na_in_year                              3995   121       53.3\n 4 na_in_verbatimScientificNameAuthorship  3995    89       52.8\n 5 na_in_issue                             3995    53       52.4\n 6 na_in_gbifID                            3995     0       51.7\n 7 na_in_datasetKey                        3995     0       51.7\n 8 na_in_verbatimScientificName            3995     0       51.7\n 9 na_in_publishingOrgKey                  3995     0       51.7\n10 na_in_taxonKey                          3995     0       51.7\n\n\nThis is one approach that can help - looking at columns ~50% missing to track down potential merge issues (expected a column to be shared and merged but it is missing values in the merged dataset). This method is also generally useful for detecting missing values in columns, which is discussed later in the book.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dataset integration</span>"
    ]
  },
  {
    "objectID": "access_integration.html#summary",
    "href": "access_integration.html#summary",
    "title": "8  Dataset integration",
    "section": "8.5 Summary",
    "text": "8.5 Summary\nWe have briefly introduced how to merge two disparate datasets, including a few data checking producedures relevant to merging data. But it should be noted that some of these checks are generally useful during the data cleaning process, and will appear throughout the book.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dataset integration</span>"
    ]
  },
  {
    "objectID": "access_integration.html#advanced-technique",
    "href": "access_integration.html#advanced-technique",
    "title": "8  Dataset integration",
    "section": "8.6 Advanced technique",
    "text": "8.6 Advanced technique\nPerforming checks and operations on more than one dataset using separate objects like we have shown above is a good way to get started. A more efficient option can be to use a list of datasets and perform operations on the list, particuarly when integrating many datasets. Using a list reduces the potential for mistakes that can occur when duplicating code. Another option would be a for loop, or the purrr package.\n\n# Examples on how to get started with a list of datasets:\ndatasets &lt;- list(\n  ala = ala_data,\n  gbif = gbif_data\n)\n# Check the number of records in each dataset\nlapply(datasets, nrow)\n# Check the number of columns in each dataset\nlapply(datasets, ncol)\n# Check the column names in each dataset\nlapply(datasets, colnames)\n# With apply functions we can operate over list elements with custom functions\ndatasets_source &lt;- lapply(names(datasets), function(name) {\n  datasets[[name]]$source &lt;- name\n  datasets[[name]]\n})",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dataset integration</span>"
    ]
  },
  {
    "objectID": "access_integration.html#alternative-method-spocc-package",
    "href": "access_integration.html#alternative-method-spocc-package",
    "title": "8  Dataset integration",
    "section": "8.7 Alternative method: spocc package",
    "text": "8.7 Alternative method: spocc package\nUsing spocc package to download data from GBIF and ALA with a combined query:\n\nlibrary(spocc)\nout &lt;- occ(\n  query = \"Litoria chloris\",\n  from = c(\"gbif\", \"ala\"),\n  gbifopts = list(hasCoordinate = TRUE), limit = 10\n)\nhead(out$gbif$data[[1]], 3) # / out$ala$data\n\n# A tibble: 3 × 74\n  name           longitude latitude issues prov  key   scientificName datasetKey\n  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;     \n1 Litoria chlor…      153.    -28.2 cdc    gbif  3909… Litoria chlor… e3ce628e-…\n2 Litoria chlor…      154.    -28.5 cdc    gbif  3749… Litoria chlor… e3ce628e-…\n3 Litoria chlor…      153     -30.5 cdc    gbif  3909… Litoria chlor… e3ce628e-…\n# ℹ 66 more variables: publishingOrgKey &lt;chr&gt;, installationKey &lt;chr&gt;,\n#   hostingOrganizationKey &lt;chr&gt;, publishingCountry &lt;chr&gt;, protocol &lt;chr&gt;,\n#   lastCrawled &lt;chr&gt;, lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, basisOfRecord &lt;chr&gt;,\n#   occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;,\n#   classKey &lt;int&gt;, orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;,\n#   speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, …\n\n\nThe occ2df() function converts the results into a single data frame. Note: this function doesn’t handle duplicate observations, you still need to check for duplicates and decide how to handle them (see duplicates section #TODO link).\n\nout_data &lt;- occ2df(out, what = \"data\")\nhead(out_data, 3)\n\n# A tibble: 3 × 6\n  name                              longitude latitude prov  date       key     \n  &lt;chr&gt;                                 &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;   \n1 Litoria chloris (Boulenger, 1892)      153.    -28.2 gbif  2022-02-20 3909517…\n2 Litoria chloris (Boulenger, 1892)      154.    -28.5 gbif  2022-02-09 3749064…\n3 Litoria chloris (Boulenger, 1892)      153     -30.5 gbif  2022-03-03 3909507…\n\n\nThis is a fast way to get started, but it doesn’t include all returned data columns. If we need those columns, we can manually bind the data from each source.\n\nocc_ala &lt;- occ2df(out$ala)\nocc_gbif &lt;- occ2df(out$gbif)\n# bind_occ &lt;- dplyr::bind_rows(occ_ala, occ_gbif)\n\nHere we get a helpful error. The bind_rows function requires columns of the same name to have the same data type, and the error message tells us that month is a character in one dataset and an integer in the other. We can solve this by converting one of the columns to match, and try again.\n\ntypeof(occ_ala$recordedBy)\n\n[1] \"list\"\n\nocc_ala$month &lt;- as.integer(occ_ala$month)\n\n# recordedBy column is also different so we will fix this as well\ntypeof(occ_ala$recordedBy)\n\n[1] \"list\"\n\nocc_ala$recordedBy &lt;- as.character(occ_ala$recordedBy)\n\n# Now we can successfully bind the data\nbind_occ &lt;- dplyr::bind_rows(occ_ala, occ_gbif)\n\nNow we inspect the bind_occ data set for any issues (using techniques discussed above). Some examples:\nThe field class has a typo in one dataset, the result is that our data contains one column classs and one class. We can fix this with the coalesce() function from dplyr. This finds the first non-missing value at each position. We can then remove classs.\n\nbind_occ$class &lt;- dplyr::coalesce(bind_occ$class, bind_occ$classs)\nbind_occ &lt;- dplyr::select(bind_occ, -classs)\n\nThere are NA values for scientificName from the ALA. But we also have column species with values for both datasets, so this is not an issue here, we can just use species.\nLooking at the species column, there are two different names. This is because the ALA taxonomic backbone for fauna is the Australian Faunal Directory (AFD), while GBIF uses a taxonomic backbone of their own. In this case, GBIF recognised our query for Litoria chloris as a synonym of Ranoidea chloris. 1 We will talk more about taxonomy issues like this and how to approach them later in the book.",
    "crumbs": [
      "Accessing biodiversity data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Dataset integration</span>"
    ]
  },
  {
    "objectID": "cleaning_intro.html#record-keeping",
    "href": "cleaning_intro.html#record-keeping",
    "title": "Cleaning biodiversity data",
    "section": "Record keeping",
    "text": "Record keeping\nKeeping a complete record of your data cleaning steps is crucial and helps to maintain the integrity of your research. It ensures transparency in how the data were handled and processed, and allows for reproducibility, such that others may replicate your steps to achieve the same outcome. In practice, a record should include where data were sourced, and any changes made to the original data, such as correcting errors, removing duplicates, or filtering out data points.",
    "crumbs": [
      "Cleaning biodiversity data"
    ]
  },
  {
    "objectID": "cleaning_intro.html#reproducible-workflows",
    "href": "cleaning_intro.html#reproducible-workflows",
    "title": "Cleaning biodiversity data",
    "section": "Reproducible workflows",
    "text": "Reproducible workflows\nA reproducible workflow is code that given the same inputs, will produce the same outputs each time, regardless of when or where it is run. Meaning, it should be portable and work on any machine, without needing to make changes to the code such as changing local file paths. Reproducible workflows are recognised as a key component for research practices, and data science applications in general.\nUtilising notebooks or dynamic documents in R is a great first step towards reproducible workflows. We recommend using R Markdown, or the next-generation version called Quarto. These packages provide file formats that allow you to interleave plain text, code, and outputs, into a single document. Besides being a powerful way to communicate your work and colaborate with others, they offer a helpful way to integrate record keeping directly into your cleaning and analysis process.",
    "crumbs": [
      "Cleaning biodiversity data"
    ]
  },
  {
    "objectID": "cleaning_intro.html#version-control",
    "href": "cleaning_intro.html#version-control",
    "title": "Cleaning biodiversity data",
    "section": "Version control",
    "text": "Version control\nVersion control refers to the process of tracking and managing changes that are made to code. We recommend using a version control system like Git, and an online repository hosting service such as GitHub or GitLab, but there are many others to choose from. These services host your code files (privately or publicly), and track every modification made to your code. This is extremely useful in data cleaning, where you might make many small changes over time. If you encounter a problem or need to revisit a previous stage of your analysis, version control allows you to easily revert to earlier versions of your work. It also offers a safer way for multiple people to work on the same project, or share code with others.\n\n\n\n\n\n\nCaution\n\n\n\nGit is not a backup! It is a very useful version control system, but it is not advised to use it as a backup system. You should always maintain a separate, dedicated backup system for your files and data.",
    "crumbs": [
      "Cleaning biodiversity data"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#setup",
    "href": "cleaning_standardisation.html#setup",
    "title": "9  General utility functions",
    "section": "9.1 Setup",
    "text": "9.1 Setup\n\nlibrary(\"galah\")\n\n\nAttaching package: 'galah'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\ngalah_config(atlas = \"Australia\") # default\ngalah_config(email = Sys.getenv(\"ALA_EMAIL\"))\n\n\nresult &lt;- galah_call() |&gt;\n  galah_identify(\"Litoria\") |&gt;\n  galah_filter(year &gt;= 2020, cl22 == \"Tasmania\") |&gt;\n  atlas_occurrences()\n\nThis query will return 1,677 records\n\n\n\nChecking queue\nCurrent queue size: 1 inqueue  running \n\nresult |&gt; head()\n\n# A tibble: 6 × 8\n  decimalLatitude decimalLongitude eventDate           scientificName \n            &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;          \n1           -43.5             147. 2021-06-01 00:00:00 Litoria ewingii\n2           -43.4             147. 2023-01-18 01:24:00 Litoria ewingii\n3           -43.4             147. 2020-09-05 00:00:00 Litoria ewingii\n4           -43.4             146. 2020-01-02 00:00:00 Litoria ewingii\n5           -43.4             146. 2020-01-02 00:00:00 Litoria ewingii\n6           -43.4             146. 2020-01-02 00:00:00 Litoria ewingii\n# ℹ 4 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#dates",
    "href": "cleaning_standardisation.html#dates",
    "title": "9  General utility functions",
    "section": "9.2 Dates",
    "text": "9.2 Dates\nSome use cases may require dates beyond a simple year value. Standardising dates involves ensuring that the variables in a dataset have values that conform to a consistent and standard format. An example of unstandardised data is having varied date formats (e.g. DD/MM/YYYY for some entries and MM/DD/YYYY for others). This may be necessary when integrating data from multiple sources, but it is important to remember that there can be inconsistencies even within a single source dataset.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#column-classes",
    "href": "cleaning_standardisation.html#column-classes",
    "title": "9  General utility functions",
    "section": "9.3 Column classes",
    "text": "9.3 Column classes\nWe can check for obvious inconsistencies using the classes of each column. We can do this with summary tables like a skimr report, or with base R. Below is a simple example where our decimalLatitude column is numeric, which is what we expect so in this case there is no problem. But as an example, if we change just one of the values to a degrees minutes seconds format, we can see that the class for the column changes to character.\n\nsapply(result, class)\n\n$decimalLatitude\n[1] \"numeric\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$recordID\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"\n\n$occurrenceStatus\n[1] \"character\"\n\n# Change one of the values to a degrees minutes seconds format\nresult$decimalLatitude[5] &lt;- \"40° 51' 59 N\"\nsapply(result, class)\n\n$decimalLatitude\n[1] \"character\"\n\n$decimalLongitude\n[1] \"numeric\"\n\n$eventDate\n[1] \"POSIXct\" \"POSIXt\" \n\n$scientificName\n[1] \"character\"\n\n$taxonConceptID\n[1] \"character\"\n\n$recordID\n[1] \"character\"\n\n$dataResourceName\n[1] \"character\"\n\n$occurrenceStatus\n[1] \"character\"",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#unexpected-values",
    "href": "cleaning_standardisation.html#unexpected-values",
    "title": "9  General utility functions",
    "section": "9.4 Unexpected values",
    "text": "9.4 Unexpected values\n\nChecking for unexpected values: this is a generic method but the resolution logic depends on the issue (taxonomic, categories, strings, etc.)\n\nContext: a merged dataset pertaining to a single species (using data frame from cleaning_integration.qmd). Species is L. chloris\n\nAssumption: species column contains only one species\n\nMethod: unique(merged_data$species)\nResult: two species names\nResolution: conform to one species name (assign)\n\nAssumption: country code contains only one country\n\nMethod: unique(merged_data$country_code)\nResult: AU, NA, JP\nResolution: Investigate NA and assign, investigate JP since chloris is an Australian species\n\n\n\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nmerged_data &lt;- read.csv(\"data/galah/chloris.csv\")\n\nunique(merged_data$countryCode)\n\n[1] \"AU\" NA   \"JP\"\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]\n\n        X decimalLatitude decimalLongitude           eventDate\n3995 3995         24.4856         151.5842 2013-12-30 14:00:00\n6722 6722         24.4856         151.5842 2013-12-30 14:00:00\n                        scientificName\n3995                   Litoria chloris\n6722 Litoria chloris (Boulenger, 1892)\n                                                                taxonConceptID\n3995 https://biodiversity.org.au/afd/taxa/f532b88a-a6c0-4006-aa24-77e3d645530e\n6722                                                                      &lt;NA&gt;\n                                 recordID                  dataResourceName\n3995 c08e641e-cf01-4f0f-b5ad-c3b8fcff4da4 ALA species sightings and OzAtlas\n6722                                 &lt;NA&gt;                              &lt;NA&gt;\n     occurrenceStatus     basisOfRecord  kingdom taxonRank   phylum    class\n3995          PRESENT HUMAN_OBSERVATION Animalia   species Chordata Amphibia\n6722          PRESENT HUMAN_OBSERVATION Animalia   SPECIES Chordata Amphibia\n     order        family    genus         species countryCode locality\n3995 Anura       Hylidae  Litoria Litoria chloris          JP mt bucca\n6722 Anura Pelodryadidae Ranoidea Litoria chloris          JP mt bucca\n     stateProvince coordinateUncertaintyInMeters coordinatePrecision\n3995          &lt;NA&gt;                          5000                  NA\n6722          &lt;NA&gt;                          5000                  NA\n       dcterms.license                         occurrenceID source     gbifID\n3995 CC-BY-NC 3.0 (Au)             52c2c6973dff6b1593e42ef9    ALA         NA\n6722              &lt;NA&gt; c08e641e-cf01-4f0f-b5ad-c3b8fcff4da4   GBIF 1632945208\n                               datasetKey infraspecificEpithet\n3995                                 &lt;NA&gt;                   NA\n6722 84a649ce-ff81-420d-9c41-aa1de59e3766                   NA\n     verbatimScientificName verbatimScientificNameAuthorship individualCount\n3995                   &lt;NA&gt;                             &lt;NA&gt;              NA\n6722        Litoria chloris                (Boulenger, 1893)              NA\n                         publishingOrgKey elevation elevationAccuracy depth\n3995                                 &lt;NA&gt;        NA                NA    NA\n6722 adc174cd-c752-4eee-9630-7c1209eb1c4a        NA                NA    NA\n     depthAccuracy day month year taxonKey speciesKey institutionCode\n3995            NA  NA    NA   NA       NA         NA            &lt;NA&gt;\n6722            NA  30    12 2013  2427866   10759325            &lt;NA&gt;\n     collectionCode catalogNumber\n3995           &lt;NA&gt;          &lt;NA&gt;\n6722           &lt;NA&gt;          &lt;NA&gt;\n                                                                                       recordNumber\n3995                                                                                           &lt;NA&gt;\n6722 https://biocollect.ala.org.au/sightings/bioActivity/index/0d598d06-a077-48e1-b632-e856bc63f264\n     identifiedBy dateIdentified   license rightsHolder    recordedBy\n3995         &lt;NA&gt;           &lt;NA&gt;      &lt;NA&gt;         &lt;NA&gt;          &lt;NA&gt;\n6722         &lt;NA&gt;           &lt;NA&gt; CC_BY_4_0         &lt;NA&gt; Kylie, Carman\n     typeStatus establishmentMeans     lastInterpreted mediaType issue\n3995       &lt;NA&gt;               &lt;NA&gt;                &lt;NA&gt;      &lt;NA&gt;  &lt;NA&gt;\n6722       &lt;NA&gt;               &lt;NA&gt; 2023-08-26 03:07:16      &lt;NA&gt;  &lt;NA&gt;\n\n# where should the point be? can check the `locality` column and coordinates\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$decimalLatitude\n\n[1] 24.4856 24.4856\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$decimalLongitude\n\n[1] 151.5842 151.5842\n\nmerged_data[which(merged_data$countryCode == \"JP\"), ]$locality\n\n[1] \"mt bucca\" \"mt bucca\"\n\n# mt bucca is in australia but the coordinates are incorrect\n# the latitude is missing an \"-\"\n# we can fix this and check the result (#TODO map vis)\nfixed &lt;- merged_data %&gt;%\n  mutate(decimalLatitude = ifelse(countryCode == \"JP\", paste0(\n    \"-\",\n    decimalLatitude\n  ), decimalLatitude)) %&gt;%\n  mutate(countryCode = ifelse(countryCode == \"JP\", \"AU\", countryCode))",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_standardisation.html#summary",
    "href": "cleaning_standardisation.html#summary",
    "title": "9  General utility functions",
    "section": "9.5 Summary",
    "text": "9.5 Summary\nIn this chapter, we learned a few basic checks for cleaning datasets, including methods to detect inconsistencies in date formats, coordinate systems, and units.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>General utility functions</span>"
    ]
  },
  {
    "objectID": "cleaning_duplicates.html#check-for-duplicate-records",
    "href": "cleaning_duplicates.html#check-for-duplicate-records",
    "title": "10  Duplicates and missing records",
    "section": "10.1 Check for duplicate records",
    "text": "10.1 Check for duplicate records\nDuplicates records can happen when using aggregated data sources. In this section we will cover detection and handling of duplicate records.\n\n# Check for duplicate records across the dataset\n# duplicated_records &lt;- merged_data[duplicated(merged_data), ]\n# Targeted checks\n# duplicated_records[which(duplicated(merged_data$occurrenceID)), ]",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Duplicates and missing records</span>"
    ]
  },
  {
    "objectID": "cleaning_duplicates.html#check-for-missing-records",
    "href": "cleaning_duplicates.html#check-for-missing-records",
    "title": "10  Duplicates and missing records",
    "section": "10.2 Check for missing records",
    "text": "10.2 Check for missing records\n\nlibrary(skimr)\niris %&gt;%\n  skim() %&gt;%\n  dplyr::filter(n_missing &gt; 0)\n\n# A tibble: 0 × 15\n# ℹ 15 variables: skim_type &lt;chr&gt;, skim_variable &lt;chr&gt;, n_missing &lt;int&gt;,\n#   complete_rate &lt;dbl&gt;, factor.ordered &lt;lgl&gt;, factor.n_unique &lt;int&gt;,\n#   factor.top_counts &lt;chr&gt;, numeric.mean &lt;dbl&gt;, numeric.sd &lt;dbl&gt;,\n#   numeric.p0 &lt;dbl&gt;, numeric.p25 &lt;dbl&gt;, numeric.p50 &lt;dbl&gt;, numeric.p75 &lt;dbl&gt;,\n#   numeric.p100 &lt;dbl&gt;, numeric.hist &lt;chr&gt;",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Duplicates and missing records</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#basic-string-manipulation",
    "href": "cleaning_manipulating_strings.html#basic-string-manipulation",
    "title": "11  Strings",
    "section": "11.1 Basic string manipulation",
    "text": "11.1 Basic string manipulation\nThe stringr package provides a number of useful functions for manipulating strings, many of which are useful when dealing with biodiversity data.\n\nlibrary(stringr)\nstr_trim(\"  Genus specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trim(\"  Genus specificus  \", side = \"left\")\n\n[1] \"Genus specificus  \"\n\nstr_squish(\"  Genus   specificus  \")\n\n[1] \"Genus specificus\"\n\nstr_trunc(\"Genus specificus\", width = 10, side = \"right\")\n\n[1] \"Genus s...\"\n\nstr_split(\"Genus specificus\", \" \")\n\n[[1]]\n[1] \"Genus\"      \"specificus\"\n\nstr_c(\"Genus\", \"specificus\", sep = \"_\")\n\n[1] \"Genus_specificus\"",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#matching",
    "href": "cleaning_manipulating_strings.html#matching",
    "title": "11  Strings",
    "section": "11.2 Matching",
    "text": "11.2 Matching\nMatching strings is a common task when working with biodiversity data. etc etc.\n\n11.2.1 Basic matching\nThe stringr package provides a number of functions for matching strings using patterns.\n\n# detect and remove\nstr_detect(\"Genus specificus\", \"Genus\")\n\n[1] TRUE\n\nstr_remove(\"Genus specificus\", pattern = \"Genus \")\n\n[1] \"specificus\"\n\n# locate and subset\nrecords &lt;- c(\"Genus\", \"species\", \"Genus species\", \"Difgenus difspecies\")\nstr_locate(records, \"Genus\")\n\n     start end\n[1,]     1   5\n[2,]    NA  NA\n[3,]     1   5\n[4,]    NA  NA\n\nstr_subset(records, \"Genus\")\n\n[1] \"Genus\"         \"Genus species\"\n\n\n\n\n11.2.2 Regex matching\nThe examples above demonstrate the use of basic patterns. But for cases that need more specific or advanced matching we can use regular expressions (regex). Regex is a powerful tool used to match patterns in strings, replace characters in strings, and extract substrings from strings. Regex can be complex and unintuitive, but there are websites available, such as Regex Generator, that are extremely helpful. Here we explore a few basic examples, and keep in mind that these methods can be applied to both column name strings and column values. In the case of column names, regex can be useful when conforming datasets (see Integration) or to meet a stylistic requirement. Applied to column values, there is a range of utility, such as unifying the formatting of taxonomic or location names.\nThe str_view() function is particularly useful for exploring regular expressions to see pattern matches. The results are shown in the console, and elements matched by the regex are surrounded with angle brackets &lt; &gt;.\n\n# Match the first word in the string (the genus)\nstr_view(tree_kangaroo$scientificName, \"^[A-Z][a-z]+\")\n\n [1] │ &lt;Dendrolagus&gt; lumholtzi\n [2] │ &lt;Dendrolagus&gt; lumholtzi\n [3] │ &lt;Dendrolagus&gt; bennettianus\n [4] │ &lt;Dendrolagus&gt; bennettianus\n [5] │ &lt;Dendrolagus&gt; bennettianus\n [6] │ &lt;Dendrolagus&gt; lumholtzi\n [7] │ &lt;Dendrolagus&gt; lumholtzi\n [8] │ &lt;Dendrolagus&gt; lumholtzi\n [9] │ &lt;Dendrolagus&gt; lumholtzi\n[10] │ &lt;Dendrolagus&gt; lumholtzi\n[11] │ &lt;Dendrolagus&gt; bennettianus\n[12] │ &lt;Dendrolagus&gt; bennettianus\n[13] │ &lt;Dendrolagus&gt; lumholtzi\n[14] │ &lt;Dendrolagus&gt; lumholtzi\n[15] │ &lt;Dendrolagus&gt; lumholtzi\n[16] │ &lt;Dendrolagus&gt; lumholtzi\n[17] │ &lt;Dendrolagus&gt; lumholtzi\n[18] │ &lt;Dendrolagus&gt; lumholtzi\n[19] │ &lt;Dendrolagus&gt; lumholtzi\n[20] │ &lt;Dendrolagus&gt; lumholtzi\n... and 1232 more\n\n# Match only the second word (species name)\nstr_view(tree_kangaroo$scientificName, \"(?&lt;=\\\\s)[a-z]+\")\n\n [1] │ Dendrolagus &lt;lumholtzi&gt;\n [2] │ Dendrolagus &lt;lumholtzi&gt;\n [3] │ Dendrolagus &lt;bennettianus&gt;\n [4] │ Dendrolagus &lt;bennettianus&gt;\n [5] │ Dendrolagus &lt;bennettianus&gt;\n [6] │ Dendrolagus &lt;lumholtzi&gt;\n [7] │ Dendrolagus &lt;lumholtzi&gt;\n [8] │ Dendrolagus &lt;lumholtzi&gt;\n [9] │ Dendrolagus &lt;lumholtzi&gt;\n[10] │ Dendrolagus &lt;lumholtzi&gt;\n[11] │ Dendrolagus &lt;bennettianus&gt;\n[12] │ Dendrolagus &lt;bennettianus&gt;\n[13] │ Dendrolagus &lt;lumholtzi&gt;\n[14] │ Dendrolagus &lt;lumholtzi&gt;\n[15] │ Dendrolagus &lt;lumholtzi&gt;\n[16] │ Dendrolagus &lt;lumholtzi&gt;\n[17] │ Dendrolagus &lt;lumholtzi&gt;\n[18] │ Dendrolagus &lt;lumholtzi&gt;\n[19] │ Dendrolagus &lt;lumholtzi&gt;\n[20] │ Dendrolagus &lt;lumholtzi&gt;\n... and 849 more\n\n\n\n\n11.2.3 Replacements\nIn base R the gsub() function can be used for pattern replacement. In stringr, the str_replace() function can be used to replace the first match of a string. The str_replace_all() function can be used to replace all matches.\n\n# str_replace() example\n\nBase example:\n\ntree_kangaroo$scientificName &lt;- gsub(\n  pattern = \"Dendrolagus\",\n  replacement = \"Newname\",\n  x = tree_kangaroo$scientificName\n)",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#case-style",
    "href": "cleaning_manipulating_strings.html#case-style",
    "title": "11  Strings",
    "section": "11.3 Case style",
    "text": "11.3 Case style\nCase style can vary across data providers due to variable naming conventions. There are some basic functions available to change the case of strings in stringr:\n\nstr_to_lower(plants$scientific_name[1])\n\n[1] \"hakea eriantha\"\n\nstr_to_upper(plants$scientific_name[1])\n\n[1] \"HAKEA ERIANTHA\"\n\nstr_to_title(plants$scientific_name[1])\n\n[1] \"Hakea Eriantha\"\n\n\nIn some cases a more specific detection and replacement is required. For example, the World Register of Marine Species (WoRMS) uses a combination of lower case (scientific_name) and camel case (isExtinct). However, the Australian Fauna Directory (AFD) uses screaming snake case e.g. SCIENTIFIC_NAME. To work with both, case differences can be conformed to a single style, but the format you choose is a matter of personal preference.\n\n\nworms_small &lt;- head(worms)\n\n# gsub is a base R function for replacing strings\ncolnames(worms_small) &lt;- sapply(colnames(worms_small), function(name) {\n  name &lt;- tolower(gsub(\"([a-z])([A-Z])\", \"\\\\1_\\\\2\", name))\n  gsub(\"^_\", \"\", name)\n})\n\n# stringr version of above (with a slightly different regex approach)\ncolnames(worms_small) &lt;- sapply(colnames(worms_small), function(name) {\n  str_to_lower(str_replace_all(name, \"(?&lt;=\\\\p{Ll})(\\\\p{Lu})\", \"_\\\\1\"))\n})",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_manipulating_strings.html#simple-case-study",
    "href": "cleaning_manipulating_strings.html#simple-case-study",
    "title": "11  Strings",
    "section": "11.4 Simple case study",
    "text": "11.4 Simple case study\nWe will use the janitor R package to explore whether our elephant data has any string issues. The function tabyl will compute a counts and percent of total rows for each unique value.\n\nlibrary(dplyr)\nlibrary(janitor)\nafrican_ele &lt;- arrow::read_parquet(\"data/gbif/elephant\")\nafrican_ele |&gt;\n  pull(stateProvince) |&gt;\n  tabyl() |&gt;\n  tibble() |&gt;\n  print(n = 20)\n\n# A tibble: 197 × 4\n   `pull(african_ele, stateProvince)`     n   percent valid_percent\n   &lt;chr&gt;                              &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez                                 1 0.0000561     0.0000879\n 2 Al Qahirah                             1 0.0000561     0.0000879\n 3 Alibori                              601 0.0337        0.0528   \n 4 Arusha                               327 0.0183        0.0287   \n 5 Arusha Region                          1 0.0000561     0.0000879\n 6 Atacora                              366 0.0205        0.0322   \n 7 Atakora                              249 0.0140        0.0219   \n 8 Balaka                                 8 0.000449      0.000703 \n 9 Bassila                                1 0.0000561     0.0000879\n10 Batha                                  1 0.0000561     0.0000879\n11 Bauchi                                 7 0.000393      0.000615 \n12 Bengo                                  3 0.000168      0.000264 \n13 Bizerte                                2 0.000112      0.000176 \n14 Borgou                                 7 0.000393      0.000615 \n15 Bouaflé                                3 0.000168      0.000264 \n16 Bouna                                  1 0.0000561     0.0000879\n17 Budongo Forest                         1 0.0000561     0.0000879\n18 Bushenyi                              84 0.00471       0.00738  \n19 Cabo Delgado                           3 0.000168      0.000264 \n20 Cape Prov.                             2 0.000112      0.000176 \n# ℹ 177 more rows\n\n\nFrom the tabyl output, we can see there are few different variations of Province, Prov., Prov. As an example, we will correct these with the tidyverse packages stringr, dplyr, tidyr as well as glue.\n\nlibrary(glue)\n# Create a regular expression to match Prov. and Prov\npattern &lt;- regex(\"Prov(?![:lower:])\")\n# Use `str_subset` to pull out the cases that match our pattern\n# Confirm that these are the problematic ones\n# Assign these into an object\nstr_subset(african_ele$stateProvince, pattern = pattern)\n\n [1] \"Cape Prov.\"        \"Cape Prov.\"        \"West Nile Prov.\"  \n [4] \"Central Prov\"      \"Central Prov\"      \"Coastal Prov\"     \n [7] \"Northeastern Prov\" \"Central Prov\"      \"Eastern Prov\"     \n[10] \"Coastal Prov\"     \n\ntypos_provinces &lt;- str_subset(african_ele$stateProvince, pattern = pattern)\n\n# Create a new variable `stateProvince_clean`\n# `str_detect` for matches of pattern (returns TRUE for match)\n# `if_else`: if TRUE, the `glue` function will take the first part of the province name enclosed in and join it with word Province.\n# if FALSE , it will just take the corresponding value in stateProvince\n# Note that we are assigning these changes to a new object (`african_ele_2`)\nafrican_ele_2 &lt;- african_ele %&gt;%\n  mutate(stateProvince_clean = if_else(str_detect(stateProvince, pattern = pattern),\n    true = glue('{word(stateProvince, sep = \" P\")} Province'),\n    false = stateProvince\n  ))\n\n# Once we've made the correction we want to check we've done it correctly.\n# ALWAYS CHECK YOUR CORRECTIONS\n# Use the `select` function to isolate columns that `starts_with` \"stateProvince\"\n# Use the `filter` function to subset our the problematic provinces\nafrican_ele_2 %&gt;%\n  select(starts_with(\"stateProvince\")) %&gt;%\n  filter(stateProvince %in% typos_provinces)\n\n# A tibble: 10 × 2\n   stateProvince     stateProvince_clean  \n   &lt;chr&gt;             &lt;glue&gt;               \n 1 Cape Prov.        Cape Province        \n 2 Cape Prov.        Cape Province        \n 3 West Nile Prov.   West Nile Province   \n 4 Central Prov      Central Province     \n 5 Central Prov      Central Province     \n 6 Coastal Prov      Coastal Province     \n 7 Northeastern Prov Northeastern Province\n 8 Central Prov      Central Province     \n 9 Eastern Prov      Eastern Province     \n10 Coastal Prov      Coastal Province     \n\n# Its good practice to check the other values were not affected by your corrections\n# Here we are removing the NA with `drop_na` and subsetting unique rows with `distinct`\nafrican_ele_2 %&gt;%\n  select(starts_with(\"stateProvince\")) %&gt;%\n  tidyr::drop_na() %&gt;%\n  distinct()\n\n# A tibble: 196 × 2\n   stateProvince    stateProvince_clean\n   &lt;chr&gt;            &lt;glue&gt;             \n 1 Southern         Southern           \n 2 Taita Taveta     Taita Taveta       \n 3 Mara             Mara               \n 4 Arusha           Arusha             \n 5 Simiyu           Simiyu             \n 6 Morogoro         Morogoro           \n 7 Mashonaland West Mashonaland West   \n 8 Mpumalanga       Mpumalanga         \n 9 KwaZulu-Natal    KwaZulu-Natal      \n10 Manicaland       Manicaland         \n# ℹ 186 more rows\n\n# Final check\n# Check with the original code that detected the issue\nafrican_ele_2 %&gt;%\n  pull(stateProvince_clean) %&gt;%\n  tabyl() %&gt;%\n  tibble() %&gt;%\n  print(n = 20)\n\n# A tibble: 195 × 4\n   .                  n   percent valid_percent\n   &lt;glue&gt;         &lt;int&gt;     &lt;dbl&gt;         &lt;dbl&gt;\n 1 Agadez             1 0.0000561     0.0000879\n 2 Al Qahirah         1 0.0000561     0.0000879\n 3 Alibori          601 0.0337        0.0528   \n 4 Arusha           327 0.0183        0.0287   \n 5 Arusha Region      1 0.0000561     0.0000879\n 6 Atacora          366 0.0205        0.0322   \n 7 Atakora          249 0.0140        0.0219   \n 8 Balaka             8 0.000449      0.000703 \n 9 Bassila            1 0.0000561     0.0000879\n10 Batha              1 0.0000561     0.0000879\n11 Bauchi             7 0.000393      0.000615 \n12 Bengo              3 0.000168      0.000264 \n13 Bizerte            2 0.000112      0.000176 \n14 Borgou             7 0.000393      0.000615 \n15 Bouaflé            3 0.000168      0.000264 \n16 Bouna              1 0.0000561     0.0000879\n17 Budongo Forest     1 0.0000561     0.0000879\n18 Bushenyi          84 0.00471       0.00738  \n19 Cabo Delgado       3 0.000168      0.000264 \n20 Cape Province      3 0.000168      0.000264 \n# ℹ 175 more rows\n\n\nThere are some other issues that can be corrected in a similar approach:\n\nNorth West, North West District and North-Western\nÀfrica Central, Central Province and Central\nAtacora and Atakora\nCoastal Province and Coastal\n\nWe recommend consulting reputable sources to delineate and consolidate similar values.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Strings</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomy.html#missing-data",
    "href": "cleaning_taxonomy.html#missing-data",
    "title": "12  Taxonomy",
    "section": "12.1 Missing data",
    "text": "12.1 Missing data\nOne issue you might face is that higher taxonomy from different providers may not match. If this is the case, we suggest choosing the data provider with the higher taxonomy that is consistent with your naming authority and use it to back fill the higher taxonomy of the other data sources\n\n# higher_taxonomy &lt;- inverts %&gt;%\n#   select(scientificName) %&gt;%\n#   distinct() %&gt;%\n#   search_taxa()\n\n# higher_taxonomy",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomy.html#filtering-out-taxa",
    "href": "cleaning_taxonomy.html#filtering-out-taxa",
    "title": "12  Taxonomy",
    "section": "12.2 Filtering out taxa",
    "text": "12.2 Filtering out taxa\nDepending on your project’s data scope, it may be necessary to remove certain groups of taxa. Here we present a few use cases, based on some commonly required criteria. This type of taxonomic filtering is particularly useful for large, multi-species datasets.\n\n12.2.1 Introduced or invasive species\nIf your project requires only native species, we can filter out those records using lists available online. Here we are using the list for Australia from the Global Register of Introduced and Invasive Species (GRIIS). After downloading this list, we read it into R, and exclude invasive species from our example dataset:\n\nlibrary(dplyr)\nplants &lt;- arrow::open_dataset(\"data/dap/plants_subset\") |&gt; dplyr::collect()\ngriis_ls &lt;- read.csv(\"./data/lists/GRIIS_Australia_20230331-121730.csv\")\nglimpse(griis_ls)\n\nRows: 2,979\nColumns: 16\n$ scientific_name                  &lt;chr&gt; \"Oenothera longiflora L.\", \"Lampranth…\n$ scientific_name_type             &lt;chr&gt; \"species\", \"species\", \"species\", \"spe…\n$ kingdom                          &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ establishment_means              &lt;chr&gt; \"alien\", \"alien\", \"alien\", \"alien\", \"…\n$ is_invasive                      &lt;chr&gt; \"null\", \"null\", \"null\", \"null\", \"null…\n$ occurrence_status                &lt;chr&gt; \"present\", \"present\", \"present\", \"pre…\n$ checklist.name                   &lt;chr&gt; \"Australia\", \"Australia\", \"Australia\"…\n$ checklist.iso_countrycode_alpha3 &lt;chr&gt; \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"AUS\", \"A…\n$ accepted_name.species            &lt;chr&gt; \"Oenothera longiflora\", \"Lampranthus …\n$ accepted_name.kingdom            &lt;chr&gt; \"Plantae\", \"Plantae\", \"Plantae\", \"Pla…\n$ accepted_name.phylum             &lt;chr&gt; \"Tracheophyta\", \"Tracheophyta\", \"Trac…\n$ accepted_name.class              &lt;chr&gt; \"Magnoliopsida\", \"Magnoliopsida\", \"Ma…\n$ accepted_name.order              &lt;chr&gt; \"Myrtales\", \"Caryophyllales\", \"Erical…\n$ accepted_name.family             &lt;chr&gt; \"Onagraceae\", \"Aizoaceae\", \"Ericaceae…\n$ accepted_name.habitat            &lt;chr&gt; \"[\\\"terrestrial\\\"]\", \"[\\\"terrestrial\\…\n$ accepted_name                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n# Check which species matched the GRIIS list\nmatches &lt;- filter(plants, scientific_name %in% griis_ls$accepted_name.species)\n\n# If you are happy with the matches, you can proceed to remove any records\n# that were matched\nplants_no_griis &lt;- filter(plants, !scientific_name %in% matches)\n\n\n\n\n\n\n\nTip\n\n\n\nYou can apply this concept of filtering to any list of species, or other fields, that you would like to exclude (or include, by removing the ! in the filter() step)\n\n\n\n\n12.2.2 Extinct species\nIn most cases, a year filter applied during your download query should remove most extinct species. Nevertheless, it is important to cross check for extinct species. We can do this using the Interim Register of Marine and Nonmarine Genera (IRMNG). The list is comprehensive and actively maintained. However, much of the data doesn’t go down to species level. As such, we recommend using the following approach to find potentially extinct taxa and further investigate the records that are flagged.\nThe required files are organised by year and can be downloaded from here, and unzipped to your project directory. Below we process the downloaded files and then check for matches in our dataset.\n\nirmng_taxa &lt;- arrow::open_dataset(\"data/lists/IRMNG_genera_DwCA_2023-05-19/taxon_subset\") |&gt;\n  collect()\n\nirmng_sp &lt;- arrow::open_dataset(\"data/lists/IRMNG_genera_DwCA_2023-05-19/speciesprofile\") |&gt;\n  collect()\n\n\n\nlibrary(\"stringr\")\ninverts &lt;- arrow::open_dataset(\"data/galah/inverts\") |&gt; dplyr::collect()\n\nawc_pattern &lt;- \"(awaiting allocation)\"\ninsed_pattern &lt;- \"incertae sedis\"\n\ncleaned_irmng_taxa &lt;- irmng_taxa |&gt;\n  mutate(\n    class = ifelse(str_detect(class, pattern = paste0(awc_pattern, \"|\", insed_pattern)),\n      word(class), class\n    )\n  ) |&gt;\n  filter(taxonomicStatus == \"accepted\") |&gt; # Filter to accepted names\n  filter(\n    kingdom %in% c(\"Animalia\", \"Plantae\"),\n    !kingdom == \"Questionable / non-biota (fossil)\"\n  ) # Filter to Animal and plants - change if working with other kingdoms\n\n# Join with species profile, remove pesky values and filter to extinct taxa\nextinct_irmng &lt;- irmng_taxa |&gt;\n  left_join(irmng_sp, by = \"taxonID\") |&gt;\n  filter(!scientificName == \"Questionable / non-biota (fossil)\") |&gt;\n  filter(isExtinct == TRUE)\n\n# Summary of extinct species by taxonRank\nextinct_irmng$taxonRank |&gt; janitor::tabyl()\n\n extinct_irmng$taxonRank     n      percent\n                   Class    14 5.926177e-04\n                  Family  1675 7.090247e-02\n                   Genus 21718 9.193193e-01\n              Infraclass     1 4.232983e-05\n                   Order   210 8.889265e-03\n                  Phylum     4 1.693193e-04\n                Subclass     2 8.465967e-05\n\n# Create genus\ninverts_2 &lt;- inverts |&gt;\n  mutate(genus = word(scientificName, 1))\n\n# Extract unique extinct genus and remove genus that have punctuation in them\nextinct_genus &lt;- extinct_irmng |&gt;\n  tidyr::drop_na(genus) |&gt;\n  filter(!str_detect(genus, pattern = regex(\"[:punct:]\"))) |&gt;\n  pull(genus) |&gt;\n  unique()\n\n# Check if there are any matches at genus level\ncheck &lt;- inverts_2 |&gt;\n  filter(str_detect(genus, pattern = regex(paste0(extinct_genus, collapse = \"|\")))) |&gt;\n  pull(scientificName) |&gt;\n  unique()\n\nprint(check)\n\n[1] \"Halobates (Halobates) acherontis\"\n\n\nAlternatively, we can use the IUCN to retrieve a list of extinct species that are in their database. See the IUCN API for more information on queries based on species categories. Below we will the rredlist package to interface with the IUCN API. Note that you will need to register for an API token, which can take a day or two to be approved. Then we use the rl_sp_category(\"EX\") to return extinct species, to check against our dataset.\n\n\n# Create IUCN token\nrredlist::rl_use_iucn() # Application can take a day or two!\nusethis::edit_r_environ() # Place the approved token in your R environment\n\nextinct_iucn &lt;- rredlist::rl_sp_category(\"EX\")\nskimr::skim(extinct_iucn)\n\n# Note these are extinct species across the globe\nextinct_sp &lt;- tibble(extinct_iucn$result)\n\n# Find matches\nfilter(inverts, scientificName %in% extinct_sp$scientific_name) # No matches\n\n\n\n12.2.3 Biological attributes and life cycle stages\nIn some cases, you may want to filter out records based on attributes such as sex or life cycle stage, if this metadata is available for your records. In the example below, we download a dataset, including the extra metadata fields needed. We then examine the fields we want to filter by, to see what values are available and how many records are missing values.\n\nlibrary(galah)\n\ngalah_config(\n  email = Sys.getenv(\"ALA_EMAIL\"),\n  atlas = \"Australia\"\n)\n\nbilby &lt;- galah_call() |&gt;\n  galah_identify(\"Macrotis lagotis\") |&gt;\n  galah_filter(year == 2022) |&gt;\n  galah_select(group = \"basic\", sex, lifeStage, reproductiveCondition) |&gt;\n  atlas_occurrences()\n\n\nChecking queue\nCurrent queue size: 1 inqueue . running .\n\n# Quick way to check the unique values for each field\nlapply(bilby[c(\"sex\", \"lifeStage\", \"reproductiveCondition\")], unique)\n\n$sex\n[1] NA       \"MALE\"   \"FEMALE\"\n\n$lifeStage\n[1] NA\n\n$reproductiveCondition\n[1] NA                      \"A Adult\"               \"J Juveniles\"          \n[4] \"I Immature (subadult)\" \"- Not breeding\"       \n\n\nThe check above shows that the lifeStage field has only NA values, so we won’t be able to use it. The other two fields have values so it’s worth checking them out in more detail using skimr::skim() For this example we will focus on the sex field.\n\n# Skim without charts for a more compact output, making sure sex is treated as a factor\nbilby$sex &lt;- factor(bilby$sex)\nskimr::skim_without_charts(bilby, sex) |&gt;\n  skimr::yank(\"factor\")\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nsex\n21375\n0.02\nFALSE\n2\nMAL: 361, FEM: 139\n\n\n\n\n\nThe dataset is mostly NA values for the sex field, but say that our project is focused only on female greater bilbies, now we can do our simple filter using == as shown below.\n\nhead(filter(bilby, sex == \"FEMALE\"), 3)\n\n# A tibble: 3 × 11\n  decimalLatitude decimalLongitude eventDate           scientificName  \n            &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;           \n1           -34.2             143. 2022-06-17 00:00:00 Macrotis lagotis\n2           -34.2             143. 2022-06-15 00:00:00 Macrotis lagotis\n3           -34.2             143. 2022-03-23 00:00:00 Macrotis lagotis\n# ℹ 7 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;, sex &lt;fct&gt;, lifeStage &lt;lgl&gt;,\n#   reproductiveCondition &lt;chr&gt;\n\n\nWe could also use != \"MALE to get the same result, since we only have two factor levels, and dplyr::filter() drops NA values. Be aware that if filtering with base R subsetting, the same approach would drop male rows but keep both female and NA rows.\n\nnrow(filter(bilby, sex != \"MALE\"))\n\n[1] 139\n\nnrow(filter(bilby[bilby$sex != \"MALE\", ]))\n\n[1] 21514\n\n\n\n\n12.2.4 Ecosystems\nFiltering by ecosystem, such as removing terrestrial records or aquatic records, can be necessary depending on the project. Below we demonstrate an example of filtering against the World Register of Marine Species (WoRMS), to remove marine invertebrates from our dataset. Note that you could apply this approach to any other ecosystem by using an appropriate list of species.\n\n\n\n\n# Obtain species list\nmy_species &lt;- inverts |&gt;\n  pull(scientificName) |&gt;\n  unique()\n\n# Query WoRMs\nmarine_check &lt;- purrr::map_dfr(\n  my_species,\n  purrr::possibly(~ worrms::wm_records_name(name = .x) |&gt;\n    mutate(search_term = .x))\n)\n# Filter species that are TRUE for isMarine\nmarine_inverts &lt;- marine_check |&gt;\n  filter(isMarine == TRUE)\n\n# Exclude marine invertebrates\nfilter(inverts, !scientificName %in% marine_inverts$search_term)\n\n# A tibble: 4 × 8\n  decimalLatitude decimalLongitude eventDate           scientificName           \n            &lt;dbl&gt;            &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;                    \n1           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n2           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n3           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n4           -13.8             131. 1977-12-11 00:00:00 Halobates (Halobates) ac…\n# ℹ 4 more variables: taxonConceptID &lt;chr&gt;, recordID &lt;chr&gt;,\n#   dataResourceName &lt;chr&gt;, occurrenceStatus &lt;chr&gt;\n\n\nAfter filtering we are left with only four records of one species. It’s always worth double checking the results of your filtering, to make sure any species excluded or included are as expected.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Taxonomy</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomic_validation.html#taxonomic-classification",
    "href": "cleaning_taxonomic_validation.html#taxonomic-classification",
    "title": "13  Taxonomic validation",
    "section": "13.1 Taxonomic classification",
    "text": "13.1 Taxonomic classification\nTaxonomic classification is a complex issue when working with open source biodiversity data. Data infrastructures have their own taxonomic systems, which can lead to variations across platforms in hierarchical information. Furthermore, taxonomic classification is in a state of constant change, and views may differ within the literature or across authorities (refer back to Taxnomy and open source data). As a result, it is often the case that you will have synonyms, meaning, more than one name for the same species, in your dataset. Keep in mind that there is no universal solution to these issues. However you choose to resolve them, we recommend that you maintain a clear and explicit record of any decisions and changes made with respect to the data.\n\n13.1.1 Detecting synonyms\nThere are several packages available that can be used to query different taxonomic databases and check for synonyms.\n\n13.1.1.1 worrms\nThe {worrms} is the R interface to the World Register of Marine Species and has the ability to cross check synonyms with their database for taxa that has an AphiaID. The function will return synonymous record(s) associated with another different AphiaID.\n\nlibrary(worrms)\n\nmarine_sp &lt;- read_csv(\"data/worms/worms.csv\")\n\nmarine_sp |&gt;\n  slice(7) |&gt;\n  pull(AphiaID) |&gt;\n  wm_synonyms()\n\n# A tibble: 1 × 27\n  AphiaID url   scientificname authority status unacceptreason taxonRankID rank \n    &lt;int&gt; &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt;  &lt;lgl&gt;                &lt;int&gt; &lt;chr&gt;\n1  453207 http… Goniosoma ina… Walker, … super… NA                     220 Spec…\n# ℹ 19 more variables: valid_AphiaID &lt;int&gt;, valid_name &lt;chr&gt;,\n#   valid_authority &lt;chr&gt;, parentNameUsageID &lt;int&gt;, kingdom &lt;chr&gt;,\n#   phylum &lt;chr&gt;, class &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;,\n#   citation &lt;chr&gt;, lsid &lt;chr&gt;, isMarine &lt;int&gt;, isBrackish &lt;int&gt;,\n#   isFreshwater &lt;int&gt;, isTerrestrial &lt;int&gt;, isExtinct &lt;int&gt;, match_type &lt;chr&gt;,\n#   modified &lt;chr&gt;\n\n\n\n\n13.1.1.2 taxize\n\n\nThe taxize package allows users to search over many taxonomic data sources for hierarchial taxonomic information, such as species names (scientific and common), to resolve synonymy. The gnr_resolve() function matches a supplied list with up to 118 data sources including GBIF, Catalogue of Life, World Register of Marine Species and many more. The function scores how well matched your name is to these sources.\n\nlibrary(taxize)\n\n# Read in a naming authority list\nafd &lt;- read_csv(\"data/naming/afd.csv\")\nunique(afd$VALID_NAME)\n\n [1] \"Prosphaerosyllis battiri\"         \"Clavellopsis parasargi\"          \n [3] \"Platypontonia hyotis\"             \"Palirhoeus eatoni\"               \n [5] \"Diastylis kapalae\"                \"Xenobates chinai\"                \n [7] \"Paratanais gaspodei\"              \"Paradexamine flindersi\"          \n [9] \"Prostebbingia brevicornis\"        \"Cythere lactea\"                  \n[11] \"Cythere melobesioides\"            \"Achelia transfugoides\"           \n[13] \"Halobates (Halobates) acherontis\" \"Quadraceps hopkinsi apophoretus\" \n[15] \"Anabarhynchus striatus\"           \"Australocytheridea vandenboldi\"  \n[17] \"Enigmaplax littoralis\"            \"Hyphalus insularis\"              \n[19] \"Plesiopenaeus armatus\"            \"Uroptychus brucei\"               \n[21] \"Caligus dasyaticus\"               \"Coralliophila tetragona\"         \n[23] \"Triphora alveolata\"               \"Clavus obliquatus\"               \n[25] \"Naria beckii\"                     \"Pharaonella rostrata\"            \n[27] \"Lasaea australis\"                 \"Cadulus rudmani\"                 \n[29] \"Bembicium flavescens\"             \"Mormula philippiana\"             \n[31] \"Turbonilla tiara\"                 \"Chlorodiloma crinita\"            \n[33] \"Mitrella merita\"                  \"Tritonoharpa antiquata\"          \n[35] \"Mauritia depressa dispersa\"       \"Laevidentalium zeidleri\"         \n[37] \"Conus (Harmoniconus) musicus\"     \"Marionia cyanobranchiata\"        \n[39] \"Tucetona flabellata\"              \"Neochromadora bilineata\"         \n[41] \"Desmoscolex membranosus\"          \"Echeneidocoelium indicum\"        \n[43] \"Indodidymozoon suttiei\"           \"Diploproctodaeum yosogi\"         \n[45] \"Pseudopecoelus japonicus\"         \"Pedibothrium lloydae\"            \n[47] \"Amphitethya stipitata\"            \"Pseudosuberites mollis\"          \n[49] \"Psammochela psammodes\"           \n\n# Resolve names\nresolved &lt;- gnr_resolve(unique(afd$VALID_NAME), best_match_only = TRUE)\nresolved |&gt; print(n = 50)\n\n# A tibble: 49 × 5\n   user_supplied_name        submitted_name matched_name data_source_title score\n * &lt;chr&gt;                     &lt;chr&gt;          &lt;chr&gt;        &lt;chr&gt;             &lt;dbl&gt;\n 1 Prosphaerosyllis battiri  Prosphaerosyl… Prosphaeros… National Center … 0.988\n 2 Clavellopsis parasargi    Clavellopsis … Clavellopsi… uBio NameBank     0.988\n 3 Platypontonia hyotis      Platypontonia… Platyponton… National Center … 0.988\n 4 Palirhoeus eatoni         Palirhoeus ea… Palirhoeus … Wikispecies       0.988\n 5 Diastylis kapalae         Diastylis kap… Diastylis k… Encyclopedia of … 0.988\n 6 Xenobates chinai          Xenobates chi… Xenobates c… Encyclopedia of … 0.988\n 7 Paratanais gaspodei       Paratanais ga… Paratanais … Wikispecies       0.988\n 8 Paradexamine flindersi    Paradexamine … Paradexamin… Encyclopedia of … 0.988\n 9 Prostebbingia brevicornis Prostebbingia… Prostebbing… Encyclopedia of … 0.988\n10 Cythere lactea            Cythere lactea Cythere lac… Encyclopedia of … 0.988\n11 Cythere melobesioides     Cythere melob… Cythere mel… Encyclopedia of … 0.988\n12 Achelia transfugoides     Achelia trans… Achelia tra… National Center … 0.988\n13 Halobates (Halobates) ac… Halobates (ha… Halobates (… CU*STAR           0.999\n14 Quadraceps hopkinsi apop… Quadraceps ho… Quadraceps … Catalogue of Lif… 0.999\n15 Anabarhynchus striatus    Anabarhynchus… Anabarhynch… Encyclopedia of … 0.988\n16 Australocytheridea vande… Australocythe… Australocyt… Encyclopedia of … 0.988\n17 Enigmaplax littoralis     Enigmaplax li… Enigmaplax … Encyclopedia of … 0.988\n18 Hyphalus insularis        Hyphalus insu… Hyphalus in… Wikispecies       0.988\n19 Plesiopenaeus armatus     Plesiopenaeus… Plesiopenae… Wikispecies       0.988\n20 Uroptychus brucei         Uroptychus br… Uroptychus … Wikispecies       0.988\n21 Caligus dasyaticus        Caligus dasya… Caligus das… Encyclopedia of … 0.988\n22 Coralliophila tetragona   Coralliophila… Coralliophi… Encyclopedia of … 0.988\n23 Triphora alveolata        Triphora alve… Triphora al… uBio NameBank     0.988\n24 Clavus obliquatus         Clavus obliqu… Clavus obli… Encyclopedia of … 0.988\n25 Naria beckii              Naria beckii   Naria beckii National Center … 0.988\n26 Pharaonella rostrata      Pharaonella r… Pharaonella… Arctos            0.988\n27 Lasaea australis          Lasaea austra… Lasaea aust… National Center … 0.988\n28 Cadulus rudmani           Cadulus rudma… Cadulus rud… Encyclopedia of … 0.988\n29 Bembicium flavescens      Bembicium fla… Bembicium f… National Center … 0.988\n30 Mormula philippiana       Mormula phili… Mormula phi… Encyclopedia of … 0.988\n31 Turbonilla tiara          Turbonilla ti… Turbonilla … Encyclopedia of … 0.988\n32 Chlorodiloma crinita      Chlorodiloma … Chlorodilom… National Center … 0.988\n33 Mitrella merita           Mitrella meri… Mitrella me… Encyclopedia of … 0.988\n34 Tritonoharpa antiquata    Tritonoharpa … Tritonoharp… National Center … 0.988\n35 Mauritia depressa disper… Mauritia depr… Mauritia de… National Center … 0.999\n36 Laevidentalium zeidleri   Laevidentaliu… Laevidental… Encyclopedia of … 0.988\n37 Conus (Harmoniconus) mus… Conus (harmon… Conus Linna… Catalogue of Lif… 0.75 \n38 Marionia cyanobranchiata  Marionia cyan… Marionia cy… National Center … 0.988\n39 Tucetona flabellata       Tucetona flab… Tucetona fl… Encyclopedia of … 0.988\n40 Neochromadora bilineata   Neochromadora… Neochromado… National Center … 0.988\n41 Desmoscolex membranosus   Desmoscolex m… Desmoscolex… Encyclopedia of … 0.988\n42 Echeneidocoelium indicum  Echeneidocoel… Echeneidoco… Integrated Taxon… 0.988\n43 Indodidymozoon suttiei    Indodidymozoo… Indodidymoz… National Center … 0.988\n44 Diploproctodaeum yosogi   Diploproctoda… Diploprocto… Encyclopedia of … 0.988\n45 Pseudopecoelus japonicus  Pseudopecoelu… Pseudopecoe… Integrated Taxon… 0.988\n46 Pedibothrium lloydae      Pedibothrium … Pedibothriu… Encyclopedia of … 0.988\n47 Amphitethya stipitata     Amphitethya s… Amphitethya… Wikispecies       0.988\n48 Pseudosuberites mollis    Pseudosuberit… Pseudosuber… Encyclopedia of … 0.988\n49 Psammochela psammodes     Psammochela p… Psammochela… Wikispecies       0.988\n\n# Retrieve synonyms\ntsn &lt;- get_tsn(unique(afd$VALID_NAME)[1:5])\n\n══  5 queries  ═══════════════\n✖  Not Found:  Prosphaerosyllis battiri\n✖  Not Found:  Clavellopsis parasargi\n✔  Found:  Platypontonia hyotis\n✖  Not Found:  Palirhoeus eatoni\n✖  Not Found:  Diastylis kapalae\n══  Results  ═════════════════\n\n• Total: 5 \n• Found: 1 \n• Not Found: 4\n\nsynonyms(tsn)\n\n$&lt;NA&gt;\n[1] NA\n\n$&lt;NA&gt;\n[1] NA\n\n$`612530`\n  sub_tsn acc_tsn   syn_author                  syn_name syn_tsn\n1  612530  612530 Suzuki, 1971 Platypontonia pterostreae 1191962\n\n$&lt;NA&gt;\n[1] NA\n\n$&lt;NA&gt;\n[1] NA",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "cleaning_taxonomic_validation.html#input-from-experts",
    "href": "cleaning_taxonomic_validation.html#input-from-experts",
    "title": "13  Taxonomic validation",
    "section": "13.2 Input from experts",
    "text": "13.2 Input from experts\nProgrammatic solutions for resolving synonymy can only go so far. Seeking validation from experts is sensible if your goal is to obtain a high quality species list. Museums or taxonomic societies are extensive sources of knowledge. Below we have provided a list of some of Australian taxonomic society groups.\n\n13.2.1 Australian taxonomic society groups\nVERTEBRATES\n\nAmphibians and reptiles - Australian Herpetological Society\n\nBirds - Birdlife Australia\n\nFish - Australian Society for Fish Biology\n\nMammals - The Australian Mammal Society\n\nINVERTEBRATES\n\nArachnology - Australasian Arachnological Society\n\nEntomology - Australian Entomological Society\n\nMalacology - The Malacological Society of Australasia\n\nNematology - Australasian Association of Nematologists\n\n\n\n13.2.2 Global taxonomy\n\nGBIF taxonomic backbone - Uses over 100 different sources\nIntegrated Taxonomic Information System, ITIS - Authoritative taxonomic information on plants, animals, fungi, and microbes\nCatalogue of Life - Global taxonomic catalogue\n\n\n\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi, and Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys Species (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of Fresh Water Habitats by Macrodasyids.” Scientific Reports 9 (1): 2067.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Taxonomic validation</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-precision-and-uncertainty",
    "href": "cleaning_geospatial.html#coordinate-precision-and-uncertainty",
    "title": "14  Geospatial data",
    "section": "14.1 Coordinate precision and uncertainty",
    "text": "14.1 Coordinate precision and uncertainty\nCoordinate precision describes the consistency of values if one were to record the coordinates of the same location, multiple times. Coordinate precision can vary between data sources and recording equipment. For example, coordinates recorded with a GPS unit or a phone generally has higher precision compared to those manually determined from locality descriptions.\n\n\nDepending on the scope of your research question, you may need to limit your occurrence data to a certain level of coordinate.\nWe recommend first including coordinatePrecision in your download query and excluding???? its completeness and range before you exclude any data.\n\nlibrary(galah)\nlibrary(skimr)\n\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  galah_select(group = \"basic\", coordinatePrecision) |&gt; \n  atlas_occurrences()\n\n# banksia_serrata |&gt; \n#   select(coordinatePrecision) |&gt; \n#   skim()\n\n# Filter by number of decimal places\n# banksia_serrata |&gt; \n#   filter(coordinatePrecision &lt; XXX) \n\nhttps://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/j.1365-2664.2007.01408.x",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-uncertainty",
    "href": "cleaning_geospatial.html#coordinate-uncertainty",
    "title": "14  Geospatial data",
    "section": "14.2 Coordinate Uncertainty",
    "text": "14.2 Coordinate Uncertainty\nAlternatively, you can refine your data using coordinate uncertainty which describes the possible circular area in meters where the true location is in.\n\nbanksia_serrata &lt;- galah_call() |&gt; \n  galah_identify(\"banksia_serrata\") |&gt; \n  galah_filter(year &gt; 2022) |&gt;  \n  galah_select(group = \"basic\", coordinatePrecision, coordinateUncertaintyInMeters) |&gt; \n  atlas_occurrences()\n\n# Filter by number of decimal places\n# banksia_serrata |&gt; \n#   filter(coordinateUncertaintyInMeters &lt; XXX) \n\n\n14.2.1 Missing coordinate data\nIf your research question requires spatial information, then it may be useful to exclude records that are missing coordinates data. Many spatial analytical tools are not compatible with missing coordinate data. We recommend tallying and identifying the rows that have missing data before excluding.\nYou can use drop_na() to remove missing values from your dataset.\n\nlibrary(dplyr)\n\n# Identify missing data in coordinates\nbanksia_serrata |&gt; \n  filter(is.na(decimalLatitude) | is.na (decimalLongitude))\n\n# Excluding them\nbanksia_serrata |&gt; \n  tidyr::drop_na(decimalLatitude, decimalLongitude)",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-correction",
    "href": "cleaning_geospatial.html#coordinate-correction",
    "title": "14  Geospatial data",
    "section": "14.3 Coordinate correction",
    "text": "14.3 Coordinate correction\nSome of these steps may have been completed in a pre-cleaning step, however it’s now time to be more rigorous. As always we’ll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:\nFlipped coordinates: Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected. (Jin and Yang 2020)\n\n#example map of some flipped coordinates (what to look for) \n# https://www.gbif.org/occurrence/3013406216 this has flipped coordinates, which GBIF has corrected\n# https://www.gbif.org/occurrence/search?q=mammalia&continent=SOUTH_AMERICA&has_coordinate=true&has_geospatial_issue=false&issue=PRESUMED_SWAPPED_COORDINATE&advanced=1. ## the issue and flag is called 'presumed swapped coordinate' \n\nNumerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.\n\n#example map, like coordinates off the coast of japan\n\n# https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51360942&qualityProfile=CSDM&radius=50&lat=35.66845370835343&lon=138.9990234375#tab_recordsView\n\n# eucs &lt;- galah_call() %&gt;% \n#  galah_identify(\"Eucalyptus\") %&gt;%\n#  galah_filter( year == 2005, \n#             dataResourceName == \"The University of Melbourne Herbarium (MELU) AVH data\") %&gt;%\n#  atlas_occurrences()\n\nCountry field doesn’t match coordinates: The coordinates could be wrong or just the country listed.\n\n## this doesnt seem to be very common- atleast not in ALA data- because there is no neighboring country\n# https://biocache.ala.org.au/occurrences/a34fca43-9e7c-4b37-8fe4-07cc18369465 Australian coordinates, country listed as Trinidad and Tobago\n# https://www.gbif.org/occurrence/search?advanced=true&continent=SOUTH_AMERICA&geometry=POLYGON((-78.74961%20-8.25249,-76.29838%20-8.25249,-76.29838%20-4.74121,-78.74961%20-4.74121,-78.74961%20-8.25249))&has_coordinate=true&issue=COUNTRY_MISMATCH&locale=en&q=reptilia   # GBIF example- reptiles located in Peru, originally recorded as Ecuador\n\n\n14.3.1 Quick visualisation\nOne of the most straightforward ways to check for spatial errors is to plot your data onto a map. More obvious spatial errors are much easier to spot visually.\n\n\nlibrary(ggplot2)\nlibrary(ozmaps) \nlibrary(sf)\n\n# Retrieve map of Australia\naus &lt;- st_transform(ozmap_country, 4326)\n\n# Remove missing coordinates in Banksia data\n# Then transform into 'sf' object\nbanksia_sf &lt;- banksia_serrata |&gt; \n  tidyr::drop_na(starts_with(\"decimal\")) |&gt; \n  st_as_sf(coords = c(\"decimalLongitude\", \"decimalLatitude\"), \n           crs = 4326)\n\n# A quick plot\nggplot() + \n  geom_sf(data = aus, colour = \"black\", fill = NA) + \n  geom_sf(data = banksia_sf)",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#coordinate-cleaning",
    "href": "cleaning_geospatial.html#coordinate-cleaning",
    "title": "14  Geospatial data",
    "section": "14.4 Coordinate cleaning",
    "text": "14.4 Coordinate cleaning\nOnce you have fixed everything you can, it’s time to remove records that still have errors. This doesn’t mean removing all outliers, you must have more than “it’s far away from the others” to justify a records removal.\nRemove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, check first, however likely will need to remove\nRemove records with zero coordinates: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.\n\n#zero coordinates acacia \n\n#https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51382879&disableAllQualityFilters=true&qualityProfile=ALA&fq=spatiallyValid%3A%22false%22&radius=25&lat=-0.024032592068740033&lon=-0.06591796875#tab_recordsView",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "cleaning_geospatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "href": "cleaning_geospatial.html#remove-records-plotted-away-from-the-known-area-of-distribution-of-the-species.",
    "title": "14  Geospatial data",
    "section": "14.5 Remove records plotted away from the known area of distribution of the species.",
    "text": "14.5 Remove records plotted away from the known area of distribution of the species.\nIt is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it’s worth checking the literature before discarding records like these. These can also be mis-identified species, if you’re working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.\n\n\n\n\n14.5.1 Remove records with coordinates assigned to country and province centroids\nCentroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or grown in horticulture, which were not clearly labelled as such.\n\n\n14.5.2 Remove records from biological institutions\nsuch as botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and GBIF headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.\nIn a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.\nRemove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.\n\n\n14.5.3 CoordinateCleaner\nThis package probably worth looking at.\n\n\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning Taxonomic and Geographic Errors in Occurrence Data Archived in Biodiversity Databases.” Global Ecology and Conservation 21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Geospatial data</span>"
    ]
  },
  {
    "objectID": "outliers.html#alternative-methods",
    "href": "outliers.html#alternative-methods",
    "title": "15  Outliers",
    "section": "15.1 Alternative methods",
    "text": "15.1 Alternative methods\nHere we document some other existing methods that can be used for outlier detection, and their limitations.\n\nSpecies Distribution Modelling for outlier detection:\n\nSimões and Peterson (2018)\nMaxiomum Entropy modelling (MaxEnt) was used to model habitat suitability for five species of leaf beetles in the genus Mesomphalia\nThe method relies on the assumption that an errornous point will have a lower habitat suitability value than a true point.\nFor their dataset, the method was useful for identifying geographical position errors, but not species level identification errors.\n\n\n\n\n\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and Limitations of Climate-Matching Approaches in Detecting Different Types of Spatial Errors in Biodiversity Data.” Insect Conservation and Diversity 11 (5): 407–14.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Outliers</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "16  References",
    "section": "",
    "text": "Führding-Potschkat, Petra, Holger Kreft, and Stefanie M. Ickert-Bond.\n2022. “Influence of Different Data Cleaning Solutions of\nPoint-Occurrence Records on Downstream Macroecological Diversity\nModels.” Ecology and Evolution 12 (8): e9168. https://doi.org/10.1002/ece3.9168.\n\n\nGarraffoni, André RS, Thiago Q Araújo, Anete P Lourenço, Loretta Guidi,\nand Maria Balsamo. 2019. “Integrative Taxonomy of a New Redudasys\nSpecies (Gastrotricha: Macrodasyida) Sheds Light on the Invasion of\nFresh Water Habitats by Macrodasyids.” Scientific\nReports 9 (1): 2067.\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David\nAlbrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021.\n“Implications of the 2019–2020 Megafires for the Biogeography and\nConservation of Australian Vegetation.” Nature\nCommunications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nGueta, Tomer, and Yohay Carmel. 2016. “Quantifying the Value of\nUser-Level Data Cleaning for Big Data: A Case Study Using\nMammal Distribution Models.” Ecological Informatics 34\n(July): 139–45. https://doi.org/10.1016/j.ecoinf.2016.06.001.\n\n\nJin, Jing, and Jun Yang. 2020. “BDcleaner: A Workflow for Cleaning\nTaxonomic and Geographic Errors in Occurrence Data Archived in\nBiodiversity Databases.” Global Ecology and Conservation\n21 (March): e00852. https://doi.org/10.1016/j.gecco.2019.e00852.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville,\nLibby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts\nof the 2019-20 Wildfires of Southern and Eastern Australia on\nInvertebrate Species Final Report.”\n\n\nMarsh, Jessica R., Payal Bal, Hannah Fraser, Kate Umbers, Tanya Latty,\nAaron Greenville, Libby Rumpff, and John C. Z. Woinarski. 2022.\n“Accounting for the Neglected: Invertebrate Species\nand the 2019–2020 Australian Megafires.” Global\nEcology and Biogeography n/a (n/a). https://doi.org/10.1111/geb.13550.\n\n\nRodrigues, Arthur Vinicius, Gabriel Nakamura, Vanessa Graziele\nStaggemeier, and Leandro Duarte. 2022. “Species Misidentification\nAffects Biodiversity Metrics: Dealing with This Issue Using\nthe New R Package naturaList.” Ecological\nInformatics 69 (July): 101625. https://doi.org/10.1016/j.ecoinf.2022.101625.\n\n\nRowley, Jodi JL, and Corey T Callaghan. 2020. “The FrogID Dataset:\nExpert-Validated Occurrence Records of Australia’s Frogs Collected by\nCitizen Scientists.” ZooKeys 912: 139.\n\n\nSimões, Marianna VP, and A Townsend Peterson. 2018. “Utility and\nLimitations of Climate-Matching Approaches in Detecting Different Types\nof Spatial Errors in Biodiversity Data.” Insect Conservation\nand Diversity 11 (5): 407–14.\n\n\nZizka, Alexander, Fernanda Antunes Carvalho, Alice Calvente, Mabel Rocio\nBaez-Lizarazo, Andressa Cabral, Jéssica Fernanda Ramos Coelho, Matheus\nColli-Silva, Mariana Ramos Fantinati, Moabe F Fernandes, and Thais\nFerreira-Araújo. 2020. “No One-Size-Fits-All Solution to Clean\nGBIF.” PeerJ 8: e9916.",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "17  Appendix",
    "section": "",
    "text": "We don’t claim to be experts in data cleaning, therefore in order to ensure content for this book was current and relevant we undertook an informal literature review of both peer reviewed and grey literature. Key themes searched were:\n\nCleaning data for species distribution models\nCleaning open biodiversity data\nAustralian and global naming authorities\nR packages for biodiversity data cleaning\n\nAs this was not a comprehensive literature review recent papers were selected first as the R environment is a rapidly evolving space. Methods sections outlining data cleaning protocols were read and collated into a database. Papers which were frequently referenced were also chosen for review in order to not miss older seminal papers. Additionally our project partners outputs (Marsh et al. 2021; Godfree et al. 2021) have been investigated in detail to understand and streamline their data cleaning processes. This has included detailed review of their code base as well as meetings with the authors of the papers to understand their processes, issues and needs.\nAll steps for acquiring and cleaning data were then looked at together in order to understand what were essential steps, versus what was done in certain use cases. We also investigated the order in which steps were undertaken with the idea of developing a streamlined workflow. However the diagrams below show the complexity of this, with data cleaning being extremely iterative.\n \n\n\n\n\nGodfree, Robert C., Nunzio Knerr, Francisco Encinas-Viso, David Albrecht, David Bush, D. Christine Cargill, Mark Clements, et al. 2021. “Implications of the 2019–2020 Megafires for the Biogeography and Conservation of Australian Vegetation.” Nature Communications 12 (1): 1023. https://doi.org/10.1038/s41467-021-21266-5.\n\n\nMarsh, Jess, Payal Bal, Hannah Fraser, Kate Umbers, Aaron Greenville, Libby Rumpff, and John Woinarski. 2021. “Assessment of the Impacts of the 2019-20 Wildfires of Southern and Eastern Australia on Invertebrate Species Final Report.”",
    "crumbs": [
      "Cleaning biodiversity data",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Appendix</span>"
    ]
  }
]