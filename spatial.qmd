# Spatial data {#sec-spatial}

You've been through the taxonomic cleaning steps so now it's time to clean up the spatial element. You may have flagged records as being taxonomically incorrect, it's important to keep those in mind as you go through the spatial cleaning steps as you might learn more about those records. We will discuss some different ways to check for spatial outliers as well as the removal of records in certain geographic areas known to be problematic.

## Quick visualisation

Now is a great time to plot your data onto a map again. Spatial errors are much easier to spot from a visual perspective.

```{r}

```

## Coordinate precision

Open access data will be collected from many people using different tools with varying expertise, some record coordinates may have been recorded with a phone, some with a GPS, or a place name and coordinates added after the fact. Depending on the level of precision you need, you might consider discarding data of lower precision, or removing decimal places for data you know could not be that precise. At the ALA there is a "cooridnateprecision"/ "coordinateUncertainityIn Meters" assertion ([see assertion section to download these with the data)]{.underline}

![](images/image-613988507.png)

https://xkcd.wtf/2170/

Most people will be working with between 2 and 5 decimal places. Studies often have different precision cut-offs. For example, coordinate precision below 100km represents the grain size of many macroecological analyses. Some studies have used a cut-off of spatial resolution \>25,000m or precision with less than three decimal places (**add a reference here**). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision. Understanding the level of quality you need is important before removing/keeping large volumes of data.

-   How to filter by \# of decimal places

    ```{r}

    ```

## Coordinate correction

Some of these steps may have been completed in a pre-cleaning step, however it's now time to be more rigorous. As always we'll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:

-   Correct flipped coordinates: Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected.

    *example map of some flipped coordinates (what to look for)*

    ```{r}

    ```

-   Correct poorly formatted coordinates: Different datasets can provide coordinates in different formats, so it is crucial to correct the format of the coordinates before discarding any points.

-   Correct numerical sign confusion: As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.

    *example map, like coordinates off the coast of japan*

    ```{r}

    ```

-   Check for records with coordinates in a different country than is listed in the country field: The coordinates could be wrong or just the country listed. Note that the country should only be changed to match the coordinates if the data is trustworthy.

## Coordinate cleaning

Now that you've gone through and fixed what you can, it's time to remove records that still have errors. This doesn't mean removing outliers, we'll talk about those later.

-   Remove records with null or missing coordinates. This will be records missing partial or complete information. Missing values can cause errors, many analytical tools do not respond well to missing values. If you can't find the information elsewhere, it's best to remove it.

-   Remove records where longitude and latitude are equal: High likelihood that this is not where the record was recorded and, therefore, should be checked and (possibly) removed.

-   Remove records with zero coordinates \[that could not be georeferenced\]: When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.

    ```{r}

    ```

-   Remove records plotted away from the known area of distribution of the species. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it's worth checking the literature before discarding records like these. These can also be mis-identified species, if you're working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.

    There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area.

    ```{r}

    ```

    ### Optional record removal  

-   Remove records with coordinates assigned to country and province centroids: such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.

    Centroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such.

    In a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.

```{r}

```

-   Remove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.

## Checklist of data standardization

Add here a downloadable checklist of issues to be checked.
