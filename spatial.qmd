# Spatial data {#sec-spatial}

```{r, include=FALSE}
pacman::p_load(tidyverse, galah, arrow, ggplot2)

galah_config(atlas = "Australia",
             email = Sys.getenv("ALA_EMAIL"))

```

```{r,include=FALSE}
# Data for this chapter
acacia_serrata <- galah_call() |> 
  galah_identify("Acacia serrata") |> 
  galah_filter(year == 2023) |> 
  atlas_occurrences()

write_parquet(acacia_serrata, "data/galah/acacia_serrata")
```

You've been through the taxonomic cleaning steps so now it's time to clean up the spatial elements. You may have flagged records as being taxonomically incorrect, it's important to keep those in mind as you go through the spatial cleaning steps as you might learn more about those records. We will discuss some different ways to check for spatial outliers as well as the removal of records in certain geographic areas known to be problematic.

## Quick visualisation

One of the most straightforward ways to check for spatial errors is to plot your data onto a map. More obvious spatial errors are much easier to spot visually.

<!-- This is a good first step but needs to be guided into the following ones. Not sure what the map looks like, but it might be good to make another map that puts boxes around some obvious ones you can see and why -->

```{r}

```


## Coordinate precision

Data from different sources are collected by different people often using differing tools. For example, some might record coordinates with a tool with high precision like a phone or a GPS, whereas others might record coordinates with low precision by manually recording a place name or writing coordinates after the fact.

Depending on the level of precision to answer your research question, <!--# the following two options are opposites, and it's weird to have them together because they solve the problem very differently. Maybe use these ideas like subsections and describe when you might choose to do one or the other? --> you might consider discarding data of lower precision, or removing decimal places for data you know could not be that precise. At the ALA there is a "cooridnateprecision"/ "coordinateUncertainityIn Meters" assertion ([see assertion section to download these with the data)]{.underline}

![](images/image-613988507.png)

https://xkcd.wtf/2170/

Coordinate precision below 100km represents the grain size of many macroecological analyses [@zizka2020]. Some studies have used a cut-off of spatial resolution \>25,000m or precision with less than three decimal places (**add a reference here**). It is important to note that rasterized collections often have a significant proportion of records that might have low coordinate precision. Understanding the level of quality you need is important before removing/keeping large volumes of data.

```{r}
# How to filter by number of decimal places
```

## Coordinate correction

Some of these steps may have been completed in a pre-cleaning step, however it's now time to be more rigorous. As always we'll start with fixing data before discarding, many coordinates issues can be solved with data manipulation instead of discarding:

**Flipped coordinates:** Flipped coordinates typically appear as a clustering of points, whereby swapping the latitude and longitude will place the coordinates where they are expected. [@jin2020]

```{r}
#example map of some flipped coordinates (what to look for) 
# https://www.gbif.org/occurrence/3013406216 this has flipped coordinates, which GBIF has corrected
# https://www.gbif.org/occurrence/search?q=mammalia&continent=SOUTH_AMERICA&has_coordinate=true&has_geospatial_issue=false&issue=PRESUMED_SWAPPED_COORDINATE&advanced=1. ## the issue and flag is called 'presumed swapped coordinate' 
```

**Numerical sign confusion:** As with flipped coordinates, if there is a clustering of points mirrored to another hemisphere, consider swapping the sign and correct rather than discarding the points.

```{r}
#example map, like coordinates off the coast of japan

# https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51360942&qualityProfile=CSDM&radius=50&lat=35.66845370835343&lon=138.9990234375#tab_recordsView

# eucs <- galah_call() %>% 
#  galah_identify("Eucalyptus") %>%
#  galah_filter( year == 2005, 
#             dataResourceName == "The University of Melbourne Herbarium (MELU) AVH data") %>%
#  atlas_occurrences()

```

**Country field doesn't match coordinates:** The coordinates could be wrong or just the country listed.

```{r}

## this doesnt seem to be very common- atleast not in ALA data- because there is no neighboring country
# https://biocache.ala.org.au/occurrences/a34fca43-9e7c-4b37-8fe4-07cc18369465 Australian coordinates, country listed as Trinidad and Tobago
# https://www.gbif.org/occurrence/search?advanced=true&continent=SOUTH_AMERICA&geometry=POLYGON((-78.74961%20-8.25249,-76.29838%20-8.25249,-76.29838%20-4.74121,-78.74961%20-4.74121,-78.74961%20-8.25249))&has_coordinate=true&issue=COUNTRY_MISMATCH&locale=en&q=reptilia   # GBIF example- reptiles located in Peru, originally recorded as Ecuador
```

## Coordinate cleaning

Once you have fixed everything you can, it's time to remove records that still have errors. This doesn't mean removing all outliers, you must have more than "it's far away from the others" to justify a records removal.

**Remove records with null or missing coordinates:** This will be records missing partial or complete information. Missing values can cause errors, many analytical tools do not respond well to missing values. If you can't find the information elsewhere, it's best to remove it.

**Remove records where longitude and latitude are equal:** High likelihood that this is not where the record was recorded and, check first, however likely will need to remove

**Remove records with zero coordinates:** When plotting it on a map, zero coordinates will be found around the point at zero latitudes and longitudes. These records will not accurately represent their valid location and must be removed.

```{r}
#zero coordinates acacia 

#https://biocache.ala.org.au/occurrences/search?q=lsid%3Ahttps%3A%2F%2Fid.biodiversity.org.au%2Ftaxon%2Fapni%2F51382879&disableAllQualityFilters=true&qualityProfile=ALA&fq=spatiallyValid%3A%22false%22&radius=25&lat=-0.024032592068740033&lon=-0.06591796875#tab_recordsView 
```

```{r}

```

Remove records plotted away from the known area of distribution of the species. It is essential to check the metadata to ensure that it is a data entry error and not a real outlier. In some cases, it's worth checking the literature before discarding records like these. These can also be mis-identified species, if you're working with data from many species, and you find a species point in amongst the environmental bounds of a similar looking species it might be worth going back to the original record and taking a closer look. However, if no images exist it might be difficult to determine if it is a taxonomic or spatial issue.There are several ways of dealing with this issue, but one option can be to mask data to remove points from falling off a determined area. --\> unsure about this bit

**I'm not sure I understand what the above means. But I think in general for less obvious errors, it's best to suggest that before data analysis (and honestly, before seeing the data at all), people should determine whether there is an upper bound to remove coordinates (like a 95% confidence interval, or within xx km of an accepted expert distribution). Then run whatever model or test with the complete data and with the reduced data. If it makes a difference, probably make an informed decision based on literature of which results to use as the "main" findings.**

**Having written this out, a brief discussion about this rather than any suggestions is probably all that's in scope for this book**

**The final decisions depend on the species, research question, model parameters etc**

```{r}

```

## Optional record removal

**Not sure why the below is optional? I think a lot of national or global analyses would require some kind of data cleaning for this**

Remove records with coordinates assigned to country and province centroids: such as Centre of Country, botanic gardens, zoos, country capitals, biodiversity institutions, urban areas, and gbif headquarters. In some cases these records will haven actually been recorded at a zoo for example, in other cases this is often incorrectly georeferenced records. They can be tricky to spot but there are a few packages that deal with centroid data. Exploratory visuals can also help support findings, making it easier to spot clusterings of points.

Centroids are common when records are being assigned from georeferencing based on vague locality descriptions or from incorrect georeferencing. Sometimes, records are erroneously entered with the physical location of the specimen or because they represent individuals from captivity or horticulture, which were not clearly labeled as such.

In a few cases, zoos and botanic gardens might be where the record was sighted. However, in this case, it is not naturally occurring and should be removed. Records in urban areas may not want to be removed by everyone, but it is essential to note that it could be old data or have vague locality descriptions.

Remove records outside of the country of interest: In some cases, records outside the country of origin may be outliers. In other cases, they may be perfectly valid. It is important to analyze case-by-case and remove the record if necessary.

```{r}

```

## Checklist of data standardization

# Notes

## Missing data

(I wonder if this is really the place for this or better to just do this in the Spatial chapter)

-   Remove records with no coordinates

## Quick visualiations

A graphic plot of your data can be very telling and can help you spot potential errors that may be due to formatting.

### GGally

A visual inspection of your entire dataset can save time and solve easy-to-spot errors.

### Quick map

(I wonder if this is really the place for this or better to just do this in the Spatial chapter)

A simple way to visualize your data is to plot it on a map.

-   Fix minor coordinates errors, such as inverted or badly formatted

```{r}

```

### 

### CoordinateCleaner

<!-- Move to spatial? -->

```{r}

```
