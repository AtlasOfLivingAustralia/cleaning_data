---
editor: 
  markdown: 
    wrap: 72
code-annotations: hover
number-depth: 3
---

# Inspect

Before diving into cleaning, itâ€™s a good idea to familiarise yourself with the data. In this chapter we will cover ways to initially inspect the data and metadata of a dataset.

### Prerequisites

In this chapter we will use Kingfisher (*Alcedinidae*) occurrence records in 2023 from the ALA.

```{r prereq-internal}
#| echo: false
#| warning: false
#| message: false
# packages
library(ggplot2)
library(galah)
library(dplyr)
galah_config(email = Sys.getenv("ALA_EMAIL"),
             verbose = FALSE)

# get DOIs for chapter
doi_table <- here::here("data", "galah-dois", "doi_table") |>
  arrow::open_dataset() |>
  filter(chapter == "Inspect") |>
  collect()

# extract dois
doi_birds <- doi_table |> filter(name == "birds") |> pull(doi)

# download
birds <- galah_call() |>
  filter(doi == doi_birds) |>
  atlas_occurrences()
```

```{r prereq-external}
#| echo: false
test <- glue::glue(
"
# packages
library(galah)
library(ggplot2)
galah_config(email = \"your-email-here\") # ALA-registered email

birds <- galah_call() |>
  filter(doi == \"{doi_birds}\") |>
  atlas_occurrences()
"
)
```

```{r prereq-printed}
#| eval: false
#| code: !expr test
#| echo: true
```

<!-- Images -->

:::{.aside}

<img class = "rounded" src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/2/5/1/d/9525c6da-fd47-41fa-8eff-55c6747ed152/original"></img>

::: {.figure-caption}
[*Todiramphus (Todiramphus) sanctus* perched on a branch. Photo by Kerri-Lee Harris CC-BY-NC 4.0
(Int)](https://biocache.ala.org.au/occurrences/77b8aac0-18af-4ec6-a03c-ff825859a6f3)
:::
:::

<!-- Queries-->

:::{.callout-note collapse="true" appearance="minimal"}

#### Original download queries

**Note:** You don't need to run this code block to read this chapter. It can, however, be useful to see the original download query. This code will download the latest data from the ALA, which you are welcome to use instead, though the data might not exactly reproduce results in this chapter.

```{r prereq-orig-query}
#| eval: false
library(galah)
galah_config(email = "your-email-here")

birds <- galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2023) |>
  select(group = "basic", genus, species) |>
  atlas_occurrences() # <1>
```
1. We created a custom DOI for our download by using `atlas_occurrences(mint_doi = TRUE)`.

:::


## Getting to know your data

**Metadata** is a description of data, where information about different aspects of the data is documented. Some examples include definitions of the variables being measured, how and why the data were collected, and any data standards used. Reviewing the metadata associated with a dataset can be very helpful for understanding the types of data you are working with and any considerations that may need to be accounted for in your analyses. 

Many datasets include descriptions of the data's taxonomic, spatial, and temporal
parameters. An example of well formatted metadata is of [FrogID from the Australian
Museum](https://collections.ala.org.au/public/show/dr14760).

![Metadata of the FrogID dataset on the ALA](images/example_frogid.png)

From reading FrogID's metadata [@rowley2020frogid], we understand that:

1.  The dataset comprises acoustic data[^1]
2.  This is citizen science data[^2]
3.  Audio is recorded via a smartphone app[^3]
4.  These data record presences, but not absences
5.  The data are under a Creative Commons license which is relevant for reuse and republishing

[^1]: Meaning the majority of individuals recorded are male.
[^2]: Suggesting these data could be biased towards populated areas.
[^3]: As a result, the authors recommend filtering data to `geographic uncertainty of <3000m` if you require high coordinate precision. 


::: {.callout-note collapse="true"}

#### Data standards

Many data infrastructures like the Atlas of Living Australia also follow and encourage a data
standard to help consolidate data from many different data
providers[^inspect-1].

The data standard used by the Atlas of Living Australia is called **Darwin Core**.
Darwin Core works by defining a) a [set of standard terms](https://dwc.tdwg.org/terms/)[^inspect-2] 
to use across datasets as column names, and b) values eligible to be recorded
underneath these terms. Darwin Core standards require that additional files 
detailing metadata and data structure are supplied along with the dataset. This 
helps make sure the data is ingested correctly into the data infrastructure.

Knowing whether your dataset follows a standard can allow you to look up term
definitions to help you familiarise yourself with the data.
:::

[^inspect-1]: Making datasets easier to consolidate is also referred to as
    *interoperability*, [one of the principles of FAIR
    data](https://ardc.edu.au/resource/fair-data/).

[^inspect-2]: We suggest using `Ctrl/CMD + F` and searching your variable name
    on the webpage. Don't hesitate to Google variable names if you are unsure
    what they represent.

## A first glimpse

When starting with a new dataset, we want to get an initial idea:

  * How many rows and columns are there? 
  * What are the column names? 
  * What types of data are in each column? 
  * What are their possible values or ranges? 
  
These answers are useful to know before jumping into wrangling and cleaning data.

There are several ways to return an overview of your data, ranging in how
comprehensively you wish to summarise your data's structure.

::: {.panel-tabset .nav-pills}
#### `glimpse()`

Return a condensed summary of your data's structure using `glimpse()` from
dplyr.

```{r}
#| message: false
#| warning: false
library(dplyr)

glimpse(birds)
```

#### `skim()`

Return tables of descriptive statistics for each variable, grouped by data type
(e.g., `numeric`, `character`, `date`) using `skim()` from skimr.

```{r}
#| message: false
#| warning: false
library(skimr)

skim(birds)
```

#### `str()`

Return a quick summary of your data's structure using base R `str()`

```{r}
str(birds)
```
:::

:::{.aside}

<img class = "rounded" src="https://images.ala.org.au/image/details?imageId=5a0ff06d-d7ac-44d2-a152-b2207cc98ab4"></img>

::: {.figure-caption}
[*Dacelo (Dacelo) novaeguineae* perched with a fresh worm in its beak. Photo by Rob Shepherd CC-BY-NC 4.0
(Int)](https://biocache.ala.org.au/occurrences/1cb231bd-6000-43dd-9feb-409a29e93779)
:::
:::

At this early stage, it's helpful to assess whether your dataset meets your expectations. Consider if the data appear as anticipated. Are the values in each column reasonable? Are there any noticeable gaps or errors that might need to be corrected, or that could potentially render the data unusable?


## Next steps

We have just learned some ways to initially inspect our dataset. Keep in mind, we don't expect everything to be perfect. Some issues are expected and may indicate problems with our query or the data itself. This initial inspection is a good opportunity to identify where these issues might be and assess their severity.

When you are confident that the dataset is largely as expected, you are ready to start summarising your data.
