# Summarise

In the last chapter, we learned how to see a brief glimpse of our data's structure, including how many rows there are, what columns there are, and where there might be missing data.

In this chapter, we learn how to briefly summarise ecological data. These summaries will fall within three domains: **Taxonomic**, **Temporal** and **Spatial**. Summarising our data will help us see the diversity in our dataset, learn more about its scope, and determine whether it is the right dataset for our analysis.

Over this chapter there are many places where we can use the galah package to summarise our data. The galah package can summarise data on the server-side, prior to downloading any data locally onto your computer, meaning that you can filter or summarise data without needing to have them on your local computer first. 

We will show how to use galah (prior to download) or dplyr (after a download) when both options are available.

### Prerequisite

```{r prereq}
#| message: false
#| warning: false
#| echo: false
library(ggplot2)
library(galah)
library(dplyr)
library(tidyr)
library(janitor)
galah_config(email = Sys.getenv("ALA_EMAIL"),
             verbose = FALSE)

birds <- galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  select(group = "basic", 
         family, genus, species, cl22, eventDate, month) |>
  atlas_occurrences()
```

```{r}
#| eval: false
# packages
library(ggplot2)
library(galah)
library(dplyr)
library(tidyr)
library(janitor)

# data: Kingfisher records from 2023
galah_config(email = "your-email-here") # ALA Registered email

birds <- galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  select(group = "basic", 
         family, genus, species, cl22, eventDate, month) |>
  atlas_occurrences()
```

:::{.aside}

<img class = "rounded" src="https://ala-images.s3.ap-southeast-2.amazonaws.com/store/2/5/1/d/9525c6da-fd47-41fa-8eff-55c6747ed152/original"></img>

::: {.figure-caption}
[*Todiramphus (Todiramphus) sanctus* perched on a branch. Photo by Kerri-Lee Harris CC-BY-NC 4.0
(Int)](https://biocache.ala.org.au/occurrences/77b8aac0-18af-4ec6-a03c-ff825859a6f3)
:::
:::

## Taxonomic

### Counts

Prior to downloading occurrences, it can be useful to summarise the number of records...

```{r}
galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  atlas_counts()
```

...and break them down by a taxonomic clade like genus...

```{r}
galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  group_by(genus) |>
  atlas_counts()
```

...or species.

```{r}
galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  group_by(species) |>
  atlas_counts()
```

Our results show that the large majority of records are of *Dacelo novaeguineae* (aka the Laughing Kookaburra).

You can get the same summaries after downloading the data locally using dplyr or janitor.

:::{.panel-tabset .nav-pills}
#### dplyr

```{r}
# Using our pre-downloaded dataset
birds |>
  group_by(genus) |>
  count() |>
  arrange(desc(-n))

birds |>
  group_by(species) |>
  count() |>
  arrange(desc(-n))
```


#### janitor

```{r}
# Using our pre-downloaded dataset
birds |>
  tabyl(genus) |>
  adorn_pct_formatting()

birds |>
  tabyl(species) |>
  adorn_pct_formatting()
```
:::

## Spatial

### Counts by region

It can be useful to summarise occurrence numbers by a specific region. With galah, you can do this summarising prior to downloading occurrence records.

For example, you might wish to summarise your data by state/territory. We can search for the correct field to use in galah, determining that field ID `cl22` contains "Australian States and Territories" and seems to suit our needs best.

```{r}
search_all(fields, "states")
```

Now we can use the field ID `cl22` to group our counts.

```{r}
galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  group_by(cl22) |>
  atlas_counts()
```

We can also group our counts by state/territory *and* a taxonomic rank like genus.

```{r}
galah_call() |>
  identify("alcedinidae") |>
  filter(year == 2022) |>
  group_by(cl22, genus) |>
  atlas_counts()
```

Our results show that we have the most records in Queensland and New South Wales.

You can get the same summaries after downloading the data locally with dplyr and janitor.

:::{.panel-tabset .nav-pills}
#### dplyr

```{r}
# Using our pre-downloaded dataset
birds |>
  group_by(cl22) |>
  count() |>
  arrange(desc(n))

birds |>
  group_by(cl22, species) |>
  count() |>
  arrange(desc(n))
```


#### janitor

```{r}
# Using our pre-downloaded dataset
birds |>
  tabyl(cl22) |>
  adorn_pct_formatting()

birds |>
  tabyl(cl22, species) |>
  adorn_pct_formatting()
```
:::


### Maps

We can use maps to visually summarise our data. To do so, we will use the sf package to handle spatial data, and the ozmaps package to get maps of Australia (as [vector data](described in earlier chapter xxxadd link)).

```{r}
#| message: false
#| warning: false
library(sf)
library(ozmaps)
```

The easiest way to get a spatial summary is to create a quick map of observations. 

There are a few stray data points in our `birds` data that are outside of Australia. For simplicity, we will filter our data to records within Australia's land mass.

```{r}
# filter records to within Australia
birds_filtered <- birds |>
  filter(decimalLongitude > 110,
         decimalLongitude < 155, 
         decimalLatitude > -45,
         decimalLatitude < -10)
```

Our first step is to get a map of Australia, and an excellent place to get one is from the ozmaps package. We will transform its Coordinate Reference System (CRS)[^1] projection to EPSG:4326 to match the CRS projection of ALA data[^2].

[^1]: The Coordinate Reference System (CRS) determines how to display our shape of Australia, which exists on a spherical globe (the Earth), onto a flat surface (our map).

[^2]: Data from the ALA use EPSG:4326 (also known as “WGS84”) as the Coordinate Reference System. Transforming our map to the same projection of our data ensures the points are plotted in their actual locations on the map.

```{r}
# Get map of australia, and transform projection
aus <- ozmaps::ozmap_states |>
  st_transform(crs = st_crs(4326))
```

Then we can plot our occurrence points onto our map.

:::{.panel-tabset .nav-pills}

#### Point map

Point maps are quick and useful visualisations of where your occurrence records are located. Here we have also adjusted the size and alpha values to make the points slightly larger and more transparent.

```{r}
# Plot the observations on our map of Australia
ggplot() +
  geom_sf(data = aus, 
          colour = "grey60", 
          fill = "white") +
  geom_point(data = birds_filtered,
             aes(x = decimalLongitude, 
                 y = decimalLatitude),
             colour = "#428afe",
             size = 1.8, 
             alpha = 0.6) +
  theme_void()
```

#### Point density map

We can use the [ggpointdensity package](https://github.com/LKremer/ggpointdensity) to visualise locations where there are many overlapping occurrences. With over 40,000 points plotted on our map, `geom_pointdensity()` allows us to see areas with higher densities of observations.

```{r}
#| warning: false
#| message: false
library(ggpointdensity)
library(viridis) # colour palette

ggplot() +
  geom_sf(data = aus, 
          colour = "grey60", 
          fill = "white") +
  geom_pointdensity(data = birds_filtered,
             aes(x = decimalLongitude, 
                 y = decimalLatitude),
             size = 1.8, 
             alpha = 0.6) +
  scale_colour_viridis_c(option = "F",     # palette
                         end = .8,         # final light colour value
                         direction = -1) + # reverse light-to-dark
  guides(
    colour = guide_colourbar(
      title = "Number of\noverlapping\nobservations")
    ) +
  theme_void()
```

#### Facetted maps

It can also be useful to create a collection of maps grouped by a specific variable (i.e., facetted). Here is one taxonomic example, grouping by species with `facet_wrap()`. Visualising by groups can reveal spatial trends, and also help you determine whether there is enough data for each species or taxonomic group for your later analyses.

```{r}
ggplot() +
  geom_sf(data = aus, 
          colour = "grey60", 
          fill = "white") +
  geom_point(data = birds_filtered |> 
               drop_na(species), # remove NA values 
             aes(x = decimalLongitude, 
                 y = decimalLatitude,
                 colour = species),
             size = 1.8, 
             alpha = 0.6) +
  pilot::scale_color_pilot() +
  theme_void() + 
  facet_wrap( ~ species) + 
  theme(legend.position = "none")
```

:::

## Temporal

### Counts by time scales

Knowing the breakdown of when observations are recorded can reveal trends in seasonality between species. Checking this breakdown can also help you determine whether you have enough data to make inferences about patterns over the span of a week, month, year, decade or even century, or whether you're inferences about temporal trends are limited by the amount of existing data.

#### Year

For example, an easy first summary is to know the number of records in each year. You can do this in galah prior to downloading data. We can search for the correct field to use in galah, determining that field ID `year` seems to suit our needs best.

```{r}
search_all(fields, "year")
```

Now we can use the field ID `year` to group our counts, returning years since 2016.

```{r}
galah_call() |>
  identify("alcedinidae") |>
  filter(year > 2016) |>
  group_by(year) |>
  atlas_counts()
```

You can summarise after downloading counts locally with help from the lubridate package. 

We'll convert our column `eventDate` to a `date` class in R. Then we can extract relevant date data...

```{r}
#| message: false
#| warning: false
# Using our pre-downloaded dataset
library(lubridate)

birds_date <- birds |>
  mutate(eventDate = date(eventDate), # convert to date
         year = year(eventDate),      # extract year
         month = month(eventDate,     # extract month
                       label = TRUE))

birds_date |>
  select(scientificName, eventDate, year, month)
```

...and summarise using dplyr or janitor.

:::{.panel-tabset .nav-pills}
#### dplyr

```{r}
# by year
birds_date |>   
  group_by(year) |>
  count()
```

```{r}
# by month
birds_date |>
  group_by(month) |>
  count() |>
  arrange(-desc(month))
```

#### janitor

```{r}
# by year
birds_date |>
  tabyl(year) |>
  adorn_pct_formatting()
```

```{r}
# by month
birds_date |>
  tabyl(month) |>
  arrange(desc(month))
```

:::


#### Line plots

Another way to summarise temporal data is using line plots to visualise trends at different time scales over one or more years.

There are a few records that seem to be from 2021 despite downloading data for 2022[^timezones]. For simplicity, we'll filter them out.  

[^timezones]: This is due to timezone conversion when the ALA standardises its data. There are several timezones across Australia, so although these points might have been in 2022, once converted they fell outside of 2022!

```{r}
# filter dataset to 2022 only
birds_day <- birds_date |>
  filter(year(eventDate) == 2022) |>
  mutate(
    day = yday(eventDate))
```


Now we can group our records by each day of the year, and summarise the record count for each day... 

```{r}
birds_day <- birds_day |>
  group_by(day) |>
  summarise(count = n()) 
birds_day
```

...which we can visualise as a line plot. There are huge fluctuations in our daily count data (from near zero to nearly 1000 observations), so to make the plot easier to read, we can use a `log10` scale.

```{r}
#| fig-cap: "Number of observations per day (2022)"
ggplot(birds_day, aes(x = day, y = count)) +
  geom_line() +  # Add lines
  geom_point() + # Add points
  labs(x = "Day", y = "Count (log10)") +
  scale_x_continuous(breaks = seq(1, 365, by = 30)) +
  scale_y_log10() +  # Set logarithmic scale for y-axis
  theme_minimal()  # Set a minimal theme
```

The same method above can be used to group record counts by week[^logscale]. 

[^logscale]: Notice, though, that we've ommitted the log scale because grouping by week has less variation in counts than by day (above).

```{r}
#| code-fold: true
#| fig-cap: "Number of observations per week (2022)"
birds_week <- birds_date |>
  filter(year(eventDate) == 2022) |>
  mutate(
    week = week(eventDate)) |>
  group_by(week) |>
  summarise(count = n()) 

ggplot(birds_week, aes(x = week, y = count)) +
  geom_line() +  # Add lines
  geom_point() + # Add points
  labs(x = "Week", y = "Count") +
  scale_x_continuous(breaks = seq(1, 52, by = 4)) + 
  # scale_y_log10() +  # Set logarithmic scale for y-axis
  theme_minimal()  # Set a minimal theme
```

Our temporal plots show that occurrences generally drop in the earlier months, then inflate in the later months of the year.

## Summary

In this chapter we have provided a few ways to summarise your data taxonomically, spatially and temporally. We hope that you can copy these code chunks and use them to summarise your own data. Summarising and visualising data is one of the most useful ways to spot errors for data cleaning. As such, we suggest using these tools often over your entire analysis.

In the next part of this book, we will tackle these issues to clean your dataset.