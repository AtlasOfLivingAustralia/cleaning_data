---
output: html_document
editor: source
editor_options: 
  chunk_output_type: console
bibliography: references.bib 
csl: methods-in-ecology-and-evolution.csl
---

# Introduction 

> "Garbage in, garbage out" 

The idea of flawed or sub-par input data produces nonsensical output is one that is well known in many scientific disciplines. In biodiversity research, scientists often have to collate large amounts of open access data from various sources  to address their research question. This can be challenging as the quality of data can vary depending on the data provider. 

Data cleaning is therefore an essential step in biodiversity research. The process of identifying and fixing incorrect or doubtful data can improve data quality and the validity of scientific findings. [@rodrigues_species_2022].

Here, we will guide you through how to acquire and clean open access biodiversity data in R. 

## What you will learn

```{r}
# new diagram here
library(DiagrammeR)

```
Import data 
Tidy and familiarise 
Investigate taxonomy
Investigate spatial data
Investigate duplicates
Investigate outliers

### Outline of the book

The major cleaning steps will focus on taxonomic and spatial issues.

In the following chapters, we will take a deep dive into the different data cleaning steps. We'll start with how to download open source biodiversity data. One you have your data we'll go through the importance of standardizing taxonomy and suggestions of how to do this, followed by investigating spatial errors. We will then discuss the issue of duplicates in open source data, and lastly outliers.

## What you won't learn

- How to clean other data types e.g. environmental or trait data
- How to run a species distribution model
- Hypothesis testing

## Prerequisites

We will be working with point-based species occurrence data from online infrastructures such as [Global Biodiversity Information Facility](https://www.gbif.org/) (GBIF) and the [Atlas of Living Australia](https://www.ala.org.au/) (ALA). If you have occurrence data you have personally collected, some parts of this book may still be relevant.

### User accounts

Getting a galah account, galah config

### R

Install 

### RStudio

Install







## Notes 

and resources on important steps to take to improve the quality of the data you're working with. Some steps are crucial and others may be considered less so, there will always be a point of 'diminishing returns' in data cleaning where it's important to stop, and assess your goals for this data, before the process becomes too much of a time sink.

note to add a "checklist of data standardization" section, downloadable checklist of issues to be checked
