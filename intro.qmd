---
output: 
  html_document
editor: 
  markdown: 
    wrap: 72
editor_options: 
  chunk_output_type: console
bibliography: references.bib 
csl: methods-in-ecology-and-evolution.csl
code-annotations: hover
df-print: kable
---

# Introduction {.unnumbered}

<!-- In ecology and biology, researchers, managers and decision makers often
want to answer questions about where species live, what
biological and environmental factors affect their survival and success,
and how these factors might affect their future survival. These questions are 
difficult but essential to answer for conservation and ecosystem management. 

To address these questions, many ecologists must combine large amounts
of species data from different sources for analysis. These data usually
vary in structure, formatting, and quality because each data source
might structure their data a little differently to the next. Merging
them correctly can be challenging and time consuming. Formatting errors,
spelling errors, taxonomic inconsistencies and spatial errors are some
of the most common problems, but the ecologist must fix these errors
before the data can be analysed.

There is, however, no ‘one-size-fits-all’ approach to cleaning
ecological data. What is considered a "clean" dataset varies depending
on the project and the data sources. Yet there are some common processes
and concepts that can be applied to many data cleaning workflows. This
book aims to offer these processes and concepts in one place.

Many ecologists and researchers choose to use code for data wrangling,
analysis and visualisation. There are many languages (e.g., Python, R,
Julia) that can achieve the same result. This book is a resource to
assist researchers and decision makers that wish to clean geo-referenced
biodiversity data using R.-->  

Data cleaning is a process that biologists and ecologists invariably have to 
engage with before they can answer questions using data. Depending on the sources
of the data, it may be necessary to standardise formats, correct spelling errors,
and resolve taxonomic inconsistency and spatial **[SMTH]** before these data can 
be analysed. The "correct" degree of data cleaning will depend on the project and
the questions being asked of the data, so there is no one-size-fits-all approach. 
There are, however, some common processes that will be broadly applicable to 
many data cleaning workflows. This book consolidates those processes into a resource 
for users who are interested in understanding how to clean their datasets.   

## Who is this book for? {.unnumbered}

If you are new to working with georeferenced biodiversity data in R, or are looking
for a quick reference to data cleaning processes or concepts in R, then
this book is for you. By learning how to download and apply common data
cleaning steps, you will also develop a better understanding of
biodiversity data, and common issues to be aware of.

## What this book covers {.unnumbered}

In this book, we provide an overview of a typical data cleaning workflow
for open-access geo-referenced biodiversity data—from
acquisition, to error identification, to correction. These processes are broken 
down into four sections. The chapters within each
section include practical guidelines, example R code, and additional
resources that may aid with each data cleaning step. 

The first section is about **accessing data**. [summary]

The second section is about **exploring data**. [summary]

The third section is about **general data cleaning processes**. [summary]

The fourth section is about **data cleaning processes that require expertise in your study species**. [summary]


## What we don't cover {.unnumbered}

The areas of research and uses of biodiversity data are many and varied.
Here we have focused on just one facet - downloading and cleaning
georeferenced occurrence / biodiversity data. As such, this book will
not cover:

-   Hypothesis testing or experimental design
-   How to clean environmental data that is not occurrence /
    biodiversity data (e.g. trait data)
-   How to perform analyses (e.g. species distribution modelling)

## Requirements {.unnumbered}

### User accounts

We will be working with point-based species occurrence data retrieved
from online infrastructures such as [Global Biodiversity Information
Facility](https://www.gbif.org/) (GBIF) and the [Atlas of Living
Australia](https://www.ala.org.au/) (ALA). To retrieve data from these
services, you will need to create a user account, if you do not already
have one:

-   [Register account: Atlas of Living Australia](https://auth.ala.org.au/userdetails/registration/createAccount)
-   [Register account: Global Biodiversity Information Facility](https://www.gbif.org/user/profile)

### R

To get the most out of this book, a basic knowledge of using R and
RStudio is recommended. We use R because it is commonly used across ecological 
projects and has a rich ecosystem of packages for data cleaning and visualisation.
If you are new to R or need a refresher, there are many amazing and freely available resources available online. [Data Analysis and Visualisation in R for
Ecologists](https://datacarpentry.org/R-ecology-lesson/) and [R for
Data Science](https://r4ds.had.co.nz/index.html) are both excellent
starting points.

Download R from [CRAN](https://cloud.r-project.org/), selecting the
version that matches your operating system, and install it on your
device.

### RStudio

RStudio is an integrated development environment (IDE) for R
programming. RStudio provides a range of tools to make working with R
easier, and you can download and install RStudio for your operating
system [here](https://posit.co/download/rstudio-desktop/).  
**Should we offer a list of other IDEs that also work for R?**  

### Packages

We use a range of R packages throughout the book, primarily for data
cleaning and visualisation. These packages will be noted at the
beginning of a code block, typically at the start of a chapter. To
access biodiversity data we will be working with the
[`galah`](https://galah.ala.org.au/) package. If you have collected your
own occurrence data, you should still find this book useful.

A list of the most common packages in this book can be found on the [Packages page](packages.html).

## Conventions {.unnumbered}

### Code blocks

Demonstrations and instructions throughout this book are accompanied by
code blocks. These blocks show how a particular task was executed in R:

``` {r}
#| eval: false
# This is a code block with a comment
library(package-name)

mtcars |>
   dplyr::group_by(cyl) |>
   dplyr::summarise(mean_mpg = mean(mpg))
```

::: {.callout-tip appearance="simple"}
You can copy code by clicking the [clipboard icon] button in the top right corner of a
code block.
:::

### Code line comments

Some code blocks have circled numbers near the right edge of the code block. You can hover over these numbers to read additional context about that specific line of code.

```{r}
#| eval: false
mtcars |>
  dplyr::group_by(cyl) # <1>
```
1. This line of code groups `mtcars` data by each distinct value in the variable `cyl`

Throughout this book, we use “pipes” in our code (`|>`, or `%>%` from the `magrittr` package). Pipes allow you to chain multiple functions sequentially to an object or a dataset. Pipes can be read as saying “and then”.

For example, the code block above can be read as "Get data `mtcars`, **and then** group by `cyl`, **and then** summarise (setting `mean_mpg` to contain the mean of `mpg`)."

